I0321 11:36:54.899275      19 test_context.go:359] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-434046417
I0321 11:36:54.899932      19 e2e.go:224] Starting e2e run "a0052222-4bcd-11e9-9c6a-0a581900021b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1553168213 - Will randomize all specs
Will run 201 of 2161 specs

Mar 21 11:36:55.313: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 11:36:55.317: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 21 11:36:55.342: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 21 11:36:55.421: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 21 11:36:55.421: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar 21 11:36:55.421: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 21 11:36:55.451: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Mar 21 11:36:55.451: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Mar 21 11:36:55.451: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Mar 21 11:36:55.451: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Mar 21 11:36:55.451: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Mar 21 11:36:55.451: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar 21 11:36:55.451: INFO: e2e test version: v1.13.4
Mar 21 11:36:55.454: INFO: kube-apiserver version: v1.13.4
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:36:55.454: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
Mar 21 11:36:55.556: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 21 11:36:55.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:36:56.269: INFO: stderr: ""
Mar 21 11:36:56.269: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 21 11:36:56.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:36:56.454: INFO: stderr: ""
Mar 21 11:36:56.454: INFO: stdout: "update-demo-nautilus-ftx2b update-demo-nautilus-hxdld "
Mar 21 11:36:56.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:36:56.622: INFO: stderr: ""
Mar 21 11:36:56.622: INFO: stdout: ""
Mar 21 11:36:56.622: INFO: update-demo-nautilus-ftx2b is created but not running
Mar 21 11:37:01.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:01.814: INFO: stderr: ""
Mar 21 11:37:01.814: INFO: stdout: "update-demo-nautilus-ftx2b update-demo-nautilus-hxdld "
Mar 21 11:37:01.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:02.069: INFO: stderr: ""
Mar 21 11:37:02.069: INFO: stdout: "true"
Mar 21 11:37:02.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:02.273: INFO: stderr: ""
Mar 21 11:37:02.273: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 11:37:02.273: INFO: validating pod update-demo-nautilus-ftx2b
Mar 21 11:37:02.294: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 11:37:02.294: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 11:37:02.294: INFO: update-demo-nautilus-ftx2b is verified up and running
Mar 21 11:37:02.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-hxdld -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:02.485: INFO: stderr: ""
Mar 21 11:37:02.485: INFO: stdout: "true"
Mar 21 11:37:02.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-hxdld -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:02.659: INFO: stderr: ""
Mar 21 11:37:02.659: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 11:37:02.659: INFO: validating pod update-demo-nautilus-hxdld
Mar 21 11:37:02.669: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 11:37:02.669: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 11:37:02.669: INFO: update-demo-nautilus-hxdld is verified up and running
STEP: scaling down the replication controller
Mar 21 11:37:02.674: INFO: scanned /root for discovery docs: <nil>
Mar 21 11:37:02.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:03.909: INFO: stderr: ""
Mar 21 11:37:03.909: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 21 11:37:03.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:04.124: INFO: stderr: ""
Mar 21 11:37:04.124: INFO: stdout: "update-demo-nautilus-ftx2b update-demo-nautilus-hxdld "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 21 11:37:09.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:09.373: INFO: stderr: ""
Mar 21 11:37:09.373: INFO: stdout: "update-demo-nautilus-ftx2b update-demo-nautilus-hxdld "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 21 11:37:14.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:14.551: INFO: stderr: ""
Mar 21 11:37:14.551: INFO: stdout: "update-demo-nautilus-ftx2b "
Mar 21 11:37:14.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:14.719: INFO: stderr: ""
Mar 21 11:37:14.719: INFO: stdout: "true"
Mar 21 11:37:14.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:14.909: INFO: stderr: ""
Mar 21 11:37:14.909: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 11:37:14.909: INFO: validating pod update-demo-nautilus-ftx2b
Mar 21 11:37:14.920: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 11:37:14.920: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 11:37:14.920: INFO: update-demo-nautilus-ftx2b is verified up and running
STEP: scaling up the replication controller
Mar 21 11:37:14.922: INFO: scanned /root for discovery docs: <nil>
Mar 21 11:37:14.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:16.179: INFO: stderr: ""
Mar 21 11:37:16.179: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 21 11:37:16.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:16.381: INFO: stderr: ""
Mar 21 11:37:16.383: INFO: stdout: "update-demo-nautilus-ftx2b update-demo-nautilus-mqt5h "
Mar 21 11:37:16.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:16.598: INFO: stderr: ""
Mar 21 11:37:16.598: INFO: stdout: "true"
Mar 21 11:37:16.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:16.797: INFO: stderr: ""
Mar 21 11:37:16.797: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 11:37:16.797: INFO: validating pod update-demo-nautilus-ftx2b
Mar 21 11:37:16.802: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 11:37:16.802: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 11:37:16.802: INFO: update-demo-nautilus-ftx2b is verified up and running
Mar 21 11:37:16.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-mqt5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:16.994: INFO: stderr: ""
Mar 21 11:37:16.994: INFO: stdout: ""
Mar 21 11:37:16.994: INFO: update-demo-nautilus-mqt5h is created but not running
Mar 21 11:37:21.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:22.172: INFO: stderr: ""
Mar 21 11:37:22.172: INFO: stdout: "update-demo-nautilus-ftx2b update-demo-nautilus-mqt5h "
Mar 21 11:37:22.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:22.304: INFO: stderr: ""
Mar 21 11:37:22.304: INFO: stdout: "true"
Mar 21 11:37:22.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ftx2b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:22.428: INFO: stderr: ""
Mar 21 11:37:22.428: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 11:37:22.428: INFO: validating pod update-demo-nautilus-ftx2b
Mar 21 11:37:22.433: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 11:37:22.433: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 11:37:22.433: INFO: update-demo-nautilus-ftx2b is verified up and running
Mar 21 11:37:22.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-mqt5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:22.560: INFO: stderr: ""
Mar 21 11:37:22.562: INFO: stdout: "true"
Mar 21 11:37:22.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-mqt5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:22.701: INFO: stderr: ""
Mar 21 11:37:22.701: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 11:37:22.701: INFO: validating pod update-demo-nautilus-mqt5h
Mar 21 11:37:22.709: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 11:37:22.710: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 11:37:22.710: INFO: update-demo-nautilus-mqt5h is verified up and running
STEP: using delete to clean up resources
Mar 21 11:37:22.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:22.884: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 11:37:22.884: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 21 11:37:22.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-27kjg'
Mar 21 11:37:23.106: INFO: stderr: "No resources found.\n"
Mar 21 11:37:23.106: INFO: stdout: ""
Mar 21 11:37:23.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -l name=update-demo --namespace=e2e-tests-kubectl-27kjg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 21 11:37:23.245: INFO: stderr: ""
Mar 21 11:37:23.245: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:37:23.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-27kjg" for this suite.
Mar 21 11:37:45.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:37:45.323: INFO: namespace: e2e-tests-kubectl-27kjg, resource: bindings, ignored listing per whitelist
Mar 21 11:37:45.344: INFO: namespace e2e-tests-kubectl-27kjg deletion completed in 22.094706949s

• [SLOW TEST:49.890 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:37:45.344: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:37:45.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fm96j" for this suite.
Mar 21 11:37:51.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:37:51.458: INFO: namespace: e2e-tests-services-fm96j, resource: bindings, ignored listing per whitelist
Mar 21 11:37:51.510: INFO: namespace e2e-tests-services-fm96j deletion completed in 6.098187171s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.166 seconds]
[sig-network] Services
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:37:51.511: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 21 11:37:51.585: INFO: Waiting up to 5m0s for pod "pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-kbpb6" to be "success or failure"
Mar 21 11:37:51.589: INFO: Pod "pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.262841ms
Mar 21 11:37:53.593: INFO: Pod "pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007043784s
Mar 21 11:37:55.597: INFO: Pod "pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011100917s
STEP: Saw pod success
Mar 21 11:37:55.597: INFO: Pod "pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:37:55.599: INFO: Trying to get logs from node jaguar pod pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:37:55.629: INFO: Waiting for pod pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b to disappear
Mar 21 11:37:55.632: INFO: Pod pod-c28b5e5d-4bcd-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:37:55.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kbpb6" for this suite.
Mar 21 11:38:01.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:38:01.709: INFO: namespace: e2e-tests-emptydir-kbpb6, resource: bindings, ignored listing per whitelist
Mar 21 11:38:01.763: INFO: namespace e2e-tests-emptydir-kbpb6 deletion completed in 6.128285283s

• [SLOW TEST:10.253 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:38:01.764: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c8abc506-4bcd-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 11:38:01.869: INFO: Waiting up to 5m0s for pod "pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-zgxzm" to be "success or failure"
Mar 21 11:38:01.873: INFO: Pod "pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.388393ms
Mar 21 11:38:03.881: INFO: Pod "pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011967415s
Mar 21 11:38:05.886: INFO: Pod "pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016392526s
STEP: Saw pod success
Mar 21 11:38:05.886: INFO: Pod "pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:38:05.889: INFO: Trying to get logs from node antelope pod pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 11:38:05.922: INFO: Waiting for pod pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b to disappear
Mar 21 11:38:05.924: INFO: Pod pod-secrets-c8ac5e54-4bcd-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:38:05.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zgxzm" for this suite.
Mar 21 11:38:11.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:38:11.969: INFO: namespace: e2e-tests-secrets-zgxzm, resource: bindings, ignored listing per whitelist
Mar 21 11:38:12.062: INFO: namespace e2e-tests-secrets-zgxzm deletion completed in 6.134593207s

• [SLOW TEST:10.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:38:12.063: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 21 11:38:18.672: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cecdb206-4bcd-11e9-9c6a-0a581900021b"
Mar 21 11:38:18.673: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cecdb206-4bcd-11e9-9c6a-0a581900021b" in namespace "e2e-tests-pods-bssgm" to be "terminated due to deadline exceeded"
Mar 21 11:38:18.676: INFO: Pod "pod-update-activedeadlineseconds-cecdb206-4bcd-11e9-9c6a-0a581900021b": Phase="Running", Reason="", readiness=true. Elapsed: 3.074364ms
Mar 21 11:38:20.680: INFO: Pod "pod-update-activedeadlineseconds-cecdb206-4bcd-11e9-9c6a-0a581900021b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.007446474s
Mar 21 11:38:20.680: INFO: Pod "pod-update-activedeadlineseconds-cecdb206-4bcd-11e9-9c6a-0a581900021b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:38:20.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bssgm" for this suite.
Mar 21 11:38:26.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:38:26.759: INFO: namespace: e2e-tests-pods-bssgm, resource: bindings, ignored listing per whitelist
Mar 21 11:38:26.806: INFO: namespace e2e-tests-pods-bssgm deletion completed in 6.116316655s

• [SLOW TEST:14.743 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:38:26.807: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar 21 11:38:27.417: INFO: Waiting up to 5m0s for pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n" in namespace "e2e-tests-svcaccounts-m25cb" to be "success or failure"
Mar 21 11:38:27.421: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n": Phase="Pending", Reason="", readiness=false. Elapsed: 3.755124ms
Mar 21 11:38:29.424: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007316999s
Mar 21 11:38:31.428: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01101171s
STEP: Saw pod success
Mar 21 11:38:31.428: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n" satisfied condition "success or failure"
Mar 21 11:38:31.431: INFO: Trying to get logs from node wolf pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n container token-test: <nil>
STEP: delete the pod
Mar 21 11:38:31.459: INFO: Waiting for pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n to disappear
Mar 21 11:38:31.462: INFO: Pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-v8p7n no longer exists
STEP: Creating a pod to test consume service account root CA
Mar 21 11:38:31.466: INFO: Waiting up to 5m0s for pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr" in namespace "e2e-tests-svcaccounts-m25cb" to be "success or failure"
Mar 21 11:38:31.472: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr": Phase="Pending", Reason="", readiness=false. Elapsed: 5.915552ms
Mar 21 11:38:33.476: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00994682s
Mar 21 11:38:35.479: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013290814s
STEP: Saw pod success
Mar 21 11:38:35.479: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr" satisfied condition "success or failure"
Mar 21 11:38:35.482: INFO: Trying to get logs from node wolf pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr container root-ca-test: <nil>
STEP: delete the pod
Mar 21 11:38:35.509: INFO: Waiting for pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr to disappear
Mar 21 11:38:35.512: INFO: Pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-mfhwr no longer exists
STEP: Creating a pod to test consume service account namespace
Mar 21 11:38:35.516: INFO: Waiting up to 5m0s for pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-7qgkt" in namespace "e2e-tests-svcaccounts-m25cb" to be "success or failure"
Mar 21 11:38:35.520: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-7qgkt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.204247ms
Mar 21 11:38:37.525: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-7qgkt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009061124s
STEP: Saw pod success
Mar 21 11:38:37.525: INFO: Pod "pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-7qgkt" satisfied condition "success or failure"
Mar 21 11:38:37.529: INFO: Trying to get logs from node wolf pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-7qgkt container namespace-test: <nil>
STEP: delete the pod
Mar 21 11:38:37.548: INFO: Waiting for pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-7qgkt to disappear
Mar 21 11:38:37.550: INFO: Pod pod-service-account-d7e6a1ea-4bcd-11e9-9c6a-0a581900021b-7qgkt no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:38:37.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-m25cb" for this suite.
Mar 21 11:38:43.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:38:43.595: INFO: namespace: e2e-tests-svcaccounts-m25cb, resource: bindings, ignored listing per whitelist
Mar 21 11:38:43.651: INFO: namespace e2e-tests-svcaccounts-m25cb deletion completed in 6.09491803s

• [SLOW TEST:16.844 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:38:43.653: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar 21 11:38:43.731: INFO: Waiting up to 5m0s for pod "client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b" in namespace "e2e-tests-containers-r96vm" to be "success or failure"
Mar 21 11:38:43.734: INFO: Pod "client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.665725ms
Mar 21 11:38:45.738: INFO: Pod "client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006537329s
Mar 21 11:38:47.741: INFO: Pod "client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010365565s
STEP: Saw pod success
Mar 21 11:38:47.741: INFO: Pod "client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:38:47.745: INFO: Trying to get logs from node antelope pod client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:38:47.764: INFO: Waiting for pod client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b to disappear
Mar 21 11:38:47.766: INFO: Pod client-containers-e1a015b3-4bcd-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:38:47.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-r96vm" for this suite.
Mar 21 11:38:53.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:38:53.788: INFO: namespace: e2e-tests-containers-r96vm, resource: bindings, ignored listing per whitelist
Mar 21 11:38:53.874: INFO: namespace e2e-tests-containers-r96vm deletion completed in 6.104262111s

• [SLOW TEST:10.221 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:38:53.875: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 21 11:39:02.005: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:02.010: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:04.011: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:04.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:06.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:06.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:08.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:08.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:10.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:10.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:12.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:12.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:14.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:14.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:16.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:16.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:18.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:18.014: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 21 11:39:20.010: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 21 11:39:20.014: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:39:20.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4bjpr" for this suite.
Mar 21 11:39:42.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:39:42.060: INFO: namespace: e2e-tests-container-lifecycle-hook-4bjpr, resource: bindings, ignored listing per whitelist
Mar 21 11:39:42.120: INFO: namespace e2e-tests-container-lifecycle-hook-4bjpr deletion completed in 22.093788258s

• [SLOW TEST:48.245 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:39:42.120: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar 21 11:39:48.215: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:39:48.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bkdzz" for this suite.
Mar 21 11:39:54.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:39:54.254: INFO: namespace: e2e-tests-gc-bkdzz, resource: bindings, ignored listing per whitelist
Mar 21 11:39:54.320: INFO: namespace e2e-tests-gc-bkdzz deletion completed in 6.100752092s

• [SLOW TEST:12.199 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:39:54.321: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 21 11:39:58.924: INFO: Successfully updated pod "annotationupdate0bbe5c53-4bce-11e9-9c6a-0a581900021b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:40:00.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ldh6b" for this suite.
Mar 21 11:40:22.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:40:23.041: INFO: namespace: e2e-tests-downward-api-ldh6b, resource: bindings, ignored listing per whitelist
Mar 21 11:40:23.041: INFO: namespace e2e-tests-downward-api-ldh6b deletion completed in 22.09355927s

• [SLOW TEST:28.720 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:40:23.041: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar 21 11:40:23.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 --namespace=e2e-tests-kubectl-mrggk run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 21 11:40:27.260: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 21 11:40:27.260: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:40:29.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mrggk" for this suite.
Mar 21 11:40:41.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:40:41.381: INFO: namespace: e2e-tests-kubectl-mrggk, resource: bindings, ignored listing per whitelist
Mar 21 11:40:41.386: INFO: namespace e2e-tests-kubectl-mrggk deletion completed in 12.116301416s

• [SLOW TEST:18.345 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:40:41.386: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 11:40:41.486: INFO: Waiting up to 5m0s for pod "downwardapi-volume-27d01bea-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-7kgbr" to be "success or failure"
Mar 21 11:40:41.491: INFO: Pod "downwardapi-volume-27d01bea-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.751791ms
Mar 21 11:40:43.495: INFO: Pod "downwardapi-volume-27d01bea-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008645623s
STEP: Saw pod success
Mar 21 11:40:43.495: INFO: Pod "downwardapi-volume-27d01bea-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:40:43.498: INFO: Trying to get logs from node wolf pod downwardapi-volume-27d01bea-4bce-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 11:40:43.515: INFO: Waiting for pod downwardapi-volume-27d01bea-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:40:43.517: INFO: Pod downwardapi-volume-27d01bea-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:40:43.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7kgbr" for this suite.
Mar 21 11:40:49.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:40:49.609: INFO: namespace: e2e-tests-downward-api-7kgbr, resource: bindings, ignored listing per whitelist
Mar 21 11:40:49.652: INFO: namespace e2e-tests-downward-api-7kgbr deletion completed in 6.131434488s

• [SLOW TEST:8.266 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:40:49.653: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 21 11:40:49.720: INFO: Waiting up to 5m0s for pod "pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-wkpgr" to be "success or failure"
Mar 21 11:40:49.724: INFO: Pod "pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.374285ms
Mar 21 11:40:51.727: INFO: Pod "pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006742947s
Mar 21 11:40:53.731: INFO: Pod "pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010042153s
STEP: Saw pod success
Mar 21 11:40:53.731: INFO: Pod "pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:40:53.733: INFO: Trying to get logs from node antelope pod pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:40:53.748: INFO: Waiting for pod pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:40:53.751: INFO: Pod pod-2cb89b9d-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:40:53.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wkpgr" for this suite.
Mar 21 11:40:59.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:40:59.806: INFO: namespace: e2e-tests-emptydir-wkpgr, resource: bindings, ignored listing per whitelist
Mar 21 11:40:59.848: INFO: namespace e2e-tests-emptydir-wkpgr deletion completed in 6.093993837s

• [SLOW TEST:10.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:40:59.849: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 11:40:59.919: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32ccb82d-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-9bxns" to be "success or failure"
Mar 21 11:40:59.922: INFO: Pod "downwardapi-volume-32ccb82d-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.58954ms
Mar 21 11:41:01.926: INFO: Pod "downwardapi-volume-32ccb82d-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007575416s
STEP: Saw pod success
Mar 21 11:41:01.926: INFO: Pod "downwardapi-volume-32ccb82d-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:41:01.930: INFO: Trying to get logs from node wolf pod downwardapi-volume-32ccb82d-4bce-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 11:41:01.948: INFO: Waiting for pod downwardapi-volume-32ccb82d-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:41:01.951: INFO: Pod downwardapi-volume-32ccb82d-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:41:01.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9bxns" for this suite.
Mar 21 11:41:07.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:41:08.025: INFO: namespace: e2e-tests-projected-9bxns, resource: bindings, ignored listing per whitelist
Mar 21 11:41:08.049: INFO: namespace e2e-tests-projected-9bxns deletion completed in 6.094309443s

• [SLOW TEST:8.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:41:08.049: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:42:08.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-txx5p" for this suite.
Mar 21 11:42:30.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:42:30.139: INFO: namespace: e2e-tests-container-probe-txx5p, resource: bindings, ignored listing per whitelist
Mar 21 11:42:30.204: INFO: namespace e2e-tests-container-probe-txx5p deletion completed in 22.082422024s

• [SLOW TEST:82.155 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:42:30.204: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar 21 11:42:32.280: INFO: Pod pod-hostip-68a7309c-4bce-11e9-9c6a-0a581900021b has hostIP: 178.128.168.147
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:42:32.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sgh6l" for this suite.
Mar 21 11:42:54.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:42:54.347: INFO: namespace: e2e-tests-pods-sgh6l, resource: bindings, ignored listing per whitelist
Mar 21 11:42:54.391: INFO: namespace e2e-tests-pods-sgh6l deletion completed in 22.107200137s

• [SLOW TEST:24.187 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:42:54.392: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar 21 11:42:56.490: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:43:20.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-dmppj" for this suite.
Mar 21 11:43:26.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:43:26.660: INFO: namespace: e2e-tests-namespaces-dmppj, resource: bindings, ignored listing per whitelist
Mar 21 11:43:26.690: INFO: namespace e2e-tests-namespaces-dmppj deletion completed in 6.10865419s
STEP: Destroying namespace "e2e-tests-nsdeletetest-dngj4" for this suite.
Mar 21 11:43:26.693: INFO: Namespace e2e-tests-nsdeletetest-dngj4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-x7cg8" for this suite.
Mar 21 11:43:32.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:43:32.720: INFO: namespace: e2e-tests-nsdeletetest-x7cg8, resource: bindings, ignored listing per whitelist
Mar 21 11:43:32.790: INFO: namespace e2e-tests-nsdeletetest-x7cg8 deletion completed in 6.097051616s

• [SLOW TEST:38.398 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:43:32.790: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 21 11:43:32.875: INFO: Waiting up to 5m0s for pod "pod-8df7d1ca-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-68rkr" to be "success or failure"
Mar 21 11:43:32.882: INFO: Pod "pod-8df7d1ca-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.192393ms
Mar 21 11:43:34.885: INFO: Pod "pod-8df7d1ca-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010652484s
STEP: Saw pod success
Mar 21 11:43:34.885: INFO: Pod "pod-8df7d1ca-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:43:34.888: INFO: Trying to get logs from node jaguar pod pod-8df7d1ca-4bce-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:43:34.905: INFO: Waiting for pod pod-8df7d1ca-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:43:34.907: INFO: Pod pod-8df7d1ca-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:43:34.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-68rkr" for this suite.
Mar 21 11:43:40.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:43:40.994: INFO: namespace: e2e-tests-emptydir-68rkr, resource: bindings, ignored listing per whitelist
Mar 21 11:43:41.012: INFO: namespace e2e-tests-emptydir-68rkr deletion completed in 6.100998854s

• [SLOW TEST:8.222 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:43:41.013: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-92e07762-4bce-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 11:43:41.142: INFO: Waiting up to 5m0s for pod "pod-secrets-92e53911-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-tqwm9" to be "success or failure"
Mar 21 11:43:41.144: INFO: Pod "pod-secrets-92e53911-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.632746ms
Mar 21 11:43:43.147: INFO: Pod "pod-secrets-92e53911-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005738502s
STEP: Saw pod success
Mar 21 11:43:43.148: INFO: Pod "pod-secrets-92e53911-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:43:43.150: INFO: Trying to get logs from node wolf pod pod-secrets-92e53911-4bce-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 11:43:43.167: INFO: Waiting for pod pod-secrets-92e53911-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:43:43.169: INFO: Pod pod-secrets-92e53911-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:43:43.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tqwm9" for this suite.
Mar 21 11:43:49.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:43:49.196: INFO: namespace: e2e-tests-secrets-tqwm9, resource: bindings, ignored listing per whitelist
Mar 21 11:43:49.278: INFO: namespace e2e-tests-secrets-tqwm9 deletion completed in 6.105477366s
STEP: Destroying namespace "e2e-tests-secret-namespace-g55jp" for this suite.
Mar 21 11:43:55.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:43:55.362: INFO: namespace: e2e-tests-secret-namespace-g55jp, resource: bindings, ignored listing per whitelist
Mar 21 11:43:55.373: INFO: namespace e2e-tests-secret-namespace-g55jp deletion completed in 6.094975251s

• [SLOW TEST:14.360 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:43:55.373: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar 21 11:44:05.548: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:44:05.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-km6nm" for this suite.
Mar 21 11:44:11.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:44:11.633: INFO: namespace: e2e-tests-gc-km6nm, resource: bindings, ignored listing per whitelist
Mar 21 11:44:11.646: INFO: namespace e2e-tests-gc-km6nm deletion completed in 6.094529288s

• [SLOW TEST:16.273 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:44:11.646: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 11:44:11.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a521a80c-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-snr7q" to be "success or failure"
Mar 21 11:44:11.740: INFO: Pod "downwardapi-volume-a521a80c-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.864193ms
Mar 21 11:44:13.749: INFO: Pod "downwardapi-volume-a521a80c-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012942452s
STEP: Saw pod success
Mar 21 11:44:13.750: INFO: Pod "downwardapi-volume-a521a80c-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:44:13.753: INFO: Trying to get logs from node antelope pod downwardapi-volume-a521a80c-4bce-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 11:44:13.772: INFO: Waiting for pod downwardapi-volume-a521a80c-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:44:13.774: INFO: Pod downwardapi-volume-a521a80c-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:44:13.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-snr7q" for this suite.
Mar 21 11:44:19.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:44:19.817: INFO: namespace: e2e-tests-projected-snr7q, resource: bindings, ignored listing per whitelist
Mar 21 11:44:19.877: INFO: namespace e2e-tests-projected-snr7q deletion completed in 6.094511548s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:44:19.878: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-aa05f9ea-4bce-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 11:44:19.946: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aa067484-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-h4m8v" to be "success or failure"
Mar 21 11:44:19.950: INFO: Pod "pod-projected-configmaps-aa067484-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.491419ms
Mar 21 11:44:21.954: INFO: Pod "pod-projected-configmaps-aa067484-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008158135s
STEP: Saw pod success
Mar 21 11:44:21.954: INFO: Pod "pod-projected-configmaps-aa067484-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:44:21.957: INFO: Trying to get logs from node antelope pod pod-projected-configmaps-aa067484-4bce-11e9-9c6a-0a581900021b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 11:44:21.976: INFO: Waiting for pod pod-projected-configmaps-aa067484-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:44:21.983: INFO: Pod pod-projected-configmaps-aa067484-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:44:21.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h4m8v" for this suite.
Mar 21 11:44:28.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:44:28.092: INFO: namespace: e2e-tests-projected-h4m8v, resource: bindings, ignored listing per whitelist
Mar 21 11:44:28.103: INFO: namespace e2e-tests-projected-h4m8v deletion completed in 6.116989574s

• [SLOW TEST:8.225 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:44:28.104: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 11:44:28.194: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:44:32.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7zdrk" for this suite.
Mar 21 11:45:16.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:45:16.597: INFO: namespace: e2e-tests-pods-7zdrk, resource: bindings, ignored listing per whitelist
Mar 21 11:45:16.635: INFO: namespace e2e-tests-pods-7zdrk deletion completed in 44.100872892s

• [SLOW TEST:48.531 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:45:16.637: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-cbe0069a-4bce-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 11:45:16.740: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-qq889" to be "success or failure"
Mar 21 11:45:16.744: INFO: Pod "pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.732405ms
Mar 21 11:45:18.747: INFO: Pod "pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007477322s
Mar 21 11:45:20.751: INFO: Pod "pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011424239s
STEP: Saw pod success
Mar 21 11:45:20.752: INFO: Pod "pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:45:20.754: INFO: Trying to get logs from node jaguar pod pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 21 11:45:20.772: INFO: Waiting for pod pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:45:20.774: INFO: Pod pod-projected-secrets-cbe08c67-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:45:20.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qq889" for this suite.
Mar 21 11:45:26.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:45:26.841: INFO: namespace: e2e-tests-projected-qq889, resource: bindings, ignored listing per whitelist
Mar 21 11:45:26.914: INFO: namespace e2e-tests-projected-qq889 deletion completed in 6.135946932s

• [SLOW TEST:10.277 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:45:26.914: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d1fdeee1-4bce-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 11:45:27.003: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d1fe76a8-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-r8b9q" to be "success or failure"
Mar 21 11:45:27.006: INFO: Pod "pod-projected-configmaps-d1fe76a8-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.916566ms
Mar 21 11:45:29.009: INFO: Pod "pod-projected-configmaps-d1fe76a8-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006441576s
STEP: Saw pod success
Mar 21 11:45:29.010: INFO: Pod "pod-projected-configmaps-d1fe76a8-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:45:29.014: INFO: Trying to get logs from node wolf pod pod-projected-configmaps-d1fe76a8-4bce-11e9-9c6a-0a581900021b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 11:45:29.030: INFO: Waiting for pod pod-projected-configmaps-d1fe76a8-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:45:29.032: INFO: Pod pod-projected-configmaps-d1fe76a8-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:45:29.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r8b9q" for this suite.
Mar 21 11:45:35.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:45:35.079: INFO: namespace: e2e-tests-projected-r8b9q, resource: bindings, ignored listing per whitelist
Mar 21 11:45:35.136: INFO: namespace e2e-tests-projected-r8b9q deletion completed in 6.100580117s

• [SLOW TEST:8.222 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:45:35.136: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 11:45:35.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6e25e78-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-xsj6w" to be "success or failure"
Mar 21 11:45:35.210: INFO: Pod "downwardapi-volume-d6e25e78-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.678298ms
Mar 21 11:45:37.213: INFO: Pod "downwardapi-volume-d6e25e78-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006503902s
STEP: Saw pod success
Mar 21 11:45:37.213: INFO: Pod "downwardapi-volume-d6e25e78-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:45:37.217: INFO: Trying to get logs from node jaguar pod downwardapi-volume-d6e25e78-4bce-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 11:45:37.237: INFO: Waiting for pod downwardapi-volume-d6e25e78-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:45:37.245: INFO: Pod downwardapi-volume-d6e25e78-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:45:37.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xsj6w" for this suite.
Mar 21 11:45:43.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:45:43.319: INFO: namespace: e2e-tests-projected-xsj6w, resource: bindings, ignored listing per whitelist
Mar 21 11:45:43.358: INFO: namespace e2e-tests-projected-xsj6w deletion completed in 6.107002463s

• [SLOW TEST:8.222 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:45:43.358: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-dbcbd204-4bce-11e9-9c6a-0a581900021b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-dbcbd204-4bce-11e9-9c6a-0a581900021b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:45:47.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n75cq" for this suite.
Mar 21 11:46:09.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:46:09.573: INFO: namespace: e2e-tests-projected-n75cq, resource: bindings, ignored listing per whitelist
Mar 21 11:46:09.596: INFO: namespace e2e-tests-projected-n75cq deletion completed in 22.09748468s

• [SLOW TEST:26.239 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:46:09.598: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-eb6bec7f-4bce-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 11:46:09.665: INFO: Waiting up to 5m0s for pod "pod-configmaps-eb6c6738-4bce-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-46p5m" to be "success or failure"
Mar 21 11:46:09.669: INFO: Pod "pod-configmaps-eb6c6738-4bce-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.295674ms
Mar 21 11:46:11.673: INFO: Pod "pod-configmaps-eb6c6738-4bce-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007115377s
STEP: Saw pod success
Mar 21 11:46:11.673: INFO: Pod "pod-configmaps-eb6c6738-4bce-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:46:11.676: INFO: Trying to get logs from node wolf pod pod-configmaps-eb6c6738-4bce-11e9-9c6a-0a581900021b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 11:46:11.693: INFO: Waiting for pod pod-configmaps-eb6c6738-4bce-11e9-9c6a-0a581900021b to disappear
Mar 21 11:46:11.695: INFO: Pod pod-configmaps-eb6c6738-4bce-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:46:11.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-46p5m" for this suite.
Mar 21 11:46:17.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:46:17.757: INFO: namespace: e2e-tests-configmap-46p5m, resource: bindings, ignored listing per whitelist
Mar 21 11:46:17.799: INFO: namespace e2e-tests-configmap-46p5m deletion completed in 6.099767925s

• [SLOW TEST:8.202 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:46:17.800: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 21 11:46:17.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-fvbnp'
Mar 21 11:46:18.145: INFO: stderr: ""
Mar 21 11:46:18.145: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 21 11:46:19.149: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 11:46:19.149: INFO: Found 0 / 1
Mar 21 11:46:20.149: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 11:46:20.149: INFO: Found 0 / 1
Mar 21 11:46:21.149: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 11:46:21.149: INFO: Found 0 / 1
Mar 21 11:46:22.149: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 11:46:22.149: INFO: Found 1 / 1
Mar 21 11:46:22.149: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 21 11:46:22.153: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 11:46:22.153: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 21 11:46:22.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 patch pod redis-master-4sgg8 --namespace=e2e-tests-kubectl-fvbnp -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 21 11:46:22.286: INFO: stderr: ""
Mar 21 11:46:22.286: INFO: stdout: "pod/redis-master-4sgg8 patched\n"
STEP: checking annotations
Mar 21 11:46:22.289: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 11:46:22.289: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:46:22.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fvbnp" for this suite.
Mar 21 11:46:44.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:46:44.357: INFO: namespace: e2e-tests-kubectl-fvbnp, resource: bindings, ignored listing per whitelist
Mar 21 11:46:44.382: INFO: namespace e2e-tests-kubectl-fvbnp deletion completed in 22.089070579s

• [SLOW TEST:26.582 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:46:44.383: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar 21 11:46:44.443: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-434046417 proxy --unix-socket=/tmp/kubectl-proxy-unix202464508/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:46:44.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-svn2s" for this suite.
Mar 21 11:46:50.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:46:50.632: INFO: namespace: e2e-tests-kubectl-svn2s, resource: bindings, ignored listing per whitelist
Mar 21 11:46:50.689: INFO: namespace e2e-tests-kubectl-svn2s deletion completed in 6.141179189s

• [SLOW TEST:6.306 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:46:50.692: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-c2nqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-c2nqq to expose endpoints map[]
Mar 21 11:46:50.780: INFO: Get endpoints failed (4.134502ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar 21 11:46:51.785: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-c2nqq exposes endpoints map[] (1.00913075s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-c2nqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-c2nqq to expose endpoints map[pod1:[80]]
Mar 21 11:46:54.869: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-c2nqq exposes endpoints map[pod1:[80]] (3.078721768s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-c2nqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-c2nqq to expose endpoints map[pod2:[80] pod1:[80]]
Mar 21 11:46:56.907: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-c2nqq exposes endpoints map[pod1:[80] pod2:[80]] (2.033917333s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-c2nqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-c2nqq to expose endpoints map[pod2:[80]]
Mar 21 11:46:57.945: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-c2nqq exposes endpoints map[pod2:[80]] (1.034724581s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-c2nqq
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-c2nqq to expose endpoints map[]
Mar 21 11:46:58.956: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-c2nqq exposes endpoints map[] (1.005547474s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:46:58.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-c2nqq" for this suite.
Mar 21 11:47:20.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:47:21.078: INFO: namespace: e2e-tests-services-c2nqq, resource: bindings, ignored listing per whitelist
Mar 21 11:47:21.078: INFO: namespace e2e-tests-services-c2nqq deletion completed in 22.102980944s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.386 seconds]
[sig-network] Services
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:47:21.078: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-16083237-4bcf-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 11:47:21.155: INFO: Waiting up to 5m0s for pod "pod-secrets-1608b4ea-4bcf-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-8r764" to be "success or failure"
Mar 21 11:47:21.157: INFO: Pod "pod-secrets-1608b4ea-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.753882ms
Mar 21 11:47:23.161: INFO: Pod "pod-secrets-1608b4ea-4bcf-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006532809s
STEP: Saw pod success
Mar 21 11:47:23.161: INFO: Pod "pod-secrets-1608b4ea-4bcf-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:47:23.164: INFO: Trying to get logs from node jaguar pod pod-secrets-1608b4ea-4bcf-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 11:47:23.181: INFO: Waiting for pod pod-secrets-1608b4ea-4bcf-11e9-9c6a-0a581900021b to disappear
Mar 21 11:47:23.183: INFO: Pod pod-secrets-1608b4ea-4bcf-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:47:23.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8r764" for this suite.
Mar 21 11:47:29.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:47:29.256: INFO: namespace: e2e-tests-secrets-8r764, resource: bindings, ignored listing per whitelist
Mar 21 11:47:29.293: INFO: namespace e2e-tests-secrets-8r764 deletion completed in 6.105689133s

• [SLOW TEST:8.214 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:47:29.294: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 11:47:29.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-5rqg2" to be "success or failure"
Mar 21 11:47:29.398: INFO: Pod "downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.516468ms
Mar 21 11:47:31.402: INFO: Pod "downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006227982s
Mar 21 11:47:33.406: INFO: Pod "downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010031129s
STEP: Saw pod success
Mar 21 11:47:33.406: INFO: Pod "downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:47:33.409: INFO: Trying to get logs from node jaguar pod downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 11:47:33.424: INFO: Waiting for pod downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b to disappear
Mar 21 11:47:33.427: INFO: Pod downwardapi-volume-1af235c8-4bcf-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:47:33.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5rqg2" for this suite.
Mar 21 11:47:39.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:47:39.499: INFO: namespace: e2e-tests-projected-5rqg2, resource: bindings, ignored listing per whitelist
Mar 21 11:47:39.531: INFO: namespace e2e-tests-projected-5rqg2 deletion completed in 6.099898875s

• [SLOW TEST:10.237 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:47:39.531: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 21 11:47:39.608: INFO: Waiting up to 5m0s for pod "pod-21086cee-4bcf-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-njvq9" to be "success or failure"
Mar 21 11:47:39.611: INFO: Pod "pod-21086cee-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.470389ms
Mar 21 11:47:41.615: INFO: Pod "pod-21086cee-4bcf-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00718546s
STEP: Saw pod success
Mar 21 11:47:41.615: INFO: Pod "pod-21086cee-4bcf-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:47:41.618: INFO: Trying to get logs from node antelope pod pod-21086cee-4bcf-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:47:41.634: INFO: Waiting for pod pod-21086cee-4bcf-11e9-9c6a-0a581900021b to disappear
Mar 21 11:47:41.636: INFO: Pod pod-21086cee-4bcf-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:47:41.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-njvq9" for this suite.
Mar 21 11:47:47.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:47:47.689: INFO: namespace: e2e-tests-emptydir-njvq9, resource: bindings, ignored listing per whitelist
Mar 21 11:47:47.752: INFO: namespace e2e-tests-emptydir-njvq9 deletion completed in 6.108540134s

• [SLOW TEST:8.222 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:47:47.753: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-czzhm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 21 11:47:47.827: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 21 11:48:17.903: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://25.0.2.49:8080/dial?request=hostName&protocol=udp&host=25.0.3.43&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-czzhm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 11:48:17.904: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 11:48:18.055: INFO: Waiting for endpoints: map[]
Mar 21 11:48:18.058: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://25.0.2.49:8080/dial?request=hostName&protocol=udp&host=25.0.2.48&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-czzhm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 11:48:18.058: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 11:48:18.181: INFO: Waiting for endpoints: map[]
Mar 21 11:48:18.188: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://25.0.2.49:8080/dial?request=hostName&protocol=udp&host=25.0.1.45&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-czzhm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 11:48:18.188: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 11:48:18.304: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:48:18.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-czzhm" for this suite.
Mar 21 11:48:40.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:48:40.354: INFO: namespace: e2e-tests-pod-network-test-czzhm, resource: bindings, ignored listing per whitelist
Mar 21 11:48:40.403: INFO: namespace e2e-tests-pod-network-test-czzhm deletion completed in 22.094709651s

• [SLOW TEST:52.650 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:48:40.405: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 21 11:48:40.484: INFO: Waiting up to 5m0s for pod "downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-mk485" to be "success or failure"
Mar 21 11:48:40.487: INFO: Pod "downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.893495ms
Mar 21 11:48:42.491: INFO: Pod "downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006402007s
Mar 21 11:48:44.495: INFO: Pod "downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010752994s
Mar 21 11:48:46.499: INFO: Pod "downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01468892s
STEP: Saw pod success
Mar 21 11:48:46.499: INFO: Pod "downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:48:46.502: INFO: Trying to get logs from node jaguar pod downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 11:48:46.521: INFO: Waiting for pod downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b to disappear
Mar 21 11:48:46.523: INFO: Pod downward-api-45516a3c-4bcf-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:48:46.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mk485" for this suite.
Mar 21 11:48:52.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:48:52.573: INFO: namespace: e2e-tests-downward-api-mk485, resource: bindings, ignored listing per whitelist
Mar 21 11:48:52.618: INFO: namespace e2e-tests-downward-api-mk485 deletion completed in 6.090379993s

• [SLOW TEST:12.213 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:48:52.619: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 21 11:48:52.720: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mlfsq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mlfsq/configmaps/e2e-watch-test-label-changed,UID:4c9a578d-4bcf-11e9-8b3c-9eae6a3150d7,ResourceVersion:12641,Generation:0,CreationTimestamp:2019-03-21 11:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 21 11:48:52.721: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mlfsq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mlfsq/configmaps/e2e-watch-test-label-changed,UID:4c9a578d-4bcf-11e9-8b3c-9eae6a3150d7,ResourceVersion:12642,Generation:0,CreationTimestamp:2019-03-21 11:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 21 11:48:52.721: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mlfsq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mlfsq/configmaps/e2e-watch-test-label-changed,UID:4c9a578d-4bcf-11e9-8b3c-9eae6a3150d7,ResourceVersion:12643,Generation:0,CreationTimestamp:2019-03-21 11:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 21 11:49:02.746: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mlfsq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mlfsq/configmaps/e2e-watch-test-label-changed,UID:4c9a578d-4bcf-11e9-8b3c-9eae6a3150d7,ResourceVersion:12661,Generation:0,CreationTimestamp:2019-03-21 11:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 21 11:49:02.746: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mlfsq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mlfsq/configmaps/e2e-watch-test-label-changed,UID:4c9a578d-4bcf-11e9-8b3c-9eae6a3150d7,ResourceVersion:12662,Generation:0,CreationTimestamp:2019-03-21 11:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 21 11:49:02.746: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mlfsq,SelfLink:/api/v1/namespaces/e2e-tests-watch-mlfsq/configmaps/e2e-watch-test-label-changed,UID:4c9a578d-4bcf-11e9-8b3c-9eae6a3150d7,ResourceVersion:12663,Generation:0,CreationTimestamp:2019-03-21 11:48:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:49:02.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mlfsq" for this suite.
Mar 21 11:49:08.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:49:08.857: INFO: namespace: e2e-tests-watch-mlfsq, resource: bindings, ignored listing per whitelist
Mar 21 11:49:08.874: INFO: namespace e2e-tests-watch-mlfsq deletion completed in 6.123863031s

• [SLOW TEST:16.255 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:49:08.874: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:49:12.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-pfw6z" for this suite.
Mar 21 11:49:18.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:49:19.049: INFO: namespace: e2e-tests-kubelet-test-pfw6z, resource: bindings, ignored listing per whitelist
Mar 21 11:49:19.074: INFO: namespace e2e-tests-kubelet-test-pfw6z deletion completed in 6.121531275s

• [SLOW TEST:10.200 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:49:19.075: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qqxgx
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar 21 11:49:19.177: INFO: Found 0 stateful pods, waiting for 3
Mar 21 11:49:29.182: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 11:49:29.182: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 11:49:29.182: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 21 11:49:29.208: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 21 11:49:39.240: INFO: Updating stateful set ss2
Mar 21 11:49:39.247: INFO: Waiting for Pod e2e-tests-statefulset-qqxgx/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 11:49:49.257: INFO: Waiting for Pod e2e-tests-statefulset-qqxgx/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar 21 11:49:59.288: INFO: Found 2 stateful pods, waiting for 3
Mar 21 11:50:09.293: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 11:50:09.293: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 11:50:09.293: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 21 11:50:09.322: INFO: Updating stateful set ss2
Mar 21 11:50:09.330: INFO: Waiting for Pod e2e-tests-statefulset-qqxgx/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 11:50:19.350: INFO: Waiting for Pod e2e-tests-statefulset-qqxgx/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 11:50:29.358: INFO: Updating stateful set ss2
Mar 21 11:50:29.366: INFO: Waiting for StatefulSet e2e-tests-statefulset-qqxgx/ss2 to complete update
Mar 21 11:50:29.366: INFO: Waiting for Pod e2e-tests-statefulset-qqxgx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 11:50:39.373: INFO: Waiting for StatefulSet e2e-tests-statefulset-qqxgx/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 21 11:50:49.373: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qqxgx
Mar 21 11:50:49.376: INFO: Scaling statefulset ss2 to 0
Mar 21 11:50:59.391: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 11:50:59.393: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:50:59.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qqxgx" for this suite.
Mar 21 11:51:05.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:51:05.441: INFO: namespace: e2e-tests-statefulset-qqxgx, resource: bindings, ignored listing per whitelist
Mar 21 11:51:05.532: INFO: namespace e2e-tests-statefulset-qqxgx deletion completed in 6.121618023s

• [SLOW TEST:106.457 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:51:05.533: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar 21 11:51:05.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 api-versions'
Mar 21 11:51:05.787: INFO: stderr: ""
Mar 21 11:51:05.787: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:51:05.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hntqb" for this suite.
Mar 21 11:51:11.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:51:11.834: INFO: namespace: e2e-tests-kubectl-hntqb, resource: bindings, ignored listing per whitelist
Mar 21 11:51:11.913: INFO: namespace e2e-tests-kubectl-hntqb deletion completed in 6.121206638s

• [SLOW TEST:6.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:51:11.913: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar 21 11:51:12.512: INFO: created pod pod-service-account-defaultsa
Mar 21 11:51:12.513: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 21 11:51:12.518: INFO: created pod pod-service-account-mountsa
Mar 21 11:51:12.518: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 21 11:51:12.526: INFO: created pod pod-service-account-nomountsa
Mar 21 11:51:12.526: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 21 11:51:12.531: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 21 11:51:12.531: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 21 11:51:12.534: INFO: created pod pod-service-account-mountsa-mountspec
Mar 21 11:51:12.534: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 21 11:51:12.538: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 21 11:51:12.538: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 21 11:51:12.544: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 21 11:51:12.544: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 21 11:51:12.551: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 21 11:51:12.551: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 21 11:51:12.568: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 21 11:51:12.568: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:51:12.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-7gpgs" for this suite.
Mar 21 11:51:18.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:51:18.599: INFO: namespace: e2e-tests-svcaccounts-7gpgs, resource: bindings, ignored listing per whitelist
Mar 21 11:51:18.681: INFO: namespace e2e-tests-svcaccounts-7gpgs deletion completed in 6.100510562s

• [SLOW TEST:6.767 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:51:18.681: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 21 11:51:18.755: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 21 11:51:18.762: INFO: Waiting for terminating namespaces to be deleted...
Mar 21 11:51:18.772: INFO: 
Logging pods the kubelet thinks is on node antelope before test
Mar 21 11:51:18.781: INFO: kube-proxy-9hr7b from kube-system started at 2019-03-21 10:15:53 +0000 UTC (1 container statuses recorded)
Mar 21 11:51:18.781: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 11:51:18.781: INFO: kube-flannel-ds-amd64-rqwz5 from kube-system started at 2019-03-21 10:15:53 +0000 UTC (1 container statuses recorded)
Mar 21 11:51:18.781: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 11:51:18.781: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdl77 from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 11:51:18.781: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 21 11:51:18.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 11:51:18.781: INFO: sonobuoy-e2e-job-0facb6ec3f244997 from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 11:51:18.781: INFO: 	Container e2e ready: true, restart count 0
Mar 21 11:51:18.781: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 11:51:18.781: INFO: 
Logging pods the kubelet thinks is on node jaguar before test
Mar 21 11:51:18.789: INFO: kube-flannel-ds-amd64-qw9mb from kube-system started at 2019-03-21 10:15:55 +0000 UTC (1 container statuses recorded)
Mar 21 11:51:18.789: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 11:51:18.789: INFO: kube-proxy-h2wk8 from kube-system started at 2019-03-21 10:15:55 +0000 UTC (1 container statuses recorded)
Mar 21 11:51:18.789: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 11:51:18.789: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-21 11:36:19 +0000 UTC (1 container statuses recorded)
Mar 21 11:51:18.789: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 21 11:51:18.789: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-cxr4t from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 11:51:18.789: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 21 11:51:18.789: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 11:51:18.789: INFO: 
Logging pods the kubelet thinks is on node wolf before test
Mar 21 11:51:18.802: INFO: kube-flannel-ds-amd64-b427k from kube-system started at 2019-03-21 10:15:51 +0000 UTC (1 container statuses recorded)
Mar 21 11:51:18.802: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 11:51:18.802: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdpng from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 11:51:18.802: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 21 11:51:18.802: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 11:51:18.802: INFO: kube-proxy-k5xgj from kube-system started at 2019-03-21 10:15:51 +0000 UTC (1 container statuses recorded)
Mar 21 11:51:18.802: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node antelope
STEP: verifying the node has the label node jaguar
STEP: verifying the node has the label node wolf
Mar 21 11:51:18.853: INFO: Pod sonobuoy requesting resource cpu=0m on Node jaguar
Mar 21 11:51:18.853: INFO: Pod sonobuoy-e2e-job-0facb6ec3f244997 requesting resource cpu=0m on Node antelope
Mar 21 11:51:18.853: INFO: Pod sonobuoy-systemd-logs-daemon-set-aad7590584424748-cxr4t requesting resource cpu=0m on Node jaguar
Mar 21 11:51:18.853: INFO: Pod sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdl77 requesting resource cpu=0m on Node antelope
Mar 21 11:51:18.853: INFO: Pod sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdpng requesting resource cpu=0m on Node wolf
Mar 21 11:51:18.853: INFO: Pod kube-flannel-ds-amd64-b427k requesting resource cpu=100m on Node wolf
Mar 21 11:51:18.853: INFO: Pod kube-flannel-ds-amd64-qw9mb requesting resource cpu=100m on Node jaguar
Mar 21 11:51:18.853: INFO: Pod kube-flannel-ds-amd64-rqwz5 requesting resource cpu=100m on Node antelope
Mar 21 11:51:18.853: INFO: Pod kube-proxy-9hr7b requesting resource cpu=0m on Node antelope
Mar 21 11:51:18.853: INFO: Pod kube-proxy-h2wk8 requesting resource cpu=0m on Node jaguar
Mar 21 11:51:18.853: INFO: Pod kube-proxy-k5xgj requesting resource cpu=0m on Node wolf
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b77daf-4bcf-11e9-9c6a-0a581900021b.158df70c55ce67bc], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-65g9z/filler-pod-a3b77daf-4bcf-11e9-9c6a-0a581900021b to antelope]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b77daf-4bcf-11e9-9c6a-0a581900021b.158df70c88c907bc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b77daf-4bcf-11e9-9c6a-0a581900021b.158df70c8bd9df17], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b77daf-4bcf-11e9-9c6a-0a581900021b.158df70c9b80812a], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b8741c-4bcf-11e9-9c6a-0a581900021b.158df70c56201c15], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-65g9z/filler-pod-a3b8741c-4bcf-11e9-9c6a-0a581900021b to jaguar]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b8741c-4bcf-11e9-9c6a-0a581900021b.158df70c8b307e6e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b8741c-4bcf-11e9-9c6a-0a581900021b.158df70c8e9dc5b5], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b8741c-4bcf-11e9-9c6a-0a581900021b.158df70c9bdb8983], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b94ab1-4bcf-11e9-9c6a-0a581900021b.158df70c568a607a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-65g9z/filler-pod-a3b94ab1-4bcf-11e9-9c6a-0a581900021b to wolf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b94ab1-4bcf-11e9-9c6a-0a581900021b.158df70c812e8dc1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b94ab1-4bcf-11e9-9c6a-0a581900021b.158df70c85880b1a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a3b94ab1-4bcf-11e9-9c6a-0a581900021b.158df70c9167ae82], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.158df70ccee47703], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node antelope
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node jaguar
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node wolf
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:51:22.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-65g9z" for this suite.
Mar 21 11:51:28.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:51:28.198: INFO: namespace: e2e-tests-sched-pred-65g9z, resource: bindings, ignored listing per whitelist
Mar 21 11:51:28.215: INFO: namespace e2e-tests-sched-pred-65g9z deletion completed in 6.179861309s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.534 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:51:28.216: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 21 11:51:28.332: INFO: Waiting up to 5m0s for pod "pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-lgk6w" to be "success or failure"
Mar 21 11:51:28.334: INFO: Pod "pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.648629ms
Mar 21 11:51:30.338: INFO: Pod "pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006388026s
Mar 21 11:51:32.343: INFO: Pod "pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011616703s
STEP: Saw pod success
Mar 21 11:51:32.343: INFO: Pod "pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:51:32.346: INFO: Trying to get logs from node antelope pod pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:51:32.364: INFO: Waiting for pod pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b to disappear
Mar 21 11:51:32.378: INFO: Pod pod-a95cddd0-4bcf-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:51:32.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lgk6w" for this suite.
Mar 21 11:51:38.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:51:38.498: INFO: namespace: e2e-tests-emptydir-lgk6w, resource: bindings, ignored listing per whitelist
Mar 21 11:51:38.515: INFO: namespace e2e-tests-emptydir-lgk6w deletion completed in 6.130421477s

• [SLOW TEST:10.300 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:51:38.516: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-af7aeb8d-4bcf-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 11:51:38.599: INFO: Waiting up to 5m0s for pod "pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-cffwj" to be "success or failure"
Mar 21 11:51:38.603: INFO: Pod "pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095833ms
Mar 21 11:51:40.607: INFO: Pod "pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007883652s
Mar 21 11:51:42.611: INFO: Pod "pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011529191s
STEP: Saw pod success
Mar 21 11:51:42.611: INFO: Pod "pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:51:42.614: INFO: Trying to get logs from node antelope pod pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 11:51:42.630: INFO: Waiting for pod pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b to disappear
Mar 21 11:51:42.632: INFO: Pod pod-configmaps-af7b9fbe-4bcf-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:51:42.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cffwj" for this suite.
Mar 21 11:51:48.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:51:48.686: INFO: namespace: e2e-tests-configmap-cffwj, resource: bindings, ignored listing per whitelist
Mar 21 11:51:48.741: INFO: namespace e2e-tests-configmap-cffwj deletion completed in 6.104157999s

• [SLOW TEST:10.225 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:51:48.742: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Mar 21 11:51:58.847: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:51:58.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jkrxn" for this suite.
Mar 21 11:52:04.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:52:04.885: INFO: namespace: e2e-tests-gc-jkrxn, resource: bindings, ignored listing per whitelist
Mar 21 11:52:04.960: INFO: namespace e2e-tests-gc-jkrxn deletion completed in 6.10956331s

• [SLOW TEST:16.219 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:52:04.961: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zf9nb
Mar 21 11:52:07.066: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zf9nb
STEP: checking the pod's current state and verifying that restartCount is present
Mar 21 11:52:07.069: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:56:07.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zf9nb" for this suite.
Mar 21 11:56:13.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:56:13.654: INFO: namespace: e2e-tests-container-probe-zf9nb, resource: bindings, ignored listing per whitelist
Mar 21 11:56:13.694: INFO: namespace e2e-tests-container-probe-zf9nb deletion completed in 6.09466106s

• [SLOW TEST:248.733 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:56:13.695: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 21 11:56:13.754: INFO: PodSpec: initContainers in spec.initContainers
Mar 21 11:56:59.938: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-537ddbe2-4bd0-11e9-9c6a-0a581900021b", GenerateName:"", Namespace:"e2e-tests-init-container-q2j68", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-q2j68/pods/pod-init-537ddbe2-4bd0-11e9-9c6a-0a581900021b", UID:"537e7882-4bd0-11e9-8b3c-9eae6a3150d7", ResourceVersion:"13998", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688766173, loc:(*time.Location)(0x7b4abe0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"754884365"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-ljzw8", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001996980), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ljzw8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ljzw8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ljzw8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001c603a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"wolf", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000fbad20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c60430)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c60450)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001c60458), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001c6045c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688766173, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688766173, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688766173, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688766173, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"104.248.170.89", PodIP:"25.0.1.54", StartTime:(*v1.Time)(0xc0015179a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ed25b0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ed2690)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://2d4ce6a2a53968475cbb15d71d4cb231ecfe0367e059a14424ede821ff54a880"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001517a00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0015179e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:56:59.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-q2j68" for this suite.
Mar 21 11:57:21.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:57:22.016: INFO: namespace: e2e-tests-init-container-q2j68, resource: bindings, ignored listing per whitelist
Mar 21 11:57:22.030: INFO: namespace e2e-tests-init-container-q2j68 deletion completed in 22.087704586s

• [SLOW TEST:68.336 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:57:22.032: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:57:22.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-kq58c" for this suite.
Mar 21 11:57:28.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:57:28.172: INFO: namespace: e2e-tests-kubelet-test-kq58c, resource: bindings, ignored listing per whitelist
Mar 21 11:57:28.216: INFO: namespace e2e-tests-kubelet-test-kq58c deletion completed in 6.092836103s

• [SLOW TEST:6.184 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:57:28.216: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7fe882d3-4bd0-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 11:57:28.283: INFO: Waiting up to 5m0s for pod "pod-configmaps-7fe90224-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-plm2g" to be "success or failure"
Mar 21 11:57:28.289: INFO: Pod "pod-configmaps-7fe90224-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009665ms
Mar 21 11:57:30.293: INFO: Pod "pod-configmaps-7fe90224-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009580736s
STEP: Saw pod success
Mar 21 11:57:30.293: INFO: Pod "pod-configmaps-7fe90224-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:57:30.296: INFO: Trying to get logs from node jaguar pod pod-configmaps-7fe90224-4bd0-11e9-9c6a-0a581900021b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 11:57:30.313: INFO: Waiting for pod pod-configmaps-7fe90224-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:57:30.316: INFO: Pod pod-configmaps-7fe90224-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:57:30.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-plm2g" for this suite.
Mar 21 11:57:36.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:57:36.361: INFO: namespace: e2e-tests-configmap-plm2g, resource: bindings, ignored listing per whitelist
Mar 21 11:57:36.415: INFO: namespace e2e-tests-configmap-plm2g deletion completed in 6.095821813s

• [SLOW TEST:8.199 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:57:36.415: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar 21 11:57:36.486: INFO: Waiting up to 5m0s for pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-var-expansion-9n8d9" to be "success or failure"
Mar 21 11:57:36.490: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.970514ms
Mar 21 11:57:38.500: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014925026s
Mar 21 11:57:40.504: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018354121s
Mar 21 11:57:42.507: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021695331s
Mar 21 11:57:44.510: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024799347s
Mar 21 11:57:46.514: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.028586943s
Mar 21 11:57:48.518: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.032534995s
STEP: Saw pod success
Mar 21 11:57:48.518: INFO: Pod "var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:57:48.521: INFO: Trying to get logs from node wolf pod var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 11:57:48.541: INFO: Waiting for pod var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:57:48.544: INFO: Pod var-expansion-84ccccbb-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:57:48.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9n8d9" for this suite.
Mar 21 11:57:54.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:57:54.636: INFO: namespace: e2e-tests-var-expansion-9n8d9, resource: bindings, ignored listing per whitelist
Mar 21 11:57:54.639: INFO: namespace e2e-tests-var-expansion-9n8d9 deletion completed in 6.090837449s

• [SLOW TEST:18.224 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:57:54.640: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 21 11:57:54.731: INFO: Waiting up to 5m0s for pod "downward-api-8fac9430-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-rsljx" to be "success or failure"
Mar 21 11:57:54.734: INFO: Pod "downward-api-8fac9430-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.704486ms
Mar 21 11:57:56.738: INFO: Pod "downward-api-8fac9430-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006503893s
STEP: Saw pod success
Mar 21 11:57:56.738: INFO: Pod "downward-api-8fac9430-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:57:56.741: INFO: Trying to get logs from node jaguar pod downward-api-8fac9430-4bd0-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 11:57:56.759: INFO: Waiting for pod downward-api-8fac9430-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:57:56.761: INFO: Pod downward-api-8fac9430-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:57:56.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rsljx" for this suite.
Mar 21 11:58:02.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:58:02.865: INFO: namespace: e2e-tests-downward-api-rsljx, resource: bindings, ignored listing per whitelist
Mar 21 11:58:02.900: INFO: namespace e2e-tests-downward-api-rsljx deletion completed in 6.134550454s

• [SLOW TEST:8.260 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:58:02.900: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-9499bbcb-4bd0-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 11:58:02.997: INFO: Waiting up to 5m0s for pod "pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-99vxn" to be "success or failure"
Mar 21 11:58:03.000: INFO: Pod "pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.680655ms
Mar 21 11:58:05.004: INFO: Pod "pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006458161s
Mar 21 11:58:07.008: INFO: Pod "pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010091817s
STEP: Saw pod success
Mar 21 11:58:07.008: INFO: Pod "pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:58:07.011: INFO: Trying to get logs from node wolf pod pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 11:58:07.030: INFO: Waiting for pod pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:58:07.033: INFO: Pod pod-secrets-949a3c75-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:58:07.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-99vxn" for this suite.
Mar 21 11:58:13.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:58:13.094: INFO: namespace: e2e-tests-secrets-99vxn, resource: bindings, ignored listing per whitelist
Mar 21 11:58:13.141: INFO: namespace e2e-tests-secrets-99vxn deletion completed in 6.104443562s

• [SLOW TEST:10.241 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:58:13.142: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar 21 11:58:13.221: INFO: Waiting up to 5m0s for pod "client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-containers-jhkgj" to be "success or failure"
Mar 21 11:58:13.223: INFO: Pod "client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399995ms
Mar 21 11:58:15.229: INFO: Pod "client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008428841s
Mar 21 11:58:17.233: INFO: Pod "client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012567227s
Mar 21 11:58:19.238: INFO: Pod "client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016618493s
STEP: Saw pod success
Mar 21 11:58:19.238: INFO: Pod "client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:58:19.240: INFO: Trying to get logs from node wolf pod client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:58:19.259: INFO: Waiting for pod client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:58:19.261: INFO: Pod client-containers-9ab21cbe-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:58:19.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jhkgj" for this suite.
Mar 21 11:58:25.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:58:25.351: INFO: namespace: e2e-tests-containers-jhkgj, resource: bindings, ignored listing per whitelist
Mar 21 11:58:25.360: INFO: namespace e2e-tests-containers-jhkgj deletion completed in 6.094706232s

• [SLOW TEST:12.218 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:58:25.361: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 21 11:58:25.451: INFO: Waiting up to 5m0s for pod "pod-a1fc70af-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-s2v4c" to be "success or failure"
Mar 21 11:58:25.455: INFO: Pod "pod-a1fc70af-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.073739ms
Mar 21 11:58:27.459: INFO: Pod "pod-a1fc70af-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007455668s
STEP: Saw pod success
Mar 21 11:58:27.459: INFO: Pod "pod-a1fc70af-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:58:27.461: INFO: Trying to get logs from node antelope pod pod-a1fc70af-4bd0-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:58:27.495: INFO: Waiting for pod pod-a1fc70af-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:58:27.500: INFO: Pod pod-a1fc70af-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:58:27.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s2v4c" for this suite.
Mar 21 11:58:33.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:58:33.556: INFO: namespace: e2e-tests-emptydir-s2v4c, resource: bindings, ignored listing per whitelist
Mar 21 11:58:33.616: INFO: namespace e2e-tests-emptydir-s2v4c deletion completed in 6.108717205s

• [SLOW TEST:8.256 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:58:33.616: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a6e70b18-4bd0-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 11:58:33.704: INFO: Waiting up to 5m0s for pod "pod-configmaps-a6e78beb-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-tmgbd" to be "success or failure"
Mar 21 11:58:33.707: INFO: Pod "pod-configmaps-a6e78beb-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.106599ms
Mar 21 11:58:35.710: INFO: Pod "pod-configmaps-a6e78beb-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006385882s
STEP: Saw pod success
Mar 21 11:58:35.710: INFO: Pod "pod-configmaps-a6e78beb-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:58:35.713: INFO: Trying to get logs from node jaguar pod pod-configmaps-a6e78beb-4bd0-11e9-9c6a-0a581900021b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 11:58:35.728: INFO: Waiting for pod pod-configmaps-a6e78beb-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:58:35.730: INFO: Pod pod-configmaps-a6e78beb-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:58:35.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tmgbd" for this suite.
Mar 21 11:58:41.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:58:41.795: INFO: namespace: e2e-tests-configmap-tmgbd, resource: bindings, ignored listing per whitelist
Mar 21 11:58:41.839: INFO: namespace e2e-tests-configmap-tmgbd deletion completed in 6.104943268s

• [SLOW TEST:8.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:58:41.839: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 21 11:58:41.946: INFO: Waiting up to 5m0s for pod "pod-abd141a9-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-jswql" to be "success or failure"
Mar 21 11:58:41.951: INFO: Pod "pod-abd141a9-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.404275ms
Mar 21 11:58:43.954: INFO: Pod "pod-abd141a9-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007891776s
STEP: Saw pod success
Mar 21 11:58:43.954: INFO: Pod "pod-abd141a9-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:58:43.957: INFO: Trying to get logs from node wolf pod pod-abd141a9-4bd0-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 11:58:43.975: INFO: Waiting for pod pod-abd141a9-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:58:43.982: INFO: Pod pod-abd141a9-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:58:43.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jswql" for this suite.
Mar 21 11:58:49.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:58:50.062: INFO: namespace: e2e-tests-emptydir-jswql, resource: bindings, ignored listing per whitelist
Mar 21 11:58:50.101: INFO: namespace e2e-tests-emptydir-jswql deletion completed in 6.114865468s

• [SLOW TEST:8.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:58:50.104: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b0b8429d-4bd0-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 11:58:50.174: INFO: Waiting up to 5m0s for pod "pod-secrets-b0b8b028-4bd0-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-4vslw" to be "success or failure"
Mar 21 11:58:50.177: INFO: Pod "pod-secrets-b0b8b028-4bd0-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.984462ms
Mar 21 11:58:52.180: INFO: Pod "pod-secrets-b0b8b028-4bd0-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006299188s
STEP: Saw pod success
Mar 21 11:58:52.180: INFO: Pod "pod-secrets-b0b8b028-4bd0-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 11:58:52.183: INFO: Trying to get logs from node jaguar pod pod-secrets-b0b8b028-4bd0-11e9-9c6a-0a581900021b container secret-env-test: <nil>
STEP: delete the pod
Mar 21 11:58:52.201: INFO: Waiting for pod pod-secrets-b0b8b028-4bd0-11e9-9c6a-0a581900021b to disappear
Mar 21 11:58:52.204: INFO: Pod pod-secrets-b0b8b028-4bd0-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:58:52.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4vslw" for this suite.
Mar 21 11:58:58.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:58:58.230: INFO: namespace: e2e-tests-secrets-4vslw, resource: bindings, ignored listing per whitelist
Mar 21 11:58:58.328: INFO: namespace e2e-tests-secrets-4vslw deletion completed in 6.120147742s

• [SLOW TEST:8.224 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:58:58.328: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 21 11:58:58.425: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-7tkb5,SelfLink:/api/v1/namespaces/e2e-tests-watch-7tkb5/configmaps/e2e-watch-test-resource-version,UID:b5a0f3b9-4bd0-11e9-8b3c-9eae6a3150d7,ResourceVersion:14441,Generation:0,CreationTimestamp:2019-03-21 11:58:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 21 11:58:58.425: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-7tkb5,SelfLink:/api/v1/namespaces/e2e-tests-watch-7tkb5/configmaps/e2e-watch-test-resource-version,UID:b5a0f3b9-4bd0-11e9-8b3c-9eae6a3150d7,ResourceVersion:14442,Generation:0,CreationTimestamp:2019-03-21 11:58:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 11:58:58.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7tkb5" for this suite.
Mar 21 11:59:04.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 11:59:04.485: INFO: namespace: e2e-tests-watch-7tkb5, resource: bindings, ignored listing per whitelist
Mar 21 11:59:04.540: INFO: namespace e2e-tests-watch-7tkb5 deletion completed in 6.111187247s

• [SLOW TEST:6.212 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 11:59:04.540: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-79jz4
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-79jz4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-79jz4
Mar 21 11:59:04.644: INFO: Found 0 stateful pods, waiting for 1
Mar 21 11:59:14.650: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 21 11:59:14.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 11:59:14.987: INFO: stderr: ""
Mar 21 11:59:14.987: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 11:59:14.987: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 11:59:14.990: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 21 11:59:24.994: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 11:59:24.994: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 11:59:25.014: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 11:59:25.014: INFO: ss-0  jaguar  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 11:59:25.014: INFO: 
Mar 21 11:59:25.014: INFO: StatefulSet ss has not reached scale 3, at 1
Mar 21 11:59:26.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996515978s
Mar 21 11:59:27.025: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988900952s
Mar 21 11:59:28.029: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984778621s
Mar 21 11:59:29.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980750661s
Mar 21 11:59:30.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976255646s
Mar 21 11:59:31.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972309108s
Mar 21 11:59:32.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967699574s
Mar 21 11:59:33.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963458795s
Mar 21 11:59:34.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.203064ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-79jz4
Mar 21 11:59:35.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 11:59:35.330: INFO: stderr: ""
Mar 21 11:59:35.330: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 11:59:35.331: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 11:59:35.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 11:59:35.685: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 21 11:59:35.685: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 11:59:35.685: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 11:59:35.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 11:59:35.987: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar 21 11:59:35.987: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 11:59:35.987: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 11:59:35.990: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Mar 21 11:59:45.994: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 11:59:45.994: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 11:59:45.994: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 21 11:59:45.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 11:59:46.258: INFO: stderr: ""
Mar 21 11:59:46.258: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 11:59:46.258: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 11:59:46.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 11:59:46.633: INFO: stderr: ""
Mar 21 11:59:46.633: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 11:59:46.633: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 11:59:46.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 11:59:47.037: INFO: stderr: ""
Mar 21 11:59:47.037: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 11:59:47.037: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 11:59:47.037: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 11:59:47.041: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 21 11:59:57.050: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 11:59:57.051: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 11:59:57.051: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 11:59:57.062: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 21 11:59:57.062: INFO: ss-0  jaguar    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 11:59:57.062: INFO: ss-1  antelope  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 11:59:57.062: INFO: ss-2  wolf      Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 11:59:57.063: INFO: 
Mar 21 11:59:57.063: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 21 11:59:58.067: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 21 11:59:58.067: INFO: ss-0  jaguar    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 11:59:58.067: INFO: ss-1  antelope  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 11:59:58.067: INFO: ss-2  wolf      Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 11:59:58.067: INFO: 
Mar 21 11:59:58.067: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 21 11:59:59.071: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Mar 21 11:59:59.071: INFO: ss-0  jaguar    Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 11:59:59.071: INFO: ss-1  antelope  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 11:59:59.071: INFO: ss-2  wolf      Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 11:59:59.071: INFO: 
Mar 21 11:59:59.071: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 21 12:00:00.075: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 12:00:00.075: INFO: ss-0  jaguar  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 12:00:00.075: INFO: ss-2  wolf    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 12:00:00.075: INFO: 
Mar 21 12:00:00.075: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 21 12:00:01.079: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 12:00:01.079: INFO: ss-0  jaguar  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 12:00:01.079: INFO: ss-2  wolf    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 12:00:01.079: INFO: 
Mar 21 12:00:01.079: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 21 12:00:02.084: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 12:00:02.084: INFO: ss-0  jaguar  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 12:00:02.084: INFO: ss-2  wolf    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 12:00:02.084: INFO: 
Mar 21 12:00:02.084: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 21 12:00:03.089: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 12:00:03.089: INFO: ss-0  jaguar  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 12:00:03.089: INFO: ss-2  wolf    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 12:00:03.089: INFO: 
Mar 21 12:00:03.089: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 21 12:00:04.093: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 12:00:04.093: INFO: ss-0  jaguar  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 12:00:04.093: INFO: ss-2  wolf    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 12:00:04.093: INFO: 
Mar 21 12:00:04.093: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 21 12:00:05.097: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 12:00:05.097: INFO: ss-0  jaguar  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 12:00:05.097: INFO: ss-2  wolf    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 12:00:05.097: INFO: 
Mar 21 12:00:05.097: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 21 12:00:06.101: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Mar 21 12:00:06.101: INFO: ss-0  jaguar  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:04 +0000 UTC  }]
Mar 21 12:00:06.102: INFO: ss-2  wolf    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 11:59:25 +0000 UTC  }]
Mar 21 12:00:06.102: INFO: 
Mar 21 12:00:06.102: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-79jz4
Mar 21 12:00:07.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:00:07.312: INFO: rc: 1
Mar 21 12:00:07.312: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc000b79620 exit status 1 <nil> <nil> true [0xc002212aa0 0xc002212ab8 0xc002212ad0] [0xc002212aa0 0xc002212ab8 0xc002212ad0] [0xc002212ab0 0xc002212ac8] [0x932a40 0x932a40] 0xc001ccb320 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Mar 21 12:00:17.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:00:17.445: INFO: rc: 1
Mar 21 12:00:17.445: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002330b70 exit status 1 <nil> <nil> true [0xc00169e708 0xc00169e720 0xc00169e738] [0xc00169e708 0xc00169e720 0xc00169e738] [0xc00169e718 0xc00169e730] [0x932a40 0x932a40] 0xc001cb9a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:00:27.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:00:27.616: INFO: rc: 1
Mar 21 12:00:27.616: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00109e420 exit status 1 <nil> <nil> true [0xc001e7ed08 0xc001e7ed20 0xc001e7ed38] [0xc001e7ed08 0xc001e7ed20 0xc001e7ed38] [0xc001e7ed18 0xc001e7ed30] [0x932a40 0x932a40] 0xc000fd0360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:00:37.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:00:37.838: INFO: rc: 1
Mar 21 12:00:37.838: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002330f90 exit status 1 <nil> <nil> true [0xc00169e750 0xc00169e790 0xc00169e7a8] [0xc00169e750 0xc00169e790 0xc00169e7a8] [0xc00169e788 0xc00169e7a0] [0x932a40 0x932a40] 0xc001920000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:00:47.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:00:47.965: INFO: rc: 1
Mar 21 12:00:47.965: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001dfe3c0 exit status 1 <nil> <nil> true [0xc00042a028 0xc00042a070 0xc00042a0b8] [0xc00042a028 0xc00042a070 0xc00042a0b8] [0xc00042a068 0xc00042a080] [0x932a40 0x932a40] 0xc00243c240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:00:57.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:00:58.136: INFO: rc: 1
Mar 21 12:00:58.136: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001dfe780 exit status 1 <nil> <nil> true [0xc00042a0e0 0xc00042a148 0xc00042a170] [0xc00042a0e0 0xc00042a148 0xc00042a170] [0xc00042a110 0xc00042a168] [0x932a40 0x932a40] 0xc00243c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:01:08.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:01:08.241: INFO: rc: 1
Mar 21 12:01:08.241: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f84420 exit status 1 <nil> <nil> true [0xc00000e250 0xc00000e4c0 0xc00000e600] [0xc00000e250 0xc00000e4c0 0xc00000e600] [0xc00000e2d8 0xc00000e568] [0x932a40 0x932a40] 0xc001cb8240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:01:18.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:01:18.458: INFO: rc: 1
Mar 21 12:01:18.458: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001dfecf0 exit status 1 <nil> <nil> true [0xc00042a178 0xc00042a1a8 0xc00042a1d8] [0xc00042a178 0xc00042a1a8 0xc00042a1d8] [0xc00042a188 0xc00042a1d0] [0x932a40 0x932a40] 0xc00243c8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:01:28.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:01:28.641: INFO: rc: 1
Mar 21 12:01:28.641: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8a3c0 exit status 1 <nil> <nil> true [0xc000160010 0xc000160050 0xc0001600b8] [0xc000160010 0xc000160050 0xc0001600b8] [0xc000160040 0xc000160098] [0x932a40 0x932a40] 0xc00176e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:01:38.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:01:38.803: INFO: rc: 1
Mar 21 12:01:38.803: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8a750 exit status 1 <nil> <nil> true [0xc0001600d8 0xc000160138 0xc000160178] [0xc0001600d8 0xc000160138 0xc000160178] [0xc000160128 0xc000160158] [0x932a40 0x932a40] 0xc00176f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:01:48.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:01:48.977: INFO: rc: 1
Mar 21 12:01:48.977: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f84840 exit status 1 <nil> <nil> true [0xc00000e610 0xc00000e710 0xc00000e858] [0xc00000e610 0xc00000e710 0xc00000e858] [0xc00000e658 0xc00000e820] [0x932a40 0x932a40] 0xc001cb85a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:01:58.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:01:59.166: INFO: rc: 1
Mar 21 12:01:59.166: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001dff0b0 exit status 1 <nil> <nil> true [0xc00042a1e0 0xc00042a248 0xc00042a280] [0xc00042a1e0 0xc00042a248 0xc00042a280] [0xc00042a220 0xc00042a278] [0x932a40 0x932a40] 0xc00243ce40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:02:09.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:02:09.430: INFO: rc: 1
Mar 21 12:02:09.430: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f84c60 exit status 1 <nil> <nil> true [0xc00000e878 0xc00000e9d8 0xc00000ea60] [0xc00000e878 0xc00000e9d8 0xc00000ea60] [0xc00000e988 0xc00000ea48] [0x932a40 0x932a40] 0xc001cb8ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:02:19.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:02:19.541: INFO: rc: 1
Mar 21 12:02:19.541: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001dff470 exit status 1 <nil> <nil> true [0xc00042a290 0xc00042a2b8 0xc00042a2e8] [0xc00042a290 0xc00042a2b8 0xc00042a2e8] [0xc00042a2a0 0xc00042a2c8] [0x932a40 0x932a40] 0xc00243d440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:02:29.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:02:29.737: INFO: rc: 1
Mar 21 12:02:29.738: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001dff830 exit status 1 <nil> <nil> true [0xc00042a300 0xc00042a320 0xc00042a360] [0xc00042a300 0xc00042a320 0xc00042a360] [0xc00042a318 0xc00042a358] [0x932a40 0x932a40] 0xc00243d920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:02:39.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:02:39.878: INFO: rc: 1
Mar 21 12:02:39.878: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f85170 exit status 1 <nil> <nil> true [0xc00000eb08 0xc00000ec38 0xc00000ed38] [0xc00000eb08 0xc00000ec38 0xc00000ed38] [0xc00000ec08 0xc00000ed20] [0x932a40 0x932a40] 0xc001cb92c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:02:49.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:02:50.049: INFO: rc: 1
Mar 21 12:02:50.049: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8a3f0 exit status 1 <nil> <nil> true [0xc000160030 0xc000160070 0xc0001600d8] [0xc000160030 0xc000160070 0xc0001600d8] [0xc000160050 0xc0001600b8] [0x932a40 0x932a40] 0xc00176e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:03:00.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:03:00.187: INFO: rc: 1
Mar 21 12:03:00.188: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8a7b0 exit status 1 <nil> <nil> true [0xc000160118 0xc000160140 0xc0001601a0] [0xc000160118 0xc000160140 0xc0001601a0] [0xc000160138 0xc000160178] [0x932a40 0x932a40] 0xc00176f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:03:10.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:03:10.390: INFO: rc: 1
Mar 21 12:03:10.390: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8ab40 exit status 1 <nil> <nil> true [0xc0001601a8 0xc0001601f8 0xc000160250] [0xc0001601a8 0xc0001601f8 0xc000160250] [0xc0001601d8 0xc000160220] [0x932a40 0x932a40] 0xc00176f8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:03:20.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:03:20.517: INFO: rc: 1
Mar 21 12:03:20.517: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8af30 exit status 1 <nil> <nil> true [0xc000160268 0xc000160280 0xc000160420] [0xc000160268 0xc000160280 0xc000160420] [0xc000160278 0xc0001602c0] [0x932a40 0x932a40] 0xc00176fc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:03:30.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:03:30.687: INFO: rc: 1
Mar 21 12:03:30.687: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8b350 exit status 1 <nil> <nil> true [0xc000160440 0xc000160508 0xc000160560] [0xc000160440 0xc000160508 0xc000160560] [0xc0001604e8 0xc000160540] [0x932a40 0x932a40] 0xc00176ff80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:03:40.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:03:40.871: INFO: rc: 1
Mar 21 12:03:40.871: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b8b740 exit status 1 <nil> <nil> true [0xc000160578 0xc000160608 0xc000160660] [0xc000160578 0xc000160608 0xc000160660] [0xc0001605f8 0xc000160640] [0x932a40 0x932a40] 0xc001cb82a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:03:50.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:03:51.035: INFO: rc: 1
Mar 21 12:03:51.035: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001866390 exit status 1 <nil> <nil> true [0xc00000e250 0xc00000e4c0 0xc00000e600] [0xc00000e250 0xc00000e4c0 0xc00000e600] [0xc00000e2d8 0xc00000e568] [0x932a40 0x932a40] 0xc00243c240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:04:01.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:04:01.284: INFO: rc: 1
Mar 21 12:04:01.284: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f84450 exit status 1 <nil> <nil> true [0xc00042a020 0xc00042a068 0xc00042a080] [0xc00042a020 0xc00042a068 0xc00042a080] [0xc00042a050 0xc00042a078] [0x932a40 0x932a40] 0xc001804240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:04:11.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:04:11.496: INFO: rc: 1
Mar 21 12:04:11.497: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f84810 exit status 1 <nil> <nil> true [0xc00042a0b8 0xc00042a110 0xc00042a168] [0xc00042a0b8 0xc00042a110 0xc00042a168] [0xc00042a0e8 0xc00042a160] [0x932a40 0x932a40] 0xc0018045a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:04:21.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:04:21.689: INFO: rc: 1
Mar 21 12:04:21.689: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f84bd0 exit status 1 <nil> <nil> true [0xc00042a170 0xc00042a188 0xc00042a1d0] [0xc00042a170 0xc00042a188 0xc00042a1d0] [0xc00042a180 0xc00042a1c8] [0x932a40 0x932a40] 0xc0018048a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:04:31.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:04:31.804: INFO: rc: 1
Mar 21 12:04:31.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000f850e0 exit status 1 <nil> <nil> true [0xc00042a1d8 0xc00042a220 0xc00042a278] [0xc00042a1d8 0xc00042a220 0xc00042a278] [0xc00042a200 0xc00042a268] [0x932a40 0x932a40] 0xc001804ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:04:41.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:04:41.941: INFO: rc: 1
Mar 21 12:04:41.941: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001dfe420 exit status 1 <nil> <nil> true [0xc00049e748 0xc00049ea28 0xc00049ec50] [0xc00049e748 0xc00049ea28 0xc00049ec50] [0xc00049e928 0xc00049ebd0] [0x932a40 0x932a40] 0xc00126e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:04:51.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:04:52.084: INFO: rc: 1
Mar 21 12:04:52.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018663c0 exit status 1 <nil> <nil> true [0xc00000e2d0 0xc00000e508 0xc00000e610] [0xc00000e2d0 0xc00000e508 0xc00000e610] [0xc00000e4c0 0xc00000e600] [0x932a40 0x932a40] 0xc00176e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:05:02.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:05:02.409: INFO: rc: 1
Mar 21 12:05:02.409: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0018667b0 exit status 1 <nil> <nil> true [0xc00000e618 0xc00000e7c8 0xc00000e878] [0xc00000e618 0xc00000e7c8 0xc00000e878] [0xc00000e710 0xc00000e858] [0x932a40 0x932a40] 0xc00176f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Mar 21 12:05:12.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-79jz4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:05:12.569: INFO: rc: 1
Mar 21 12:05:12.569: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Mar 21 12:05:12.569: INFO: Scaling statefulset ss to 0
Mar 21 12:05:12.580: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 21 12:05:12.582: INFO: Deleting all statefulset in ns e2e-tests-statefulset-79jz4
Mar 21 12:05:12.585: INFO: Scaling statefulset ss to 0
Mar 21 12:05:12.597: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 12:05:12.600: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:05:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-79jz4" for this suite.
Mar 21 12:05:18.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:05:18.729: INFO: namespace: e2e-tests-statefulset-79jz4, resource: bindings, ignored listing per whitelist
Mar 21 12:05:18.731: INFO: namespace e2e-tests-statefulset-79jz4 deletion completed in 6.102790925s

• [SLOW TEST:374.191 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:05:18.731: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Mar 21 12:05:58.831: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:05:58.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mx8mk" for this suite.
Mar 21 12:06:04.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:06:04.915: INFO: namespace: e2e-tests-gc-mx8mk, resource: bindings, ignored listing per whitelist
Mar 21 12:06:04.971: INFO: namespace e2e-tests-gc-mx8mk deletion completed in 6.134978742s

• [SLOW TEST:46.240 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:06:04.971: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4kqzp
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-4kqzp
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-4kqzp
Mar 21 12:06:05.069: INFO: Found 0 stateful pods, waiting for 1
Mar 21 12:06:15.072: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 21 12:06:15.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 12:06:15.602: INFO: stderr: ""
Mar 21 12:06:15.602: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 12:06:15.602: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 12:06:15.606: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 21 12:06:25.610: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 12:06:25.610: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 12:06:25.624: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999417s
Mar 21 12:06:26.628: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996736669s
Mar 21 12:06:27.632: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99259985s
Mar 21 12:06:28.636: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988003456s
Mar 21 12:06:29.641: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983798863s
Mar 21 12:06:30.644: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979643705s
Mar 21 12:06:31.648: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975995827s
Mar 21 12:06:32.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.972202414s
Mar 21 12:06:33.656: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.968043317s
Mar 21 12:06:34.660: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.159171ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-4kqzp
Mar 21 12:06:35.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:06:36.045: INFO: stderr: ""
Mar 21 12:06:36.045: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 12:06:36.045: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 12:06:36.048: INFO: Found 1 stateful pods, waiting for 3
Mar 21 12:06:46.057: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 12:06:46.057: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 12:06:46.058: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 21 12:06:46.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 12:06:46.416: INFO: stderr: ""
Mar 21 12:06:46.416: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 12:06:46.416: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 12:06:46.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 12:06:46.981: INFO: stderr: ""
Mar 21 12:06:46.981: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 12:06:46.981: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 12:06:46.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 12:06:47.370: INFO: stderr: ""
Mar 21 12:06:47.370: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 12:06:47.370: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 12:06:47.370: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 12:06:47.374: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar 21 12:06:57.381: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 12:06:57.381: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 12:06:57.381: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 21 12:06:57.394: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999408s
Mar 21 12:06:58.399: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995660797s
Mar 21 12:06:59.403: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990762239s
Mar 21 12:07:00.408: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985795561s
Mar 21 12:07:01.413: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981438864s
Mar 21 12:07:02.417: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976629762s
Mar 21 12:07:03.424: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972076755s
Mar 21 12:07:04.428: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965251651s
Mar 21 12:07:05.433: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960633344s
Mar 21 12:07:06.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.612625ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-4kqzp
Mar 21 12:07:07.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:07:07.879: INFO: stderr: ""
Mar 21 12:07:07.879: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 12:07:07.879: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 12:07:07.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:07:08.319: INFO: stderr: ""
Mar 21 12:07:08.319: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 12:07:08.319: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 12:07:08.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-4kqzp ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:07:08.646: INFO: stderr: ""
Mar 21 12:07:08.646: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 12:07:08.646: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 12:07:08.646: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 21 12:07:38.685: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4kqzp
Mar 21 12:07:38.689: INFO: Scaling statefulset ss to 0
Mar 21 12:07:38.698: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 12:07:38.702: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:07:38.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4kqzp" for this suite.
Mar 21 12:07:44.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:07:44.835: INFO: namespace: e2e-tests-statefulset-4kqzp, resource: bindings, ignored listing per whitelist
Mar 21 12:07:44.849: INFO: namespace e2e-tests-statefulset-4kqzp deletion completed in 6.130602382s

• [SLOW TEST:99.878 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:07:44.851: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:07:44.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-pfrqr" to be "success or failure"
Mar 21 12:07:45.050: INFO: Pod "downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 111.193535ms
Mar 21 12:07:47.054: INFO: Pod "downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115264068s
Mar 21 12:07:49.058: INFO: Pod "downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.118911019s
STEP: Saw pod success
Mar 21 12:07:49.058: INFO: Pod "downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:07:49.061: INFO: Trying to get logs from node wolf pod downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:07:49.081: INFO: Waiting for pod downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b to disappear
Mar 21 12:07:49.084: INFO: Pod downwardapi-volume-ef76fa8a-4bd1-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:07:49.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pfrqr" for this suite.
Mar 21 12:07:55.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:07:55.218: INFO: namespace: e2e-tests-projected-pfrqr, resource: bindings, ignored listing per whitelist
Mar 21 12:07:55.222: INFO: namespace e2e-tests-projected-pfrqr deletion completed in 6.133898172s

• [SLOW TEST:10.371 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:07:55.222: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:07:55.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-6wzwz" to be "success or failure"
Mar 21 12:07:55.342: INFO: Pod "downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.990075ms
Mar 21 12:07:57.345: INFO: Pod "downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006486529s
Mar 21 12:07:59.349: INFO: Pod "downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010505549s
STEP: Saw pod success
Mar 21 12:07:59.350: INFO: Pod "downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:07:59.352: INFO: Trying to get logs from node antelope pod downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:07:59.383: INFO: Waiting for pod downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b to disappear
Mar 21 12:07:59.390: INFO: Pod downwardapi-volume-f5aa20bd-4bd1-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:07:59.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6wzwz" for this suite.
Mar 21 12:08:05.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:08:05.445: INFO: namespace: e2e-tests-projected-6wzwz, resource: bindings, ignored listing per whitelist
Mar 21 12:08:05.511: INFO: namespace e2e-tests-projected-6wzwz deletion completed in 6.115913481s

• [SLOW TEST:10.289 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:08:05.511: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-k9tb8.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-k9tb8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-k9tb8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-k9tb8.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-k9tb8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-k9tb8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 21 12:08:19.688: INFO: DNS probes using e2e-tests-dns-k9tb8/dns-test-fbc65d99-4bd1-11e9-9c6a-0a581900021b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:08:19.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-k9tb8" for this suite.
Mar 21 12:08:25.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:08:25.781: INFO: namespace: e2e-tests-dns-k9tb8, resource: bindings, ignored listing per whitelist
Mar 21 12:08:25.804: INFO: namespace e2e-tests-dns-k9tb8 deletion completed in 6.104853526s

• [SLOW TEST:20.293 seconds]
[sig-network] DNS
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:08:25.804: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 21 12:08:25.918: INFO: Waiting up to 5m0s for pod "pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-btznf" to be "success or failure"
Mar 21 12:08:25.921: INFO: Pod "pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.968447ms
Mar 21 12:08:27.929: INFO: Pod "pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010892577s
Mar 21 12:08:29.933: INFO: Pod "pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014471186s
STEP: Saw pod success
Mar 21 12:08:29.933: INFO: Pod "pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:08:29.936: INFO: Trying to get logs from node antelope pod pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 12:08:29.955: INFO: Waiting for pod pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b to disappear
Mar 21 12:08:29.960: INFO: Pod pod-07e3cbca-4bd2-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:08:29.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-btznf" for this suite.
Mar 21 12:08:35.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:08:36.006: INFO: namespace: e2e-tests-emptydir-btznf, resource: bindings, ignored listing per whitelist
Mar 21 12:08:36.077: INFO: namespace e2e-tests-emptydir-btznf deletion completed in 6.109994721s

• [SLOW TEST:10.273 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:08:36.079: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b
Mar 21 12:08:36.193: INFO: Pod name my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b: Found 0 pods out of 1
Mar 21 12:08:41.199: INFO: Pod name my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b: Found 1 pods out of 1
Mar 21 12:08:41.199: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b" are running
Mar 21 12:08:41.202: INFO: Pod "my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b-5k5pf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:08:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:08:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:08:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:08:36 +0000 UTC Reason: Message:}])
Mar 21 12:08:41.202: INFO: Trying to dial the pod
Mar 21 12:08:46.215: INFO: Controller my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b: Got expected result from replica 1 [my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b-5k5pf]: "my-hostname-basic-0e0410b1-4bd2-11e9-9c6a-0a581900021b-5k5pf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:08:46.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-msb44" for this suite.
Mar 21 12:08:52.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:08:52.322: INFO: namespace: e2e-tests-replication-controller-msb44, resource: bindings, ignored listing per whitelist
Mar 21 12:08:52.328: INFO: namespace e2e-tests-replication-controller-msb44 deletion completed in 6.107675079s

• [SLOW TEST:16.249 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:08:52.329: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-17adbb7f-4bd2-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:08:52.408: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17ae5b27-4bd2-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-rmrpq" to be "success or failure"
Mar 21 12:08:52.411: INFO: Pod "pod-projected-configmaps-17ae5b27-4bd2-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.678232ms
Mar 21 12:08:54.415: INFO: Pod "pod-projected-configmaps-17ae5b27-4bd2-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006595447s
STEP: Saw pod success
Mar 21 12:08:54.415: INFO: Pod "pod-projected-configmaps-17ae5b27-4bd2-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:08:54.418: INFO: Trying to get logs from node jaguar pod pod-projected-configmaps-17ae5b27-4bd2-11e9-9c6a-0a581900021b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 12:08:54.469: INFO: Waiting for pod pod-projected-configmaps-17ae5b27-4bd2-11e9-9c6a-0a581900021b to disappear
Mar 21 12:08:54.471: INFO: Pod pod-projected-configmaps-17ae5b27-4bd2-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:08:54.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rmrpq" for this suite.
Mar 21 12:09:00.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:09:00.588: INFO: namespace: e2e-tests-projected-rmrpq, resource: bindings, ignored listing per whitelist
Mar 21 12:09:00.617: INFO: namespace e2e-tests-projected-rmrpq deletion completed in 6.141641537s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:09:00.618: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:09:00.707: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ca08fef-4bd2-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-8qd2h" to be "success or failure"
Mar 21 12:09:00.710: INFO: Pod "downwardapi-volume-1ca08fef-4bd2-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.176402ms
Mar 21 12:09:02.715: INFO: Pod "downwardapi-volume-1ca08fef-4bd2-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007680506s
STEP: Saw pod success
Mar 21 12:09:02.715: INFO: Pod "downwardapi-volume-1ca08fef-4bd2-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:09:02.718: INFO: Trying to get logs from node wolf pod downwardapi-volume-1ca08fef-4bd2-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:09:02.736: INFO: Waiting for pod downwardapi-volume-1ca08fef-4bd2-11e9-9c6a-0a581900021b to disappear
Mar 21 12:09:02.740: INFO: Pod downwardapi-volume-1ca08fef-4bd2-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:09:02.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8qd2h" for this suite.
Mar 21 12:09:08.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:09:08.771: INFO: namespace: e2e-tests-projected-8qd2h, resource: bindings, ignored listing per whitelist
Mar 21 12:09:08.862: INFO: namespace e2e-tests-projected-8qd2h deletion completed in 6.117816623s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:09:08.864: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-8d9k
STEP: Creating a pod to test atomic-volume-subpath
Mar 21 12:09:08.958: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-8d9k" in namespace "e2e-tests-subpath-nwfqs" to be "success or failure"
Mar 21 12:09:08.964: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Pending", Reason="", readiness=false. Elapsed: 5.457005ms
Mar 21 12:09:10.968: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009223343s
Mar 21 12:09:12.972: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 4.013059076s
Mar 21 12:09:14.976: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 6.017038049s
Mar 21 12:09:16.980: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 8.021069584s
Mar 21 12:09:18.984: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 10.025366393s
Mar 21 12:09:20.988: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 12.029601155s
Mar 21 12:09:22.992: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 14.033467519s
Mar 21 12:09:25.048: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 16.089567949s
Mar 21 12:09:27.053: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 18.094283258s
Mar 21 12:09:29.057: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 20.098604163s
Mar 21 12:09:31.061: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Running", Reason="", readiness=false. Elapsed: 22.102822478s
Mar 21 12:09:33.069: INFO: Pod "pod-subpath-test-downwardapi-8d9k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.11076683s
STEP: Saw pod success
Mar 21 12:09:33.069: INFO: Pod "pod-subpath-test-downwardapi-8d9k" satisfied condition "success or failure"
Mar 21 12:09:33.072: INFO: Trying to get logs from node antelope pod pod-subpath-test-downwardapi-8d9k container test-container-subpath-downwardapi-8d9k: <nil>
STEP: delete the pod
Mar 21 12:09:33.095: INFO: Waiting for pod pod-subpath-test-downwardapi-8d9k to disappear
Mar 21 12:09:33.097: INFO: Pod pod-subpath-test-downwardapi-8d9k no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-8d9k
Mar 21 12:09:33.098: INFO: Deleting pod "pod-subpath-test-downwardapi-8d9k" in namespace "e2e-tests-subpath-nwfqs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:09:33.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nwfqs" for this suite.
Mar 21 12:09:39.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:09:39.198: INFO: namespace: e2e-tests-subpath-nwfqs, resource: bindings, ignored listing per whitelist
Mar 21 12:09:39.201: INFO: namespace e2e-tests-subpath-nwfqs deletion completed in 6.096064176s

• [SLOW TEST:30.338 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:09:39.201: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 21 12:09:39.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-qr89h'
Mar 21 12:09:39.666: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 21 12:09:39.666: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Mar 21 12:09:41.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-qr89h'
Mar 21 12:09:41.817: INFO: stderr: ""
Mar 21 12:09:41.817: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:09:41.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qr89h" for this suite.
Mar 21 12:10:03.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:10:03.902: INFO: namespace: e2e-tests-kubectl-qr89h, resource: bindings, ignored listing per whitelist
Mar 21 12:10:03.975: INFO: namespace e2e-tests-kubectl-qr89h deletion completed in 22.153407008s

• [SLOW TEST:24.774 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:10:03.977: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-v2sq
STEP: Creating a pod to test atomic-volume-subpath
Mar 21 12:10:04.073: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-v2sq" in namespace "e2e-tests-subpath-5j7gd" to be "success or failure"
Mar 21 12:10:04.076: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Pending", Reason="", readiness=false. Elapsed: 3.220401ms
Mar 21 12:10:06.080: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007465493s
Mar 21 12:10:08.085: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 4.012189349s
Mar 21 12:10:10.089: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 6.016154565s
Mar 21 12:10:12.093: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 8.020128469s
Mar 21 12:10:14.097: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 10.024029113s
Mar 21 12:10:16.101: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 12.027886661s
Mar 21 12:10:18.105: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 14.03196912s
Mar 21 12:10:20.109: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 16.035798976s
Mar 21 12:10:22.113: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 18.040023097s
Mar 21 12:10:24.117: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 20.043849652s
Mar 21 12:10:26.120: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Running", Reason="", readiness=false. Elapsed: 22.047652587s
Mar 21 12:10:28.124: INFO: Pod "pod-subpath-test-configmap-v2sq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051694749s
STEP: Saw pod success
Mar 21 12:10:28.125: INFO: Pod "pod-subpath-test-configmap-v2sq" satisfied condition "success or failure"
Mar 21 12:10:28.128: INFO: Trying to get logs from node wolf pod pod-subpath-test-configmap-v2sq container test-container-subpath-configmap-v2sq: <nil>
STEP: delete the pod
Mar 21 12:10:28.150: INFO: Waiting for pod pod-subpath-test-configmap-v2sq to disappear
Mar 21 12:10:28.153: INFO: Pod pod-subpath-test-configmap-v2sq no longer exists
STEP: Deleting pod pod-subpath-test-configmap-v2sq
Mar 21 12:10:28.153: INFO: Deleting pod "pod-subpath-test-configmap-v2sq" in namespace "e2e-tests-subpath-5j7gd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:10:28.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5j7gd" for this suite.
Mar 21 12:10:34.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:10:34.230: INFO: namespace: e2e-tests-subpath-5j7gd, resource: bindings, ignored listing per whitelist
Mar 21 12:10:34.286: INFO: namespace e2e-tests-subpath-5j7gd deletion completed in 6.125098505s

• [SLOW TEST:30.310 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:10:34.287: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:10:38.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-hmgp7" for this suite.
Mar 21 12:10:44.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:10:44.510: INFO: namespace: e2e-tests-emptydir-wrapper-hmgp7, resource: bindings, ignored listing per whitelist
Mar 21 12:10:44.522: INFO: namespace e2e-tests-emptydir-wrapper-hmgp7 deletion completed in 6.109241502s

• [SLOW TEST:10.235 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:10:44.522: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-78cgt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 21 12:10:44.603: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 21 12:11:10.700: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://25.0.2.71:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-78cgt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:11:10.700: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:11:10.851: INFO: Found all expected endpoints: [netserver-0]
Mar 21 12:11:10.854: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://25.0.1.70:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-78cgt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:11:10.854: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:11:10.990: INFO: Found all expected endpoints: [netserver-1]
Mar 21 12:11:10.993: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://25.0.3.63:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-78cgt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:11:10.993: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:11:11.111: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:11:11.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-78cgt" for this suite.
Mar 21 12:11:33.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:11:33.208: INFO: namespace: e2e-tests-pod-network-test-78cgt, resource: bindings, ignored listing per whitelist
Mar 21 12:11:33.211: INFO: namespace e2e-tests-pod-network-test-78cgt deletion completed in 22.095093317s

• [SLOW TEST:48.689 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:11:33.211: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 21 12:11:33.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6p5qv'
Mar 21 12:11:33.519: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 21 12:11:33.519: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Mar 21 12:11:33.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-6p5qv'
Mar 21 12:11:33.671: INFO: stderr: ""
Mar 21 12:11:33.671: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:11:33.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6p5qv" for this suite.
Mar 21 12:11:55.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:11:55.750: INFO: namespace: e2e-tests-kubectl-6p5qv, resource: bindings, ignored listing per whitelist
Mar 21 12:11:55.776: INFO: namespace e2e-tests-kubectl-6p5qv deletion completed in 22.100373339s

• [SLOW TEST:22.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:11:55.777: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Mar 21 12:12:26.373: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:12:26.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l5bzj" for this suite.
Mar 21 12:12:32.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:12:32.462: INFO: namespace: e2e-tests-gc-l5bzj, resource: bindings, ignored listing per whitelist
Mar 21 12:12:32.474: INFO: namespace e2e-tests-gc-l5bzj deletion completed in 6.09676412s

• [SLOW TEST:36.697 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:12:32.474: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 21 12:12:37.083: INFO: Successfully updated pod "labelsupdate9ae65030-4bd2-11e9-9c6a-0a581900021b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:12:39.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ssz2x" for this suite.
Mar 21 12:13:01.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:13:01.243: INFO: namespace: e2e-tests-downward-api-ssz2x, resource: bindings, ignored listing per whitelist
Mar 21 12:13:01.250: INFO: namespace e2e-tests-downward-api-ssz2x deletion completed in 22.143700219s

• [SLOW TEST:28.776 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:13:01.251: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-l2jgd
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-l2jgd
STEP: Deleting pre-stop pod
Mar 21 12:13:12.405: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:13:12.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-l2jgd" for this suite.
Mar 21 12:13:50.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:13:50.462: INFO: namespace: e2e-tests-prestop-l2jgd, resource: bindings, ignored listing per whitelist
Mar 21 12:13:50.507: INFO: namespace e2e-tests-prestop-l2jgd deletion completed in 38.093860335s

• [SLOW TEST:49.257 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:13:50.508: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 21 12:13:50.569: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 21 12:13:50.576: INFO: Waiting for terminating namespaces to be deleted...
Mar 21 12:13:50.579: INFO: 
Logging pods the kubelet thinks is on node antelope before test
Mar 21 12:13:50.588: INFO: sonobuoy-e2e-job-0facb6ec3f244997 from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:13:50.588: INFO: 	Container e2e ready: true, restart count 0
Mar 21 12:13:50.588: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 12:13:50.588: INFO: kube-proxy-9hr7b from kube-system started at 2019-03-21 10:15:53 +0000 UTC (1 container statuses recorded)
Mar 21 12:13:50.588: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 12:13:50.588: INFO: kube-flannel-ds-amd64-rqwz5 from kube-system started at 2019-03-21 10:15:53 +0000 UTC (1 container statuses recorded)
Mar 21 12:13:50.588: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 12:13:50.588: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdl77 from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:13:50.588: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 21 12:13:50.588: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 12:13:50.588: INFO: 
Logging pods the kubelet thinks is on node jaguar before test
Mar 21 12:13:50.595: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-cxr4t from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:13:50.595: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 21 12:13:50.595: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 12:13:50.595: INFO: kube-flannel-ds-amd64-qw9mb from kube-system started at 2019-03-21 10:15:55 +0000 UTC (1 container statuses recorded)
Mar 21 12:13:50.595: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 12:13:50.595: INFO: kube-proxy-h2wk8 from kube-system started at 2019-03-21 10:15:55 +0000 UTC (1 container statuses recorded)
Mar 21 12:13:50.595: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 12:13:50.595: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-21 11:36:19 +0000 UTC (1 container statuses recorded)
Mar 21 12:13:50.595: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 21 12:13:50.595: INFO: 
Logging pods the kubelet thinks is on node wolf before test
Mar 21 12:13:50.604: INFO: kube-proxy-k5xgj from kube-system started at 2019-03-21 10:15:51 +0000 UTC (1 container statuses recorded)
Mar 21 12:13:50.604: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 12:13:50.604: INFO: kube-flannel-ds-amd64-b427k from kube-system started at 2019-03-21 10:15:51 +0000 UTC (1 container statuses recorded)
Mar 21 12:13:50.604: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 12:13:50.604: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdpng from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:13:50.604: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar 21 12:13:50.604: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158df84710eb390a], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:13:51.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-8wr6n" for this suite.
Mar 21 12:13:57.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:13:57.705: INFO: namespace: e2e-tests-sched-pred-8wr6n, resource: bindings, ignored listing per whitelist
Mar 21 12:13:57.734: INFO: namespace e2e-tests-sched-pred-8wr6n deletion completed in 6.104547668s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.226 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:13:57.734: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Mar 21 12:13:58.845: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:13:58.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-92ddx" for this suite.
Mar 21 12:14:04.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:14:04.931: INFO: namespace: e2e-tests-gc-92ddx, resource: bindings, ignored listing per whitelist
Mar 21 12:14:04.950: INFO: namespace e2e-tests-gc-92ddx deletion completed in 6.102317158s

• [SLOW TEST:7.216 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:14:04.954: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-gmj72
Mar 21 12:14:07.036: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gmj72
STEP: checking the pod's current state and verifying that restartCount is present
Mar 21 12:14:07.039: INFO: Initial restart count of pod liveness-exec is 0
Mar 21 12:14:55.136: INFO: Restart count of pod e2e-tests-container-probe-gmj72/liveness-exec is now 1 (48.096237399s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:14:55.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gmj72" for this suite.
Mar 21 12:15:01.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:15:01.212: INFO: namespace: e2e-tests-container-probe-gmj72, resource: bindings, ignored listing per whitelist
Mar 21 12:15:01.293: INFO: namespace e2e-tests-container-probe-gmj72 deletion completed in 6.14437191s

• [SLOW TEST:56.339 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:15:01.293: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:15:01.422: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 21 12:15:06.427: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 21 12:15:06.427: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 21 12:15:08.431: INFO: Creating deployment "test-rollover-deployment"
Mar 21 12:15:08.438: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 21 12:15:10.444: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 21 12:15:10.450: INFO: Ensure that both replica sets have 1 created replica
Mar 21 12:15:10.456: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 21 12:15:10.461: INFO: Updating deployment test-rollover-deployment
Mar 21 12:15:10.461: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 21 12:15:12.467: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 21 12:15:12.473: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 21 12:15:12.479: INFO: all replica sets need to contain the pod-template-hash label
Mar 21 12:15:12.480: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767310, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 21 12:15:14.486: INFO: all replica sets need to contain the pod-template-hash label
Mar 21 12:15:14.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767313, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 21 12:15:16.487: INFO: all replica sets need to contain the pod-template-hash label
Mar 21 12:15:16.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767313, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 21 12:15:18.486: INFO: all replica sets need to contain the pod-template-hash label
Mar 21 12:15:18.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767313, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 21 12:15:20.487: INFO: all replica sets need to contain the pod-template-hash label
Mar 21 12:15:20.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767313, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 21 12:15:22.487: INFO: all replica sets need to contain the pod-template-hash label
Mar 21 12:15:22.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767313, loc:(*time.Location)(0x7b4abe0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767308, loc:(*time.Location)(0x7b4abe0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 21 12:15:24.486: INFO: 
Mar 21 12:15:24.487: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 21 12:15:24.495: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-2m9hc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2m9hc/deployments/test-rollover-deployment,UID:f7d020ec-4bd2-11e9-8b3c-9eae6a3150d7,ResourceVersion:17277,Generation:2,CreationTimestamp:2019-03-21 12:15:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-21 12:15:08 +0000 UTC 2019-03-21 12:15:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-21 12:15:23 +0000 UTC 2019-03-21 12:15:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 21 12:15:24.499: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-2m9hc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2m9hc/replicasets/test-rollover-deployment-6b7f9d6597,UID:f905d92c-4bd2-11e9-8b3c-9eae6a3150d7,ResourceVersion:17268,Generation:2,CreationTimestamp:2019-03-21 12:15:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f7d020ec-4bd2-11e9-8b3c-9eae6a3150d7 0xc0013139b7 0xc0013139b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 21 12:15:24.499: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 21 12:15:24.499: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-2m9hc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2m9hc/replicasets/test-rollover-controller,UID:f3a16938-4bd2-11e9-8b3c-9eae6a3150d7,ResourceVersion:17276,Generation:2,CreationTimestamp:2019-03-21 12:15:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f7d020ec-4bd2-11e9-8b3c-9eae6a3150d7 0xc001313827 0xc001313828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 21 12:15:24.499: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-2m9hc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2m9hc/replicasets/test-rollover-deployment-6586df867b,UID:f7d2af09-4bd2-11e9-8b3c-9eae6a3150d7,ResourceVersion:17235,Generation:2,CreationTimestamp:2019-03-21 12:15:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment f7d020ec-4bd2-11e9-8b3c-9eae6a3150d7 0xc0013138e7 0xc0013138e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 21 12:15:24.503: INFO: Pod "test-rollover-deployment-6b7f9d6597-rvzq9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-rvzq9,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-2m9hc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2m9hc/pods/test-rollover-deployment-6b7f9d6597-rvzq9,UID:f908678e-4bd2-11e9-8b3c-9eae6a3150d7,ResourceVersion:17250,Generation:0,CreationTimestamp:2019-03-21 12:15:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 f905d92c-4bd2-11e9-8b3c-9eae6a3150d7 0xc000dcab37 0xc000dcab38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g9669 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g9669,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-g9669 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dcabc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dcabe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:15:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:15:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:15:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:15:10 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:25.0.1.76,StartTime:2019-03-21 12:15:10 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-21 12:15:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://47b9b582bee346e4de836fc1e3fe4cd6f97a4d72bae8a91a0044617d0330e57e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:15:24.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2m9hc" for this suite.
Mar 21 12:15:30.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:15:30.591: INFO: namespace: e2e-tests-deployment-2m9hc, resource: bindings, ignored listing per whitelist
Mar 21 12:15:30.616: INFO: namespace e2e-tests-deployment-2m9hc deletion completed in 6.108766442s

• [SLOW TEST:29.323 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:15:30.617: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar 21 12:15:32.732: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-0516bbc3-4bd3-11e9-9c6a-0a581900021b", GenerateName:"", Namespace:"e2e-tests-pods-xsp68", SelfLink:"/api/v1/namespaces/e2e-tests-pods-xsp68/pods/pod-submit-remove-0516bbc3-4bd3-11e9-9c6a-0a581900021b", UID:"05182f31-4bd3-11e9-8b3c-9eae6a3150d7", ResourceVersion:"17341", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63688767330, loc:(*time.Location)(0x7b4abe0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"707001913"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2hj7g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001a59e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2hj7g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0005c0438), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"antelope", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0016ef860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0005c0880)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0005412a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0005412a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0005412ac)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767330, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767332, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767332, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63688767330, loc:(*time.Location)(0x7b4abe0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"104.248.166.121", PodIP:"25.0.2.75", StartTime:(*v1.Time)(0xc0003b5b40), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0003b5b60), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d", ContainerID:"docker://ccc5a497dfefedac5b21744ca25f14370a24d208ab730509818e99f12692c0ed"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:15:41.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xsp68" for this suite.
Mar 21 12:15:47.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:15:47.249: INFO: namespace: e2e-tests-pods-xsp68, resource: bindings, ignored listing per whitelist
Mar 21 12:15:47.317: INFO: namespace e2e-tests-pods-xsp68 deletion completed in 6.097278252s

• [SLOW TEST:16.701 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:15:47.318: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-0f09b0a1-4bd3-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:15:47.407: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0f0a1cf1-4bd3-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-t56th" to be "success or failure"
Mar 21 12:15:47.409: INFO: Pod "pod-projected-secrets-0f0a1cf1-4bd3-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.798705ms
Mar 21 12:15:49.413: INFO: Pod "pod-projected-secrets-0f0a1cf1-4bd3-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006753213s
STEP: Saw pod success
Mar 21 12:15:49.414: INFO: Pod "pod-projected-secrets-0f0a1cf1-4bd3-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:15:49.417: INFO: Trying to get logs from node jaguar pod pod-projected-secrets-0f0a1cf1-4bd3-11e9-9c6a-0a581900021b container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 21 12:15:49.439: INFO: Waiting for pod pod-projected-secrets-0f0a1cf1-4bd3-11e9-9c6a-0a581900021b to disappear
Mar 21 12:15:49.441: INFO: Pod pod-projected-secrets-0f0a1cf1-4bd3-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:15:49.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t56th" for this suite.
Mar 21 12:15:55.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:15:55.490: INFO: namespace: e2e-tests-projected-t56th, resource: bindings, ignored listing per whitelist
Mar 21 12:15:55.544: INFO: namespace e2e-tests-projected-t56th deletion completed in 6.098685333s

• [SLOW TEST:8.226 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:15:55.545: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-13eea43a-4bd3-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:15:55.620: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-13ef2896-4bd3-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-6rn5s" to be "success or failure"
Mar 21 12:15:55.626: INFO: Pod "pod-projected-configmaps-13ef2896-4bd3-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380183ms
Mar 21 12:15:57.630: INFO: Pod "pod-projected-configmaps-13ef2896-4bd3-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009741654s
STEP: Saw pod success
Mar 21 12:15:57.630: INFO: Pod "pod-projected-configmaps-13ef2896-4bd3-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:15:57.633: INFO: Trying to get logs from node wolf pod pod-projected-configmaps-13ef2896-4bd3-11e9-9c6a-0a581900021b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 12:15:57.651: INFO: Waiting for pod pod-projected-configmaps-13ef2896-4bd3-11e9-9c6a-0a581900021b to disappear
Mar 21 12:15:57.653: INFO: Pod pod-projected-configmaps-13ef2896-4bd3-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:15:57.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6rn5s" for this suite.
Mar 21 12:16:03.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:16:03.694: INFO: namespace: e2e-tests-projected-6rn5s, resource: bindings, ignored listing per whitelist
Mar 21 12:16:03.760: INFO: namespace e2e-tests-projected-6rn5s deletion completed in 6.096220427s

• [SLOW TEST:8.215 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:16:03.761: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:16:03.832: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:16:07.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6dkpr" for this suite.
Mar 21 12:16:53.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:16:53.940: INFO: namespace: e2e-tests-pods-6dkpr, resource: bindings, ignored listing per whitelist
Mar 21 12:16:53.978: INFO: namespace e2e-tests-pods-6dkpr deletion completed in 46.097371558s

• [SLOW TEST:50.217 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:16:53.979: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:16:54.050: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36c2e7c1-4bd3-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-54t64" to be "success or failure"
Mar 21 12:16:54.112: INFO: Pod "downwardapi-volume-36c2e7c1-4bd3-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 62.228735ms
Mar 21 12:16:56.116: INFO: Pod "downwardapi-volume-36c2e7c1-4bd3-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.066177167s
STEP: Saw pod success
Mar 21 12:16:56.116: INFO: Pod "downwardapi-volume-36c2e7c1-4bd3-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:16:56.119: INFO: Trying to get logs from node jaguar pod downwardapi-volume-36c2e7c1-4bd3-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:16:56.138: INFO: Waiting for pod downwardapi-volume-36c2e7c1-4bd3-11e9-9c6a-0a581900021b to disappear
Mar 21 12:16:56.140: INFO: Pod downwardapi-volume-36c2e7c1-4bd3-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:16:56.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-54t64" for this suite.
Mar 21 12:17:02.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:17:02.166: INFO: namespace: e2e-tests-downward-api-54t64, resource: bindings, ignored listing per whitelist
Mar 21 12:17:02.266: INFO: namespace e2e-tests-downward-api-54t64 deletion completed in 6.121028629s

• [SLOW TEST:8.288 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:17:02.267: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Mar 21 12:17:02.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-6k66s'
Mar 21 12:17:02.636: INFO: stderr: ""
Mar 21 12:17:02.636: INFO: stdout: "pod/pause created\n"
Mar 21 12:17:02.636: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 21 12:17:02.636: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-6k66s" to be "running and ready"
Mar 21 12:17:02.643: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.1127ms
Mar 21 12:17:04.647: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010981694s
Mar 21 12:17:04.647: INFO: Pod "pause" satisfied condition "running and ready"
Mar 21 12:17:04.647: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 21 12:17:04.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-6k66s'
Mar 21 12:17:04.882: INFO: stderr: ""
Mar 21 12:17:04.882: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 21 12:17:04.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6k66s'
Mar 21 12:17:05.084: INFO: stderr: ""
Mar 21 12:17:05.084: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 21 12:17:05.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 label pods pause testing-label- --namespace=e2e-tests-kubectl-6k66s'
Mar 21 12:17:05.278: INFO: stderr: ""
Mar 21 12:17:05.278: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 21 12:17:05.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6k66s'
Mar 21 12:17:05.457: INFO: stderr: ""
Mar 21 12:17:05.458: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Mar 21 12:17:05.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6k66s'
Mar 21 12:17:05.622: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:17:05.622: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 21 12:17:05.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-6k66s'
Mar 21 12:17:05.817: INFO: stderr: "No resources found.\n"
Mar 21 12:17:05.817: INFO: stdout: ""
Mar 21 12:17:05.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -l name=pause --namespace=e2e-tests-kubectl-6k66s -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 21 12:17:06.036: INFO: stderr: ""
Mar 21 12:17:06.036: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:17:06.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6k66s" for this suite.
Mar 21 12:17:12.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:17:12.231: INFO: namespace: e2e-tests-kubectl-6k66s, resource: bindings, ignored listing per whitelist
Mar 21 12:17:12.356: INFO: namespace e2e-tests-kubectl-6k66s deletion completed in 6.315157025s

• [SLOW TEST:10.089 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:17:12.357: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar 21 12:17:12.441: INFO: namespace e2e-tests-kubectl-ph6xt
Mar 21 12:17:12.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-ph6xt'
Mar 21 12:17:12.722: INFO: stderr: ""
Mar 21 12:17:12.722: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 21 12:17:13.765: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:17:13.765: INFO: Found 0 / 1
Mar 21 12:17:14.727: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:17:14.728: INFO: Found 1 / 1
Mar 21 12:17:14.728: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 21 12:17:14.731: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:17:14.731: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 21 12:17:14.731: INFO: wait on redis-master startup in e2e-tests-kubectl-ph6xt 
Mar 21 12:17:14.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 logs redis-master-c9hbz redis-master --namespace=e2e-tests-kubectl-ph6xt'
Mar 21 12:17:14.998: INFO: stderr: ""
Mar 21 12:17:14.998: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Mar 12:17:13.870 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Mar 12:17:13.870 # Server started, Redis version 3.2.12\n1:M 21 Mar 12:17:13.870 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Mar 12:17:13.870 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar 21 12:17:14.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-ph6xt'
Mar 21 12:17:15.229: INFO: stderr: ""
Mar 21 12:17:15.229: INFO: stdout: "service/rm2 exposed\n"
Mar 21 12:17:15.233: INFO: Service rm2 in namespace e2e-tests-kubectl-ph6xt found.
STEP: exposing service
Mar 21 12:17:17.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-ph6xt'
Mar 21 12:17:17.772: INFO: stderr: ""
Mar 21 12:17:17.772: INFO: stdout: "service/rm3 exposed\n"
Mar 21 12:17:17.775: INFO: Service rm3 in namespace e2e-tests-kubectl-ph6xt found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:17:20.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ph6xt" for this suite.
Mar 21 12:17:28.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:17:28.482: INFO: namespace: e2e-tests-kubectl-ph6xt, resource: bindings, ignored listing per whitelist
Mar 21 12:17:28.515: INFO: namespace e2e-tests-kubectl-ph6xt deletion completed in 8.098911473s

• [SLOW TEST:16.158 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:17:28.515: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:17:28.593: INFO: Creating ReplicaSet my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b
Mar 21 12:17:29.032: INFO: Pod name my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b: Found 0 pods out of 1
Mar 21 12:17:34.037: INFO: Pod name my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b: Found 1 pods out of 1
Mar 21 12:17:34.037: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b" is running
Mar 21 12:17:34.040: INFO: Pod "my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b-f7stf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:17:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:17:31 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:17:31 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-21 12:17:29 +0000 UTC Reason: Message:}])
Mar 21 12:17:34.040: INFO: Trying to dial the pod
Mar 21 12:17:39.055: INFO: Controller my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b: Got expected result from replica 1 [my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b-f7stf]: "my-hostname-basic-4b5ace8a-4bd3-11e9-9c6a-0a581900021b-f7stf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:17:39.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-z5jrx" for this suite.
Mar 21 12:17:47.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:17:47.118: INFO: namespace: e2e-tests-replicaset-z5jrx, resource: bindings, ignored listing per whitelist
Mar 21 12:17:47.170: INFO: namespace e2e-tests-replicaset-z5jrx deletion completed in 8.108721385s

• [SLOW TEST:18.654 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:17:47.170: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 21 12:17:47.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9tpjn'
Mar 21 12:17:47.912: INFO: stderr: ""
Mar 21 12:17:47.912: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Mar 21 12:17:47.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-9tpjn'
Mar 21 12:17:50.264: INFO: stderr: ""
Mar 21 12:17:50.264: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:17:50.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9tpjn" for this suite.
Mar 21 12:17:56.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:17:56.386: INFO: namespace: e2e-tests-kubectl-9tpjn, resource: bindings, ignored listing per whitelist
Mar 21 12:17:56.395: INFO: namespace e2e-tests-kubectl-9tpjn deletion completed in 6.12348099s

• [SLOW TEST:9.225 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:17:56.396: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:17:58.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-m2rng" for this suite.
Mar 21 12:18:42.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:18:42.580: INFO: namespace: e2e-tests-kubelet-test-m2rng, resource: bindings, ignored listing per whitelist
Mar 21 12:18:42.604: INFO: namespace e2e-tests-kubelet-test-m2rng deletion completed in 44.106505545s

• [SLOW TEST:46.209 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:18:42.605: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar 21 12:18:42.696: INFO: Waiting up to 5m0s for pod "var-expansion-77850def-4bd3-11e9-9c6a-0a581900021b" in namespace "e2e-tests-var-expansion-h8wsp" to be "success or failure"
Mar 21 12:18:42.699: INFO: Pod "var-expansion-77850def-4bd3-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.210156ms
Mar 21 12:18:44.703: INFO: Pod "var-expansion-77850def-4bd3-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00696907s
STEP: Saw pod success
Mar 21 12:18:44.703: INFO: Pod "var-expansion-77850def-4bd3-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:18:44.707: INFO: Trying to get logs from node jaguar pod var-expansion-77850def-4bd3-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 12:18:44.727: INFO: Waiting for pod var-expansion-77850def-4bd3-11e9-9c6a-0a581900021b to disappear
Mar 21 12:18:44.729: INFO: Pod var-expansion-77850def-4bd3-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:18:44.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-h8wsp" for this suite.
Mar 21 12:18:50.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:18:50.796: INFO: namespace: e2e-tests-var-expansion-h8wsp, resource: bindings, ignored listing per whitelist
Mar 21 12:18:50.850: INFO: namespace e2e-tests-var-expansion-h8wsp deletion completed in 6.117072982s

• [SLOW TEST:8.245 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:18:50.851: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:18:50.986: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"7c7416f1-4bd3-11e9-8b3c-9eae6a3150d7", Controller:(*bool)(0xc001e75692), BlockOwnerDeletion:(*bool)(0xc001e75693)}}
Mar 21 12:18:50.990: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"7c7263ec-4bd3-11e9-8b3c-9eae6a3150d7", Controller:(*bool)(0xc00193320e), BlockOwnerDeletion:(*bool)(0xc00193320f)}}
Mar 21 12:18:50.995: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"7c731667-4bd3-11e9-8b3c-9eae6a3150d7", Controller:(*bool)(0xc001e44aae), BlockOwnerDeletion:(*bool)(0xc001e44aaf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:18:56.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h7wzt" for this suite.
Mar 21 12:19:06.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:19:06.083: INFO: namespace: e2e-tests-gc-h7wzt, resource: bindings, ignored listing per whitelist
Mar 21 12:19:06.131: INFO: namespace e2e-tests-gc-h7wzt deletion completed in 10.120369702s

• [SLOW TEST:15.280 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:19:06.131: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 21 12:19:06.225: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:19:14.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-s7k9t" for this suite.
Mar 21 12:19:20.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:19:21.026: INFO: namespace: e2e-tests-init-container-s7k9t, resource: bindings, ignored listing per whitelist
Mar 21 12:19:21.082: INFO: namespace e2e-tests-init-container-s7k9t deletion completed in 6.138465906s

• [SLOW TEST:14.952 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:19:21.088: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 21 12:19:21.211: INFO: Waiting up to 5m0s for pod "downward-api-8e7a01a4-4bd3-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-nshbw" to be "success or failure"
Mar 21 12:19:21.214: INFO: Pod "downward-api-8e7a01a4-4bd3-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.563841ms
Mar 21 12:19:23.217: INFO: Pod "downward-api-8e7a01a4-4bd3-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006291836s
STEP: Saw pod success
Mar 21 12:19:23.217: INFO: Pod "downward-api-8e7a01a4-4bd3-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:19:23.221: INFO: Trying to get logs from node wolf pod downward-api-8e7a01a4-4bd3-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 12:19:23.242: INFO: Waiting for pod downward-api-8e7a01a4-4bd3-11e9-9c6a-0a581900021b to disappear
Mar 21 12:19:23.247: INFO: Pod downward-api-8e7a01a4-4bd3-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:19:23.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nshbw" for this suite.
Mar 21 12:19:29.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:19:29.313: INFO: namespace: e2e-tests-downward-api-nshbw, resource: bindings, ignored listing per whitelist
Mar 21 12:19:29.365: INFO: namespace e2e-tests-downward-api-nshbw deletion completed in 6.113316177s

• [SLOW TEST:8.277 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:19:29.365: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-93650a5b-4bd3-11e9-9c6a-0a581900021b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-93650a5b-4bd3-11e9-9c6a-0a581900021b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:19:33.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zngd5" for this suite.
Mar 21 12:19:45.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:19:45.597: INFO: namespace: e2e-tests-configmap-zngd5, resource: bindings, ignored listing per whitelist
Mar 21 12:19:45.626: INFO: namespace e2e-tests-configmap-zngd5 deletion completed in 12.113603801s

• [SLOW TEST:16.261 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:19:45.627: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-9d14e6a4-4bd3-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:19:45.719: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9d1568d0-4bd3-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-69nm8" to be "success or failure"
Mar 21 12:19:45.723: INFO: Pod "pod-projected-secrets-9d1568d0-4bd3-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.242705ms
Mar 21 12:19:47.727: INFO: Pod "pod-projected-secrets-9d1568d0-4bd3-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008086506s
STEP: Saw pod success
Mar 21 12:19:47.727: INFO: Pod "pod-projected-secrets-9d1568d0-4bd3-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:19:47.730: INFO: Trying to get logs from node wolf pod pod-projected-secrets-9d1568d0-4bd3-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 12:19:47.746: INFO: Waiting for pod pod-projected-secrets-9d1568d0-4bd3-11e9-9c6a-0a581900021b to disappear
Mar 21 12:19:47.749: INFO: Pod pod-projected-secrets-9d1568d0-4bd3-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:19:47.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-69nm8" for this suite.
Mar 21 12:19:54.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:19:54.675: INFO: namespace: e2e-tests-projected-69nm8, resource: bindings, ignored listing per whitelist
Mar 21 12:19:54.675: INFO: namespace e2e-tests-projected-69nm8 deletion completed in 6.923234383s

• [SLOW TEST:9.048 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:19:54.675: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 21 12:19:54.792: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:19:54.802: INFO: Number of nodes with available pods: 0
Mar 21 12:19:54.802: INFO: Node antelope is running more than one daemon pod
Mar 21 12:19:55.807: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:19:55.812: INFO: Number of nodes with available pods: 0
Mar 21 12:19:55.812: INFO: Node antelope is running more than one daemon pod
Mar 21 12:19:56.807: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:19:56.811: INFO: Number of nodes with available pods: 2
Mar 21 12:19:56.811: INFO: Node wolf is running more than one daemon pod
Mar 21 12:19:57.807: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:19:57.810: INFO: Number of nodes with available pods: 2
Mar 21 12:19:57.810: INFO: Node wolf is running more than one daemon pod
Mar 21 12:19:58.808: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:19:58.813: INFO: Number of nodes with available pods: 3
Mar 21 12:19:58.813: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 21 12:19:59.540: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:19:59.567: INFO: Number of nodes with available pods: 2
Mar 21 12:19:59.567: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:00.571: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:00.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:00.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:01.574: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:01.578: INFO: Number of nodes with available pods: 2
Mar 21 12:20:01.579: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:02.573: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:02.578: INFO: Number of nodes with available pods: 2
Mar 21 12:20:02.578: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:03.571: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:03.574: INFO: Number of nodes with available pods: 2
Mar 21 12:20:03.574: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:04.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:04.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:04.576: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:05.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:05.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:05.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:06.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:06.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:06.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:07.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:07.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:07.576: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:08.574: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:08.578: INFO: Number of nodes with available pods: 2
Mar 21 12:20:08.578: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:09.575: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:09.580: INFO: Number of nodes with available pods: 2
Mar 21 12:20:09.580: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:11.011: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:11.015: INFO: Number of nodes with available pods: 2
Mar 21 12:20:11.015: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:11.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:11.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:11.576: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:12.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:12.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:12.576: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:13.573: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:13.578: INFO: Number of nodes with available pods: 2
Mar 21 12:20:13.578: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:14.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:14.577: INFO: Number of nodes with available pods: 2
Mar 21 12:20:14.577: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:15.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:15.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:15.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:16.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:16.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:16.577: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:17.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:17.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:17.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:18.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:18.578: INFO: Number of nodes with available pods: 2
Mar 21 12:20:18.578: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:19.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:19.580: INFO: Number of nodes with available pods: 2
Mar 21 12:20:19.580: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:20.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:20.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:20.576: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:21.576: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:21.581: INFO: Number of nodes with available pods: 2
Mar 21 12:20:21.581: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:22.571: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:22.574: INFO: Number of nodes with available pods: 2
Mar 21 12:20:22.574: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:23.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:23.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:23.576: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:24.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:24.576: INFO: Number of nodes with available pods: 2
Mar 21 12:20:24.576: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:26.256: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:26.260: INFO: Number of nodes with available pods: 2
Mar 21 12:20:26.260: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:26.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:26.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:26.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:27.853: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:27.857: INFO: Number of nodes with available pods: 2
Mar 21 12:20:27.857: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:30.109: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:30.140: INFO: Number of nodes with available pods: 2
Mar 21 12:20:30.141: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:30.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:30.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:30.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:31.860: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:31.866: INFO: Number of nodes with available pods: 2
Mar 21 12:20:31.866: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:32.572: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:32.575: INFO: Number of nodes with available pods: 2
Mar 21 12:20:32.575: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:20:33.571: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:20:33.574: INFO: Number of nodes with available pods: 3
Mar 21 12:20:33.574: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-4n8wp, will wait for the garbage collector to delete the pods
Mar 21 12:20:33.635: INFO: Deleting DaemonSet.extensions daemon-set took: 5.291888ms
Mar 21 12:20:33.736: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.425257ms
Mar 21 12:21:10.039: INFO: Number of nodes with available pods: 0
Mar 21 12:21:10.039: INFO: Number of running nodes: 0, number of available pods: 0
Mar 21 12:21:10.044: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4n8wp/daemonsets","resourceVersion":"18368"},"items":null}

Mar 21 12:21:10.048: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4n8wp/pods","resourceVersion":"18368"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:21:10.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4n8wp" for this suite.
Mar 21 12:21:17.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:21:17.905: INFO: namespace: e2e-tests-daemonsets-4n8wp, resource: bindings, ignored listing per whitelist
Mar 21 12:21:17.928: INFO: namespace e2e-tests-daemonsets-4n8wp deletion completed in 6.965827941s

• [SLOW TEST:83.253 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:21:17.928: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:21:18.009: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4181df7-4bd3-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-qztq4" to be "success or failure"
Mar 21 12:21:18.015: INFO: Pod "downwardapi-volume-d4181df7-4bd3-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.731786ms
Mar 21 12:21:20.019: INFO: Pod "downwardapi-volume-d4181df7-4bd3-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009548435s
STEP: Saw pod success
Mar 21 12:21:20.019: INFO: Pod "downwardapi-volume-d4181df7-4bd3-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:21:20.022: INFO: Trying to get logs from node antelope pod downwardapi-volume-d4181df7-4bd3-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:21:20.045: INFO: Waiting for pod downwardapi-volume-d4181df7-4bd3-11e9-9c6a-0a581900021b to disappear
Mar 21 12:21:20.049: INFO: Pod downwardapi-volume-d4181df7-4bd3-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:21:20.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qztq4" for this suite.
Mar 21 12:21:28.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:21:28.172: INFO: namespace: e2e-tests-downward-api-qztq4, resource: bindings, ignored listing per whitelist
Mar 21 12:21:28.210: INFO: namespace e2e-tests-downward-api-qztq4 deletion completed in 8.15767462s

• [SLOW TEST:10.282 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:21:28.211: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 21 12:21:28.531: INFO: Pod name wrapped-volume-race-da5c4379-4bd3-11e9-9c6a-0a581900021b: Found 0 pods out of 5
Mar 21 12:21:33.629: INFO: Pod name wrapped-volume-race-da5c4379-4bd3-11e9-9c6a-0a581900021b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-da5c4379-4bd3-11e9-9c6a-0a581900021b in namespace e2e-tests-emptydir-wrapper-brq2t, will wait for the garbage collector to delete the pods
Mar 21 12:21:43.937: INFO: Deleting ReplicationController wrapped-volume-race-da5c4379-4bd3-11e9-9c6a-0a581900021b took: 5.676202ms
Mar 21 12:21:44.238: INFO: Terminating ReplicationController wrapped-volume-race-da5c4379-4bd3-11e9-9c6a-0a581900021b pods took: 300.4256ms
STEP: Creating RC which spawns configmap-volume pods
Mar 21 12:22:31.654: INFO: Pod name wrapped-volume-race-fffbd7aa-4bd3-11e9-9c6a-0a581900021b: Found 0 pods out of 5
Mar 21 12:22:36.661: INFO: Pod name wrapped-volume-race-fffbd7aa-4bd3-11e9-9c6a-0a581900021b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fffbd7aa-4bd3-11e9-9c6a-0a581900021b in namespace e2e-tests-emptydir-wrapper-brq2t, will wait for the garbage collector to delete the pods
Mar 21 12:22:46.762: INFO: Deleting ReplicationController wrapped-volume-race-fffbd7aa-4bd3-11e9-9c6a-0a581900021b took: 13.05627ms
Mar 21 12:22:46.862: INFO: Terminating ReplicationController wrapped-volume-race-fffbd7aa-4bd3-11e9-9c6a-0a581900021b pods took: 100.264959ms
STEP: Creating RC which spawns configmap-volume pods
Mar 21 12:23:31.676: INFO: Pod name wrapped-volume-race-23c2ca98-4bd4-11e9-9c6a-0a581900021b: Found 0 pods out of 5
Mar 21 12:23:36.687: INFO: Pod name wrapped-volume-race-23c2ca98-4bd4-11e9-9c6a-0a581900021b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-23c2ca98-4bd4-11e9-9c6a-0a581900021b in namespace e2e-tests-emptydir-wrapper-brq2t, will wait for the garbage collector to delete the pods
Mar 21 12:23:46.872: INFO: Deleting ReplicationController wrapped-volume-race-23c2ca98-4bd4-11e9-9c6a-0a581900021b took: 106.566005ms
Mar 21 12:23:46.972: INFO: Terminating ReplicationController wrapped-volume-race-23c2ca98-4bd4-11e9-9c6a-0a581900021b pods took: 100.362575ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:24:24.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-brq2t" for this suite.
Mar 21 12:24:30.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:24:31.050: INFO: namespace: e2e-tests-emptydir-wrapper-brq2t, resource: bindings, ignored listing per whitelist
Mar 21 12:24:31.080: INFO: namespace e2e-tests-emptydir-wrapper-brq2t deletion completed in 6.123257346s

• [SLOW TEST:182.869 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:24:31.081: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-gf5w8
I0321 12:24:31.152590      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-gf5w8, replica count: 1
I0321 12:24:32.203975      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0321 12:24:33.205458      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 21 12:24:33.320: INFO: Created: latency-svc-qc9t7
Mar 21 12:24:33.330: INFO: Got endpoints: latency-svc-qc9t7 [24.607938ms]
Mar 21 12:24:33.341: INFO: Created: latency-svc-vf22k
Mar 21 12:24:33.347: INFO: Got endpoints: latency-svc-vf22k [16.802827ms]
Mar 21 12:24:33.349: INFO: Created: latency-svc-fvj5k
Mar 21 12:24:33.351: INFO: Got endpoints: latency-svc-fvj5k [21.048995ms]
Mar 21 12:24:33.358: INFO: Created: latency-svc-j29qc
Mar 21 12:24:33.362: INFO: Got endpoints: latency-svc-j29qc [30.919101ms]
Mar 21 12:24:33.369: INFO: Created: latency-svc-n9sgs
Mar 21 12:24:33.378: INFO: Got endpoints: latency-svc-n9sgs [47.414633ms]
Mar 21 12:24:33.378: INFO: Created: latency-svc-wrdjx
Mar 21 12:24:33.382: INFO: Got endpoints: latency-svc-wrdjx [51.507546ms]
Mar 21 12:24:33.398: INFO: Created: latency-svc-2d8lq
Mar 21 12:24:33.401: INFO: Got endpoints: latency-svc-2d8lq [70.947727ms]
Mar 21 12:24:33.409: INFO: Created: latency-svc-pxxbl
Mar 21 12:24:33.411: INFO: Got endpoints: latency-svc-pxxbl [80.331318ms]
Mar 21 12:24:33.424: INFO: Created: latency-svc-rpwqt
Mar 21 12:24:33.430: INFO: Got endpoints: latency-svc-rpwqt [99.226677ms]
Mar 21 12:24:33.430: INFO: Created: latency-svc-cvhdk
Mar 21 12:24:33.433: INFO: Got endpoints: latency-svc-cvhdk [102.843252ms]
Mar 21 12:24:33.441: INFO: Created: latency-svc-fgxc6
Mar 21 12:24:33.443: INFO: Got endpoints: latency-svc-fgxc6 [112.878312ms]
Mar 21 12:24:33.451: INFO: Created: latency-svc-hfqgj
Mar 21 12:24:33.456: INFO: Got endpoints: latency-svc-hfqgj [125.526813ms]
Mar 21 12:24:33.461: INFO: Created: latency-svc-mlbx6
Mar 21 12:24:33.463: INFO: Got endpoints: latency-svc-mlbx6 [132.871261ms]
Mar 21 12:24:33.470: INFO: Created: latency-svc-9sxvm
Mar 21 12:24:33.472: INFO: Got endpoints: latency-svc-9sxvm [141.391314ms]
Mar 21 12:24:33.488: INFO: Created: latency-svc-m4jf2
Mar 21 12:24:33.490: INFO: Got endpoints: latency-svc-m4jf2 [159.874331ms]
Mar 21 12:24:33.497: INFO: Created: latency-svc-dj76h
Mar 21 12:24:33.506: INFO: Got endpoints: latency-svc-dj76h [174.863535ms]
Mar 21 12:24:33.513: INFO: Created: latency-svc-gmp4n
Mar 21 12:24:33.519: INFO: Created: latency-svc-qkp5t
Mar 21 12:24:33.519: INFO: Got endpoints: latency-svc-gmp4n [172.295817ms]
Mar 21 12:24:33.527: INFO: Got endpoints: latency-svc-qkp5t [21.148323ms]
Mar 21 12:24:33.530: INFO: Created: latency-svc-f5grl
Mar 21 12:24:33.535: INFO: Got endpoints: latency-svc-f5grl [183.372166ms]
Mar 21 12:24:33.540: INFO: Created: latency-svc-th552
Mar 21 12:24:33.544: INFO: Got endpoints: latency-svc-th552 [181.851973ms]
Mar 21 12:24:33.554: INFO: Created: latency-svc-6hdhs
Mar 21 12:24:33.554: INFO: Got endpoints: latency-svc-6hdhs [176.271809ms]
Mar 21 12:24:33.563: INFO: Created: latency-svc-6pf95
Mar 21 12:24:33.563: INFO: Got endpoints: latency-svc-6pf95 [180.647929ms]
Mar 21 12:24:33.568: INFO: Created: latency-svc-ntksf
Mar 21 12:24:33.573: INFO: Got endpoints: latency-svc-ntksf [171.084923ms]
Mar 21 12:24:33.577: INFO: Created: latency-svc-zxrkl
Mar 21 12:24:33.580: INFO: Got endpoints: latency-svc-zxrkl [169.136533ms]
Mar 21 12:24:33.585: INFO: Created: latency-svc-6kl6h
Mar 21 12:24:33.587: INFO: Got endpoints: latency-svc-6kl6h [156.908847ms]
Mar 21 12:24:33.593: INFO: Created: latency-svc-cjthz
Mar 21 12:24:33.595: INFO: Got endpoints: latency-svc-cjthz [161.93521ms]
Mar 21 12:24:33.598: INFO: Created: latency-svc-qtdr5
Mar 21 12:24:33.602: INFO: Got endpoints: latency-svc-qtdr5 [158.389755ms]
Mar 21 12:24:33.616: INFO: Created: latency-svc-z7d29
Mar 21 12:24:33.617: INFO: Got endpoints: latency-svc-z7d29 [160.456775ms]
Mar 21 12:24:33.618: INFO: Created: latency-svc-7klhq
Mar 21 12:24:33.625: INFO: Got endpoints: latency-svc-7klhq [161.340772ms]
Mar 21 12:24:33.646: INFO: Created: latency-svc-xgmkn
Mar 21 12:24:33.650: INFO: Got endpoints: latency-svc-xgmkn [177.65342ms]
Mar 21 12:24:33.655: INFO: Created: latency-svc-t8f9k
Mar 21 12:24:33.692: INFO: Created: latency-svc-wmjjm
Mar 21 12:24:33.694: INFO: Got endpoints: latency-svc-t8f9k [203.065036ms]
Mar 21 12:24:33.702: INFO: Got endpoints: latency-svc-wmjjm [182.768031ms]
Mar 21 12:24:33.703: INFO: Created: latency-svc-knckb
Mar 21 12:24:33.709: INFO: Got endpoints: latency-svc-knckb [182.578909ms]
Mar 21 12:24:33.721: INFO: Created: latency-svc-jbw8m
Mar 21 12:24:33.726: INFO: Got endpoints: latency-svc-jbw8m [191.410714ms]
Mar 21 12:24:33.727: INFO: Created: latency-svc-5nkz7
Mar 21 12:24:33.728: INFO: Got endpoints: latency-svc-5nkz7 [182.579391ms]
Mar 21 12:24:33.735: INFO: Created: latency-svc-4fnmk
Mar 21 12:24:33.737: INFO: Got endpoints: latency-svc-4fnmk [183.1006ms]
Mar 21 12:24:33.745: INFO: Created: latency-svc-vb4c5
Mar 21 12:24:33.753: INFO: Got endpoints: latency-svc-vb4c5 [190.048317ms]
Mar 21 12:24:33.754: INFO: Created: latency-svc-lgvdm
Mar 21 12:24:33.764: INFO: Created: latency-svc-gbmzj
Mar 21 12:24:33.764: INFO: Got endpoints: latency-svc-lgvdm [191.864663ms]
Mar 21 12:24:33.770: INFO: Created: latency-svc-kz2pd
Mar 21 12:24:33.774: INFO: Got endpoints: latency-svc-gbmzj [194.396444ms]
Mar 21 12:24:33.779: INFO: Created: latency-svc-8ngp8
Mar 21 12:24:33.788: INFO: Created: latency-svc-4j5j5
Mar 21 12:24:33.795: INFO: Created: latency-svc-p4vb9
Mar 21 12:24:33.803: INFO: Created: latency-svc-zmxn4
Mar 21 12:24:33.810: INFO: Created: latency-svc-9mtlp
Mar 21 12:24:33.819: INFO: Created: latency-svc-zbbx5
Mar 21 12:24:33.827: INFO: Created: latency-svc-fb9wz
Mar 21 12:24:33.833: INFO: Got endpoints: latency-svc-kz2pd [245.199751ms]
Mar 21 12:24:33.838: INFO: Created: latency-svc-dnsn4
Mar 21 12:24:33.847: INFO: Created: latency-svc-r86j2
Mar 21 12:24:33.861: INFO: Created: latency-svc-g4gzd
Mar 21 12:24:33.871: INFO: Created: latency-svc-jll4p
Mar 21 12:24:33.875: INFO: Got endpoints: latency-svc-8ngp8 [279.321207ms]
Mar 21 12:24:33.881: INFO: Created: latency-svc-zttm8
Mar 21 12:24:33.896: INFO: Created: latency-svc-xbp9x
Mar 21 12:24:33.900: INFO: Created: latency-svc-bzqkt
Mar 21 12:24:33.908: INFO: Created: latency-svc-xflsj
Mar 21 12:24:33.914: INFO: Created: latency-svc-598gd
Mar 21 12:24:33.924: INFO: Got endpoints: latency-svc-4j5j5 [322.121548ms]
Mar 21 12:24:33.935: INFO: Created: latency-svc-bn8w9
Mar 21 12:24:33.974: INFO: Got endpoints: latency-svc-p4vb9 [357.712272ms]
Mar 21 12:24:33.986: INFO: Created: latency-svc-w7v69
Mar 21 12:24:34.025: INFO: Got endpoints: latency-svc-zmxn4 [399.861115ms]
Mar 21 12:24:34.036: INFO: Created: latency-svc-p9chs
Mar 21 12:24:34.076: INFO: Got endpoints: latency-svc-9mtlp [425.940442ms]
Mar 21 12:24:34.094: INFO: Created: latency-svc-xhgsr
Mar 21 12:24:34.133: INFO: Got endpoints: latency-svc-zbbx5 [438.962008ms]
Mar 21 12:24:34.145: INFO: Created: latency-svc-bnhh5
Mar 21 12:24:34.176: INFO: Got endpoints: latency-svc-fb9wz [474.010792ms]
Mar 21 12:24:34.187: INFO: Created: latency-svc-92hh6
Mar 21 12:24:34.225: INFO: Got endpoints: latency-svc-dnsn4 [515.395017ms]
Mar 21 12:24:34.239: INFO: Created: latency-svc-cl88k
Mar 21 12:24:34.275: INFO: Got endpoints: latency-svc-r86j2 [548.476354ms]
Mar 21 12:24:34.286: INFO: Created: latency-svc-l9c59
Mar 21 12:24:34.325: INFO: Got endpoints: latency-svc-g4gzd [596.750156ms]
Mar 21 12:24:34.349: INFO: Created: latency-svc-qn4kh
Mar 21 12:24:34.375: INFO: Got endpoints: latency-svc-jll4p [637.053596ms]
Mar 21 12:24:34.385: INFO: Created: latency-svc-gg7gr
Mar 21 12:24:34.424: INFO: Got endpoints: latency-svc-zttm8 [671.264604ms]
Mar 21 12:24:34.435: INFO: Created: latency-svc-fvmvx
Mar 21 12:24:34.475: INFO: Got endpoints: latency-svc-xbp9x [710.186219ms]
Mar 21 12:24:34.488: INFO: Created: latency-svc-rx659
Mar 21 12:24:34.524: INFO: Got endpoints: latency-svc-bzqkt [750.148625ms]
Mar 21 12:24:34.535: INFO: Created: latency-svc-rwjm2
Mar 21 12:24:34.575: INFO: Got endpoints: latency-svc-xflsj [742.334325ms]
Mar 21 12:24:34.586: INFO: Created: latency-svc-dbmlg
Mar 21 12:24:34.625: INFO: Got endpoints: latency-svc-598gd [749.728859ms]
Mar 21 12:24:34.636: INFO: Created: latency-svc-7hlmp
Mar 21 12:24:34.675: INFO: Got endpoints: latency-svc-bn8w9 [751.085497ms]
Mar 21 12:24:34.686: INFO: Created: latency-svc-v85qh
Mar 21 12:24:34.724: INFO: Got endpoints: latency-svc-w7v69 [749.919725ms]
Mar 21 12:24:34.735: INFO: Created: latency-svc-7vfgt
Mar 21 12:24:34.775: INFO: Got endpoints: latency-svc-p9chs [749.512364ms]
Mar 21 12:24:34.785: INFO: Created: latency-svc-lwrvn
Mar 21 12:24:34.824: INFO: Got endpoints: latency-svc-xhgsr [748.691287ms]
Mar 21 12:24:34.836: INFO: Created: latency-svc-rkmfc
Mar 21 12:24:34.875: INFO: Got endpoints: latency-svc-bnhh5 [742.241349ms]
Mar 21 12:24:34.888: INFO: Created: latency-svc-qtj2l
Mar 21 12:24:34.924: INFO: Got endpoints: latency-svc-92hh6 [747.732791ms]
Mar 21 12:24:34.940: INFO: Created: latency-svc-89kff
Mar 21 12:24:34.974: INFO: Got endpoints: latency-svc-cl88k [748.911073ms]
Mar 21 12:24:34.984: INFO: Created: latency-svc-vqghs
Mar 21 12:24:35.024: INFO: Got endpoints: latency-svc-l9c59 [749.204116ms]
Mar 21 12:24:35.035: INFO: Created: latency-svc-9h94m
Mar 21 12:24:35.074: INFO: Got endpoints: latency-svc-qn4kh [749.569707ms]
Mar 21 12:24:35.085: INFO: Created: latency-svc-89825
Mar 21 12:24:35.124: INFO: Got endpoints: latency-svc-gg7gr [748.944357ms]
Mar 21 12:24:35.133: INFO: Created: latency-svc-79znh
Mar 21 12:24:35.175: INFO: Got endpoints: latency-svc-fvmvx [749.965046ms]
Mar 21 12:24:35.188: INFO: Created: latency-svc-k57cd
Mar 21 12:24:35.225: INFO: Got endpoints: latency-svc-rx659 [749.85594ms]
Mar 21 12:24:35.242: INFO: Created: latency-svc-tlpmp
Mar 21 12:24:35.275: INFO: Got endpoints: latency-svc-rwjm2 [750.182309ms]
Mar 21 12:24:35.286: INFO: Created: latency-svc-blsnj
Mar 21 12:24:35.325: INFO: Got endpoints: latency-svc-dbmlg [749.770486ms]
Mar 21 12:24:35.336: INFO: Created: latency-svc-j2ff8
Mar 21 12:24:35.375: INFO: Got endpoints: latency-svc-7hlmp [750.283255ms]
Mar 21 12:24:35.388: INFO: Created: latency-svc-72jhc
Mar 21 12:24:35.425: INFO: Got endpoints: latency-svc-v85qh [749.541501ms]
Mar 21 12:24:35.435: INFO: Created: latency-svc-6x6zf
Mar 21 12:24:35.476: INFO: Got endpoints: latency-svc-7vfgt [751.095523ms]
Mar 21 12:24:35.489: INFO: Created: latency-svc-pvp7z
Mar 21 12:24:35.528: INFO: Got endpoints: latency-svc-lwrvn [753.685744ms]
Mar 21 12:24:35.546: INFO: Created: latency-svc-4czmd
Mar 21 12:24:35.574: INFO: Got endpoints: latency-svc-rkmfc [749.470747ms]
Mar 21 12:24:35.589: INFO: Created: latency-svc-cntnj
Mar 21 12:24:35.624: INFO: Got endpoints: latency-svc-qtj2l [748.965973ms]
Mar 21 12:24:35.639: INFO: Created: latency-svc-p6vvj
Mar 21 12:24:35.676: INFO: Got endpoints: latency-svc-89kff [751.78776ms]
Mar 21 12:24:35.689: INFO: Created: latency-svc-hrlml
Mar 21 12:24:35.725: INFO: Got endpoints: latency-svc-vqghs [751.122944ms]
Mar 21 12:24:35.748: INFO: Created: latency-svc-45wnf
Mar 21 12:24:35.775: INFO: Got endpoints: latency-svc-9h94m [750.320924ms]
Mar 21 12:24:35.786: INFO: Created: latency-svc-jmckh
Mar 21 12:24:35.825: INFO: Got endpoints: latency-svc-89825 [750.497419ms]
Mar 21 12:24:35.841: INFO: Created: latency-svc-7wtdh
Mar 21 12:24:35.875: INFO: Got endpoints: latency-svc-79znh [751.487788ms]
Mar 21 12:24:35.886: INFO: Created: latency-svc-hrn57
Mar 21 12:24:35.928: INFO: Got endpoints: latency-svc-k57cd [752.862083ms]
Mar 21 12:24:35.942: INFO: Created: latency-svc-p6tqq
Mar 21 12:24:35.974: INFO: Got endpoints: latency-svc-tlpmp [749.156214ms]
Mar 21 12:24:36.010: INFO: Created: latency-svc-d4rxc
Mar 21 12:24:36.029: INFO: Got endpoints: latency-svc-blsnj [754.013439ms]
Mar 21 12:24:36.050: INFO: Created: latency-svc-sntg5
Mar 21 12:24:36.075: INFO: Got endpoints: latency-svc-j2ff8 [749.642751ms]
Mar 21 12:24:36.087: INFO: Created: latency-svc-7qkxx
Mar 21 12:24:36.124: INFO: Got endpoints: latency-svc-72jhc [749.487101ms]
Mar 21 12:24:36.136: INFO: Created: latency-svc-n8p7j
Mar 21 12:24:36.176: INFO: Got endpoints: latency-svc-6x6zf [750.959721ms]
Mar 21 12:24:36.189: INFO: Created: latency-svc-2vgs9
Mar 21 12:24:36.225: INFO: Got endpoints: latency-svc-pvp7z [749.132814ms]
Mar 21 12:24:36.243: INFO: Created: latency-svc-bz8dz
Mar 21 12:24:36.275: INFO: Got endpoints: latency-svc-4czmd [746.151783ms]
Mar 21 12:24:36.287: INFO: Created: latency-svc-wtz5r
Mar 21 12:24:36.327: INFO: Got endpoints: latency-svc-cntnj [750.346285ms]
Mar 21 12:24:36.341: INFO: Created: latency-svc-9r5k5
Mar 21 12:24:36.375: INFO: Got endpoints: latency-svc-p6vvj [751.011337ms]
Mar 21 12:24:36.386: INFO: Created: latency-svc-np6hb
Mar 21 12:24:36.424: INFO: Got endpoints: latency-svc-hrlml [747.471011ms]
Mar 21 12:24:36.434: INFO: Created: latency-svc-h4vbc
Mar 21 12:24:36.479: INFO: Got endpoints: latency-svc-45wnf [753.382591ms]
Mar 21 12:24:36.497: INFO: Created: latency-svc-xd6gp
Mar 21 12:24:36.525: INFO: Got endpoints: latency-svc-jmckh [750.044624ms]
Mar 21 12:24:36.570: INFO: Created: latency-svc-plgmc
Mar 21 12:24:36.574: INFO: Got endpoints: latency-svc-7wtdh [749.489873ms]
Mar 21 12:24:36.586: INFO: Created: latency-svc-lxxwm
Mar 21 12:24:36.625: INFO: Got endpoints: latency-svc-hrn57 [749.498715ms]
Mar 21 12:24:36.637: INFO: Created: latency-svc-5sqst
Mar 21 12:24:36.675: INFO: Got endpoints: latency-svc-p6tqq [746.7399ms]
Mar 21 12:24:36.687: INFO: Created: latency-svc-8plkz
Mar 21 12:24:36.724: INFO: Got endpoints: latency-svc-d4rxc [750.253742ms]
Mar 21 12:24:36.735: INFO: Created: latency-svc-fl9w2
Mar 21 12:24:36.777: INFO: Got endpoints: latency-svc-sntg5 [748.459163ms]
Mar 21 12:24:36.789: INFO: Created: latency-svc-pfpjq
Mar 21 12:24:36.827: INFO: Got endpoints: latency-svc-7qkxx [752.39421ms]
Mar 21 12:24:36.841: INFO: Created: latency-svc-xlqgv
Mar 21 12:24:36.874: INFO: Got endpoints: latency-svc-n8p7j [749.347594ms]
Mar 21 12:24:36.890: INFO: Created: latency-svc-59s5v
Mar 21 12:24:36.925: INFO: Got endpoints: latency-svc-2vgs9 [748.500019ms]
Mar 21 12:24:36.938: INFO: Created: latency-svc-sw52c
Mar 21 12:24:36.975: INFO: Got endpoints: latency-svc-bz8dz [749.601142ms]
Mar 21 12:24:36.988: INFO: Created: latency-svc-56zd2
Mar 21 12:24:37.024: INFO: Got endpoints: latency-svc-wtz5r [749.299995ms]
Mar 21 12:24:37.035: INFO: Created: latency-svc-f94tv
Mar 21 12:24:37.074: INFO: Got endpoints: latency-svc-9r5k5 [746.974426ms]
Mar 21 12:24:37.091: INFO: Created: latency-svc-9wrvz
Mar 21 12:24:37.133: INFO: Got endpoints: latency-svc-np6hb [757.73303ms]
Mar 21 12:24:37.146: INFO: Created: latency-svc-mfjl7
Mar 21 12:24:37.174: INFO: Got endpoints: latency-svc-h4vbc [750.217017ms]
Mar 21 12:24:37.187: INFO: Created: latency-svc-rr242
Mar 21 12:24:37.236: INFO: Got endpoints: latency-svc-xd6gp [757.356626ms]
Mar 21 12:24:37.254: INFO: Created: latency-svc-nl824
Mar 21 12:24:37.291: INFO: Got endpoints: latency-svc-plgmc [766.800256ms]
Mar 21 12:24:37.309: INFO: Created: latency-svc-vpsr7
Mar 21 12:24:37.325: INFO: Got endpoints: latency-svc-lxxwm [750.6161ms]
Mar 21 12:24:37.338: INFO: Created: latency-svc-gj99b
Mar 21 12:24:37.378: INFO: Got endpoints: latency-svc-5sqst [753.4566ms]
Mar 21 12:24:37.391: INFO: Created: latency-svc-glptt
Mar 21 12:24:37.424: INFO: Got endpoints: latency-svc-8plkz [749.386237ms]
Mar 21 12:24:37.437: INFO: Created: latency-svc-7vrcb
Mar 21 12:24:37.474: INFO: Got endpoints: latency-svc-fl9w2 [749.974528ms]
Mar 21 12:24:37.489: INFO: Created: latency-svc-4mr9p
Mar 21 12:24:37.525: INFO: Got endpoints: latency-svc-pfpjq [747.076327ms]
Mar 21 12:24:37.536: INFO: Created: latency-svc-mnqn8
Mar 21 12:24:37.582: INFO: Got endpoints: latency-svc-xlqgv [754.593187ms]
Mar 21 12:24:37.592: INFO: Created: latency-svc-9hltp
Mar 21 12:24:37.625: INFO: Got endpoints: latency-svc-59s5v [750.134005ms]
Mar 21 12:24:37.636: INFO: Created: latency-svc-hkb7j
Mar 21 12:24:37.677: INFO: Got endpoints: latency-svc-sw52c [752.746259ms]
Mar 21 12:24:37.695: INFO: Created: latency-svc-nctt5
Mar 21 12:24:37.725: INFO: Got endpoints: latency-svc-56zd2 [749.956697ms]
Mar 21 12:24:37.737: INFO: Created: latency-svc-ndn4c
Mar 21 12:24:37.774: INFO: Got endpoints: latency-svc-f94tv [750.183254ms]
Mar 21 12:24:37.787: INFO: Created: latency-svc-njb5r
Mar 21 12:24:37.829: INFO: Got endpoints: latency-svc-9wrvz [754.777095ms]
Mar 21 12:24:37.845: INFO: Created: latency-svc-2mhgq
Mar 21 12:24:37.874: INFO: Got endpoints: latency-svc-mfjl7 [741.146986ms]
Mar 21 12:24:37.885: INFO: Created: latency-svc-svqd8
Mar 21 12:24:37.925: INFO: Got endpoints: latency-svc-rr242 [751.167338ms]
Mar 21 12:24:37.936: INFO: Created: latency-svc-z9z4f
Mar 21 12:24:37.976: INFO: Got endpoints: latency-svc-nl824 [740.110699ms]
Mar 21 12:24:37.986: INFO: Created: latency-svc-xr4h8
Mar 21 12:24:38.024: INFO: Got endpoints: latency-svc-vpsr7 [732.244756ms]
Mar 21 12:24:38.033: INFO: Created: latency-svc-zchb6
Mar 21 12:24:38.077: INFO: Got endpoints: latency-svc-gj99b [751.864204ms]
Mar 21 12:24:38.086: INFO: Created: latency-svc-2pnsj
Mar 21 12:24:38.126: INFO: Got endpoints: latency-svc-glptt [748.011706ms]
Mar 21 12:24:38.137: INFO: Created: latency-svc-pzjjw
Mar 21 12:24:38.174: INFO: Got endpoints: latency-svc-7vrcb [750.131177ms]
Mar 21 12:24:38.194: INFO: Created: latency-svc-wb629
Mar 21 12:24:38.225: INFO: Got endpoints: latency-svc-4mr9p [750.746008ms]
Mar 21 12:24:38.239: INFO: Created: latency-svc-77xj6
Mar 21 12:24:38.274: INFO: Got endpoints: latency-svc-mnqn8 [749.323162ms]
Mar 21 12:24:38.285: INFO: Created: latency-svc-kxcg4
Mar 21 12:24:38.331: INFO: Got endpoints: latency-svc-9hltp [749.176244ms]
Mar 21 12:24:38.345: INFO: Created: latency-svc-96fwx
Mar 21 12:24:38.374: INFO: Got endpoints: latency-svc-hkb7j [749.473185ms]
Mar 21 12:24:38.390: INFO: Created: latency-svc-fb2rh
Mar 21 12:24:38.427: INFO: Got endpoints: latency-svc-nctt5 [749.387255ms]
Mar 21 12:24:38.456: INFO: Created: latency-svc-gcx92
Mar 21 12:24:38.482: INFO: Got endpoints: latency-svc-ndn4c [756.939041ms]
Mar 21 12:24:38.492: INFO: Created: latency-svc-55wm9
Mar 21 12:24:38.525: INFO: Got endpoints: latency-svc-njb5r [750.193293ms]
Mar 21 12:24:38.538: INFO: Created: latency-svc-5dwdk
Mar 21 12:24:38.576: INFO: Got endpoints: latency-svc-2mhgq [746.76094ms]
Mar 21 12:24:38.595: INFO: Created: latency-svc-6w6dw
Mar 21 12:24:38.624: INFO: Got endpoints: latency-svc-svqd8 [749.784991ms]
Mar 21 12:24:38.645: INFO: Created: latency-svc-4zzk2
Mar 21 12:24:38.674: INFO: Got endpoints: latency-svc-z9z4f [748.564582ms]
Mar 21 12:24:38.687: INFO: Created: latency-svc-gw8vr
Mar 21 12:24:38.727: INFO: Got endpoints: latency-svc-xr4h8 [750.334817ms]
Mar 21 12:24:38.740: INFO: Created: latency-svc-5xp4v
Mar 21 12:24:38.774: INFO: Got endpoints: latency-svc-zchb6 [749.869923ms]
Mar 21 12:24:38.783: INFO: Created: latency-svc-rb8c7
Mar 21 12:24:38.833: INFO: Got endpoints: latency-svc-2pnsj [755.516831ms]
Mar 21 12:24:38.843: INFO: Created: latency-svc-8sgcz
Mar 21 12:24:38.878: INFO: Got endpoints: latency-svc-pzjjw [751.610158ms]
Mar 21 12:24:38.897: INFO: Created: latency-svc-7mwhn
Mar 21 12:24:38.931: INFO: Got endpoints: latency-svc-wb629 [757.160729ms]
Mar 21 12:24:38.943: INFO: Created: latency-svc-5j7r5
Mar 21 12:24:38.981: INFO: Got endpoints: latency-svc-77xj6 [755.200185ms]
Mar 21 12:24:39.000: INFO: Created: latency-svc-x5j6w
Mar 21 12:24:39.025: INFO: Got endpoints: latency-svc-kxcg4 [750.546556ms]
Mar 21 12:24:39.040: INFO: Created: latency-svc-k5k2x
Mar 21 12:24:39.077: INFO: Got endpoints: latency-svc-96fwx [745.301948ms]
Mar 21 12:24:39.089: INFO: Created: latency-svc-z49jt
Mar 21 12:24:39.124: INFO: Got endpoints: latency-svc-fb2rh [749.07387ms]
Mar 21 12:24:39.153: INFO: Created: latency-svc-bm55k
Mar 21 12:24:39.174: INFO: Got endpoints: latency-svc-gcx92 [746.784501ms]
Mar 21 12:24:39.183: INFO: Created: latency-svc-z9sft
Mar 21 12:24:39.231: INFO: Got endpoints: latency-svc-55wm9 [748.712804ms]
Mar 21 12:24:39.243: INFO: Created: latency-svc-xsf6d
Mar 21 12:24:39.275: INFO: Got endpoints: latency-svc-5dwdk [749.794701ms]
Mar 21 12:24:39.285: INFO: Created: latency-svc-8pzx5
Mar 21 12:24:39.326: INFO: Got endpoints: latency-svc-6w6dw [750.722753ms]
Mar 21 12:24:39.343: INFO: Created: latency-svc-jdzs5
Mar 21 12:24:39.384: INFO: Got endpoints: latency-svc-4zzk2 [760.079239ms]
Mar 21 12:24:39.396: INFO: Created: latency-svc-nnc8m
Mar 21 12:24:39.424: INFO: Got endpoints: latency-svc-gw8vr [749.595163ms]
Mar 21 12:24:39.436: INFO: Created: latency-svc-6qb8k
Mar 21 12:24:39.477: INFO: Got endpoints: latency-svc-5xp4v [750.079979ms]
Mar 21 12:24:39.486: INFO: Created: latency-svc-mbgn5
Mar 21 12:24:39.525: INFO: Got endpoints: latency-svc-rb8c7 [750.190735ms]
Mar 21 12:24:39.534: INFO: Created: latency-svc-6tdlg
Mar 21 12:24:39.575: INFO: Got endpoints: latency-svc-8sgcz [741.856714ms]
Mar 21 12:24:39.590: INFO: Created: latency-svc-48brv
Mar 21 12:24:39.624: INFO: Got endpoints: latency-svc-7mwhn [745.811664ms]
Mar 21 12:24:39.636: INFO: Created: latency-svc-bqgmk
Mar 21 12:24:39.674: INFO: Got endpoints: latency-svc-5j7r5 [742.539069ms]
Mar 21 12:24:39.691: INFO: Created: latency-svc-wnvqp
Mar 21 12:24:39.724: INFO: Got endpoints: latency-svc-x5j6w [743.234001ms]
Mar 21 12:24:39.734: INFO: Created: latency-svc-9xbss
Mar 21 12:24:39.774: INFO: Got endpoints: latency-svc-k5k2x [748.899697ms]
Mar 21 12:24:39.785: INFO: Created: latency-svc-r7knq
Mar 21 12:24:39.826: INFO: Got endpoints: latency-svc-z49jt [749.136373ms]
Mar 21 12:24:39.836: INFO: Created: latency-svc-zllzm
Mar 21 12:24:39.875: INFO: Got endpoints: latency-svc-bm55k [750.731081ms]
Mar 21 12:24:39.888: INFO: Created: latency-svc-c9nsl
Mar 21 12:24:39.925: INFO: Got endpoints: latency-svc-z9sft [750.904471ms]
Mar 21 12:24:39.941: INFO: Created: latency-svc-p5jz9
Mar 21 12:24:39.975: INFO: Got endpoints: latency-svc-xsf6d [743.827299ms]
Mar 21 12:24:39.985: INFO: Created: latency-svc-2glr4
Mar 21 12:24:40.025: INFO: Got endpoints: latency-svc-8pzx5 [749.717238ms]
Mar 21 12:24:40.035: INFO: Created: latency-svc-7qs7b
Mar 21 12:24:40.075: INFO: Got endpoints: latency-svc-jdzs5 [748.268906ms]
Mar 21 12:24:40.087: INFO: Created: latency-svc-rw6nt
Mar 21 12:24:40.125: INFO: Got endpoints: latency-svc-nnc8m [740.261169ms]
Mar 21 12:24:40.135: INFO: Created: latency-svc-lnsw2
Mar 21 12:24:40.174: INFO: Got endpoints: latency-svc-6qb8k [750.172668ms]
Mar 21 12:24:40.186: INFO: Created: latency-svc-bf7vd
Mar 21 12:24:40.224: INFO: Got endpoints: latency-svc-mbgn5 [747.389771ms]
Mar 21 12:24:40.235: INFO: Created: latency-svc-2m7dn
Mar 21 12:24:40.274: INFO: Got endpoints: latency-svc-6tdlg [749.562002ms]
Mar 21 12:24:40.296: INFO: Created: latency-svc-c56v2
Mar 21 12:24:40.325: INFO: Got endpoints: latency-svc-48brv [749.450653ms]
Mar 21 12:24:40.334: INFO: Created: latency-svc-8cfwp
Mar 21 12:24:40.374: INFO: Got endpoints: latency-svc-bqgmk [749.469984ms]
Mar 21 12:24:40.383: INFO: Created: latency-svc-dj25q
Mar 21 12:24:40.424: INFO: Got endpoints: latency-svc-wnvqp [750.126603ms]
Mar 21 12:24:40.437: INFO: Created: latency-svc-tpcmn
Mar 21 12:24:40.475: INFO: Got endpoints: latency-svc-9xbss [750.508261ms]
Mar 21 12:24:40.487: INFO: Created: latency-svc-db8lj
Mar 21 12:24:40.528: INFO: Got endpoints: latency-svc-r7knq [753.849129ms]
Mar 21 12:24:40.541: INFO: Created: latency-svc-8z54x
Mar 21 12:24:40.575: INFO: Got endpoints: latency-svc-zllzm [748.981336ms]
Mar 21 12:24:40.585: INFO: Created: latency-svc-6qz7f
Mar 21 12:24:40.625: INFO: Got endpoints: latency-svc-c9nsl [750.110502ms]
Mar 21 12:24:40.642: INFO: Created: latency-svc-bvnz4
Mar 21 12:24:40.674: INFO: Got endpoints: latency-svc-p5jz9 [749.213736ms]
Mar 21 12:24:40.683: INFO: Created: latency-svc-x7rfc
Mar 21 12:24:40.726: INFO: Got endpoints: latency-svc-2glr4 [751.05282ms]
Mar 21 12:24:40.737: INFO: Created: latency-svc-w4c8j
Mar 21 12:24:40.774: INFO: Got endpoints: latency-svc-7qs7b [749.636682ms]
Mar 21 12:24:40.786: INFO: Created: latency-svc-8mjgg
Mar 21 12:24:40.828: INFO: Got endpoints: latency-svc-rw6nt [753.123706ms]
Mar 21 12:24:40.840: INFO: Created: latency-svc-sthcs
Mar 21 12:24:40.874: INFO: Got endpoints: latency-svc-lnsw2 [749.426983ms]
Mar 21 12:24:40.894: INFO: Created: latency-svc-cqll5
Mar 21 12:24:40.925: INFO: Got endpoints: latency-svc-bf7vd [750.506859ms]
Mar 21 12:24:40.952: INFO: Created: latency-svc-b6vnt
Mar 21 12:24:40.975: INFO: Got endpoints: latency-svc-2m7dn [750.954585ms]
Mar 21 12:24:40.990: INFO: Created: latency-svc-chxg9
Mar 21 12:24:41.025: INFO: Got endpoints: latency-svc-c56v2 [750.571554ms]
Mar 21 12:24:41.039: INFO: Created: latency-svc-qhnhj
Mar 21 12:24:41.075: INFO: Got endpoints: latency-svc-8cfwp [749.940951ms]
Mar 21 12:24:41.085: INFO: Created: latency-svc-w7pvr
Mar 21 12:24:41.127: INFO: Got endpoints: latency-svc-dj25q [753.508365ms]
Mar 21 12:24:41.139: INFO: Created: latency-svc-rz8tb
Mar 21 12:24:41.175: INFO: Got endpoints: latency-svc-tpcmn [750.134682ms]
Mar 21 12:24:41.225: INFO: Got endpoints: latency-svc-db8lj [750.361677ms]
Mar 21 12:24:41.279: INFO: Got endpoints: latency-svc-8z54x [751.511268ms]
Mar 21 12:24:41.327: INFO: Got endpoints: latency-svc-6qz7f [752.118882ms]
Mar 21 12:24:41.374: INFO: Got endpoints: latency-svc-bvnz4 [749.320069ms]
Mar 21 12:24:41.425: INFO: Got endpoints: latency-svc-x7rfc [750.253218ms]
Mar 21 12:24:41.479: INFO: Got endpoints: latency-svc-w4c8j [753.08965ms]
Mar 21 12:24:41.530: INFO: Got endpoints: latency-svc-8mjgg [755.707856ms]
Mar 21 12:24:41.577: INFO: Got endpoints: latency-svc-sthcs [749.367396ms]
Mar 21 12:24:41.625: INFO: Got endpoints: latency-svc-cqll5 [750.351821ms]
Mar 21 12:24:41.685: INFO: Got endpoints: latency-svc-b6vnt [759.814275ms]
Mar 21 12:24:41.724: INFO: Got endpoints: latency-svc-chxg9 [748.769592ms]
Mar 21 12:24:41.781: INFO: Got endpoints: latency-svc-qhnhj [755.590787ms]
Mar 21 12:24:41.826: INFO: Got endpoints: latency-svc-w7pvr [751.101599ms]
Mar 21 12:24:41.875: INFO: Got endpoints: latency-svc-rz8tb [747.107569ms]
Mar 21 12:24:41.876: INFO: Latencies: [16.802827ms 21.048995ms 21.148323ms 30.919101ms 47.414633ms 51.507546ms 70.947727ms 80.331318ms 99.226677ms 102.843252ms 112.878312ms 125.526813ms 132.871261ms 141.391314ms 156.908847ms 158.389755ms 159.874331ms 160.456775ms 161.340772ms 161.93521ms 169.136533ms 171.084923ms 172.295817ms 174.863535ms 176.271809ms 177.65342ms 180.647929ms 181.851973ms 182.578909ms 182.579391ms 182.768031ms 183.1006ms 183.372166ms 190.048317ms 191.410714ms 191.864663ms 194.396444ms 203.065036ms 245.199751ms 279.321207ms 322.121548ms 357.712272ms 399.861115ms 425.940442ms 438.962008ms 474.010792ms 515.395017ms 548.476354ms 596.750156ms 637.053596ms 671.264604ms 710.186219ms 732.244756ms 740.110699ms 740.261169ms 741.146986ms 741.856714ms 742.241349ms 742.334325ms 742.539069ms 743.234001ms 743.827299ms 745.301948ms 745.811664ms 746.151783ms 746.7399ms 746.76094ms 746.784501ms 746.974426ms 747.076327ms 747.107569ms 747.389771ms 747.471011ms 747.732791ms 748.011706ms 748.268906ms 748.459163ms 748.500019ms 748.564582ms 748.691287ms 748.712804ms 748.769592ms 748.899697ms 748.911073ms 748.944357ms 748.965973ms 748.981336ms 749.07387ms 749.132814ms 749.136373ms 749.156214ms 749.176244ms 749.204116ms 749.213736ms 749.299995ms 749.320069ms 749.323162ms 749.347594ms 749.367396ms 749.386237ms 749.387255ms 749.426983ms 749.450653ms 749.469984ms 749.470747ms 749.473185ms 749.487101ms 749.489873ms 749.498715ms 749.512364ms 749.541501ms 749.562002ms 749.569707ms 749.595163ms 749.601142ms 749.636682ms 749.642751ms 749.717238ms 749.728859ms 749.770486ms 749.784991ms 749.794701ms 749.85594ms 749.869923ms 749.919725ms 749.940951ms 749.956697ms 749.965046ms 749.974528ms 750.044624ms 750.079979ms 750.110502ms 750.126603ms 750.131177ms 750.134005ms 750.134682ms 750.148625ms 750.172668ms 750.182309ms 750.183254ms 750.190735ms 750.193293ms 750.217017ms 750.253218ms 750.253742ms 750.283255ms 750.320924ms 750.334817ms 750.346285ms 750.351821ms 750.361677ms 750.497419ms 750.506859ms 750.508261ms 750.546556ms 750.571554ms 750.6161ms 750.722753ms 750.731081ms 750.746008ms 750.904471ms 750.954585ms 750.959721ms 751.011337ms 751.05282ms 751.085497ms 751.095523ms 751.101599ms 751.122944ms 751.167338ms 751.487788ms 751.511268ms 751.610158ms 751.78776ms 751.864204ms 752.118882ms 752.39421ms 752.746259ms 752.862083ms 753.08965ms 753.123706ms 753.382591ms 753.4566ms 753.508365ms 753.685744ms 753.849129ms 754.013439ms 754.593187ms 754.777095ms 755.200185ms 755.516831ms 755.590787ms 755.707856ms 756.939041ms 757.160729ms 757.356626ms 757.73303ms 759.814275ms 760.079239ms 766.800256ms]
Mar 21 12:24:41.877: INFO: 50 %ile: 749.387255ms
Mar 21 12:24:41.878: INFO: 90 %ile: 753.123706ms
Mar 21 12:24:41.878: INFO: 99 %ile: 760.079239ms
Mar 21 12:24:41.878: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:24:41.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-gf5w8" for this suite.
Mar 21 12:24:51.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:24:51.957: INFO: namespace: e2e-tests-svc-latency-gf5w8, resource: bindings, ignored listing per whitelist
Mar 21 12:24:52.020: INFO: namespace e2e-tests-svc-latency-gf5w8 deletion completed in 10.130630661s

• [SLOW TEST:20.939 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:24:52.020: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:24:52.184: INFO: Creating deployment "test-recreate-deployment"
Mar 21 12:24:52.187: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 21 12:24:52.193: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar 21 12:24:54.200: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 21 12:24:54.203: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 21 12:24:54.209: INFO: Updating deployment test-recreate-deployment
Mar 21 12:24:54.209: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 21 12:24:54.253: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-shj7v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-shj7v/deployments/test-recreate-deployment,UID:53c1b3b4-4bd4-11e9-8b3c-9eae6a3150d7,ResourceVersion:20892,Generation:2,CreationTimestamp:2019-03-21 12:24:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-21 12:24:54 +0000 UTC 2019-03-21 12:24:54 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-21 12:24:54 +0000 UTC 2019-03-21 12:24:52 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar 21 12:24:54.257: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-shj7v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-shj7v/replicasets/test-recreate-deployment-697fbf54bf,UID:54f9c55b-4bd4-11e9-8b3c-9eae6a3150d7,ResourceVersion:20891,Generation:1,CreationTimestamp:2019-03-21 12:24:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 53c1b3b4-4bd4-11e9-8b3c-9eae6a3150d7 0xc001eb3f77 0xc001eb3f78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 21 12:24:54.257: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 21 12:24:54.257: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-shj7v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-shj7v/replicasets/test-recreate-deployment-5dfdcc846d,UID:53c2d3ed-4bd4-11e9-8b3c-9eae6a3150d7,ResourceVersion:20881,Generation:2,CreationTimestamp:2019-03-21 12:24:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 53c1b3b4-4bd4-11e9-8b3c-9eae6a3150d7 0xc001eb3eb7 0xc001eb3eb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 21 12:24:54.260: INFO: Pod "test-recreate-deployment-697fbf54bf-4nwfg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-4nwfg,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-shj7v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-shj7v/pods/test-recreate-deployment-697fbf54bf-4nwfg,UID:54fa508f-4bd4-11e9-8b3c-9eae6a3150d7,ResourceVersion:20886,Generation:0,CreationTimestamp:2019-03-21 12:24:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 54f9c55b-4bd4-11e9-8b3c-9eae6a3150d7 0xc001630ca7 0xc001630ca8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6n9jw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6n9jw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6n9jw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001630d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001630d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:24:54 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:24:54.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-shj7v" for this suite.
Mar 21 12:25:00.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:25:00.318: INFO: namespace: e2e-tests-deployment-shj7v, resource: bindings, ignored listing per whitelist
Mar 21 12:25:00.358: INFO: namespace e2e-tests-deployment-shj7v deletion completed in 6.093110536s

• [SLOW TEST:8.338 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:25:00.358: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar 21 12:25:00.429: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-434046417 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:25:00.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g7bj2" for this suite.
Mar 21 12:25:06.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:25:06.710: INFO: namespace: e2e-tests-kubectl-g7bj2, resource: bindings, ignored listing per whitelist
Mar 21 12:25:06.738: INFO: namespace e2e-tests-kubectl-g7bj2 deletion completed in 6.1170428s

• [SLOW TEST:6.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:25:06.738: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5c7c9526-4bd4-11e9-9c6a-0a581900021b
STEP: Creating configMap with name cm-test-opt-upd-5c7c9584-4bd4-11e9-9c6a-0a581900021b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5c7c9526-4bd4-11e9-9c6a-0a581900021b
STEP: Updating configmap cm-test-opt-upd-5c7c9584-4bd4-11e9-9c6a-0a581900021b
STEP: Creating configMap with name cm-test-opt-create-5c7c95a8-4bd4-11e9-9c6a-0a581900021b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:26:21.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jqwv2" for this suite.
Mar 21 12:26:43.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:26:43.404: INFO: namespace: e2e-tests-projected-jqwv2, resource: bindings, ignored listing per whitelist
Mar 21 12:26:43.452: INFO: namespace e2e-tests-projected-jqwv2 deletion completed in 22.118337436s

• [SLOW TEST:96.714 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:26:43.453: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:26:45.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zbfmq" for this suite.
Mar 21 12:27:23.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:27:23.658: INFO: namespace: e2e-tests-kubelet-test-zbfmq, resource: bindings, ignored listing per whitelist
Mar 21 12:27:23.677: INFO: namespace e2e-tests-kubelet-test-zbfmq deletion completed in 38.098871415s

• [SLOW TEST:40.225 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:27:23.678: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:27:23.758: INFO: (0) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 6.848204ms)
Mar 21 12:27:23.763: INFO: (1) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.207349ms)
Mar 21 12:27:23.767: INFO: (2) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.374638ms)
Mar 21 12:27:23.771: INFO: (3) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.991272ms)
Mar 21 12:27:23.775: INFO: (4) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.099349ms)
Mar 21 12:27:23.780: INFO: (5) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.16513ms)
Mar 21 12:27:23.785: INFO: (6) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.901718ms)
Mar 21 12:27:23.789: INFO: (7) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.221322ms)
Mar 21 12:27:23.793: INFO: (8) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.038504ms)
Mar 21 12:27:23.797: INFO: (9) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.932462ms)
Mar 21 12:27:23.801: INFO: (10) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.026754ms)
Mar 21 12:27:23.806: INFO: (11) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.145616ms)
Mar 21 12:27:23.810: INFO: (12) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.078206ms)
Mar 21 12:27:23.814: INFO: (13) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.86493ms)
Mar 21 12:27:23.819: INFO: (14) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.879919ms)
Mar 21 12:27:23.824: INFO: (15) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.66602ms)
Mar 21 12:27:23.828: INFO: (16) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.334841ms)
Mar 21 12:27:23.832: INFO: (17) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.802822ms)
Mar 21 12:27:23.837: INFO: (18) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.695146ms)
Mar 21 12:27:23.841: INFO: (19) /api/v1/nodes/antelope:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.737564ms)
[AfterEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:27:23.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-47c6n" for this suite.
Mar 21 12:27:29.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:27:29.921: INFO: namespace: e2e-tests-proxy-47c6n, resource: bindings, ignored listing per whitelist
Mar 21 12:27:29.945: INFO: namespace e2e-tests-proxy-47c6n deletion completed in 6.098928842s

• [SLOW TEST:6.267 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:27:29.946: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:27:30.018: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1d40cc8-4bd4-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-d2n8g" to be "success or failure"
Mar 21 12:27:30.022: INFO: Pod "downwardapi-volume-b1d40cc8-4bd4-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.893164ms
Mar 21 12:27:32.028: INFO: Pod "downwardapi-volume-b1d40cc8-4bd4-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01039963s
STEP: Saw pod success
Mar 21 12:27:32.028: INFO: Pod "downwardapi-volume-b1d40cc8-4bd4-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:27:32.032: INFO: Trying to get logs from node jaguar pod downwardapi-volume-b1d40cc8-4bd4-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:27:32.051: INFO: Waiting for pod downwardapi-volume-b1d40cc8-4bd4-11e9-9c6a-0a581900021b to disappear
Mar 21 12:27:32.054: INFO: Pod downwardapi-volume-b1d40cc8-4bd4-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:27:32.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d2n8g" for this suite.
Mar 21 12:27:38.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:27:38.131: INFO: namespace: e2e-tests-downward-api-d2n8g, resource: bindings, ignored listing per whitelist
Mar 21 12:27:38.155: INFO: namespace e2e-tests-downward-api-d2n8g deletion completed in 6.097195391s

• [SLOW TEST:8.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:27:38.155: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 21 12:27:40.753: INFO: Successfully updated pod "pod-update-b6b87fa5-4bd4-11e9-9c6a-0a581900021b"
STEP: verifying the updated pod is in kubernetes
Mar 21 12:27:40.760: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:27:40.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jz6wt" for this suite.
Mar 21 12:28:02.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:28:02.857: INFO: namespace: e2e-tests-pods-jz6wt, resource: bindings, ignored listing per whitelist
Mar 21 12:28:02.899: INFO: namespace e2e-tests-pods-jz6wt deletion completed in 22.135800882s

• [SLOW TEST:24.744 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:28:02.900: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 21 12:28:02.986: INFO: Waiting up to 5m0s for pod "pod-c57a7678-4bd4-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-x2nb7" to be "success or failure"
Mar 21 12:28:03.001: INFO: Pod "pod-c57a7678-4bd4-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.822081ms
Mar 21 12:28:05.005: INFO: Pod "pod-c57a7678-4bd4-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019202138s
STEP: Saw pod success
Mar 21 12:28:05.005: INFO: Pod "pod-c57a7678-4bd4-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:28:05.008: INFO: Trying to get logs from node wolf pod pod-c57a7678-4bd4-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 12:28:05.026: INFO: Waiting for pod pod-c57a7678-4bd4-11e9-9c6a-0a581900021b to disappear
Mar 21 12:28:05.033: INFO: Pod pod-c57a7678-4bd4-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:28:05.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x2nb7" for this suite.
Mar 21 12:28:11.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:28:11.119: INFO: namespace: e2e-tests-emptydir-x2nb7, resource: bindings, ignored listing per whitelist
Mar 21 12:28:11.144: INFO: namespace e2e-tests-emptydir-x2nb7 deletion completed in 6.104498589s

• [SLOW TEST:8.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:28:11.145: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar 21 12:28:11.230: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar 21 12:28:11.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:11.951: INFO: stderr: ""
Mar 21 12:28:11.951: INFO: stdout: "service/redis-slave created\n"
Mar 21 12:28:11.952: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar 21 12:28:11.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:12.373: INFO: stderr: ""
Mar 21 12:28:12.373: INFO: stdout: "service/redis-master created\n"
Mar 21 12:28:12.373: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 21 12:28:12.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:12.688: INFO: stderr: ""
Mar 21 12:28:12.688: INFO: stdout: "service/frontend created\n"
Mar 21 12:28:12.688: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar 21 12:28:12.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:13.132: INFO: stderr: ""
Mar 21 12:28:13.132: INFO: stdout: "deployment.extensions/frontend created\n"
Mar 21 12:28:13.132: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 21 12:28:13.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:13.560: INFO: stderr: ""
Mar 21 12:28:13.560: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar 21 12:28:13.560: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar 21 12:28:13.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:14.007: INFO: stderr: ""
Mar 21 12:28:14.007: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar 21 12:28:14.007: INFO: Waiting for all frontend pods to be Running.
Mar 21 12:28:29.059: INFO: Waiting for frontend to serve content.
Mar 21 12:28:34.078: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Mar 21 12:28:39.106: INFO: Trying to add a new entry to the guestbook.
Mar 21 12:28:39.126: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 21 12:28:39.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:39.294: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:28:39.294: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 21 12:28:39.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:39.468: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:28:39.468: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 21 12:28:39.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:39.670: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:28:39.670: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 21 12:28:39.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:39.905: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:28:39.905: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 21 12:28:39.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:40.064: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:28:40.064: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 21 12:28:40.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-69p59'
Mar 21 12:28:40.240: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:28:40.240: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:28:40.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-69p59" for this suite.
Mar 21 12:29:22.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:29:22.272: INFO: namespace: e2e-tests-kubectl-69p59, resource: bindings, ignored listing per whitelist
Mar 21 12:29:22.343: INFO: namespace e2e-tests-kubectl-69p59 deletion completed in 42.099790284s

• [SLOW TEST:71.198 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:29:22.344: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar 21 12:29:22.420: INFO: Waiting up to 5m0s for pod "var-expansion-f4d34463-4bd4-11e9-9c6a-0a581900021b" in namespace "e2e-tests-var-expansion-g2rkn" to be "success or failure"
Mar 21 12:29:22.423: INFO: Pod "var-expansion-f4d34463-4bd4-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.877227ms
Mar 21 12:29:24.426: INFO: Pod "var-expansion-f4d34463-4bd4-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0066394s
STEP: Saw pod success
Mar 21 12:29:24.427: INFO: Pod "var-expansion-f4d34463-4bd4-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:29:24.429: INFO: Trying to get logs from node antelope pod var-expansion-f4d34463-4bd4-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 12:29:24.449: INFO: Waiting for pod var-expansion-f4d34463-4bd4-11e9-9c6a-0a581900021b to disappear
Mar 21 12:29:24.453: INFO: Pod var-expansion-f4d34463-4bd4-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:29:24.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-g2rkn" for this suite.
Mar 21 12:29:30.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:29:30.485: INFO: namespace: e2e-tests-var-expansion-g2rkn, resource: bindings, ignored listing per whitelist
Mar 21 12:29:30.547: INFO: namespace e2e-tests-var-expansion-g2rkn deletion completed in 6.090430013s

• [SLOW TEST:8.204 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:29:30.548: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f9b550f8-4bd4-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:29:30.615: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9b5c198-4bd4-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-kj296" to be "success or failure"
Mar 21 12:29:30.618: INFO: Pod "pod-configmaps-f9b5c198-4bd4-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.920084ms
Mar 21 12:29:32.624: INFO: Pod "pod-configmaps-f9b5c198-4bd4-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009516946s
STEP: Saw pod success
Mar 21 12:29:32.624: INFO: Pod "pod-configmaps-f9b5c198-4bd4-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:29:32.628: INFO: Trying to get logs from node jaguar pod pod-configmaps-f9b5c198-4bd4-11e9-9c6a-0a581900021b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 12:29:32.642: INFO: Waiting for pod pod-configmaps-f9b5c198-4bd4-11e9-9c6a-0a581900021b to disappear
Mar 21 12:29:32.644: INFO: Pod pod-configmaps-f9b5c198-4bd4-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:29:32.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kj296" for this suite.
Mar 21 12:29:38.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:29:38.696: INFO: namespace: e2e-tests-configmap-kj296, resource: bindings, ignored listing per whitelist
Mar 21 12:29:38.751: INFO: namespace e2e-tests-configmap-kj296 deletion completed in 6.102641765s

• [SLOW TEST:8.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:29:38.751: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:29:38.824: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 21 12:29:38.836: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 21 12:29:43.840: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 21 12:29:43.840: INFO: Creating deployment "test-rolling-update-deployment"
Mar 21 12:29:43.844: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 21 12:29:43.849: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 21 12:29:45.858: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 21 12:29:45.862: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 21 12:29:45.871: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-gvn5k,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gvn5k/deployments/test-rolling-update-deployment,UID:0198f430-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21815,Generation:1,CreationTimestamp:2019-03-21 12:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-21 12:29:43 +0000 UTC 2019-03-21 12:29:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-21 12:29:45 +0000 UTC 2019-03-21 12:29:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar 21 12:29:45.876: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-gvn5k,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gvn5k/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:019b30d6-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21806,Generation:1,CreationTimestamp:2019-03-21 12:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0198f430-4bd5-11e9-8b3c-9eae6a3150d7 0xc0006ab0c7 0xc0006ab0c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 21 12:29:45.876: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 21 12:29:45.876: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-gvn5k,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gvn5k/replicasets/test-rolling-update-controller,UID:fe9b8823-4bd4-11e9-8b3c-9eae6a3150d7,ResourceVersion:21814,Generation:2,CreationTimestamp:2019-03-21 12:29:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0198f430-4bd5-11e9-8b3c-9eae6a3150d7 0xc0006ab007 0xc0006ab008}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 21 12:29:45.881: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-9g55t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-9g55t,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-gvn5k,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gvn5k/pods/test-rolling-update-deployment-68b55d7bc6-9g55t,UID:019bb4ff-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21805,Generation:0,CreationTimestamp:2019-03-21 12:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 019b30d6-4bd5-11e9-8b3c-9eae6a3150d7 0xc0006ab9f7 0xc0006ab9f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w6lks {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w6lks,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-w6lks true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0006aba70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0006aba90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:43 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:25.0.2.98,StartTime:2019-03-21 12:29:43 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://31fb298c6e2c09da4f206935e22bf7f0999994d49f357c490ac24b2337b577c1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:29:45.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gvn5k" for this suite.
Mar 21 12:29:51.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:29:51.961: INFO: namespace: e2e-tests-deployment-gvn5k, resource: bindings, ignored listing per whitelist
Mar 21 12:29:51.990: INFO: namespace e2e-tests-deployment-gvn5k deletion completed in 6.104236537s

• [SLOW TEST:13.239 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:29:51.991: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:29:52.065: INFO: Creating deployment "nginx-deployment"
Mar 21 12:29:52.068: INFO: Waiting for observed generation 1
Mar 21 12:29:54.075: INFO: Waiting for all required pods to come up
Mar 21 12:29:54.079: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 21 12:30:02.091: INFO: Waiting for deployment "nginx-deployment" to complete
Mar 21 12:30:02.101: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar 21 12:30:02.121: INFO: Updating deployment nginx-deployment
Mar 21 12:30:02.121: INFO: Waiting for observed generation 2
Mar 21 12:30:04.128: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 21 12:30:04.131: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 21 12:30:04.134: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 21 12:30:04.143: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 21 12:30:04.143: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 21 12:30:04.146: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar 21 12:30:04.151: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar 21 12:30:04.151: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar 21 12:30:04.157: INFO: Updating deployment nginx-deployment
Mar 21 12:30:04.157: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar 21 12:30:04.171: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 21 12:30:06.181: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 21 12:30:06.193: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f6z2v/deployments/nginx-deployment,UID:067fef08-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22122,Generation:3,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-03-21 12:30:04 +0000 UTC 2019-03-21 12:30:04 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-21 12:30:04 +0000 UTC 2019-03-21 12:29:52 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar 21 12:30:06.200: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f6z2v/replicasets/nginx-deployment-65bbdb5f8,UID:0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22119,Generation:3,CreationTimestamp:2019-03-21 12:30:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 067fef08-4bd5-11e9-8b3c-9eae6a3150d7 0xc001d5cd67 0xc001d5cd68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar 21 12:30:06.201: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar 21 12:30:06.201: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f6z2v/replicasets/nginx-deployment-555b55d965,UID:06806d3b-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22207,Generation:3,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 067fef08-4bd5-11e9-8b3c-9eae6a3150d7 0xc001d5cca7 0xc001d5cca8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Mar 21 12:30:06.209: INFO: Pod "nginx-deployment-555b55d965-4bshx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4bshx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-4bshx,UID:06832fc6-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21940,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc0025166f7 0xc0025166f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002516770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002516790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:25.0.2.100,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://63bf807cefdfffddd6468694b5e732dc10d8b9e5974929d83b3ebb488bb289d8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.209: INFO: Pod "nginx-deployment-555b55d965-54s7w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-54s7w,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-54s7w,UID:06840457-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21947,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002516850 0xc002516851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025168c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025168e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:25.0.3.83,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://d8d6f6948dd71bc132c31de1e7a0269ad21a9ce14ac306c60f780077a2a427fc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.209: INFO: Pod "nginx-deployment-555b55d965-5t45c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5t45c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-5t45c,UID:0dbcc654-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22146,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc0025169a0 0xc0025169a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002516a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002516a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.209: INFO: Pod "nginx-deployment-555b55d965-88k2b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-88k2b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-88k2b,UID:0684103b-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21987,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002516ae7 0xc002516ae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002516b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002516b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:25.0.1.94,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://43d1c88a314870eec7e88f5b44fd9d33864aa8b6551fe59d86b882171df3a6c8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.210: INFO: Pod "nginx-deployment-555b55d965-8gmps" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8gmps,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-8gmps,UID:0dbcec51-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22206,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002516c40 0xc002516c41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002516cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002516cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:25.0.3.87,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:30:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://b0e598f695e94d1af232854cd80198f41846e9df0af340d0656506d1ba08e0df}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.210: INFO: Pod "nginx-deployment-555b55d965-9m4w9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9m4w9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-9m4w9,UID:0db89f56-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22138,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002516d90 0xc002516d91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002516e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002516e20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.210: INFO: Pod "nginx-deployment-555b55d965-blgk2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-blgk2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-blgk2,UID:0db8771a-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22130,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002516ed7 0xc002516ed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002516f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002516f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.210: INFO: Pod "nginx-deployment-555b55d965-cgvsp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cgvsp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-cgvsp,UID:0db606e4-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22126,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517027 0xc002517028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025170a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025170c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.211: INFO: Pod "nginx-deployment-555b55d965-cvvv5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cvvv5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-cvvv5,UID:0683ff2c-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21943,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517177 0xc002517178}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025171f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:25.0.2.99,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://365e7924f593df41182511d62ec918a93ec7377b913f4801305382b825ebc7e5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.211: INFO: Pod "nginx-deployment-555b55d965-hlkl2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hlkl2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-hlkl2,UID:06854758-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21937,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc0025172d0 0xc0025172d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:25.0.2.101,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://48545c9bb44713352904c3e049ff59fad6f1fb21d178243d51aae207e77cb4c5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.211: INFO: Pod "nginx-deployment-555b55d965-l7ckz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l7ckz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-l7ckz,UID:0db57c6f-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22085,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517420 0xc002517421}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025174b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.211: INFO: Pod "nginx-deployment-555b55d965-lsqbt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lsqbt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-lsqbt,UID:06852961-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21950,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517567 0xc002517568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025175e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:25.0.3.82,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://998339b87c6ef5f88aa4a0fc96acdc9b22be9a0ae1ead25c0ff8dcda7c956bb8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.211: INFO: Pod "nginx-deployment-555b55d965-mqfxt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mqfxt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-mqfxt,UID:0dbcc8f0-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22141,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc0025176c0 0xc0025176c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.212: INFO: Pod "nginx-deployment-555b55d965-mwt58" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mwt58,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-mwt58,UID:0683262e-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21953,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517807 0xc002517808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025178a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:25.0.3.81,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://f949e3c1cfeabd6eaaacbd7fdc1667690bbfcea08efd2547db4b7c72f9435a35}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.212: INFO: Pod "nginx-deployment-555b55d965-pnmkj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pnmkj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-pnmkj,UID:0dbce200-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22163,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517960 0xc002517961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025179d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025179f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.212: INFO: Pod "nginx-deployment-555b55d965-q7b24" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q7b24,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-q7b24,UID:06840b57-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:21978,Generation:0,CreationTimestamp:2019-03-21 12:29:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517aa7 0xc002517aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:29:52 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:25.0.1.96,StartTime:2019-03-21 12:29:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:29:59 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://47ecfc0e52614f6c751ae5e529ebf7a9d85f2ff6ccb588ef5860b860cd664f2c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.212: INFO: Pod "nginx-deployment-555b55d965-s6pxr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s6pxr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-s6pxr,UID:0dbcc786-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22175,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517c00 0xc002517c01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.212: INFO: Pod "nginx-deployment-555b55d965-s9wrn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s9wrn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-s9wrn,UID:0db61f60-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22108,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517d47 0xc002517d48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.213: INFO: Pod "nginx-deployment-555b55d965-v2dzs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-v2dzs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-v2dzs,UID:0db87fca-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22142,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517ea7 0xc002517ea8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002517f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002517f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.213: INFO: Pod "nginx-deployment-555b55d965-w9lrs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w9lrs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-555b55d965-w9lrs,UID:0db874a6-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22179,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 06806d3b-4bd5-11e9-8b3c-9eae6a3150d7 0xc002517ff7 0xc002517ff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002494210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.213: INFO: Pod "nginx-deployment-65bbdb5f8-7djp9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7djp9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-7djp9,UID:0c8bc8e2-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22035,Generation:0,CreationTimestamp:2019-03-21 12:30:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002494417 0xc002494418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024944b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.213: INFO: Pod "nginx-deployment-65bbdb5f8-8cdlj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8cdlj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-8cdlj,UID:0dbc8d73-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22133,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc0024946b0 0xc0024946b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002494750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.213: INFO: Pod "nginx-deployment-65bbdb5f8-drtb8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-drtb8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-drtb8,UID:0db5fb75-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22092,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc0024948f0 0xc0024948f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002494990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.213: INFO: Pod "nginx-deployment-65bbdb5f8-fhr8h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fhr8h,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-fhr8h,UID:0c81a91f-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22180,Generation:0,CreationTimestamp:2019-03-21 12:30:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002494a50 0xc002494a51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002494b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:25.0.3.84,StartTime:2019-03-21 12:30:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.214: INFO: Pod "nginx-deployment-65bbdb5f8-fqftm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fqftm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-fqftm,UID:0db8afc6-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22162,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002494be0 0xc002494be1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002494c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.214: INFO: Pod "nginx-deployment-65bbdb5f8-ghzlk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ghzlk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-ghzlk,UID:0c8dec06-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22165,Generation:0,CreationTimestamp:2019-03-21 12:30:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002494d50 0xc002494d51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002494df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:,StartTime:2019-03-21 12:30:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.214: INFO: Pod "nginx-deployment-65bbdb5f8-jq7z9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jq7z9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-jq7z9,UID:0db9e1e0-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22135,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002494ec0 0xc002494ec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002494f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002494f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.214: INFO: Pod "nginx-deployment-65bbdb5f8-nnmx7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nnmx7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-nnmx7,UID:0db6f776-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22129,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002495020 0xc002495021}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024950a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024950c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.214: INFO: Pod "nginx-deployment-65bbdb5f8-r67bz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-r67bz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-r67bz,UID:0db6fa3f-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22109,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002495180 0xc002495181}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002495200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002495220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.214: INFO: Pod "nginx-deployment-65bbdb5f8-st2qx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-st2qx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-st2qx,UID:0c80496c-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22192,Generation:0,CreationTimestamp:2019-03-21 12:30:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc0024952e0 0xc0024952e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002495360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002495380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:25.0.1.98,StartTime:2019-03-21 12:30:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.215: INFO: Pod "nginx-deployment-65bbdb5f8-vzxg7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vzxg7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-vzxg7,UID:0dba00f6-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22137,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002495460 0xc002495461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024954e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002495500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.215: INFO: Pod "nginx-deployment-65bbdb5f8-x6gh9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x6gh9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-x6gh9,UID:0db9fd79-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22147,Generation:0,CreationTimestamp:2019-03-21 12:30:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc0024955c0 0xc0024955c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:jaguar,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002495640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002495660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:04 +0000 UTC  }],Message:,Reason:,HostIP:178.128.168.147,PodIP:,StartTime:2019-03-21 12:30:04 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar 21 12:30:06.215: INFO: Pod "nginx-deployment-65bbdb5f8-xlmvw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xlmvw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f6z2v,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f6z2v/pods/nginx-deployment-65bbdb5f8-xlmvw,UID:0c81b63d-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:22021,Generation:0,CreationTimestamp:2019-03-21 12:30:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 0c7e5114-4bd5-11e9-8b3c-9eae6a3150d7 0xc002495720 0xc002495721}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tq89f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq89f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tq89f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024957a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024957c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:30:02 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:,StartTime:2019-03-21 12:30:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:30:06.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-f6z2v" for this suite.
Mar 21 12:30:12.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:30:12.254: INFO: namespace: e2e-tests-deployment-f6z2v, resource: bindings, ignored listing per whitelist
Mar 21 12:30:12.340: INFO: namespace e2e-tests-deployment-f6z2v deletion completed in 6.115250919s

• [SLOW TEST:20.349 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:30:12.340: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:30:16.476: INFO: Waiting up to 5m0s for pod "client-envvars-150bdcdf-4bd5-11e9-9c6a-0a581900021b" in namespace "e2e-tests-pods-dnrzn" to be "success or failure"
Mar 21 12:30:16.478: INFO: Pod "client-envvars-150bdcdf-4bd5-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048928ms
Mar 21 12:30:18.481: INFO: Pod "client-envvars-150bdcdf-4bd5-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005612759s
STEP: Saw pod success
Mar 21 12:30:18.481: INFO: Pod "client-envvars-150bdcdf-4bd5-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:30:18.485: INFO: Trying to get logs from node jaguar pod client-envvars-150bdcdf-4bd5-11e9-9c6a-0a581900021b container env3cont: <nil>
STEP: delete the pod
Mar 21 12:30:18.504: INFO: Waiting for pod client-envvars-150bdcdf-4bd5-11e9-9c6a-0a581900021b to disappear
Mar 21 12:30:18.508: INFO: Pod client-envvars-150bdcdf-4bd5-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:30:18.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dnrzn" for this suite.
Mar 21 12:31:04.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:31:04.591: INFO: namespace: e2e-tests-pods-dnrzn, resource: bindings, ignored listing per whitelist
Mar 21 12:31:04.613: INFO: namespace e2e-tests-pods-dnrzn deletion completed in 46.097204873s

• [SLOW TEST:52.273 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:31:04.614: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-31ca5f59-4bd5-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:31:04.706: INFO: Waiting up to 5m0s for pod "pod-secrets-31cad2b8-4bd5-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-tq94t" to be "success or failure"
Mar 21 12:31:04.710: INFO: Pod "pod-secrets-31cad2b8-4bd5-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803908ms
Mar 21 12:31:06.714: INFO: Pod "pod-secrets-31cad2b8-4bd5-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007756807s
STEP: Saw pod success
Mar 21 12:31:06.714: INFO: Pod "pod-secrets-31cad2b8-4bd5-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:31:06.716: INFO: Trying to get logs from node wolf pod pod-secrets-31cad2b8-4bd5-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 12:31:06.736: INFO: Waiting for pod pod-secrets-31cad2b8-4bd5-11e9-9c6a-0a581900021b to disappear
Mar 21 12:31:06.739: INFO: Pod pod-secrets-31cad2b8-4bd5-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:31:06.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tq94t" for this suite.
Mar 21 12:31:12.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:31:12.779: INFO: namespace: e2e-tests-secrets-tq94t, resource: bindings, ignored listing per whitelist
Mar 21 12:31:12.855: INFO: namespace e2e-tests-secrets-tq94t deletion completed in 6.112406035s

• [SLOW TEST:8.242 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:31:12.857: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 21 12:31:16.978: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 21 12:31:16.981: INFO: Pod pod-with-prestop-http-hook still exists
Mar 21 12:31:18.982: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 21 12:31:18.985: INFO: Pod pod-with-prestop-http-hook still exists
Mar 21 12:31:20.981: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 21 12:31:20.985: INFO: Pod pod-with-prestop-http-hook still exists
Mar 21 12:31:22.982: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 21 12:31:22.985: INFO: Pod pod-with-prestop-http-hook still exists
Mar 21 12:31:24.982: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 21 12:31:24.985: INFO: Pod pod-with-prestop-http-hook still exists
Mar 21 12:31:26.981: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 21 12:31:26.985: INFO: Pod pod-with-prestop-http-hook still exists
Mar 21 12:31:28.982: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 21 12:31:28.985: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:31:28.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-p8r22" for this suite.
Mar 21 12:31:51.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:31:51.080: INFO: namespace: e2e-tests-container-lifecycle-hook-p8r22, resource: bindings, ignored listing per whitelist
Mar 21 12:31:51.145: INFO: namespace e2e-tests-container-lifecycle-hook-p8r22 deletion completed in 22.145354406s

• [SLOW TEST:38.288 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:31:51.145: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:31:51.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 version --client'
Mar 21 12:31:51.334: INFO: stderr: ""
Mar 21 12:31:51.334: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:37:52Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar 21 12:31:51.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-pt7n2'
Mar 21 12:31:51.613: INFO: stderr: ""
Mar 21 12:31:51.613: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar 21 12:31:51.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-pt7n2'
Mar 21 12:31:51.976: INFO: stderr: ""
Mar 21 12:31:51.976: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar 21 12:31:52.981: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:31:52.981: INFO: Found 0 / 1
Mar 21 12:31:53.981: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:31:53.981: INFO: Found 1 / 1
Mar 21 12:31:53.981: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 21 12:31:53.984: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:31:53.984: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 21 12:31:53.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 describe pod redis-master-q46zs --namespace=e2e-tests-kubectl-pt7n2'
Mar 21 12:31:54.181: INFO: stderr: ""
Mar 21 12:31:54.181: INFO: stdout: "Name:               redis-master-q46zs\nNamespace:          e2e-tests-kubectl-pt7n2\nPriority:           0\nPriorityClassName:  <none>\nNode:               antelope/104.248.166.121\nStart Time:         Thu, 21 Mar 2019 12:31:51 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 25.0.2.114\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://9b187dff06d7f998e1e0c308f3c5244e16f10ff2cdb9c64e984d15f5288e70a1\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 21 Mar 2019 12:31:52 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-hsbht (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-hsbht:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-hsbht\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned e2e-tests-kubectl-pt7n2/redis-master-q46zs to antelope\n  Normal  Pulled     2s    kubelet, antelope  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, antelope  Created container\n  Normal  Started    2s    kubelet, antelope  Started container\n"
Mar 21 12:31:54.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 describe rc redis-master --namespace=e2e-tests-kubectl-pt7n2'
Mar 21 12:31:54.529: INFO: stderr: ""
Mar 21 12:31:54.529: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-pt7n2\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-q46zs\n"
Mar 21 12:31:54.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 describe service redis-master --namespace=e2e-tests-kubectl-pt7n2'
Mar 21 12:31:54.724: INFO: stderr: ""
Mar 21 12:31:54.724: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-pt7n2\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.106.176.228\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         25.0.2.114:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 21 12:31:54.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 describe node antelope'
Mar 21 12:31:54.932: INFO: stderr: ""
Mar 21 12:31:54.932: INFO: stdout: "Name:               antelope\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=antelope\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"aa:87:34:ae:ea:c1\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 104.248.166.121\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 21 Mar 2019 10:15:53 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 21 Mar 2019 12:31:49 +0000   Thu, 21 Mar 2019 10:15:53 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 21 Mar 2019 12:31:49 +0000   Thu, 21 Mar 2019 10:15:53 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 21 Mar 2019 12:31:49 +0000   Thu, 21 Mar 2019 10:15:53 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 21 Mar 2019 12:31:49 +0000   Thu, 21 Mar 2019 10:16:13 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  104.248.166.121\n  Hostname:    antelope\nCapacity:\n cpu:                4\n ephemeral-storage:  162421080Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8174816Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  149687267081\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8072416Ki\n pods:               110\nSystem Info:\n Machine ID:                 0eea918bb27c48f68284b95176f945cc\n System UUID:                0EEA918B-B27C-48F6-8284-B95176F945CC\n Boot ID:                    5ff0873c-e618-45ea-8156-73a08f023936\n Kernel Version:             4.4.0-143-generic\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.13.4\n Kube-Proxy Version:         v1.13.4\nPodCIDR:                     25.0.2.0/24\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-pt7n2    redis-master-q46zs                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy-e2e-job-0facb6ec3f244997                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         55m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdl77    0 (0%)        0 (0%)      0 (0%)           0 (0%)         55m\n  kube-system                kube-flannel-ds-amd64-rqwz5                                100m (2%)     100m (2%)   50Mi (0%)        50Mi (0%)      136m\n  kube-system                kube-proxy-9hr7b                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         136m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                100m (2%)  100m (2%)\n  memory             50Mi (0%)  50Mi (0%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:              <none>\n"
Mar 21 12:31:54.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 describe namespace e2e-tests-kubectl-pt7n2'
Mar 21 12:31:55.189: INFO: stderr: ""
Mar 21 12:31:55.189: INFO: stdout: "Name:         e2e-tests-kubectl-pt7n2\nLabels:       e2e-framework=kubectl\n              e2e-run=a0052222-4bcd-11e9-9c6a-0a581900021b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:31:55.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pt7n2" for this suite.
Mar 21 12:32:17.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:32:17.263: INFO: namespace: e2e-tests-kubectl-pt7n2, resource: bindings, ignored listing per whitelist
Mar 21 12:32:17.302: INFO: namespace e2e-tests-kubectl-pt7n2 deletion completed in 22.108535581s

• [SLOW TEST:26.158 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:32:17.303: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5d1b4e04-4bd5-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:32:17.379: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5d1bc3dc-4bd5-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-7phjb" to be "success or failure"
Mar 21 12:32:17.383: INFO: Pod "pod-projected-configmaps-5d1bc3dc-4bd5-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.220423ms
Mar 21 12:32:19.389: INFO: Pod "pod-projected-configmaps-5d1bc3dc-4bd5-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00948048s
STEP: Saw pod success
Mar 21 12:32:19.389: INFO: Pod "pod-projected-configmaps-5d1bc3dc-4bd5-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:32:19.392: INFO: Trying to get logs from node jaguar pod pod-projected-configmaps-5d1bc3dc-4bd5-11e9-9c6a-0a581900021b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 12:32:19.413: INFO: Waiting for pod pod-projected-configmaps-5d1bc3dc-4bd5-11e9-9c6a-0a581900021b to disappear
Mar 21 12:32:19.416: INFO: Pod pod-projected-configmaps-5d1bc3dc-4bd5-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:32:19.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7phjb" for this suite.
Mar 21 12:32:25.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:32:25.495: INFO: namespace: e2e-tests-projected-7phjb, resource: bindings, ignored listing per whitelist
Mar 21 12:32:25.525: INFO: namespace e2e-tests-projected-7phjb deletion completed in 6.104696408s

• [SLOW TEST:8.223 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:32:25.526: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 21 12:32:25.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-l9gkk'
Mar 21 12:32:25.732: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 21 12:32:25.732: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar 21 12:32:25.738: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-m9vrx]
Mar 21 12:32:25.738: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-m9vrx" in namespace "e2e-tests-kubectl-l9gkk" to be "running and ready"
Mar 21 12:32:25.741: INFO: Pod "e2e-test-nginx-rc-m9vrx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612581ms
Mar 21 12:32:27.745: INFO: Pod "e2e-test-nginx-rc-m9vrx": Phase="Running", Reason="", readiness=true. Elapsed: 2.006524161s
Mar 21 12:32:27.745: INFO: Pod "e2e-test-nginx-rc-m9vrx" satisfied condition "running and ready"
Mar 21 12:32:27.745: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-m9vrx]
Mar 21 12:32:27.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-l9gkk'
Mar 21 12:32:27.909: INFO: stderr: ""
Mar 21 12:32:27.909: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Mar 21 12:32:27.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-l9gkk'
Mar 21 12:32:28.086: INFO: stderr: ""
Mar 21 12:32:28.086: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:32:28.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l9gkk" for this suite.
Mar 21 12:32:52.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:32:53.028: INFO: namespace: e2e-tests-kubectl-l9gkk, resource: bindings, ignored listing per whitelist
Mar 21 12:32:53.075: INFO: namespace e2e-tests-kubectl-l9gkk deletion completed in 24.983183918s

• [SLOW TEST:27.549 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:32:53.075: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-skbv4/secret-test-726fe7c3-4bd5-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:32:53.166: INFO: Waiting up to 5m0s for pod "pod-configmaps-72707c71-4bd5-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-skbv4" to be "success or failure"
Mar 21 12:32:53.170: INFO: Pod "pod-configmaps-72707c71-4bd5-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.126348ms
Mar 21 12:32:55.173: INFO: Pod "pod-configmaps-72707c71-4bd5-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006830747s
STEP: Saw pod success
Mar 21 12:32:55.173: INFO: Pod "pod-configmaps-72707c71-4bd5-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:32:55.177: INFO: Trying to get logs from node wolf pod pod-configmaps-72707c71-4bd5-11e9-9c6a-0a581900021b container env-test: <nil>
STEP: delete the pod
Mar 21 12:32:55.801: INFO: Waiting for pod pod-configmaps-72707c71-4bd5-11e9-9c6a-0a581900021b to disappear
Mar 21 12:32:55.841: INFO: Pod pod-configmaps-72707c71-4bd5-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:32:55.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-skbv4" for this suite.
Mar 21 12:33:03.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:33:03.876: INFO: namespace: e2e-tests-secrets-skbv4, resource: bindings, ignored listing per whitelist
Mar 21 12:33:03.942: INFO: namespace e2e-tests-secrets-skbv4 deletion completed in 8.09695711s

• [SLOW TEST:10.868 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:33:03.943: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-78e757f9-4bd5-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:33:04.013: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-84c5f" to be "success or failure"
Mar 21 12:33:04.018: INFO: Pod "pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.877341ms
Mar 21 12:33:06.022: INFO: Pod "pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b": Phase="Running", Reason="", readiness=true. Elapsed: 2.008640372s
Mar 21 12:33:08.026: INFO: Pod "pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01245836s
STEP: Saw pod success
Mar 21 12:33:08.026: INFO: Pod "pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:33:08.029: INFO: Trying to get logs from node antelope pod pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 21 12:33:08.046: INFO: Waiting for pod pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b to disappear
Mar 21 12:33:08.048: INFO: Pod pod-projected-secrets-78e7ca8c-4bd5-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:33:08.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-84c5f" for this suite.
Mar 21 12:33:14.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:33:14.100: INFO: namespace: e2e-tests-projected-84c5f, resource: bindings, ignored listing per whitelist
Mar 21 12:33:14.174: INFO: namespace e2e-tests-projected-84c5f deletion completed in 6.120826543s

• [SLOW TEST:10.231 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:33:14.175: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 21 12:33:14.258: INFO: Waiting up to 5m0s for pod "pod-7f02e7f8-4bd5-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-tdfpv" to be "success or failure"
Mar 21 12:33:14.260: INFO: Pod "pod-7f02e7f8-4bd5-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.323125ms
Mar 21 12:33:16.265: INFO: Pod "pod-7f02e7f8-4bd5-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006752071s
STEP: Saw pod success
Mar 21 12:33:16.265: INFO: Pod "pod-7f02e7f8-4bd5-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:33:16.268: INFO: Trying to get logs from node jaguar pod pod-7f02e7f8-4bd5-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 12:33:16.285: INFO: Waiting for pod pod-7f02e7f8-4bd5-11e9-9c6a-0a581900021b to disappear
Mar 21 12:33:16.288: INFO: Pod pod-7f02e7f8-4bd5-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:33:16.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tdfpv" for this suite.
Mar 21 12:33:22.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:33:22.342: INFO: namespace: e2e-tests-emptydir-tdfpv, resource: bindings, ignored listing per whitelist
Mar 21 12:33:22.408: INFO: namespace e2e-tests-emptydir-tdfpv deletion completed in 6.115898545s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:33:22.408: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vj955
Mar 21 12:33:26.491: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vj955
STEP: checking the pod's current state and verifying that restartCount is present
Mar 21 12:33:26.494: INFO: Initial restart count of pod liveness-http is 0
Mar 21 12:33:46.540: INFO: Restart count of pod e2e-tests-container-probe-vj955/liveness-http is now 1 (20.046061059s elapsed)
Mar 21 12:34:06.578: INFO: Restart count of pod e2e-tests-container-probe-vj955/liveness-http is now 2 (40.084040773s elapsed)
Mar 21 12:34:26.627: INFO: Restart count of pod e2e-tests-container-probe-vj955/liveness-http is now 3 (1m0.132494566s elapsed)
Mar 21 12:34:44.669: INFO: Restart count of pod e2e-tests-container-probe-vj955/liveness-http is now 4 (1m18.174781524s elapsed)
Mar 21 12:35:54.799: INFO: Restart count of pod e2e-tests-container-probe-vj955/liveness-http is now 5 (2m28.304713278s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:35:54.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vj955" for this suite.
Mar 21 12:36:00.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:36:00.900: INFO: namespace: e2e-tests-container-probe-vj955, resource: bindings, ignored listing per whitelist
Mar 21 12:36:00.925: INFO: namespace e2e-tests-container-probe-vj955 deletion completed in 6.111942279s

• [SLOW TEST:158.517 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:36:00.926: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 21 12:36:01.035: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 21 12:36:06.044: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:36:07.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-7j9xk" for this suite.
Mar 21 12:36:13.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:36:13.165: INFO: namespace: e2e-tests-replication-controller-7j9xk, resource: bindings, ignored listing per whitelist
Mar 21 12:36:13.214: INFO: namespace e2e-tests-replication-controller-7j9xk deletion completed in 6.145861052s

• [SLOW TEST:12.288 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:36:13.214: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:36:13.298: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 21 12:36:18.302: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 21 12:36:18.302: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar 21 12:36:18.321: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-gqnfb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gqnfb/deployments/test-cleanup-deployment,UID:ecb7c929-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:23430,Generation:1,CreationTimestamp:2019-03-21 12:36:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar 21 12:36:18.330: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Mar 21 12:36:18.330: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 21 12:36:18.330: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-gqnfb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gqnfb/replicasets/test-cleanup-controller,UID:e9ba6fe1-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:23431,Generation:1,CreationTimestamp:2019-03-21 12:36:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment ecb7c929-4bd5-11e9-8b3c-9eae6a3150d7 0xc000163817 0xc000163818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar 21 12:36:18.333: INFO: Pod "test-cleanup-controller-sgbdt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-sgbdt,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-gqnfb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gqnfb/pods/test-cleanup-controller-sgbdt,UID:e9bb4b7f-4bd5-11e9-8b3c-9eae6a3150d7,ResourceVersion:23422,Generation:0,CreationTimestamp:2019-03-21 12:36:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller e9ba6fe1-4bd5-11e9-8b3c-9eae6a3150d7 0xc000ed24f7 0xc000ed24f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9zmwb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9zmwb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9zmwb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:antelope,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ed25b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ed25e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:36:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:36:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:36:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:36:13 +0000 UTC  }],Message:,Reason:,HostIP:104.248.166.121,PodIP:25.0.2.117,StartTime:2019-03-21 12:36:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-21 12:36:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d docker://6c578c0982025765b12b772e700e81732e9abdce5e8ba10aa046cb7d7c74b916}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:36:18.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gqnfb" for this suite.
Mar 21 12:36:24.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:36:24.383: INFO: namespace: e2e-tests-deployment-gqnfb, resource: bindings, ignored listing per whitelist
Mar 21 12:36:24.446: INFO: namespace e2e-tests-deployment-gqnfb deletion completed in 6.10553028s

• [SLOW TEST:11.232 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:36:24.447: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-f07cbc8a-4bd5-11e9-9c6a-0a581900021b
STEP: Creating configMap with name cm-test-opt-upd-f07cbce8-4bd5-11e9-9c6a-0a581900021b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f07cbc8a-4bd5-11e9-9c6a-0a581900021b
STEP: Updating configmap cm-test-opt-upd-f07cbce8-4bd5-11e9-9c6a-0a581900021b
STEP: Creating configMap with name cm-test-opt-create-f07cbd13-4bd5-11e9-9c6a-0a581900021b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:36:28.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zqzxn" for this suite.
Mar 21 12:36:50.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:36:50.805: INFO: namespace: e2e-tests-configmap-zqzxn, resource: bindings, ignored listing per whitelist
Mar 21 12:36:50.896: INFO: namespace e2e-tests-configmap-zqzxn deletion completed in 22.141882353s

• [SLOW TEST:26.448 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:36:50.896: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-002f6187-4bd6-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:36:50.979: INFO: Waiting up to 5m0s for pod "pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-lw45z" to be "success or failure"
Mar 21 12:36:50.982: INFO: Pod "pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.251639ms
Mar 21 12:36:52.985: INFO: Pod "pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00673623s
Mar 21 12:36:54.989: INFO: Pod "pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010524701s
Mar 21 12:36:56.993: INFO: Pod "pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014226721s
STEP: Saw pod success
Mar 21 12:36:56.993: INFO: Pod "pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:36:56.995: INFO: Trying to get logs from node wolf pod pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 12:36:57.023: INFO: Waiting for pod pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:36:57.118: INFO: Pod pod-configmaps-002fcd27-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:36:57.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lw45z" for this suite.
Mar 21 12:37:03.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:37:03.175: INFO: namespace: e2e-tests-configmap-lw45z, resource: bindings, ignored listing per whitelist
Mar 21 12:37:03.243: INFO: namespace e2e-tests-configmap-lw45z deletion completed in 6.110366199s

• [SLOW TEST:12.347 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:37:03.243: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-078d1762-4bd6-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:37:03.337: INFO: Waiting up to 5m0s for pod "pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-gdt69" to be "success or failure"
Mar 21 12:37:03.340: INFO: Pod "pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.480837ms
Mar 21 12:37:05.344: INFO: Pod "pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006219976s
Mar 21 12:37:07.351: INFO: Pod "pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013813284s
STEP: Saw pod success
Mar 21 12:37:07.351: INFO: Pod "pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:37:07.355: INFO: Trying to get logs from node antelope pod pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 12:37:07.512: INFO: Waiting for pod pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:37:07.518: INFO: Pod pod-secrets-078dc144-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:37:07.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gdt69" for this suite.
Mar 21 12:37:13.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:37:13.596: INFO: namespace: e2e-tests-secrets-gdt69, resource: bindings, ignored listing per whitelist
Mar 21 12:37:13.632: INFO: namespace e2e-tests-secrets-gdt69 deletion completed in 6.108969514s

• [SLOW TEST:10.389 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:37:13.633: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:37:13.710: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0dbc3258-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-mjkk6" to be "success or failure"
Mar 21 12:37:13.714: INFO: Pod "downwardapi-volume-0dbc3258-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.686333ms
Mar 21 12:37:15.718: INFO: Pod "downwardapi-volume-0dbc3258-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00747077s
STEP: Saw pod success
Mar 21 12:37:15.718: INFO: Pod "downwardapi-volume-0dbc3258-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:37:15.721: INFO: Trying to get logs from node wolf pod downwardapi-volume-0dbc3258-4bd6-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:37:15.738: INFO: Waiting for pod downwardapi-volume-0dbc3258-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:37:15.740: INFO: Pod downwardapi-volume-0dbc3258-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:37:15.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mjkk6" for this suite.
Mar 21 12:37:21.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:37:21.830: INFO: namespace: e2e-tests-downward-api-mjkk6, resource: bindings, ignored listing per whitelist
Mar 21 12:37:21.977: INFO: namespace e2e-tests-downward-api-mjkk6 deletion completed in 6.232956617s

• [SLOW TEST:8.345 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:37:21.978: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:37:22.046: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-zr8xm" to be "success or failure"
Mar 21 12:37:22.049: INFO: Pod "downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.047516ms
Mar 21 12:37:24.053: INFO: Pod "downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007045503s
Mar 21 12:37:26.061: INFO: Pod "downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014859196s
STEP: Saw pod success
Mar 21 12:37:26.061: INFO: Pod "downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:37:26.065: INFO: Trying to get logs from node wolf pod downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:37:26.092: INFO: Waiting for pod downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:37:26.096: INFO: Pod downwardapi-volume-12b46a04-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:37:26.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zr8xm" for this suite.
Mar 21 12:37:32.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:37:32.142: INFO: namespace: e2e-tests-downward-api-zr8xm, resource: bindings, ignored listing per whitelist
Mar 21 12:37:32.209: INFO: namespace e2e-tests-downward-api-zr8xm deletion completed in 6.109497711s

• [SLOW TEST:10.232 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:37:32.211: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-bhxkp/configmap-test-18cf6123-4bd6-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:37:32.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-18cff92a-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-bhxkp" to be "success or failure"
Mar 21 12:37:32.296: INFO: Pod "pod-configmaps-18cff92a-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.506578ms
Mar 21 12:37:34.301: INFO: Pod "pod-configmaps-18cff92a-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00784828s
STEP: Saw pod success
Mar 21 12:37:34.301: INFO: Pod "pod-configmaps-18cff92a-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:37:34.304: INFO: Trying to get logs from node antelope pod pod-configmaps-18cff92a-4bd6-11e9-9c6a-0a581900021b container env-test: <nil>
STEP: delete the pod
Mar 21 12:37:34.341: INFO: Waiting for pod pod-configmaps-18cff92a-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:37:34.346: INFO: Pod pod-configmaps-18cff92a-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:37:34.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bhxkp" for this suite.
Mar 21 12:37:40.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:37:40.373: INFO: namespace: e2e-tests-configmap-bhxkp, resource: bindings, ignored listing per whitelist
Mar 21 12:37:40.459: INFO: namespace e2e-tests-configmap-bhxkp deletion completed in 6.107689986s

• [SLOW TEST:8.248 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:37:40.459: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1dba2f19-4bd6-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:37:40.546: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-f4bdz" to be "success or failure"
Mar 21 12:37:40.549: INFO: Pod "pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.81089ms
Mar 21 12:37:42.552: INFO: Pod "pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006175439s
Mar 21 12:37:44.556: INFO: Pod "pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010206892s
STEP: Saw pod success
Mar 21 12:37:44.557: INFO: Pod "pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:37:44.560: INFO: Trying to get logs from node jaguar pod pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 12:37:44.577: INFO: Waiting for pod pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:37:44.579: INFO: Pod pod-projected-configmaps-1dbb3ec9-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:37:44.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f4bdz" for this suite.
Mar 21 12:37:50.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:37:50.609: INFO: namespace: e2e-tests-projected-f4bdz, resource: bindings, ignored listing per whitelist
Mar 21 12:37:50.680: INFO: namespace e2e-tests-projected-f4bdz deletion completed in 6.097748558s

• [SLOW TEST:10.221 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:37:50.682: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:37:50.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23d17ffc-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-f7pdl" to be "success or failure"
Mar 21 12:37:50.761: INFO: Pod "downwardapi-volume-23d17ffc-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.975949ms
Mar 21 12:37:52.765: INFO: Pod "downwardapi-volume-23d17ffc-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006850702s
STEP: Saw pod success
Mar 21 12:37:52.765: INFO: Pod "downwardapi-volume-23d17ffc-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:37:52.769: INFO: Trying to get logs from node wolf pod downwardapi-volume-23d17ffc-4bd6-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:37:52.786: INFO: Waiting for pod downwardapi-volume-23d17ffc-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:37:52.788: INFO: Pod downwardapi-volume-23d17ffc-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:37:52.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f7pdl" for this suite.
Mar 21 12:37:58.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:37:58.870: INFO: namespace: e2e-tests-downward-api-f7pdl, resource: bindings, ignored listing per whitelist
Mar 21 12:37:58.889: INFO: namespace e2e-tests-downward-api-f7pdl deletion completed in 6.098267069s

• [SLOW TEST:8.208 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:37:58.890: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:38:03.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xz6dc" for this suite.
Mar 21 12:38:26.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:38:26.094: INFO: namespace: e2e-tests-replication-controller-xz6dc, resource: bindings, ignored listing per whitelist
Mar 21 12:38:26.139: INFO: namespace e2e-tests-replication-controller-xz6dc deletion completed in 22.142184662s

• [SLOW TEST:27.250 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:38:26.140: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-38f6677c-4bd6-11e9-9c6a-0a581900021b
STEP: Creating secret with name secret-projected-all-test-volume-38f6669b-4bd6-11e9-9c6a-0a581900021b
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 21 12:38:26.240: INFO: Waiting up to 5m0s for pod "projected-volume-38f6664a-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-cs977" to be "success or failure"
Mar 21 12:38:26.248: INFO: Pod "projected-volume-38f6664a-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.769572ms
Mar 21 12:38:28.252: INFO: Pod "projected-volume-38f6664a-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011893737s
STEP: Saw pod success
Mar 21 12:38:28.252: INFO: Pod "projected-volume-38f6664a-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:38:28.256: INFO: Trying to get logs from node jaguar pod projected-volume-38f6664a-4bd6-11e9-9c6a-0a581900021b container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 21 12:38:28.275: INFO: Waiting for pod projected-volume-38f6664a-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:38:28.278: INFO: Pod projected-volume-38f6664a-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:38:28.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cs977" for this suite.
Mar 21 12:38:34.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:38:34.319: INFO: namespace: e2e-tests-projected-cs977, resource: bindings, ignored listing per whitelist
Mar 21 12:38:34.394: INFO: namespace e2e-tests-projected-cs977 deletion completed in 6.111764637s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:38:34.399: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 21 12:38:34.482: INFO: Waiting up to 5m0s for pod "downward-api-3de10c09-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-g7hgc" to be "success or failure"
Mar 21 12:38:34.487: INFO: Pod "downward-api-3de10c09-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.232458ms
Mar 21 12:38:36.491: INFO: Pod "downward-api-3de10c09-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007201192s
STEP: Saw pod success
Mar 21 12:38:36.491: INFO: Pod "downward-api-3de10c09-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:38:36.494: INFO: Trying to get logs from node jaguar pod downward-api-3de10c09-4bd6-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 12:38:36.526: INFO: Waiting for pod downward-api-3de10c09-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:38:36.529: INFO: Pod downward-api-3de10c09-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:38:36.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g7hgc" for this suite.
Mar 21 12:38:42.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:38:42.569: INFO: namespace: e2e-tests-downward-api-g7hgc, resource: bindings, ignored listing per whitelist
Mar 21 12:38:42.646: INFO: namespace e2e-tests-downward-api-g7hgc deletion completed in 6.112411821s

• [SLOW TEST:8.248 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:38:42.646: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:38:42.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 version'
Mar 21 12:38:43.014: INFO: stderr: ""
Mar 21 12:38:43.014: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:37:52Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:30:26Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:38:43.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vbnp9" for this suite.
Mar 21 12:38:49.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:38:49.067: INFO: namespace: e2e-tests-kubectl-vbnp9, resource: bindings, ignored listing per whitelist
Mar 21 12:38:49.143: INFO: namespace e2e-tests-kubectl-vbnp9 deletion completed in 6.124097958s

• [SLOW TEST:6.497 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:38:49.144: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qk49l
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 21 12:38:49.214: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 21 12:39:13.325: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://25.0.2.123:8080/dial?request=hostName&protocol=http&host=25.0.1.114&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qk49l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:39:13.325: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:39:13.497: INFO: Waiting for endpoints: map[]
Mar 21 12:39:13.506: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://25.0.2.123:8080/dial?request=hostName&protocol=http&host=25.0.2.122&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qk49l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:39:13.506: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:39:13.663: INFO: Waiting for endpoints: map[]
Mar 21 12:39:13.666: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://25.0.2.123:8080/dial?request=hostName&protocol=http&host=25.0.3.103&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qk49l PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:39:13.666: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:39:13.853: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:39:13.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qk49l" for this suite.
Mar 21 12:39:35.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:39:35.948: INFO: namespace: e2e-tests-pod-network-test-qk49l, resource: bindings, ignored listing per whitelist
Mar 21 12:39:35.968: INFO: namespace e2e-tests-pod-network-test-qk49l deletion completed in 22.110750371s

• [SLOW TEST:46.824 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:39:35.970: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 21 12:39:42.581: INFO: Successfully updated pod "labelsupdate6292b3da-4bd6-11e9-9c6a-0a581900021b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:39:44.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hkbt7" for this suite.
Mar 21 12:40:06.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:40:06.696: INFO: namespace: e2e-tests-projected-hkbt7, resource: bindings, ignored listing per whitelist
Mar 21 12:40:06.736: INFO: namespace e2e-tests-projected-hkbt7 deletion completed in 22.131051524s

• [SLOW TEST:30.766 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:40:06.736: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 21 12:40:06.835: INFO: Waiting up to 5m0s for pod "pod-74ecf680-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-crm6t" to be "success or failure"
Mar 21 12:40:06.839: INFO: Pod "pod-74ecf680-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.921892ms
Mar 21 12:40:08.843: INFO: Pod "pod-74ecf680-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007728992s
Mar 21 12:40:10.846: INFO: Pod "pod-74ecf680-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01104747s
STEP: Saw pod success
Mar 21 12:40:10.847: INFO: Pod "pod-74ecf680-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:40:10.850: INFO: Trying to get logs from node antelope pod pod-74ecf680-4bd6-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 12:40:10.869: INFO: Waiting for pod pod-74ecf680-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:40:10.873: INFO: Pod pod-74ecf680-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:40:10.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-crm6t" for this suite.
Mar 21 12:40:16.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:40:16.931: INFO: namespace: e2e-tests-emptydir-crm6t, resource: bindings, ignored listing per whitelist
Mar 21 12:40:17.000: INFO: namespace e2e-tests-emptydir-crm6t deletion completed in 6.120117417s

• [SLOW TEST:10.264 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:40:17.001: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-87w9
STEP: Creating a pod to test atomic-volume-subpath
Mar 21 12:40:17.117: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-87w9" in namespace "e2e-tests-subpath-59xql" to be "success or failure"
Mar 21 12:40:17.124: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.228318ms
Mar 21 12:40:19.129: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011600957s
Mar 21 12:40:21.133: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 4.015500489s
Mar 21 12:40:23.136: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 6.018707167s
Mar 21 12:40:25.140: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 8.022535085s
Mar 21 12:40:27.144: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 10.026221513s
Mar 21 12:40:29.148: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 12.030799534s
Mar 21 12:40:31.152: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 14.034497706s
Mar 21 12:40:33.157: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 16.039991616s
Mar 21 12:40:35.161: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 18.043502396s
Mar 21 12:40:37.164: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 20.047083114s
Mar 21 12:40:39.169: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Running", Reason="", readiness=false. Elapsed: 22.051737773s
Mar 21 12:40:41.174: INFO: Pod "pod-subpath-test-secret-87w9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057102255s
STEP: Saw pod success
Mar 21 12:40:41.175: INFO: Pod "pod-subpath-test-secret-87w9" satisfied condition "success or failure"
Mar 21 12:40:41.181: INFO: Trying to get logs from node jaguar pod pod-subpath-test-secret-87w9 container test-container-subpath-secret-87w9: <nil>
STEP: delete the pod
Mar 21 12:40:41.205: INFO: Waiting for pod pod-subpath-test-secret-87w9 to disappear
Mar 21 12:40:41.208: INFO: Pod pod-subpath-test-secret-87w9 no longer exists
STEP: Deleting pod pod-subpath-test-secret-87w9
Mar 21 12:40:41.208: INFO: Deleting pod "pod-subpath-test-secret-87w9" in namespace "e2e-tests-subpath-59xql"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:40:41.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-59xql" for this suite.
Mar 21 12:40:47.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:40:47.272: INFO: namespace: e2e-tests-subpath-59xql, resource: bindings, ignored listing per whitelist
Mar 21 12:40:47.308: INFO: namespace e2e-tests-subpath-59xql deletion completed in 6.091130526s

• [SLOW TEST:30.307 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:40:47.309: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar 21 12:40:47.405: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-wtvhf" to be "success or failure"
Mar 21 12:40:47.408: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.633848ms
Mar 21 12:40:49.411: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006373773s
STEP: Saw pod success
Mar 21 12:40:49.411: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 21 12:40:49.414: INFO: Trying to get logs from node wolf pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 21 12:40:49.431: INFO: Waiting for pod pod-host-path-test to disappear
Mar 21 12:40:49.526: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:40:49.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-wtvhf" for this suite.
Mar 21 12:40:55.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:40:55.628: INFO: namespace: e2e-tests-hostpath-wtvhf, resource: bindings, ignored listing per whitelist
Mar 21 12:40:55.639: INFO: namespace e2e-tests-hostpath-wtvhf deletion completed in 6.108450009s

• [SLOW TEST:8.329 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:40:55.639: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar 21 12:40:55.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 cluster-info'
Mar 21 12:40:56.094: INFO: stderr: ""
Mar 21 12:40:56.094: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:40:56.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d4hpq" for this suite.
Mar 21 12:41:02.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:41:02.149: INFO: namespace: e2e-tests-kubectl-d4hpq, resource: bindings, ignored listing per whitelist
Mar 21 12:41:02.247: INFO: namespace e2e-tests-kubectl-d4hpq deletion completed in 6.142001488s

• [SLOW TEST:6.608 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:41:02.248: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar 21 12:41:02.330: INFO: Waiting up to 5m0s for pod "client-containers-9600f203-4bd6-11e9-9c6a-0a581900021b" in namespace "e2e-tests-containers-5gj68" to be "success or failure"
Mar 21 12:41:02.335: INFO: Pod "client-containers-9600f203-4bd6-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.248547ms
Mar 21 12:41:04.342: INFO: Pod "client-containers-9600f203-4bd6-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01253216s
STEP: Saw pod success
Mar 21 12:41:04.342: INFO: Pod "client-containers-9600f203-4bd6-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:41:04.345: INFO: Trying to get logs from node antelope pod client-containers-9600f203-4bd6-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 12:41:04.364: INFO: Waiting for pod client-containers-9600f203-4bd6-11e9-9c6a-0a581900021b to disappear
Mar 21 12:41:04.367: INFO: Pod client-containers-9600f203-4bd6-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:41:04.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5gj68" for this suite.
Mar 21 12:41:10.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:41:10.445: INFO: namespace: e2e-tests-containers-5gj68, resource: bindings, ignored listing per whitelist
Mar 21 12:41:10.466: INFO: namespace e2e-tests-containers-5gj68 deletion completed in 6.095878466s

• [SLOW TEST:8.219 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:41:10.467: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-9ae6ac94-4bd6-11e9-9c6a-0a581900021b
STEP: Creating secret with name s-test-opt-upd-9ae6aced-4bd6-11e9-9c6a-0a581900021b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9ae6ac94-4bd6-11e9-9c6a-0a581900021b
STEP: Updating secret s-test-opt-upd-9ae6aced-4bd6-11e9-9c6a-0a581900021b
STEP: Creating secret with name s-test-opt-create-9ae6ad10-4bd6-11e9-9c6a-0a581900021b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:41:14.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2ltl" for this suite.
Mar 21 12:41:36.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:41:36.754: INFO: namespace: e2e-tests-projected-d2ltl, resource: bindings, ignored listing per whitelist
Mar 21 12:41:36.759: INFO: namespace e2e-tests-projected-d2ltl deletion completed in 22.110244004s

• [SLOW TEST:26.293 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:41:36.759: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Mar 21 12:41:36.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-9627w'
Mar 21 12:41:37.189: INFO: stderr: ""
Mar 21 12:41:37.189: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar 21 12:41:38.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:38.193: INFO: Found 0 / 1
Mar 21 12:41:39.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:39.193: INFO: Found 0 / 1
Mar 21 12:41:40.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:40.193: INFO: Found 0 / 1
Mar 21 12:41:41.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:41.193: INFO: Found 0 / 1
Mar 21 12:41:42.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:42.193: INFO: Found 0 / 1
Mar 21 12:41:43.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:43.193: INFO: Found 0 / 1
Mar 21 12:41:44.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:44.193: INFO: Found 0 / 1
Mar 21 12:41:45.193: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:45.193: INFO: Found 1 / 1
Mar 21 12:41:45.193: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 21 12:41:45.197: INFO: Selector matched 1 pods for map[app:redis]
Mar 21 12:41:45.197: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar 21 12:41:45.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 logs redis-master-bljt8 redis-master --namespace=e2e-tests-kubectl-9627w'
Mar 21 12:41:45.367: INFO: stderr: ""
Mar 21 12:41:45.367: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Mar 12:41:43.796 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Mar 12:41:43.796 # Server started, Redis version 3.2.12\n1:M 21 Mar 12:41:43.796 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Mar 12:41:43.796 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar 21 12:41:45.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 log redis-master-bljt8 redis-master --namespace=e2e-tests-kubectl-9627w --tail=1'
Mar 21 12:41:45.530: INFO: stderr: ""
Mar 21 12:41:45.530: INFO: stdout: "1:M 21 Mar 12:41:43.796 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar 21 12:41:45.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 log redis-master-bljt8 redis-master --namespace=e2e-tests-kubectl-9627w --limit-bytes=1'
Mar 21 12:41:45.667: INFO: stderr: ""
Mar 21 12:41:45.667: INFO: stdout: " "
STEP: exposing timestamps
Mar 21 12:41:45.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 log redis-master-bljt8 redis-master --namespace=e2e-tests-kubectl-9627w --tail=1 --timestamps'
Mar 21 12:41:45.830: INFO: stderr: ""
Mar 21 12:41:45.830: INFO: stdout: "2019-03-21T12:41:43.798032662Z 1:M 21 Mar 12:41:43.796 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar 21 12:41:48.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 log redis-master-bljt8 redis-master --namespace=e2e-tests-kubectl-9627w --since=1s'
Mar 21 12:41:48.514: INFO: stderr: ""
Mar 21 12:41:48.514: INFO: stdout: ""
Mar 21 12:41:48.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 log redis-master-bljt8 redis-master --namespace=e2e-tests-kubectl-9627w --since=24h'
Mar 21 12:41:48.773: INFO: stderr: ""
Mar 21 12:41:48.773: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Mar 12:41:43.796 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Mar 12:41:43.796 # Server started, Redis version 3.2.12\n1:M 21 Mar 12:41:43.796 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Mar 12:41:43.796 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Mar 21 12:41:48.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9627w'
Mar 21 12:41:48.928: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:41:48.928: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar 21 12:41:48.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-9627w'
Mar 21 12:41:49.070: INFO: stderr: "No resources found.\n"
Mar 21 12:41:49.070: INFO: stdout: ""
Mar 21 12:41:49.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -l name=nginx --namespace=e2e-tests-kubectl-9627w -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 21 12:41:49.273: INFO: stderr: ""
Mar 21 12:41:49.273: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:41:49.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9627w" for this suite.
Mar 21 12:42:11.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:42:11.316: INFO: namespace: e2e-tests-kubectl-9627w, resource: bindings, ignored listing per whitelist
Mar 21 12:42:11.389: INFO: namespace e2e-tests-kubectl-9627w deletion completed in 22.107536858s

• [SLOW TEST:34.630 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:42:11.390: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:42:11.547: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 21 12:42:11.556: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:11.558: INFO: Number of nodes with available pods: 0
Mar 21 12:42:11.558: INFO: Node antelope is running more than one daemon pod
Mar 21 12:42:12.563: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:12.567: INFO: Number of nodes with available pods: 0
Mar 21 12:42:12.567: INFO: Node antelope is running more than one daemon pod
Mar 21 12:42:13.563: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:13.566: INFO: Number of nodes with available pods: 3
Mar 21 12:42:13.567: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 21 12:42:13.590: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:13.590: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:13.590: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:13.594: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:14.597: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:14.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:14.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:14.607: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:15.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:15.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:15.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:15.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:16.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:16.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:16.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:16.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:17.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:17.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:17.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:17.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:18.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:18.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:18.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:18.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:19.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:19.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:19.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:19.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:20.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:20.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:20.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:20.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:21.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:21.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:21.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:21.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:22.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:22.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:22.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:22.606: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:23.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:23.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:23.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:23.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:24.597: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:24.597: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:24.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:24.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:25.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:25.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:25.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:25.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:26.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:26.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:26.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:26.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:27.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:27.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:27.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:27.604: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:28.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:28.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:28.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:28.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:29.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:29.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:29.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:29.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:30.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:30.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:30.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:30.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:31.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:31.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:31.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:31.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:32.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:32.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:32.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:32.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:33.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:33.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:33.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:33.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:34.599: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:34.599: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:34.599: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:34.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:35.600: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:35.600: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:35.600: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:35.604: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:36.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:36.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:36.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:36.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:37.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:37.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:37.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:37.606: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:38.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:38.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:38.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:38.606: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:39.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:39.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:39.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:39.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:40.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:40.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:40.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:40.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:41.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:41.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:41.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:41.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:42.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:42.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:42.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:42.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:43.600: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:43.600: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:43.600: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:43.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:44.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:44.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:44.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:44.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:45.604: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:45.604: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:45.604: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:45.608: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:46.609: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:46.609: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:46.609: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:46.616: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:47.598: INFO: Wrong image for pod: daemon-set-6rpl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:47.598: INFO: Pod daemon-set-6rpl8 is not available
Mar 21 12:42:47.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:47.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:47.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:48.601: INFO: Pod daemon-set-hgkwh is not available
Mar 21 12:42:48.601: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:48.601: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:48.604: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:49.605: INFO: Pod daemon-set-hgkwh is not available
Mar 21 12:42:49.605: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:49.605: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:49.610: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:50.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:50.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:50.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:51.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:51.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:51.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:52.597: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:52.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:52.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:53.599: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:53.599: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:53.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:54.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:54.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:54.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:55.597: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:55.597: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:55.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:56.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:56.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:56.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:57.597: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:57.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:57.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:58.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:58.599: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:58.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:42:59.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:59.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:42:59.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:00.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:00.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:00.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:01.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:01.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:01.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:02.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:02.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:02.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:03.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:03.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:03.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:04.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:04.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:04.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:05.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:05.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:05.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:06.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:06.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:06.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:07.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:07.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:07.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:08.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:08.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:08.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:09.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:09.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:09.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:10.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:10.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:10.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:11.601: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:11.601: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:11.606: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:12.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:12.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:12.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:13.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:13.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:13.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:14.599: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:14.599: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:14.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:15.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:15.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:15.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:16.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:16.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:16.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:17.605: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:17.605: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:17.610: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:18.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:18.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:18.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:19.599: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:19.599: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:19.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:20.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:20.598: INFO: Wrong image for pod: daemon-set-vth67. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:20.598: INFO: Pod daemon-set-vth67 is not available
Mar 21 12:43:20.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:21.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:21.598: INFO: Pod daemon-set-vjqf2 is not available
Mar 21 12:43:21.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:22.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:22.604: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:23.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:23.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:24.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:24.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:25.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:25.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:26.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:26.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:27.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:27.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:28.599: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:28.605: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:29.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:29.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:30.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:30.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:31.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:31.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:32.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:32.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:33.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:33.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:34.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:34.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:35.597: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:35.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:36.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:36.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:37.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:37.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:38.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:38.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:39.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:39.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:40.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:40.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:41.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:41.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:42.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:42.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:43.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:43.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:44.597: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:44.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:45.597: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:45.601: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:46.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:46.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:47.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:47.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:48.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:48.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:49.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:49.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:50.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:50.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:51.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:51.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:52.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:52.603: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:53.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:53.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:54.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:54.598: INFO: Pod daemon-set-jz67l is not available
Mar 21 12:43:54.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:55.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:55.598: INFO: Pod daemon-set-jz67l is not available
Mar 21 12:43:55.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:56.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:56.599: INFO: Pod daemon-set-jz67l is not available
Mar 21 12:43:56.604: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:57.604: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:57.604: INFO: Pod daemon-set-jz67l is not available
Mar 21 12:43:57.609: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:58.598: INFO: Wrong image for pod: daemon-set-jz67l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar 21 12:43:58.598: INFO: Pod daemon-set-jz67l is not available
Mar 21 12:43:58.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:59.598: INFO: Pod daemon-set-8557p is not available
Mar 21 12:43:59.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 21 12:43:59.606: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:43:59.609: INFO: Number of nodes with available pods: 2
Mar 21 12:43:59.609: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:44:00.617: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:44:00.620: INFO: Number of nodes with available pods: 2
Mar 21 12:44:00.620: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:44:01.621: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:44:01.627: INFO: Number of nodes with available pods: 2
Mar 21 12:44:01.628: INFO: Node jaguar is running more than one daemon pod
Mar 21 12:44:02.614: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:44:02.617: INFO: Number of nodes with available pods: 3
Mar 21 12:44:02.617: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-kfjdw, will wait for the garbage collector to delete the pods
Mar 21 12:44:02.694: INFO: Deleting DaemonSet.extensions daemon-set took: 6.435739ms
Mar 21 12:44:02.794: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.223401ms
Mar 21 12:44:11.297: INFO: Number of nodes with available pods: 0
Mar 21 12:44:11.297: INFO: Number of running nodes: 0, number of available pods: 0
Mar 21 12:44:11.300: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kfjdw/daemonsets","resourceVersion":"24996"},"items":null}

Mar 21 12:44:11.303: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kfjdw/pods","resourceVersion":"24996"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:44:11.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kfjdw" for this suite.
Mar 21 12:44:17.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:44:17.387: INFO: namespace: e2e-tests-daemonsets-kfjdw, resource: bindings, ignored listing per whitelist
Mar 21 12:44:17.454: INFO: namespace e2e-tests-daemonsets-kfjdw deletion completed in 6.131492509s

• [SLOW TEST:126.064 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:44:17.454: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 21 12:44:17.588: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:44:17.592: INFO: Number of nodes with available pods: 0
Mar 21 12:44:17.592: INFO: Node antelope is running more than one daemon pod
Mar 21 12:44:18.602: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:44:18.606: INFO: Number of nodes with available pods: 0
Mar 21 12:44:18.606: INFO: Node antelope is running more than one daemon pod
Mar 21 12:44:19.596: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:44:19.600: INFO: Number of nodes with available pods: 3
Mar 21 12:44:19.600: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 21 12:44:19.612: INFO: DaemonSet pods can't tolerate node master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar 21 12:44:19.617: INFO: Number of nodes with available pods: 3
Mar 21 12:44:19.617: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-998c8, will wait for the garbage collector to delete the pods
Mar 21 12:44:19.683: INFO: Deleting DaemonSet.extensions daemon-set took: 4.804668ms
Mar 21 12:44:19.783: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.280826ms
Mar 21 12:44:53.687: INFO: Number of nodes with available pods: 0
Mar 21 12:44:53.687: INFO: Number of running nodes: 0, number of available pods: 0
Mar 21 12:44:53.690: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-998c8/daemonsets","resourceVersion":"25170"},"items":null}

Mar 21 12:44:53.693: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-998c8/pods","resourceVersion":"25170"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:44:53.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-998c8" for this suite.
Mar 21 12:44:59.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:44:59.890: INFO: namespace: e2e-tests-daemonsets-998c8, resource: bindings, ignored listing per whitelist
Mar 21 12:44:59.933: INFO: namespace e2e-tests-daemonsets-998c8 deletion completed in 6.223026761s

• [SLOW TEST:42.479 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:44:59.933: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar 21 12:45:00.015: INFO: Waiting up to 5m0s for pod "client-containers-23ac3699-4bd7-11e9-9c6a-0a581900021b" in namespace "e2e-tests-containers-t4zbg" to be "success or failure"
Mar 21 12:45:00.025: INFO: Pod "client-containers-23ac3699-4bd7-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.844521ms
Mar 21 12:45:02.045: INFO: Pod "client-containers-23ac3699-4bd7-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030181897s
STEP: Saw pod success
Mar 21 12:45:02.046: INFO: Pod "client-containers-23ac3699-4bd7-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:45:02.059: INFO: Trying to get logs from node antelope pod client-containers-23ac3699-4bd7-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 12:45:02.095: INFO: Waiting for pod client-containers-23ac3699-4bd7-11e9-9c6a-0a581900021b to disappear
Mar 21 12:45:02.114: INFO: Pod client-containers-23ac3699-4bd7-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:45:02.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-t4zbg" for this suite.
Mar 21 12:45:08.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:45:08.229: INFO: namespace: e2e-tests-containers-t4zbg, resource: bindings, ignored listing per whitelist
Mar 21 12:45:08.279: INFO: namespace e2e-tests-containers-t4zbg deletion completed in 6.13966307s

• [SLOW TEST:8.346 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:45:08.280: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:45:08.365: INFO: (0) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 11.944257ms)
Mar 21 12:45:08.370: INFO: (1) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.802264ms)
Mar 21 12:45:08.374: INFO: (2) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.118181ms)
Mar 21 12:45:08.378: INFO: (3) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.650821ms)
Mar 21 12:45:08.382: INFO: (4) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.658301ms)
Mar 21 12:45:08.386: INFO: (5) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.675776ms)
Mar 21 12:45:08.390: INFO: (6) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.811849ms)
Mar 21 12:45:08.395: INFO: (7) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.922393ms)
Mar 21 12:45:08.399: INFO: (8) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.924273ms)
Mar 21 12:45:08.403: INFO: (9) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.909448ms)
Mar 21 12:45:08.407: INFO: (10) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.183268ms)
Mar 21 12:45:08.412: INFO: (11) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.53091ms)
Mar 21 12:45:08.416: INFO: (12) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.122418ms)
Mar 21 12:45:08.422: INFO: (13) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 5.561092ms)
Mar 21 12:45:08.427: INFO: (14) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 5.070058ms)
Mar 21 12:45:08.431: INFO: (15) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 3.864281ms)
Mar 21 12:45:08.436: INFO: (16) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.454861ms)
Mar 21 12:45:08.440: INFO: (17) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.321794ms)
Mar 21 12:45:08.444: INFO: (18) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.343842ms)
Mar 21 12:45:08.448: INFO: (19) /api/v1/nodes/antelope/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="archive/">... (200; 4.109163ms)
[AfterEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:45:08.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-dhxw7" for this suite.
Mar 21 12:45:14.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:45:14.506: INFO: namespace: e2e-tests-proxy-dhxw7, resource: bindings, ignored listing per whitelist
Mar 21 12:45:14.563: INFO: namespace e2e-tests-proxy-dhxw7 deletion completed in 6.110410052s

• [SLOW TEST:6.283 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:45:14.563: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 21 12:45:20.687: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:20.690: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:22.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:22.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:24.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:24.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:26.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:26.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:28.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:28.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:30.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:30.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:32.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:32.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:34.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:34.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:36.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:36.694: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 21 12:45:38.690: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 21 12:45:38.694: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:45:38.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5k4jt" for this suite.
Mar 21 12:46:00.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:46:00.768: INFO: namespace: e2e-tests-container-lifecycle-hook-5k4jt, resource: bindings, ignored listing per whitelist
Mar 21 12:46:00.793: INFO: namespace e2e-tests-container-lifecycle-hook-5k4jt deletion completed in 22.094311388s

• [SLOW TEST:46.230 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:46:00.794: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar 21 12:46:00.885: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 21 12:46:00.894: INFO: Waiting for terminating namespaces to be deleted...
Mar 21 12:46:00.896: INFO: 
Logging pods the kubelet thinks is on node antelope before test
Mar 21 12:46:00.903: INFO: kube-proxy-9hr7b from kube-system started at 2019-03-21 10:15:53 +0000 UTC (1 container statuses recorded)
Mar 21 12:46:00.903: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 12:46:00.903: INFO: kube-flannel-ds-amd64-rqwz5 from kube-system started at 2019-03-21 10:15:53 +0000 UTC (1 container statuses recorded)
Mar 21 12:46:00.903: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 12:46:00.903: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdl77 from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:46:00.903: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 21 12:46:00.904: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 21 12:46:00.904: INFO: sonobuoy-e2e-job-0facb6ec3f244997 from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:46:00.904: INFO: 	Container e2e ready: true, restart count 0
Mar 21 12:46:00.904: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 21 12:46:00.904: INFO: 
Logging pods the kubelet thinks is on node jaguar before test
Mar 21 12:46:00.910: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-cxr4t from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:46:00.910: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 21 12:46:00.910: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 21 12:46:00.910: INFO: kube-flannel-ds-amd64-qw9mb from kube-system started at 2019-03-21 10:15:55 +0000 UTC (1 container statuses recorded)
Mar 21 12:46:00.910: INFO: 	Container kube-flannel ready: true, restart count 0
Mar 21 12:46:00.910: INFO: kube-proxy-h2wk8 from kube-system started at 2019-03-21 10:15:55 +0000 UTC (1 container statuses recorded)
Mar 21 12:46:00.910: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 12:46:00.910: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-21 11:36:19 +0000 UTC (1 container statuses recorded)
Mar 21 12:46:00.910: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 21 12:46:00.910: INFO: 
Logging pods the kubelet thinks is on node wolf before test
Mar 21 12:46:00.918: INFO: sonobuoy-systemd-logs-daemon-set-aad7590584424748-mdpng from heptio-sonobuoy started at 2019-03-21 11:36:24 +0000 UTC (2 container statuses recorded)
Mar 21 12:46:00.918: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Mar 21 12:46:00.918: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 21 12:46:00.918: INFO: kube-proxy-k5xgj from kube-system started at 2019-03-21 10:15:51 +0000 UTC (1 container statuses recorded)
Mar 21 12:46:00.918: INFO: 	Container kube-proxy ready: true, restart count 0
Mar 21 12:46:00.918: INFO: kube-flannel-ds-amd64-b427k from kube-system started at 2019-03-21 10:15:51 +0000 UTC (1 container statuses recorded)
Mar 21 12:46:00.918: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-492f3d33-4bd7-11e9-9c6a-0a581900021b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-492f3d33-4bd7-11e9-9c6a-0a581900021b off the node jaguar
STEP: verifying the node doesn't have the label kubernetes.io/e2e-492f3d33-4bd7-11e9-9c6a-0a581900021b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:46:04.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ll7b2" for this suite.
Mar 21 12:46:22.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:46:23.076: INFO: namespace: e2e-tests-sched-pred-ll7b2, resource: bindings, ignored listing per whitelist
Mar 21 12:46:23.081: INFO: namespace e2e-tests-sched-pred-ll7b2 deletion completed in 18.095485954s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.288 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:46:23.083: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 21 12:46:23.164: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25468,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 21 12:46:23.164: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25468,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 21 12:46:33.172: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25484,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 21 12:46:33.173: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25484,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 21 12:46:43.179: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25500,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 21 12:46:43.179: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25500,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 21 12:46:53.185: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25516,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 21 12:46:53.185: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-a,UID:553d163e-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25516,Generation:0,CreationTimestamp:2019-03-21 12:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 21 12:47:03.209: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-b,UID:6d19ebd6-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25532,Generation:0,CreationTimestamp:2019-03-21 12:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 21 12:47:03.209: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-b,UID:6d19ebd6-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25532,Generation:0,CreationTimestamp:2019-03-21 12:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 21 12:47:13.217: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-b,UID:6d19ebd6-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25549,Generation:0,CreationTimestamp:2019-03-21 12:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 21 12:47:13.217: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-mq7vg,SelfLink:/api/v1/namespaces/e2e-tests-watch-mq7vg/configmaps/e2e-watch-test-configmap-b,UID:6d19ebd6-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:25549,Generation:0,CreationTimestamp:2019-03-21 12:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:47:23.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mq7vg" for this suite.
Mar 21 12:47:29.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:47:29.280: INFO: namespace: e2e-tests-watch-mq7vg, resource: bindings, ignored listing per whitelist
Mar 21 12:47:29.355: INFO: namespace e2e-tests-watch-mq7vg deletion completed in 6.131586393s

• [SLOW TEST:66.272 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:47:29.356: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar 21 12:47:29.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:29.796: INFO: stderr: ""
Mar 21 12:47:29.796: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 21 12:47:29.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:29.934: INFO: stderr: ""
Mar 21 12:47:29.934: INFO: stdout: "update-demo-nautilus-ffzb9 update-demo-nautilus-jwqqq "
Mar 21 12:47:29.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ffzb9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:30.101: INFO: stderr: ""
Mar 21 12:47:30.101: INFO: stdout: ""
Mar 21 12:47:30.101: INFO: update-demo-nautilus-ffzb9 is created but not running
Mar 21 12:47:35.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:35.240: INFO: stderr: ""
Mar 21 12:47:35.240: INFO: stdout: "update-demo-nautilus-ffzb9 update-demo-nautilus-jwqqq "
Mar 21 12:47:35.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ffzb9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:35.393: INFO: stderr: ""
Mar 21 12:47:35.393: INFO: stdout: "true"
Mar 21 12:47:35.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-ffzb9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:35.499: INFO: stderr: ""
Mar 21 12:47:35.499: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 12:47:35.499: INFO: validating pod update-demo-nautilus-ffzb9
Mar 21 12:47:35.507: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 12:47:35.507: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 12:47:35.507: INFO: update-demo-nautilus-ffzb9 is verified up and running
Mar 21 12:47:35.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-jwqqq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:35.656: INFO: stderr: ""
Mar 21 12:47:35.656: INFO: stdout: "true"
Mar 21 12:47:35.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-jwqqq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:35.794: INFO: stderr: ""
Mar 21 12:47:35.794: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 12:47:35.794: INFO: validating pod update-demo-nautilus-jwqqq
Mar 21 12:47:35.800: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 12:47:35.800: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 12:47:35.800: INFO: update-demo-nautilus-jwqqq is verified up and running
STEP: using delete to clean up resources
Mar 21 12:47:35.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:35.951: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 21 12:47:35.951: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 21 12:47:35.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-4ghxp'
Mar 21 12:47:36.067: INFO: stderr: "No resources found.\n"
Mar 21 12:47:36.067: INFO: stdout: ""
Mar 21 12:47:36.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -l name=update-demo --namespace=e2e-tests-kubectl-4ghxp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 21 12:47:36.191: INFO: stderr: ""
Mar 21 12:47:36.191: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:47:36.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4ghxp" for this suite.
Mar 21 12:47:58.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:47:58.281: INFO: namespace: e2e-tests-kubectl-4ghxp, resource: bindings, ignored listing per whitelist
Mar 21 12:47:58.314: INFO: namespace e2e-tests-kubectl-4ghxp deletion completed in 22.108060879s

• [SLOW TEST:28.958 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:47:58.315: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 21 12:48:04.413: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:04.413: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:04.563: INFO: Exec stderr: ""
Mar 21 12:48:04.563: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:04.563: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:04.728: INFO: Exec stderr: ""
Mar 21 12:48:04.728: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:04.728: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:04.867: INFO: Exec stderr: ""
Mar 21 12:48:04.867: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:04.867: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:05.002: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 21 12:48:05.002: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:05.002: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:05.143: INFO: Exec stderr: ""
Mar 21 12:48:05.143: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:05.143: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:05.286: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 21 12:48:05.286: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:05.286: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:05.422: INFO: Exec stderr: ""
Mar 21 12:48:05.422: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:05.422: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:05.554: INFO: Exec stderr: ""
Mar 21 12:48:05.554: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:05.555: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:05.689: INFO: Exec stderr: ""
Mar 21 12:48:05.689: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rbts7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 12:48:05.689: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 12:48:05.825: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:48:05.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-rbts7" for this suite.
Mar 21 12:48:51.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:48:51.879: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-rbts7, resource: bindings, ignored listing per whitelist
Mar 21 12:48:51.932: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-rbts7 deletion completed in 46.102871313s

• [SLOW TEST:53.618 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:48:51.933: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-adf45e28-4bd7-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:48:52.012: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-adf4ea8b-4bd7-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-r2slm" to be "success or failure"
Mar 21 12:48:52.015: INFO: Pod "pod-projected-secrets-adf4ea8b-4bd7-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.803006ms
Mar 21 12:48:54.021: INFO: Pod "pod-projected-secrets-adf4ea8b-4bd7-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008401565s
STEP: Saw pod success
Mar 21 12:48:54.021: INFO: Pod "pod-projected-secrets-adf4ea8b-4bd7-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:48:54.024: INFO: Trying to get logs from node antelope pod pod-projected-secrets-adf4ea8b-4bd7-11e9-9c6a-0a581900021b container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 21 12:48:54.044: INFO: Waiting for pod pod-projected-secrets-adf4ea8b-4bd7-11e9-9c6a-0a581900021b to disappear
Mar 21 12:48:54.046: INFO: Pod pod-projected-secrets-adf4ea8b-4bd7-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:48:54.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r2slm" for this suite.
Mar 21 12:49:00.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:49:00.154: INFO: namespace: e2e-tests-projected-r2slm, resource: bindings, ignored listing per whitelist
Mar 21 12:49:00.166: INFO: namespace e2e-tests-projected-r2slm deletion completed in 6.115874449s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:49:00.167: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-6d8r4 in namespace e2e-tests-proxy-8lkhw
I0321 12:49:00.264677      19 runners.go:184] Created replication controller with name: proxy-service-6d8r4, namespace: e2e-tests-proxy-8lkhw, replica count: 1
I0321 12:49:01.315900      19 runners.go:184] proxy-service-6d8r4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0321 12:49:02.316283      19 runners.go:184] proxy-service-6d8r4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0321 12:49:03.321742      19 runners.go:184] proxy-service-6d8r4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0321 12:49:04.322009      19 runners.go:184] proxy-service-6d8r4 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0321 12:49:05.322396      19 runners.go:184] proxy-service-6d8r4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0321 12:49:06.322691      19 runners.go:184] proxy-service-6d8r4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0321 12:49:07.323023      19 runners.go:184] proxy-service-6d8r4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 21 12:49:07.325: INFO: setup took 7.07581684s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 21 12:49:07.332: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 6.442446ms)
Mar 21 12:49:07.332: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.598156ms)
Mar 21 12:49:07.335: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 8.865978ms)
Mar 21 12:49:07.335: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 8.655788ms)
Mar 21 12:49:07.342: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 15.334042ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 22.462488ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 22.107239ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 22.439034ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 22.411281ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 22.120766ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 22.404568ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 23.021466ms)
Mar 21 12:49:07.349: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 22.857662ms)
Mar 21 12:49:07.353: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 26.674461ms)
Mar 21 12:49:07.355: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 28.003658ms)
Mar 21 12:49:07.355: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 28.561223ms)
Mar 21 12:49:07.362: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.892349ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 9.678423ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 10.122328ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 10.144041ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 10.146754ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 10.119992ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 9.752329ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 10.129959ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 10.347007ms)
Mar 21 12:49:07.365: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 10.435409ms)
Mar 21 12:49:07.366: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 10.65797ms)
Mar 21 12:49:07.366: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 10.638839ms)
Mar 21 12:49:07.366: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 10.542516ms)
Mar 21 12:49:07.366: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 10.603239ms)
Mar 21 12:49:07.366: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 10.55363ms)
Mar 21 12:49:07.366: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 10.84044ms)
Mar 21 12:49:07.375: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 9.331809ms)
Mar 21 12:49:07.375: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 9.305072ms)
Mar 21 12:49:07.375: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 9.32985ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 12.708679ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 12.790507ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 13.018902ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 12.920826ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 12.896521ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 12.979893ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 13.043037ms)
Mar 21 12:49:07.379: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 13.00193ms)
Mar 21 12:49:07.380: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 14.082426ms)
Mar 21 12:49:07.380: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 14.278364ms)
Mar 21 12:49:07.380: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 14.658039ms)
Mar 21 12:49:07.380: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 14.613443ms)
Mar 21 12:49:07.381: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 14.633127ms)
Mar 21 12:49:07.385: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 4.307392ms)
Mar 21 12:49:07.389: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 6.918691ms)
Mar 21 12:49:07.402: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 20.159578ms)
Mar 21 12:49:07.402: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 20.520414ms)
Mar 21 12:49:07.402: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 19.470448ms)
Mar 21 12:49:07.402: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 19.725013ms)
Mar 21 12:49:07.404: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 22.63466ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 23.077335ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 21.875271ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 23.076914ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 21.726002ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 21.917483ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 22.55272ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 22.989646ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 22.074779ms)
Mar 21 12:49:07.405: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 24.058177ms)
Mar 21 12:49:07.414: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.639065ms)
Mar 21 12:49:07.414: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 8.626658ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 10.809113ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 10.82469ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 10.76974ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 10.069296ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 11.214274ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 10.496248ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 10.236139ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 10.6365ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 9.965146ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 10.509104ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 10.116492ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 11.517573ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 11.194366ms)
Mar 21 12:49:07.417: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 10.502792ms)
Mar 21 12:49:07.422: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 4.123462ms)
Mar 21 12:49:07.422: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 4.256733ms)
Mar 21 12:49:07.425: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.164481ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 7.78731ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 7.530207ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 8.550371ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.3257ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 7.535098ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 8.900434ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 9.363754ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 8.205544ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 8.029716ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 7.640852ms)
Mar 21 12:49:07.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 8.543074ms)
Mar 21 12:49:07.429: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 9.193236ms)
Mar 21 12:49:07.429: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 9.741856ms)
Mar 21 12:49:07.435: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 6.177168ms)
Mar 21 12:49:07.437: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 8.065898ms)
Mar 21 12:49:07.437: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 7.085474ms)
Mar 21 12:49:07.437: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 7.008785ms)
Mar 21 12:49:07.438: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 8.141842ms)
Mar 21 12:49:07.438: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 7.411071ms)
Mar 21 12:49:07.438: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 8.310404ms)
Mar 21 12:49:07.438: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 8.765236ms)
Mar 21 12:49:07.438: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 8.472058ms)
Mar 21 12:49:07.439: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 8.423682ms)
Mar 21 12:49:07.439: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 8.268337ms)
Mar 21 12:49:07.439: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 9.591445ms)
Mar 21 12:49:07.439: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 9.266487ms)
Mar 21 12:49:07.439: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 9.657107ms)
Mar 21 12:49:07.439: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 9.642943ms)
Mar 21 12:49:07.440: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 9.677246ms)
Mar 21 12:49:07.445: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 5.394604ms)
Mar 21 12:49:07.446: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 5.791286ms)
Mar 21 12:49:07.446: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.562607ms)
Mar 21 12:49:07.446: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 6.215498ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 7.026129ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.099944ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 7.090248ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 7.09076ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 7.509477ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.420225ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.491005ms)
Mar 21 12:49:07.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 7.437411ms)
Mar 21 12:49:07.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 7.934329ms)
Mar 21 12:49:07.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 8.002892ms)
Mar 21 12:49:07.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 7.916889ms)
Mar 21 12:49:07.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 8.44363ms)
Mar 21 12:49:07.454: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 4.67034ms)
Mar 21 12:49:07.454: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 5.13802ms)
Mar 21 12:49:07.454: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 5.470451ms)
Mar 21 12:49:07.454: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 5.389748ms)
Mar 21 12:49:07.454: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 5.743542ms)
Mar 21 12:49:07.454: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 6.242049ms)
Mar 21 12:49:07.477: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 27.914732ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 27.83198ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 28.442353ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 27.880231ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 28.346295ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 29.457038ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 28.555274ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 28.001001ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 29.493976ms)
Mar 21 12:49:07.478: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 28.387591ms)
Mar 21 12:49:07.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 4.430686ms)
Mar 21 12:49:07.484: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 5.545191ms)
Mar 21 12:49:07.484: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 4.842278ms)
Mar 21 12:49:07.486: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 6.840233ms)
Mar 21 12:49:07.486: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.653201ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 7.841848ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 7.150064ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 7.869635ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 7.782122ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 7.067379ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 7.769829ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.484877ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 7.988383ms)
Mar 21 12:49:07.487: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.543961ms)
Mar 21 12:49:07.488: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 8.954757ms)
Mar 21 12:49:07.488: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 8.480366ms)
Mar 21 12:49:07.494: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 5.623618ms)
Mar 21 12:49:07.499: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 9.416779ms)
Mar 21 12:49:07.513: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 23.62397ms)
Mar 21 12:49:07.513: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 24.196703ms)
Mar 21 12:49:07.513: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 23.670289ms)
Mar 21 12:49:07.513: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 24.051619ms)
Mar 21 12:49:07.513: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 24.004327ms)
Mar 21 12:49:07.513: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 24.522719ms)
Mar 21 12:49:07.513: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 24.500396ms)
Mar 21 12:49:07.514: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 24.575514ms)
Mar 21 12:49:07.514: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 24.765217ms)
Mar 21 12:49:07.514: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 24.909134ms)
Mar 21 12:49:07.514: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 24.794114ms)
Mar 21 12:49:07.514: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 25.04992ms)
Mar 21 12:49:07.514: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 25.682152ms)
Mar 21 12:49:07.514: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 25.530216ms)
Mar 21 12:49:07.523: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.359775ms)
Mar 21 12:49:07.523: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 8.790999ms)
Mar 21 12:49:07.524: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 7.746363ms)
Mar 21 12:49:07.524: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 6.829281ms)
Mar 21 12:49:07.529: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 11.705778ms)
Mar 21 12:49:07.534: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 15.993927ms)
Mar 21 12:49:07.534: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 16.248048ms)
Mar 21 12:49:07.534: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 16.239736ms)
Mar 21 12:49:07.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 16.963385ms)
Mar 21 12:49:07.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 20.277082ms)
Mar 21 12:49:07.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 17.579606ms)
Mar 21 12:49:07.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 17.728326ms)
Mar 21 12:49:07.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 12.828599ms)
Mar 21 12:49:07.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 17.703809ms)
Mar 21 12:49:07.535: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 20.538301ms)
Mar 21 12:49:07.536: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 18.422011ms)
Mar 21 12:49:07.543: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.551605ms)
Mar 21 12:49:07.544: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.564776ms)
Mar 21 12:49:07.544: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.332364ms)
Mar 21 12:49:07.544: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.874899ms)
Mar 21 12:49:07.545: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 9.035367ms)
Mar 21 12:49:07.545: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 8.983706ms)
Mar 21 12:49:07.545: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 8.178508ms)
Mar 21 12:49:07.545: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 8.158397ms)
Mar 21 12:49:07.545: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 8.610012ms)
Mar 21 12:49:07.545: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 8.679012ms)
Mar 21 12:49:07.546: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 8.982797ms)
Mar 21 12:49:07.546: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 9.620718ms)
Mar 21 12:49:07.546: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 9.741775ms)
Mar 21 12:49:07.546: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 9.674165ms)
Mar 21 12:49:07.547: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 10.294053ms)
Mar 21 12:49:07.547: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 9.976227ms)
Mar 21 12:49:07.560: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 10.755889ms)
Mar 21 12:49:07.560: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 11.372164ms)
Mar 21 12:49:07.562: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 14.02041ms)
Mar 21 12:49:07.562: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 13.569298ms)
Mar 21 12:49:07.563: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 15.747932ms)
Mar 21 12:49:07.563: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 14.181307ms)
Mar 21 12:49:07.563: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 15.187595ms)
Mar 21 12:49:07.563: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 13.858627ms)
Mar 21 12:49:07.564: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 14.507098ms)
Mar 21 12:49:07.564: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 15.346148ms)
Mar 21 12:49:07.564: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 14.440178ms)
Mar 21 12:49:07.569: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 20.674669ms)
Mar 21 12:49:07.569: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 19.33088ms)
Mar 21 12:49:07.569: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 19.344188ms)
Mar 21 12:49:07.569: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 21.979197ms)
Mar 21 12:49:07.569: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 22.205646ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 11.695972ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 11.954745ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 12.969419ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 11.406264ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 12.142042ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 11.656441ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 12.481422ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 12.787553ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 11.841026ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 12.367623ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 12.984837ms)
Mar 21 12:49:07.582: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 12.703997ms)
Mar 21 12:49:07.583: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 11.745199ms)
Mar 21 12:49:07.583: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 12.175449ms)
Mar 21 12:49:07.583: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 12.58761ms)
Mar 21 12:49:07.584: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 13.892079ms)
Mar 21 12:49:07.592: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.925652ms)
Mar 21 12:49:07.592: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 8.671237ms)
Mar 21 12:49:07.592: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 8.241804ms)
Mar 21 12:49:07.592: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 8.196966ms)
Mar 21 12:49:07.596: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 11.603184ms)
Mar 21 12:49:07.596: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 12.144293ms)
Mar 21 12:49:07.596: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 11.524378ms)
Mar 21 12:49:07.597: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 12.650506ms)
Mar 21 12:49:07.597: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 12.181239ms)
Mar 21 12:49:07.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 13.702123ms)
Mar 21 12:49:07.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 12.800058ms)
Mar 21 12:49:07.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 13.41307ms)
Mar 21 12:49:07.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 13.090641ms)
Mar 21 12:49:07.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 14.186809ms)
Mar 21 12:49:07.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 13.595397ms)
Mar 21 12:49:07.598: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 13.210655ms)
Mar 21 12:49:07.605: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 5.980401ms)
Mar 21 12:49:07.605: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 6.386215ms)
Mar 21 12:49:07.605: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.56196ms)
Mar 21 12:49:07.605: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 6.002408ms)
Mar 21 12:49:07.605: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.094741ms)
Mar 21 12:49:07.606: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 6.361562ms)
Mar 21 12:49:07.606: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.132219ms)
Mar 21 12:49:07.606: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 7.034083ms)
Mar 21 12:49:07.606: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 6.617935ms)
Mar 21 12:49:07.606: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 6.941638ms)
Mar 21 12:49:07.607: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 8.019212ms)
Mar 21 12:49:07.607: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 8.108693ms)
Mar 21 12:49:07.607: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 8.993927ms)
Mar 21 12:49:07.608: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 8.795274ms)
Mar 21 12:49:07.608: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 8.725393ms)
Mar 21 12:49:07.608: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 9.238228ms)
Mar 21 12:49:07.611: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 3.668083ms)
Mar 21 12:49:07.614: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 5.433384ms)
Mar 21 12:49:07.614: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 5.66275ms)
Mar 21 12:49:07.615: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 7.539742ms)
Mar 21 12:49:07.616: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 6.865487ms)
Mar 21 12:49:07.616: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 7.855631ms)
Mar 21 12:49:07.616: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 7.941696ms)
Mar 21 12:49:07.616: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.839455ms)
Mar 21 12:49:07.616: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 6.872598ms)
Mar 21 12:49:07.616: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.200248ms)
Mar 21 12:49:07.617: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 9.306165ms)
Mar 21 12:49:07.617: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 9.391759ms)
Mar 21 12:49:07.617: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 9.508947ms)
Mar 21 12:49:07.617: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 8.567686ms)
Mar 21 12:49:07.617: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 9.482365ms)
Mar 21 12:49:07.620: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 12.528393ms)
Mar 21 12:49:07.627: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 5.782541ms)
Mar 21 12:49:07.627: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 6.820947ms)
Mar 21 12:49:07.627: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 6.08932ms)
Mar 21 12:49:07.627: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 6.072419ms)
Mar 21 12:49:07.628: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 7.330772ms)
Mar 21 12:49:07.628: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 7.041645ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 6.853809ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 7.436967ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 7.48115ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 7.382742ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 7.855904ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 7.971892ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 7.671366ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 8.644915ms)
Mar 21 12:49:07.629: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 8.350092ms)
Mar 21 12:49:07.630: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 8.796877ms)
Mar 21 12:49:07.636: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:462/proxy/: tls qux (200; 6.169766ms)
Mar 21 12:49:07.637: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:1080/proxy/... (200; 6.09597ms)
Mar 21 12:49:07.636: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 5.926985ms)
Mar 21 12:49:07.637: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:460/proxy/: tls baz (200; 6.034093ms)
Mar 21 12:49:07.637: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname2/proxy/: tls qux (200; 6.72323ms)
Mar 21 12:49:07.637: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:160/proxy/: foo (200; 6.733981ms)
Mar 21 12:49:07.637: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/http:proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 7.019057ms)
Mar 21 12:49:07.637: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b/proxy/rewriteme"... (200; 6.925337ms)
Mar 21 12:49:07.638: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/https:proxy-service-6d8r4-cnz2b:443/proxy/... (200; 7.135131ms)
Mar 21 12:49:07.638: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:1080/proxy/rewri... (200; 7.247984ms)
Mar 21 12:49:07.638: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/pods/proxy-service-6d8r4-cnz2b:162/proxy/: bar (200; 8.049192ms)
Mar 21 12:49:07.638: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname1/proxy/: foo (200; 8.043449ms)
Mar 21 12:49:07.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/https:proxy-service-6d8r4:tlsportname1/proxy/: tls baz (200; 8.191914ms)
Mar 21 12:49:07.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname2/proxy/: bar (200; 8.299073ms)
Mar 21 12:49:07.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/proxy-service-6d8r4:portname2/proxy/: bar (200; 9.005265ms)
Mar 21 12:49:07.640: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8lkhw/services/http:proxy-service-6d8r4:portname1/proxy/: foo (200; 9.139906ms)
STEP: deleting ReplicationController proxy-service-6d8r4 in namespace e2e-tests-proxy-8lkhw, will wait for the garbage collector to delete the pods
Mar 21 12:49:07.701: INFO: Deleting ReplicationController proxy-service-6d8r4 took: 6.697008ms
Mar 21 12:49:07.801: INFO: Terminating ReplicationController proxy-service-6d8r4 pods took: 100.378284ms
[AfterEach] version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:49:09.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8lkhw" for this suite.
Mar 21 12:49:15.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:49:15.836: INFO: namespace: e2e-tests-proxy-8lkhw, resource: bindings, ignored listing per whitelist
Mar 21 12:49:15.929: INFO: namespace e2e-tests-proxy-8lkhw deletion completed in 6.121328161s

• [SLOW TEST:15.762 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:49:15.929: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 21 12:49:16.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dl5nn'
Mar 21 12:49:16.296: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 21 12:49:16.296: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Mar 21 12:49:16.311: INFO: scanned /root for discovery docs: <nil>
Mar 21 12:49:16.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-dl5nn'
Mar 21 12:49:30.474: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 21 12:49:30.474: INFO: stdout: "Created e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e\nScaling up e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar 21 12:49:30.474: INFO: stdout: "Created e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e\nScaling up e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar 21 12:49:30.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dl5nn'
Mar 21 12:49:30.649: INFO: stderr: ""
Mar 21 12:49:30.649: INFO: stdout: "e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e-s6png e2e-test-nginx-rc-jtkpm "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Mar 21 12:49:35.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dl5nn'
Mar 21 12:49:35.824: INFO: stderr: ""
Mar 21 12:49:35.824: INFO: stdout: "e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e-s6png "
Mar 21 12:49:35.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e-s6png -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dl5nn'
Mar 21 12:49:36.030: INFO: stderr: ""
Mar 21 12:49:36.030: INFO: stdout: "true"
Mar 21 12:49:36.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e-s6png -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dl5nn'
Mar 21 12:49:36.265: INFO: stderr: ""
Mar 21 12:49:36.265: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar 21 12:49:36.265: INFO: e2e-test-nginx-rc-0e98091224c6265c215d9c55c8fb6c9e-s6png is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Mar 21 12:49:36.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dl5nn'
Mar 21 12:49:36.484: INFO: stderr: ""
Mar 21 12:49:36.484: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:49:36.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dl5nn" for this suite.
Mar 21 12:49:42.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:49:42.522: INFO: namespace: e2e-tests-kubectl-dl5nn, resource: bindings, ignored listing per whitelist
Mar 21 12:49:42.608: INFO: namespace e2e-tests-kubectl-dl5nn deletion completed in 6.109330193s

• [SLOW TEST:26.679 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:49:42.608: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:49:42.710: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 21 12:49:42.716: INFO: Number of nodes with available pods: 0
Mar 21 12:49:42.716: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 21 12:49:42.734: INFO: Number of nodes with available pods: 0
Mar 21 12:49:42.737: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:43.741: INFO: Number of nodes with available pods: 0
Mar 21 12:49:43.741: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:44.741: INFO: Number of nodes with available pods: 1
Mar 21 12:49:44.741: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 21 12:49:44.757: INFO: Number of nodes with available pods: 1
Mar 21 12:49:44.757: INFO: Number of running nodes: 0, number of available pods: 1
Mar 21 12:49:45.761: INFO: Number of nodes with available pods: 0
Mar 21 12:49:45.761: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 21 12:49:45.769: INFO: Number of nodes with available pods: 0
Mar 21 12:49:45.769: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:46.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:46.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:47.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:47.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:48.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:48.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:49.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:49.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:50.772: INFO: Number of nodes with available pods: 0
Mar 21 12:49:50.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:51.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:51.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:52.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:52.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:53.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:53.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:54.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:54.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:55.772: INFO: Number of nodes with available pods: 0
Mar 21 12:49:55.772: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:56.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:56.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:57.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:57.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:58.772: INFO: Number of nodes with available pods: 0
Mar 21 12:49:58.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:49:59.773: INFO: Number of nodes with available pods: 0
Mar 21 12:49:59.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:00.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:00.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:01.781: INFO: Number of nodes with available pods: 0
Mar 21 12:50:01.781: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:02.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:02.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:03.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:03.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:04.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:04.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:05.774: INFO: Number of nodes with available pods: 0
Mar 21 12:50:05.774: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:06.777: INFO: Number of nodes with available pods: 0
Mar 21 12:50:06.777: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:07.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:07.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:08.772: INFO: Number of nodes with available pods: 0
Mar 21 12:50:08.772: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:09.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:09.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:10.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:10.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:11.772: INFO: Number of nodes with available pods: 0
Mar 21 12:50:11.772: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:12.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:12.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:13.869: INFO: Number of nodes with available pods: 0
Mar 21 12:50:13.869: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:14.772: INFO: Number of nodes with available pods: 0
Mar 21 12:50:14.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:15.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:15.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:16.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:16.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:17.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:17.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:18.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:18.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:19.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:19.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:20.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:20.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:21.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:21.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:22.773: INFO: Number of nodes with available pods: 0
Mar 21 12:50:22.773: INFO: Node antelope is running more than one daemon pod
Mar 21 12:50:23.773: INFO: Number of nodes with available pods: 1
Mar 21 12:50:23.773: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-wjmkw, will wait for the garbage collector to delete the pods
Mar 21 12:50:23.838: INFO: Deleting DaemonSet.extensions daemon-set took: 5.963698ms
Mar 21 12:50:23.938: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.407699ms
Mar 21 12:50:57.642: INFO: Number of nodes with available pods: 0
Mar 21 12:50:57.642: INFO: Number of running nodes: 0, number of available pods: 0
Mar 21 12:50:57.644: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wjmkw/daemonsets","resourceVersion":"26217"},"items":null}

Mar 21 12:50:57.647: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wjmkw/pods","resourceVersion":"26217"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:50:57.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wjmkw" for this suite.
Mar 21 12:51:03.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:51:03.735: INFO: namespace: e2e-tests-daemonsets-wjmkw, resource: bindings, ignored listing per whitelist
Mar 21 12:51:03.762: INFO: namespace e2e-tests-daemonsets-wjmkw deletion completed in 6.095447918s

• [SLOW TEST:81.154 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:51:03.763: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 21 12:51:03.845: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-pkz5g,SelfLink:/api/v1/namespaces/e2e-tests-watch-pkz5g/configmaps/e2e-watch-test-watch-closed,UID:fc8862ec-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:26252,Generation:0,CreationTimestamp:2019-03-21 12:51:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 21 12:51:03.845: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-pkz5g,SelfLink:/api/v1/namespaces/e2e-tests-watch-pkz5g/configmaps/e2e-watch-test-watch-closed,UID:fc8862ec-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:26253,Generation:0,CreationTimestamp:2019-03-21 12:51:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 21 12:51:03.858: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-pkz5g,SelfLink:/api/v1/namespaces/e2e-tests-watch-pkz5g/configmaps/e2e-watch-test-watch-closed,UID:fc8862ec-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:26254,Generation:0,CreationTimestamp:2019-03-21 12:51:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 21 12:51:03.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-pkz5g,SelfLink:/api/v1/namespaces/e2e-tests-watch-pkz5g/configmaps/e2e-watch-test-watch-closed,UID:fc8862ec-4bd7-11e9-8b3c-9eae6a3150d7,ResourceVersion:26255,Generation:0,CreationTimestamp:2019-03-21 12:51:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:51:03.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-pkz5g" for this suite.
Mar 21 12:51:09.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:51:09.982: INFO: namespace: e2e-tests-watch-pkz5g, resource: bindings, ignored listing per whitelist
Mar 21 12:51:09.991: INFO: namespace e2e-tests-watch-pkz5g deletion completed in 6.116546596s

• [SLOW TEST:6.228 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:51:09.991: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 21 12:51:10.074: INFO: Waiting up to 5m0s for pod "pod-003f6e8b-4bd8-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-pv7kp" to be "success or failure"
Mar 21 12:51:10.077: INFO: Pod "pod-003f6e8b-4bd8-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.66451ms
Mar 21 12:51:12.082: INFO: Pod "pod-003f6e8b-4bd8-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007622457s
STEP: Saw pod success
Mar 21 12:51:12.082: INFO: Pod "pod-003f6e8b-4bd8-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:51:12.088: INFO: Trying to get logs from node antelope pod pod-003f6e8b-4bd8-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 12:51:12.135: INFO: Waiting for pod pod-003f6e8b-4bd8-11e9-9c6a-0a581900021b to disappear
Mar 21 12:51:12.138: INFO: Pod pod-003f6e8b-4bd8-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:51:12.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pv7kp" for this suite.
Mar 21 12:51:18.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:51:18.229: INFO: namespace: e2e-tests-emptydir-pv7kp, resource: bindings, ignored listing per whitelist
Mar 21 12:51:18.238: INFO: namespace e2e-tests-emptydir-pv7kp deletion completed in 6.095842323s

• [SLOW TEST:8.247 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:51:18.241: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 12:51:18.354: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Mar 21 12:51:18.361: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2tsp5/daemonsets","resourceVersion":"26310"},"items":null}

Mar 21 12:51:18.367: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2tsp5/pods","resourceVersion":"26310"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:51:18.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2tsp5" for this suite.
Mar 21 12:51:24.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:51:24.456: INFO: namespace: e2e-tests-daemonsets-2tsp5, resource: bindings, ignored listing per whitelist
Mar 21 12:51:24.507: INFO: namespace e2e-tests-daemonsets-2tsp5 deletion completed in 6.120547206s

S [SKIPPING] [6.266 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar 21 12:51:18.354: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:51:24.508: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lrqcn
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar 21 12:51:24.585: INFO: Found 0 stateful pods, waiting for 3
Mar 21 12:51:34.589: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 12:51:34.589: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 12:51:34.589: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 21 12:51:34.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-lrqcn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 12:51:34.976: INFO: stderr: ""
Mar 21 12:51:34.976: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 12:51:34.976: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar 21 12:51:45.007: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 21 12:51:55.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-lrqcn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:51:55.414: INFO: stderr: ""
Mar 21 12:51:55.414: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 12:51:55.414: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 12:52:05.435: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqcn/ss2 to complete update
Mar 21 12:52:05.435: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 12:52:05.435: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 12:52:05.435: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 12:52:15.442: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqcn/ss2 to complete update
Mar 21 12:52:15.442: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar 21 12:52:25.443: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqcn/ss2 to complete update
Mar 21 12:52:25.443: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar 21 12:52:35.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-lrqcn ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar 21 12:52:35.842: INFO: stderr: ""
Mar 21 12:52:35.842: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar 21 12:52:35.842: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar 21 12:52:45.885: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 21 12:52:55.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 exec --namespace=e2e-tests-statefulset-lrqcn ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar 21 12:52:56.282: INFO: stderr: ""
Mar 21 12:52:56.282: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar 21 12:52:56.282: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar 21 12:53:06.303: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqcn/ss2 to complete update
Mar 21 12:53:06.303: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 21 12:53:06.304: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 21 12:53:06.304: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 21 12:53:16.310: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqcn/ss2 to complete update
Mar 21 12:53:16.310: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 21 12:53:16.310: INFO: Waiting for Pod e2e-tests-statefulset-lrqcn/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar 21 12:53:26.311: INFO: Waiting for StatefulSet e2e-tests-statefulset-lrqcn/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 21 12:53:36.310: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lrqcn
Mar 21 12:53:36.314: INFO: Scaling statefulset ss2 to 0
Mar 21 12:53:56.331: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 12:53:56.334: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:53:56.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lrqcn" for this suite.
Mar 21 12:54:02.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:54:02.480: INFO: namespace: e2e-tests-statefulset-lrqcn, resource: bindings, ignored listing per whitelist
Mar 21 12:54:02.489: INFO: namespace e2e-tests-statefulset-lrqcn deletion completed in 6.138395134s

• [SLOW TEST:157.982 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:54:02.490: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:54:08.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-mtt2f" for this suite.
Mar 21 12:54:14.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:54:14.742: INFO: namespace: e2e-tests-namespaces-mtt2f, resource: bindings, ignored listing per whitelist
Mar 21 12:54:14.799: INFO: namespace e2e-tests-namespaces-mtt2f deletion completed in 6.106984107s
STEP: Destroying namespace "e2e-tests-nsdeletetest-md4g8" for this suite.
Mar 21 12:54:14.803: INFO: Namespace e2e-tests-nsdeletetest-md4g8 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-x2x6n" for this suite.
Mar 21 12:54:20.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:54:20.842: INFO: namespace: e2e-tests-nsdeletetest-x2x6n, resource: bindings, ignored listing per whitelist
Mar 21 12:54:20.971: INFO: namespace e2e-tests-nsdeletetest-x2x6n deletion completed in 6.167926402s

• [SLOW TEST:18.481 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:54:20.971: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 21 12:54:21.091: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:54:24.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-9tnsm" for this suite.
Mar 21 12:54:30.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:54:30.918: INFO: namespace: e2e-tests-init-container-9tnsm, resource: bindings, ignored listing per whitelist
Mar 21 12:54:31.004: INFO: namespace e2e-tests-init-container-9tnsm deletion completed in 6.105074605s

• [SLOW TEST:10.033 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:54:31.005: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-780e7ccf-4bd8-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 12:54:31.086: INFO: Waiting up to 5m0s for pod "pod-configmaps-780f045f-4bd8-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-wn7j8" to be "success or failure"
Mar 21 12:54:31.093: INFO: Pod "pod-configmaps-780f045f-4bd8-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.77142ms
Mar 21 12:54:33.097: INFO: Pod "pod-configmaps-780f045f-4bd8-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010746247s
STEP: Saw pod success
Mar 21 12:54:33.097: INFO: Pod "pod-configmaps-780f045f-4bd8-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:54:33.100: INFO: Trying to get logs from node wolf pod pod-configmaps-780f045f-4bd8-11e9-9c6a-0a581900021b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 12:54:33.120: INFO: Waiting for pod pod-configmaps-780f045f-4bd8-11e9-9c6a-0a581900021b to disappear
Mar 21 12:54:33.123: INFO: Pod pod-configmaps-780f045f-4bd8-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:54:33.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wn7j8" for this suite.
Mar 21 12:54:39.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:54:39.240: INFO: namespace: e2e-tests-configmap-wn7j8, resource: bindings, ignored listing per whitelist
Mar 21 12:54:39.253: INFO: namespace e2e-tests-configmap-wn7j8 deletion completed in 6.12595633s

• [SLOW TEST:8.249 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:54:39.254: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7cfc08a6-4bd8-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 12:54:39.352: INFO: Waiting up to 5m0s for pod "pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b" in namespace "e2e-tests-secrets-wdtmn" to be "success or failure"
Mar 21 12:54:39.356: INFO: Pod "pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.857194ms
Mar 21 12:54:41.359: INFO: Pod "pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007743097s
Mar 21 12:54:43.363: INFO: Pod "pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011374846s
STEP: Saw pod success
Mar 21 12:54:43.363: INFO: Pod "pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:54:43.371: INFO: Trying to get logs from node antelope pod pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b container secret-volume-test: <nil>
STEP: delete the pod
Mar 21 12:54:43.390: INFO: Waiting for pod pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b to disappear
Mar 21 12:54:43.393: INFO: Pod pod-secrets-7cfc95c1-4bd8-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:54:43.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wdtmn" for this suite.
Mar 21 12:54:49.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:54:49.497: INFO: namespace: e2e-tests-secrets-wdtmn, resource: bindings, ignored listing per whitelist
Mar 21 12:54:49.548: INFO: namespace e2e-tests-secrets-wdtmn deletion completed in 6.150916107s

• [SLOW TEST:10.295 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:54:49.549: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar 21 12:54:49.618: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:54:53.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cpwcb" for this suite.
Mar 21 12:55:15.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:55:15.570: INFO: namespace: e2e-tests-init-container-cpwcb, resource: bindings, ignored listing per whitelist
Mar 21 12:55:15.620: INFO: namespace e2e-tests-init-container-cpwcb deletion completed in 22.096487342s

• [SLOW TEST:26.071 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:55:15.620: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:55:15.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-ngbqw" to be "success or failure"
Mar 21 12:55:15.697: INFO: Pod "downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320448ms
Mar 21 12:55:17.700: INFO: Pod "downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b": Phase="Running", Reason="", readiness=true. Elapsed: 2.007221427s
Mar 21 12:55:19.704: INFO: Pod "downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011147073s
STEP: Saw pod success
Mar 21 12:55:19.704: INFO: Pod "downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:55:19.707: INFO: Trying to get logs from node jaguar pod downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:55:19.725: INFO: Waiting for pod downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b to disappear
Mar 21 12:55:19.728: INFO: Pod downwardapi-volume-92a5e798-4bd8-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:55:19.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ngbqw" for this suite.
Mar 21 12:55:25.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:55:25.811: INFO: namespace: e2e-tests-projected-ngbqw, resource: bindings, ignored listing per whitelist
Mar 21 12:55:25.822: INFO: namespace e2e-tests-projected-ngbqw deletion completed in 6.089846781s

• [SLOW TEST:10.202 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:55:25.823: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-q9zlx;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-q9zlx;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q9zlx.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 20.178.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.178.20_udp@PTR;check="$$(dig +tcp +noall +answer +search 20.178.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.178.20_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-q9zlx;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-q9zlx.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-q9zlx.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q9zlx.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 20.178.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.178.20_udp@PTR;check="$$(dig +tcp +noall +answer +search 20.178.105.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.105.178.20_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 21 12:55:27.946: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:27.974: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.010: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.014: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.018: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.023: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.027: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.030: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.034: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.038: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:28.068: INFO: Lookups using e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q9zlx jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc]

Mar 21 12:55:33.072: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.096: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.130: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.136: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.141: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.145: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.149: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.153: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.157: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.162: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:33.190: INFO: Lookups using e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q9zlx jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc]

Mar 21 12:55:38.073: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.098: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.131: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.135: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.139: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.143: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.147: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.150: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.154: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.157: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:38.183: INFO: Lookups using e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q9zlx jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc]

Mar 21 12:55:43.073: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.099: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.278: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.282: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.286: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.290: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.296: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.301: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.305: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.310: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:43.335: INFO: Lookups using e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q9zlx jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc]

Mar 21 12:55:48.073: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.098: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.149: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.153: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.157: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.160: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.164: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.168: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.172: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.176: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:48.206: INFO: Lookups using e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q9zlx jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc]

Mar 21 12:55:53.074: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.095: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.129: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.134: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.138: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.142: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.146: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.149: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.154: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.158: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc from pod e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b: the server could not find the requested resource (get pods dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b)
Mar 21 12:55:53.184: INFO: Lookups using e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b failed for: [wheezy_udp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-q9zlx jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx jessie_udp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@dns-test-service.e2e-tests-dns-q9zlx.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-q9zlx.svc]

Mar 21 12:55:58.183: INFO: DNS probes using e2e-tests-dns-q9zlx/dns-test-98bf3bcc-4bd8-11e9-9c6a-0a581900021b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:55:58.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-q9zlx" for this suite.
Mar 21 12:56:04.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:56:04.261: INFO: namespace: e2e-tests-dns-q9zlx, resource: bindings, ignored listing per whitelist
Mar 21 12:56:04.378: INFO: namespace e2e-tests-dns-q9zlx deletion completed in 6.14784237s

• [SLOW TEST:38.555 seconds]
[sig-network] DNS
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:56:04.379: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-bs52
STEP: Creating a pod to test atomic-volume-subpath
Mar 21 12:56:04.459: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bs52" in namespace "e2e-tests-subpath-qwl7d" to be "success or failure"
Mar 21 12:56:04.462: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.582112ms
Mar 21 12:56:06.465: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006305538s
Mar 21 12:56:08.469: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 4.009830638s
Mar 21 12:56:10.473: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 6.013884078s
Mar 21 12:56:12.477: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 8.017601394s
Mar 21 12:56:14.480: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 10.020860993s
Mar 21 12:56:16.484: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 12.024752783s
Mar 21 12:56:18.488: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 14.028786647s
Mar 21 12:56:20.492: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 16.032638892s
Mar 21 12:56:22.495: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 18.036085352s
Mar 21 12:56:24.499: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 20.039682088s
Mar 21 12:56:26.503: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Running", Reason="", readiness=false. Elapsed: 22.04341464s
Mar 21 12:56:28.506: INFO: Pod "pod-subpath-test-configmap-bs52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046996649s
STEP: Saw pod success
Mar 21 12:56:28.506: INFO: Pod "pod-subpath-test-configmap-bs52" satisfied condition "success or failure"
Mar 21 12:56:28.509: INFO: Trying to get logs from node jaguar pod pod-subpath-test-configmap-bs52 container test-container-subpath-configmap-bs52: <nil>
STEP: delete the pod
Mar 21 12:56:28.527: INFO: Waiting for pod pod-subpath-test-configmap-bs52 to disappear
Mar 21 12:56:28.530: INFO: Pod pod-subpath-test-configmap-bs52 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bs52
Mar 21 12:56:28.530: INFO: Deleting pod "pod-subpath-test-configmap-bs52" in namespace "e2e-tests-subpath-qwl7d"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:56:28.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qwl7d" for this suite.
Mar 21 12:56:34.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:56:34.663: INFO: namespace: e2e-tests-subpath-qwl7d, resource: bindings, ignored listing per whitelist
Mar 21 12:56:34.665: INFO: namespace e2e-tests-subpath-qwl7d deletion completed in 6.128135885s

• [SLOW TEST:30.287 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:56:34.668: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 21 12:56:36.758: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-c1c38cbe-4bd8-11e9-9c6a-0a581900021b,GenerateName:,Namespace:e2e-tests-events-xnvj9,SelfLink:/api/v1/namespaces/e2e-tests-events-xnvj9/pods/send-events-c1c38cbe-4bd8-11e9-9c6a-0a581900021b,UID:c1c401b8-4bd8-11e9-8b3c-9eae6a3150d7,ResourceVersion:27426,Generation:0,CreationTimestamp:2019-03-21 12:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 734823737,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dpkk4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dpkk4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-dpkk4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:wolf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e5c000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e5c020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:56:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:56:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:56:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-21 12:56:34 +0000 UTC  }],Message:,Reason:,HostIP:104.248.170.89,PodIP:25.0.1.130,StartTime:2019-03-21 12:56:34 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-21 12:56:35 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a187d511135456ccb5a0d77a76b87a2fb75f1825bdd20e4148ccacca13f82e69}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar 21 12:56:38.762: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 21 12:56:40.766: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:56:40.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xnvj9" for this suite.
Mar 21 12:57:20.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:57:20.811: INFO: namespace: e2e-tests-events-xnvj9, resource: bindings, ignored listing per whitelist
Mar 21 12:57:20.872: INFO: namespace e2e-tests-events-xnvj9 deletion completed in 40.0950789s

• [SLOW TEST:46.204 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:57:20.873: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 12:57:20.947: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd4e174b-4bd8-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-t2dcg" to be "success or failure"
Mar 21 12:57:20.952: INFO: Pod "downwardapi-volume-dd4e174b-4bd8-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.657846ms
Mar 21 12:57:22.956: INFO: Pod "downwardapi-volume-dd4e174b-4bd8-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009304713s
STEP: Saw pod success
Mar 21 12:57:22.957: INFO: Pod "downwardapi-volume-dd4e174b-4bd8-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 12:57:22.959: INFO: Trying to get logs from node antelope pod downwardapi-volume-dd4e174b-4bd8-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 12:57:22.991: INFO: Waiting for pod downwardapi-volume-dd4e174b-4bd8-11e9-9c6a-0a581900021b to disappear
Mar 21 12:57:22.994: INFO: Pod downwardapi-volume-dd4e174b-4bd8-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:57:22.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t2dcg" for this suite.
Mar 21 12:57:29.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:57:29.026: INFO: namespace: e2e-tests-downward-api-t2dcg, resource: bindings, ignored listing per whitelist
Mar 21 12:57:29.112: INFO: namespace e2e-tests-downward-api-t2dcg deletion completed in 6.111934159s

• [SLOW TEST:8.239 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:57:29.113: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-e2375800-4bd8-11e9-9c6a-0a581900021b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 12:57:31.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jtrx8" for this suite.
Mar 21 12:57:53.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 12:57:53.334: INFO: namespace: e2e-tests-configmap-jtrx8, resource: bindings, ignored listing per whitelist
Mar 21 12:57:53.341: INFO: namespace e2e-tests-configmap-jtrx8 deletion completed in 22.110195692s

• [SLOW TEST:24.228 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 12:57:53.342: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-z754j
Mar 21 12:57:55.428: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-z754j
STEP: checking the pod's current state and verifying that restartCount is present
Mar 21 12:57:55.431: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:01:55.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z754j" for this suite.
Mar 21 13:02:01.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:02:01.939: INFO: namespace: e2e-tests-container-probe-z754j, resource: bindings, ignored listing per whitelist
Mar 21 13:02:01.990: INFO: namespace e2e-tests-container-probe-z754j deletion completed in 6.093261956s

• [SLOW TEST:248.648 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:02:01.990: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kmsgn
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-kmsgn
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-kmsgn
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-kmsgn
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-kmsgn
Mar 21 13:02:06.111: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kmsgn, name: ss-0, uid: 87091c7d-4bd9-11e9-8b3c-9eae6a3150d7, status phase: Pending. Waiting for statefulset controller to delete.
Mar 21 13:02:06.290: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kmsgn, name: ss-0, uid: 87091c7d-4bd9-11e9-8b3c-9eae6a3150d7, status phase: Failed. Waiting for statefulset controller to delete.
Mar 21 13:02:06.295: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-kmsgn, name: ss-0, uid: 87091c7d-4bd9-11e9-8b3c-9eae6a3150d7, status phase: Failed. Waiting for statefulset controller to delete.
Mar 21 13:02:06.297: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-kmsgn
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-kmsgn
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-kmsgn and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar 21 13:02:10.315: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kmsgn
Mar 21 13:02:10.317: INFO: Scaling statefulset ss to 0
Mar 21 13:02:20.335: INFO: Waiting for statefulset status.replicas updated to 0
Mar 21 13:02:20.338: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:02:20.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kmsgn" for this suite.
Mar 21 13:02:26.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:02:26.388: INFO: namespace: e2e-tests-statefulset-kmsgn, resource: bindings, ignored listing per whitelist
Mar 21 13:02:26.485: INFO: namespace e2e-tests-statefulset-kmsgn deletion completed in 6.131541988s

• [SLOW TEST:24.495 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:02:26.486: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-wq8h2/configmap-test-9379a21b-4bd9-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 13:02:26.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b" in namespace "e2e-tests-configmap-wq8h2" to be "success or failure"
Mar 21 13:02:26.587: INFO: Pod "pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.544216ms
Mar 21 13:02:28.591: INFO: Pod "pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006425476s
Mar 21 13:02:30.595: INFO: Pod "pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010295713s
STEP: Saw pod success
Mar 21 13:02:30.595: INFO: Pod "pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:02:30.598: INFO: Trying to get logs from node antelope pod pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b container env-test: <nil>
STEP: delete the pod
Mar 21 13:02:30.621: INFO: Waiting for pod pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b to disappear
Mar 21 13:02:30.623: INFO: Pod pod-configmaps-937ab99f-4bd9-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:02:30.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wq8h2" for this suite.
Mar 21 13:02:36.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:02:36.690: INFO: namespace: e2e-tests-configmap-wq8h2, resource: bindings, ignored listing per whitelist
Mar 21 13:02:36.743: INFO: namespace e2e-tests-configmap-wq8h2 deletion completed in 6.104520003s

• [SLOW TEST:10.257 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:02:36.743: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 21 13:02:36.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sxmk5'
Mar 21 13:02:37.292: INFO: stderr: ""
Mar 21 13:02:37.292: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar 21 13:02:42.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sxmk5 -o json'
Mar 21 13:02:42.570: INFO: stderr: ""
Mar 21 13:02:42.570: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-03-21T13:02:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-sxmk5\",\n        \"resourceVersion\": \"28255\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-sxmk5/pods/e2e-test-nginx-pod\",\n        \"uid\": \"99d92c1a-4bd9-11e9-8b3c-9eae6a3150d7\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-tbwg9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"antelope\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-tbwg9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-tbwg9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-21T13:02:37Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-21T13:02:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-21T13:02:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-21T13:02:37Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c0174fd9478a22bb75c29b13db25a928e2289cf225b5b5588736282f6b2075e3\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b67e90a1d8088f0e205c77c793c271524773a6de163fb3855b1c1bedf979da7d\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-21T13:02:38Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"104.248.166.121\",\n        \"phase\": \"Running\",\n        \"podIP\": \"25.0.2.145\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-21T13:02:37Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 21 13:02:42.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 replace -f - --namespace=e2e-tests-kubectl-sxmk5'
Mar 21 13:02:42.889: INFO: stderr: ""
Mar 21 13:02:42.890: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Mar 21 13:02:42.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sxmk5'
Mar 21 13:02:45.577: INFO: stderr: ""
Mar 21 13:02:45.577: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:02:45.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sxmk5" for this suite.
Mar 21 13:02:51.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:02:51.633: INFO: namespace: e2e-tests-kubectl-sxmk5, resource: bindings, ignored listing per whitelist
Mar 21 13:02:51.676: INFO: namespace e2e-tests-kubectl-sxmk5 deletion completed in 6.094447409s

• [SLOW TEST:14.933 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:02:51.676: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a27a8b99-4bd9-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume configMaps
Mar 21 13:02:51.753: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a27b255d-4bd9-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-wlpv9" to be "success or failure"
Mar 21 13:02:51.757: INFO: Pod "pod-projected-configmaps-a27b255d-4bd9-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.391784ms
Mar 21 13:02:53.761: INFO: Pod "pod-projected-configmaps-a27b255d-4bd9-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00840741s
STEP: Saw pod success
Mar 21 13:02:53.762: INFO: Pod "pod-projected-configmaps-a27b255d-4bd9-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:02:53.765: INFO: Trying to get logs from node wolf pod pod-projected-configmaps-a27b255d-4bd9-11e9-9c6a-0a581900021b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 21 13:02:53.786: INFO: Waiting for pod pod-projected-configmaps-a27b255d-4bd9-11e9-9c6a-0a581900021b to disappear
Mar 21 13:02:53.788: INFO: Pod pod-projected-configmaps-a27b255d-4bd9-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:02:53.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wlpv9" for this suite.
Mar 21 13:02:59.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:02:59.853: INFO: namespace: e2e-tests-projected-wlpv9, resource: bindings, ignored listing per whitelist
Mar 21 13:02:59.886: INFO: namespace e2e-tests-projected-wlpv9 deletion completed in 6.094535164s

• [SLOW TEST:8.210 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:02:59.887: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar 21 13:02:59.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-svh9c'
Mar 21 13:03:00.110: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 21 13:03:00.110: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Mar 21 13:03:02.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-svh9c'
Mar 21 13:03:02.367: INFO: stderr: ""
Mar 21 13:03:02.367: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:03:02.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-svh9c" for this suite.
Mar 21 13:03:08.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:03:08.400: INFO: namespace: e2e-tests-kubectl-svh9c, resource: bindings, ignored listing per whitelist
Mar 21 13:03:08.504: INFO: namespace e2e-tests-kubectl-svh9c deletion completed in 6.131651116s

• [SLOW TEST:8.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:03:08.506: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 21 13:03:13.656: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:03:14.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-gj2rz" for this suite.
Mar 21 13:03:36.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:03:36.767: INFO: namespace: e2e-tests-replicaset-gj2rz, resource: bindings, ignored listing per whitelist
Mar 21 13:03:36.773: INFO: namespace e2e-tests-replicaset-gj2rz deletion completed in 22.091315089s

• [SLOW TEST:28.267 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:03:36.774: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 13:03:36.857: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd5d8a8f-4bd9-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-46q8k" to be "success or failure"
Mar 21 13:03:36.861: INFO: Pod "downwardapi-volume-bd5d8a8f-4bd9-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.626974ms
Mar 21 13:03:38.866: INFO: Pod "downwardapi-volume-bd5d8a8f-4bd9-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008584063s
STEP: Saw pod success
Mar 21 13:03:38.866: INFO: Pod "downwardapi-volume-bd5d8a8f-4bd9-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:03:38.873: INFO: Trying to get logs from node antelope pod downwardapi-volume-bd5d8a8f-4bd9-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 13:03:38.893: INFO: Waiting for pod downwardapi-volume-bd5d8a8f-4bd9-11e9-9c6a-0a581900021b to disappear
Mar 21 13:03:38.895: INFO: Pod downwardapi-volume-bd5d8a8f-4bd9-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:03:38.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-46q8k" for this suite.
Mar 21 13:03:44.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:03:44.978: INFO: namespace: e2e-tests-projected-46q8k, resource: bindings, ignored listing per whitelist
Mar 21 13:03:45.000: INFO: namespace e2e-tests-projected-46q8k deletion completed in 6.100470707s

• [SLOW TEST:8.226 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:03:45.001: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:03:45.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2hhf5" for this suite.
Mar 21 13:04:07.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:04:07.204: INFO: namespace: e2e-tests-pods-2hhf5, resource: bindings, ignored listing per whitelist
Mar 21 13:04:07.239: INFO: namespace e2e-tests-pods-2hhf5 deletion completed in 22.137144542s

• [SLOW TEST:22.238 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:04:07.239: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-sbz7
STEP: Creating a pod to test atomic-volume-subpath
Mar 21 13:04:07.377: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sbz7" in namespace "e2e-tests-subpath-gqxh7" to be "success or failure"
Mar 21 13:04:07.380: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.683877ms
Mar 21 13:04:09.385: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008087098s
Mar 21 13:04:11.389: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 4.011881659s
Mar 21 13:04:13.393: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 6.015389156s
Mar 21 13:04:15.397: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 8.019388345s
Mar 21 13:04:17.400: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 10.023113611s
Mar 21 13:04:19.405: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 12.027335233s
Mar 21 13:04:21.408: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 14.031299906s
Mar 21 13:04:23.413: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 16.035817286s
Mar 21 13:04:25.417: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 18.039528318s
Mar 21 13:04:27.421: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 20.044310653s
Mar 21 13:04:29.430: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Running", Reason="", readiness=false. Elapsed: 22.052862901s
Mar 21 13:04:31.434: INFO: Pod "pod-subpath-test-projected-sbz7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.056441715s
STEP: Saw pod success
Mar 21 13:04:31.434: INFO: Pod "pod-subpath-test-projected-sbz7" satisfied condition "success or failure"
Mar 21 13:04:31.445: INFO: Trying to get logs from node wolf pod pod-subpath-test-projected-sbz7 container test-container-subpath-projected-sbz7: <nil>
STEP: delete the pod
Mar 21 13:04:31.464: INFO: Waiting for pod pod-subpath-test-projected-sbz7 to disappear
Mar 21 13:04:31.467: INFO: Pod pod-subpath-test-projected-sbz7 no longer exists
STEP: Deleting pod pod-subpath-test-projected-sbz7
Mar 21 13:04:31.467: INFO: Deleting pod "pod-subpath-test-projected-sbz7" in namespace "e2e-tests-subpath-gqxh7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:04:31.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gqxh7" for this suite.
Mar 21 13:04:37.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:04:37.504: INFO: namespace: e2e-tests-subpath-gqxh7, resource: bindings, ignored listing per whitelist
Mar 21 13:04:37.580: INFO: namespace e2e-tests-subpath-gqxh7 deletion completed in 6.107615804s

• [SLOW TEST:30.341 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:04:37.581: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e19acbe3-4bd9-11e9-9c6a-0a581900021b
STEP: Creating secret with name s-test-opt-upd-e19acc46-4bd9-11e9-9c6a-0a581900021b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e19acbe3-4bd9-11e9-9c6a-0a581900021b
STEP: Updating secret s-test-opt-upd-e19acc46-4bd9-11e9-9c6a-0a581900021b
STEP: Creating secret with name s-test-opt-create-e19accc0-4bd9-11e9-9c6a-0a581900021b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:04:41.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gr8ll" for this suite.
Mar 21 13:05:03.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:05:03.788: INFO: namespace: e2e-tests-secrets-gr8ll, resource: bindings, ignored listing per whitelist
Mar 21 13:05:03.862: INFO: namespace e2e-tests-secrets-gr8ll deletion completed in 22.107795716s

• [SLOW TEST:26.281 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:05:03.862: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-n85fr
Mar 21 13:05:07.956: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-n85fr
STEP: checking the pod's current state and verifying that restartCount is present
Mar 21 13:05:07.958: INFO: Initial restart count of pod liveness-http is 0
Mar 21 13:05:30.012: INFO: Restart count of pod e2e-tests-container-probe-n85fr/liveness-http is now 1 (22.053368552s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:05:30.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n85fr" for this suite.
Mar 21 13:05:36.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:05:36.087: INFO: namespace: e2e-tests-container-probe-n85fr, resource: bindings, ignored listing per whitelist
Mar 21 13:05:36.120: INFO: namespace e2e-tests-container-probe-n85fr deletion completed in 6.09756108s

• [SLOW TEST:32.258 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:05:36.121: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-047e7945-4bda-11e9-9c6a-0a581900021b
STEP: Creating a pod to test consume secrets
Mar 21 13:05:36.197: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-047f3a3d-4bda-11e9-9c6a-0a581900021b" in namespace "e2e-tests-projected-kcjck" to be "success or failure"
Mar 21 13:05:36.201: INFO: Pod "pod-projected-secrets-047f3a3d-4bda-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.653241ms
Mar 21 13:05:38.205: INFO: Pod "pod-projected-secrets-047f3a3d-4bda-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007961313s
STEP: Saw pod success
Mar 21 13:05:38.205: INFO: Pod "pod-projected-secrets-047f3a3d-4bda-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:05:38.209: INFO: Trying to get logs from node wolf pod pod-projected-secrets-047f3a3d-4bda-11e9-9c6a-0a581900021b container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 21 13:05:38.225: INFO: Waiting for pod pod-projected-secrets-047f3a3d-4bda-11e9-9c6a-0a581900021b to disappear
Mar 21 13:05:38.227: INFO: Pod pod-projected-secrets-047f3a3d-4bda-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:05:38.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kcjck" for this suite.
Mar 21 13:05:44.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:05:44.268: INFO: namespace: e2e-tests-projected-kcjck, resource: bindings, ignored listing per whitelist
Mar 21 13:05:44.331: INFO: namespace e2e-tests-projected-kcjck deletion completed in 6.09978158s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:05:44.332: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:05:48.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6n2f7" for this suite.
Mar 21 13:06:26.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:06:26.449: INFO: namespace: e2e-tests-kubelet-test-6n2f7, resource: bindings, ignored listing per whitelist
Mar 21 13:06:26.561: INFO: namespace e2e-tests-kubelet-test-6n2f7 deletion completed in 38.134251377s

• [SLOW TEST:42.229 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:06:26.562: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 21 13:06:26.649: INFO: Waiting up to 5m0s for pod "pod-2291cc36-4bda-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-9xfhh" to be "success or failure"
Mar 21 13:06:26.652: INFO: Pod "pod-2291cc36-4bda-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.555543ms
Mar 21 13:06:28.656: INFO: Pod "pod-2291cc36-4bda-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006057645s
STEP: Saw pod success
Mar 21 13:06:28.656: INFO: Pod "pod-2291cc36-4bda-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:06:28.659: INFO: Trying to get logs from node jaguar pod pod-2291cc36-4bda-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 13:06:28.675: INFO: Waiting for pod pod-2291cc36-4bda-11e9-9c6a-0a581900021b to disappear
Mar 21 13:06:28.678: INFO: Pod pod-2291cc36-4bda-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:06:28.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9xfhh" for this suite.
Mar 21 13:06:34.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:06:34.755: INFO: namespace: e2e-tests-emptydir-9xfhh, resource: bindings, ignored listing per whitelist
Mar 21 13:06:34.789: INFO: namespace e2e-tests-emptydir-9xfhh deletion completed in 6.107075189s

• [SLOW TEST:8.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:06:34.790: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar 21 13:06:37.399: INFO: Successfully updated pod "annotationupdate277791b1-4bda-11e9-9c6a-0a581900021b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:06:39.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6fs6p" for this suite.
Mar 21 13:07:01.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:07:01.453: INFO: namespace: e2e-tests-projected-6fs6p, resource: bindings, ignored listing per whitelist
Mar 21 13:07:01.551: INFO: namespace e2e-tests-projected-6fs6p deletion completed in 22.123652217s

• [SLOW TEST:26.761 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:07:01.552: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 21 13:07:05.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 21 13:07:05.720: INFO: Pod pod-with-poststart-http-hook still exists
Mar 21 13:07:07.721: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 21 13:07:07.724: INFO: Pod pod-with-poststart-http-hook still exists
Mar 21 13:07:09.721: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 21 13:07:09.725: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:07:09.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-sjrgx" for this suite.
Mar 21 13:07:31.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:07:31.797: INFO: namespace: e2e-tests-container-lifecycle-hook-sjrgx, resource: bindings, ignored listing per whitelist
Mar 21 13:07:31.823: INFO: namespace e2e-tests-container-lifecycle-hook-sjrgx deletion completed in 22.093648772s

• [SLOW TEST:30.271 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:07:31.824: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar 21 13:07:31.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 create -f - --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:07:32.178: INFO: stderr: ""
Mar 21 13:07:32.178: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 21 13:07:32.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:07:32.334: INFO: stderr: ""
Mar 21 13:07:32.334: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Mar 21 13:07:37.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:07:37.568: INFO: stderr: ""
Mar 21 13:07:37.568: INFO: stdout: "update-demo-nautilus-4bvrv update-demo-nautilus-6v789 "
Mar 21 13:07:37.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-4bvrv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:07:37.729: INFO: stderr: ""
Mar 21 13:07:37.729: INFO: stdout: "true"
Mar 21 13:07:37.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-4bvrv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:07:37.873: INFO: stderr: ""
Mar 21 13:07:37.873: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 13:07:37.873: INFO: validating pod update-demo-nautilus-4bvrv
Mar 21 13:07:37.881: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 13:07:37.881: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 13:07:37.881: INFO: update-demo-nautilus-4bvrv is verified up and running
Mar 21 13:07:37.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-6v789 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:07:38.006: INFO: stderr: ""
Mar 21 13:07:38.006: INFO: stdout: "true"
Mar 21 13:07:38.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-nautilus-6v789 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:07:38.142: INFO: stderr: ""
Mar 21 13:07:38.142: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 21 13:07:38.142: INFO: validating pod update-demo-nautilus-6v789
Mar 21 13:07:38.149: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 21 13:07:38.149: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 21 13:07:38.149: INFO: update-demo-nautilus-6v789 is verified up and running
STEP: rolling-update to new replication controller
Mar 21 13:07:38.152: INFO: scanned /root for discovery docs: <nil>
Mar 21 13:07:38.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:08:00.780: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 21 13:08:00.780: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 21 13:08:00.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:08:00.930: INFO: stderr: ""
Mar 21 13:08:00.930: INFO: stdout: "update-demo-kitten-kl4mh update-demo-kitten-phjjw "
Mar 21 13:08:00.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-kitten-kl4mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:08:01.071: INFO: stderr: ""
Mar 21 13:08:01.071: INFO: stdout: "true"
Mar 21 13:08:01.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-kitten-kl4mh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:08:01.234: INFO: stderr: ""
Mar 21 13:08:01.234: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 21 13:08:01.234: INFO: validating pod update-demo-kitten-kl4mh
Mar 21 13:08:01.242: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 21 13:08:01.242: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 21 13:08:01.242: INFO: update-demo-kitten-kl4mh is verified up and running
Mar 21 13:08:01.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-kitten-phjjw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:08:01.503: INFO: stderr: ""
Mar 21 13:08:01.503: INFO: stdout: "true"
Mar 21 13:08:01.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-434046417 get pods update-demo-kitten-phjjw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2dwbq'
Mar 21 13:08:01.741: INFO: stderr: ""
Mar 21 13:08:01.741: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 21 13:08:01.741: INFO: validating pod update-demo-kitten-phjjw
Mar 21 13:08:01.749: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 21 13:08:01.749: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 21 13:08:01.749: INFO: update-demo-kitten-phjjw is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:08:01.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2dwbq" for this suite.
Mar 21 13:08:23.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:08:23.803: INFO: namespace: e2e-tests-kubectl-2dwbq, resource: bindings, ignored listing per whitelist
Mar 21 13:08:23.849: INFO: namespace e2e-tests-kubectl-2dwbq deletion completed in 22.09504666s

• [SLOW TEST:52.025 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:08:23.849: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 13:08:23.924: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:08:24.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-wv7zm" for this suite.
Mar 21 13:08:30.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:08:31.138: INFO: namespace: e2e-tests-custom-resource-definition-wv7zm, resource: bindings, ignored listing per whitelist
Mar 21 13:08:31.144: INFO: namespace e2e-tests-custom-resource-definition-wv7zm deletion completed in 6.16975972s

• [SLOW TEST:7.295 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:08:31.144: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:08:57.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-sjc2j" for this suite.
Mar 21 13:09:03.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:09:03.584: INFO: namespace: e2e-tests-container-runtime-sjc2j, resource: bindings, ignored listing per whitelist
Mar 21 13:09:03.584: INFO: namespace e2e-tests-container-runtime-sjc2j deletion completed in 6.1196486s

• [SLOW TEST:32.440 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:09:03.585: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 21 13:09:03.664: INFO: Waiting up to 5m0s for pod "pod-802818b7-4bda-11e9-9c6a-0a581900021b" in namespace "e2e-tests-emptydir-bb6fg" to be "success or failure"
Mar 21 13:09:03.667: INFO: Pod "pod-802818b7-4bda-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.68494ms
Mar 21 13:09:05.671: INFO: Pod "pod-802818b7-4bda-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007494131s
STEP: Saw pod success
Mar 21 13:09:05.671: INFO: Pod "pod-802818b7-4bda-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:09:05.674: INFO: Trying to get logs from node jaguar pod pod-802818b7-4bda-11e9-9c6a-0a581900021b container test-container: <nil>
STEP: delete the pod
Mar 21 13:09:05.692: INFO: Waiting for pod pod-802818b7-4bda-11e9-9c6a-0a581900021b to disappear
Mar 21 13:09:05.694: INFO: Pod pod-802818b7-4bda-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:09:05.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bb6fg" for this suite.
Mar 21 13:09:11.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:09:11.728: INFO: namespace: e2e-tests-emptydir-bb6fg, resource: bindings, ignored listing per whitelist
Mar 21 13:09:11.812: INFO: namespace e2e-tests-emptydir-bb6fg deletion completed in 6.112716832s

• [SLOW TEST:8.227 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:09:11.812: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar 21 13:09:11.887: INFO: Waiting up to 5m0s for pod "downward-api-850effbd-4bda-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-8l49m" to be "success or failure"
Mar 21 13:09:11.889: INFO: Pod "downward-api-850effbd-4bda-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.583967ms
Mar 21 13:09:13.893: INFO: Pod "downward-api-850effbd-4bda-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006392715s
STEP: Saw pod success
Mar 21 13:09:13.893: INFO: Pod "downward-api-850effbd-4bda-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:09:13.896: INFO: Trying to get logs from node jaguar pod downward-api-850effbd-4bda-11e9-9c6a-0a581900021b container dapi-container: <nil>
STEP: delete the pod
Mar 21 13:09:13.913: INFO: Waiting for pod downward-api-850effbd-4bda-11e9-9c6a-0a581900021b to disappear
Mar 21 13:09:13.917: INFO: Pod downward-api-850effbd-4bda-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:09:13.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8l49m" for this suite.
Mar 21 13:09:19.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:09:19.998: INFO: namespace: e2e-tests-downward-api-8l49m, resource: bindings, ignored listing per whitelist
Mar 21 13:09:20.027: INFO: namespace e2e-tests-downward-api-8l49m deletion completed in 6.105174993s

• [SLOW TEST:8.215 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:09:20.027: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bhppm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 21 13:09:20.092: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 21 13:09:42.167: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 25.0.1.141 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhppm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 13:09:42.167: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 13:09:43.356: INFO: Found all expected endpoints: [netserver-0]
Mar 21 13:09:43.365: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 25.0.2.152 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhppm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 13:09:43.365: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 13:09:44.551: INFO: Found all expected endpoints: [netserver-1]
Mar 21 13:09:44.555: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 25.0.3.132 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhppm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 21 13:09:44.555: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
Mar 21 13:09:45.765: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:09:45.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bhppm" for this suite.
Mar 21 13:10:07.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:10:07.801: INFO: namespace: e2e-tests-pod-network-test-bhppm, resource: bindings, ignored listing per whitelist
Mar 21 13:10:07.877: INFO: namespace e2e-tests-pod-network-test-bhppm deletion completed in 22.107791632s

• [SLOW TEST:47.850 seconds]
[sig-network] Networking
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:10:07.878: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar 21 13:10:07.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a67a4203-4bda-11e9-9c6a-0a581900021b" in namespace "e2e-tests-downward-api-jtdrq" to be "success or failure"
Mar 21 13:10:07.958: INFO: Pod "downwardapi-volume-a67a4203-4bda-11e9-9c6a-0a581900021b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.031223ms
Mar 21 13:10:09.962: INFO: Pod "downwardapi-volume-a67a4203-4bda-11e9-9c6a-0a581900021b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006836717s
STEP: Saw pod success
Mar 21 13:10:09.962: INFO: Pod "downwardapi-volume-a67a4203-4bda-11e9-9c6a-0a581900021b" satisfied condition "success or failure"
Mar 21 13:10:09.964: INFO: Trying to get logs from node wolf pod downwardapi-volume-a67a4203-4bda-11e9-9c6a-0a581900021b container client-container: <nil>
STEP: delete the pod
Mar 21 13:10:09.982: INFO: Waiting for pod downwardapi-volume-a67a4203-4bda-11e9-9c6a-0a581900021b to disappear
Mar 21 13:10:09.984: INFO: Pod downwardapi-volume-a67a4203-4bda-11e9-9c6a-0a581900021b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:10:09.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jtdrq" for this suite.
Mar 21 13:10:15.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:10:16.031: INFO: namespace: e2e-tests-downward-api-jtdrq, resource: bindings, ignored listing per whitelist
Mar 21 13:10:16.097: INFO: namespace e2e-tests-downward-api-jtdrq deletion completed in 6.108773477s

• [SLOW TEST:8.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:10:16.098: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar 21 13:10:32.175: INFO: Container started at 2019-03-21 13:10:17 +0000 UTC, pod became ready at 2019-03-21 13:10:32 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:10:32.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lx7mw" for this suite.
Mar 21 13:10:54.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:10:54.253: INFO: namespace: e2e-tests-container-probe-lx7mw, resource: bindings, ignored listing per whitelist
Mar 21 13:10:54.272: INFO: namespace e2e-tests-container-probe-lx7mw deletion completed in 22.093143497s

• [SLOW TEST:38.175 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar 21 13:10:54.273: INFO: >>> kubeConfig: /tmp/kubeconfig-434046417
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-jb4nb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jb4nb to expose endpoints map[]
Mar 21 13:10:54.435: INFO: Get endpoints failed (60.30846ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 21 13:10:55.439: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jb4nb exposes endpoints map[] (1.064032999s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-jb4nb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jb4nb to expose endpoints map[pod1:[100]]
Mar 21 13:10:57.461: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jb4nb exposes endpoints map[pod1:[100]] (2.01663631s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-jb4nb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jb4nb to expose endpoints map[pod1:[100] pod2:[101]]
Mar 21 13:11:00.499: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jb4nb exposes endpoints map[pod1:[100] pod2:[101]] (3.034304751s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-jb4nb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jb4nb to expose endpoints map[pod2:[101]]
Mar 21 13:11:01.514: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jb4nb exposes endpoints map[pod2:[101]] (1.010744966s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-jb4nb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-jb4nb to expose endpoints map[]
Mar 21 13:11:02.526: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-jb4nb exposes endpoints map[] (1.006489758s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar 21 13:11:02.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jb4nb" for this suite.
Mar 21 13:11:24.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar 21 13:11:24.618: INFO: namespace: e2e-tests-services-jb4nb, resource: bindings, ignored listing per whitelist
Mar 21 13:11:24.633: INFO: namespace e2e-tests-services-jb4nb deletion completed in 22.08533608s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.360 seconds]
[sig-network] Services
/workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.4-beta.0.55+c27b913fddd1a6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSMar 21 13:11:24.633: INFO: Running AfterSuite actions on all nodes
Mar 21 13:11:24.633: INFO: Running AfterSuite actions on node 1
Mar 21 13:11:24.633: INFO: Skipping dumping logs from cluster

Ran 200 of 2161 Specs in 5669.320 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1961 Skipped PASS

Ginkgo ran 1 suite in 1h34m31.137783957s
Test Suite Passed
