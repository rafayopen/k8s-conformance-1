I0425 16:36:47.540610      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-806739710
I0425 16:36:47.540767      18 e2e.go:224] Starting e2e run "5155ae63-6778-11e9-9f66-ae72f7f5c328" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1556210206 - Will randomize all specs
Will run 201 of 1946 specs

Apr 25 16:36:47.666: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 16:36:47.668: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 25 16:36:47.678: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 25 16:36:47.706: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 25 16:36:47.707: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Apr 25 16:36:47.707: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 25 16:36:47.714: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
Apr 25 16:36:47.714: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-do-node' (0 seconds elapsed)
Apr 25 16:36:47.714: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'do-node-agent' (0 seconds elapsed)
Apr 25 16:36:47.714: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 25 16:36:47.714: INFO: e2e test version: v1.13.0
Apr 25 16:36:47.716: INFO: kube-apiserver version: v1.13.5
SSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:36:47.716: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
Apr 25 16:36:47.786: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 25 16:36:47.804: INFO: Waiting up to 5m0s for pod "downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-2tmw7" to be "success or failure"
Apr 25 16:36:47.810: INFO: Pod "downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.505304ms
Apr 25 16:36:49.814: INFO: Pod "downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010110819s
Apr 25 16:36:51.818: INFO: Pod "downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013857349s
STEP: Saw pod success
Apr 25 16:36:51.818: INFO: Pod "downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:36:51.821: INFO: Trying to get logs from node test113-q3hn pod downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 16:36:51.841: INFO: Waiting for pod downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:36:51.844: INFO: Pod downward-api-51d10574-6778-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:36:51.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2tmw7" for this suite.
Apr 25 16:36:57.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:36:57.925: INFO: namespace: e2e-tests-downward-api-2tmw7, resource: bindings, ignored listing per whitelist
Apr 25 16:36:57.951: INFO: namespace e2e-tests-downward-api-2tmw7 deletion completed in 6.103290069s

• [SLOW TEST:10.235 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:36:57.952: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 25 16:36:58.085: INFO: Waiting up to 5m0s for pod "downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-qvmm4" to be "success or failure"
Apr 25 16:36:58.094: INFO: Pod "downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.472593ms
Apr 25 16:37:00.098: INFO: Pod "downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012249594s
Apr 25 16:37:02.101: INFO: Pod "downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015662657s
STEP: Saw pod success
Apr 25 16:37:02.101: INFO: Pod "downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:37:02.103: INFO: Trying to get logs from node test113-q3hn pod downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 16:37:02.150: INFO: Waiting for pod downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:37:02.155: INFO: Pod downward-api-57f2be5c-6778-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:37:02.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qvmm4" for this suite.
Apr 25 16:37:08.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:37:08.256: INFO: namespace: e2e-tests-downward-api-qvmm4, resource: bindings, ignored listing per whitelist
Apr 25 16:37:08.267: INFO: namespace e2e-tests-downward-api-qvmm4 deletion completed in 6.107080558s

• [SLOW TEST:10.316 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:37:08.268: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 16:37:08.397: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e179aa8-6778-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-t52q4" to be "success or failure"
Apr 25 16:37:08.405: INFO: Pod "downwardapi-volume-5e179aa8-6778-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.412329ms
Apr 25 16:37:10.409: INFO: Pod "downwardapi-volume-5e179aa8-6778-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011903722s
STEP: Saw pod success
Apr 25 16:37:10.409: INFO: Pod "downwardapi-volume-5e179aa8-6778-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:37:10.411: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-5e179aa8-6778-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 16:37:10.431: INFO: Waiting for pod downwardapi-volume-5e179aa8-6778-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:37:10.434: INFO: Pod downwardapi-volume-5e179aa8-6778-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:37:10.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t52q4" for this suite.
Apr 25 16:37:16.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:37:16.543: INFO: namespace: e2e-tests-projected-t52q4, resource: bindings, ignored listing per whitelist
Apr 25 16:37:16.550: INFO: namespace e2e-tests-projected-t52q4 deletion completed in 6.112683399s

• [SLOW TEST:8.282 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:37:16.550: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 16:37:16.650: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 25 16:37:16.662: INFO: Number of nodes with available pods: 0
Apr 25 16:37:16.662: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 25 16:37:16.691: INFO: Number of nodes with available pods: 0
Apr 25 16:37:16.691: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:17.695: INFO: Number of nodes with available pods: 0
Apr 25 16:37:17.695: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:18.695: INFO: Number of nodes with available pods: 0
Apr 25 16:37:18.695: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:19.695: INFO: Number of nodes with available pods: 1
Apr 25 16:37:19.695: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 25 16:37:19.716: INFO: Number of nodes with available pods: 1
Apr 25 16:37:19.716: INFO: Number of running nodes: 0, number of available pods: 1
Apr 25 16:37:20.720: INFO: Number of nodes with available pods: 0
Apr 25 16:37:20.720: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 25 16:37:20.753: INFO: Number of nodes with available pods: 0
Apr 25 16:37:20.753: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:21.759: INFO: Number of nodes with available pods: 0
Apr 25 16:37:21.759: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:22.759: INFO: Number of nodes with available pods: 0
Apr 25 16:37:22.759: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:23.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:23.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:24.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:24.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:25.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:25.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:26.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:26.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:27.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:27.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:28.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:28.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:29.758: INFO: Number of nodes with available pods: 0
Apr 25 16:37:29.758: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:30.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:30.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:31.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:31.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:32.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:32.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:33.756: INFO: Number of nodes with available pods: 0
Apr 25 16:37:33.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:34.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:34.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:35.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:35.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:36.759: INFO: Number of nodes with available pods: 0
Apr 25 16:37:36.759: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:37.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:37.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:38.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:38.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:39.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:39.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:40.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:40.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:41.759: INFO: Number of nodes with available pods: 0
Apr 25 16:37:41.759: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:42.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:42.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:43.756: INFO: Number of nodes with available pods: 0
Apr 25 16:37:43.756: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:44.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:44.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:45.758: INFO: Number of nodes with available pods: 0
Apr 25 16:37:45.758: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:46.756: INFO: Number of nodes with available pods: 0
Apr 25 16:37:46.756: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:47.762: INFO: Number of nodes with available pods: 0
Apr 25 16:37:47.762: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:48.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:48.758: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:49.756: INFO: Number of nodes with available pods: 0
Apr 25 16:37:49.756: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:50.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:50.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:51.765: INFO: Number of nodes with available pods: 0
Apr 25 16:37:51.766: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:52.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:52.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:53.758: INFO: Number of nodes with available pods: 0
Apr 25 16:37:53.758: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:54.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:54.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:55.757: INFO: Number of nodes with available pods: 0
Apr 25 16:37:55.757: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:56.763: INFO: Number of nodes with available pods: 0
Apr 25 16:37:56.763: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:57.759: INFO: Number of nodes with available pods: 0
Apr 25 16:37:57.759: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:37:58.756: INFO: Number of nodes with available pods: 1
Apr 25 16:37:58.756: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-wjkct, will wait for the garbage collector to delete the pods
Apr 25 16:37:58.821: INFO: Deleting DaemonSet.extensions daemon-set took: 6.530474ms
Apr 25 16:37:58.921: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.215132ms
Apr 25 16:38:32.324: INFO: Number of nodes with available pods: 0
Apr 25 16:38:32.325: INFO: Number of running nodes: 0, number of available pods: 0
Apr 25 16:38:32.329: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wjkct/daemonsets","resourceVersion":"17790"},"items":null}

Apr 25 16:38:32.332: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wjkct/pods","resourceVersion":"17790"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:38:32.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wjkct" for this suite.
Apr 25 16:38:38.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:38:38.390: INFO: namespace: e2e-tests-daemonsets-wjkct, resource: bindings, ignored listing per whitelist
Apr 25 16:38:38.457: INFO: namespace e2e-tests-daemonsets-wjkct deletion completed in 6.099140486s

• [SLOW TEST:81.907 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:38:38.458: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:38:38.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cksxs" for this suite.
Apr 25 16:39:00.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:39:00.732: INFO: namespace: e2e-tests-pods-cksxs, resource: bindings, ignored listing per whitelist
Apr 25 16:39:00.739: INFO: namespace e2e-tests-pods-cksxs deletion completed in 22.151533538s

• [SLOW TEST:22.281 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:39:00.739: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-589tm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 25 16:39:00.869: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 25 16:39:23.068: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.130:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-589tm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 16:39:23.068: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 16:39:23.275: INFO: Found all expected endpoints: [netserver-0]
Apr 25 16:39:23.279: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.40:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-589tm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 16:39:23.279: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 16:39:23.468: INFO: Found all expected endpoints: [netserver-1]
Apr 25 16:39:23.471: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.179:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-589tm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 16:39:23.471: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 16:39:23.666: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:39:23.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-589tm" for this suite.
Apr 25 16:39:45.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:39:45.789: INFO: namespace: e2e-tests-pod-network-test-589tm, resource: bindings, ignored listing per whitelist
Apr 25 16:39:45.791: INFO: namespace e2e-tests-pod-network-test-589tm deletion completed in 22.121074803s

• [SLOW TEST:45.052 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:39:45.792: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 16:39:45.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-st85k" to be "success or failure"
Apr 25 16:39:45.942: INFO: Pod "downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 13.148706ms
Apr 25 16:39:47.947: INFO: Pod "downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.017814555s
Apr 25 16:39:49.950: INFO: Pod "downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021169613s
STEP: Saw pod success
Apr 25 16:39:49.950: INFO: Pod "downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:39:49.953: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 16:39:49.977: INFO: Waiting for pod downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:39:49.981: INFO: Pod downwardapi-volume-bbfcf971-6778-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:39:49.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-st85k" for this suite.
Apr 25 16:39:55.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:39:56.055: INFO: namespace: e2e-tests-downward-api-st85k, resource: bindings, ignored listing per whitelist
Apr 25 16:39:56.086: INFO: namespace e2e-tests-downward-api-st85k deletion completed in 6.101425873s

• [SLOW TEST:10.295 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:39:56.086: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 25 16:39:56.219: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:40:01.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-26s7w" for this suite.
Apr 25 16:40:23.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:40:23.703: INFO: namespace: e2e-tests-init-container-26s7w, resource: bindings, ignored listing per whitelist
Apr 25 16:40:23.732: INFO: namespace e2e-tests-init-container-26s7w deletion completed in 22.143055304s

• [SLOW TEST:27.646 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:40:23.732: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:40:29.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-p5djx" for this suite.
Apr 25 16:40:36.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:40:36.038: INFO: namespace: e2e-tests-namespaces-p5djx, resource: bindings, ignored listing per whitelist
Apr 25 16:40:36.144: INFO: namespace e2e-tests-namespaces-p5djx deletion completed in 6.152386009s
STEP: Destroying namespace "e2e-tests-nsdeletetest-tcfx8" for this suite.
Apr 25 16:40:36.147: INFO: Namespace e2e-tests-nsdeletetest-tcfx8 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-fw4dq" for this suite.
Apr 25 16:40:42.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:40:42.188: INFO: namespace: e2e-tests-nsdeletetest-fw4dq, resource: bindings, ignored listing per whitelist
Apr 25 16:40:42.257: INFO: namespace e2e-tests-nsdeletetest-fw4dq deletion completed in 6.110328174s

• [SLOW TEST:18.524 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:40:42.258: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 25 16:40:42.325: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 25 16:40:42.331: INFO: Waiting for terminating namespaces to be deleted...
Apr 25 16:40:42.333: INFO: 
Logging pods the kubelet thinks is on node test113-q3hn before test
Apr 25 16:40:42.343: INFO: cilium-qrhts from kube-system started at 2019-04-25 16:15:55 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.343: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 16:40:42.343: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-25 16:36:41 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.343: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 25 16:40:42.343: INFO: kube-proxy-dplbd from kube-system started at 2019-04-25 16:15:55 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.343: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 16:40:42.343: INFO: csi-do-node-7jfmk from kube-system started at 2019-04-25 16:16:16 +0000 UTC (2 container statuses recorded)
Apr 25 16:40:42.343: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 16:40:42.343: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 16:40:42.344: INFO: do-node-agent-jwjhn from kube-system started at 2019-04-25 16:16:16 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.344: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 16:40:42.344: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-wpdwt from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 16:40:42.344: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 25 16:40:42.344: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 16:40:42.344: INFO: 
Logging pods the kubelet thinks is on node test113-q3k9 before test
Apr 25 16:40:42.353: INFO: kube-proxy-v8p4s from kube-system started at 2019-04-25 16:15:37 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 16:40:42.353: INFO: cilium-operator-7c9bd57c88-lstbs from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 25 16:40:42.353: INFO: do-node-agent-fxrn4 from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 16:40:42.353: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8kx8h from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 25 16:40:42.353: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 16:40:42.353: INFO: coredns-5d668bd598-xfpfd from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container coredns ready: true, restart count 0
Apr 25 16:40:42.353: INFO: csi-do-node-dznmp from kube-system started at 2019-04-25 16:15:57 +0000 UTC (2 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 16:40:42.353: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 16:40:42.353: INFO: coredns-5d668bd598-pmwb2 from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container coredns ready: true, restart count 0
Apr 25 16:40:42.353: INFO: cilium-rcnl7 from kube-system started at 2019-04-25 16:15:37 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.353: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 16:40:42.353: INFO: 
Logging pods the kubelet thinks is on node test113-q3kz before test
Apr 25 16:40:42.363: INFO: cilium-jsp4p from kube-system started at 2019-04-25 16:15:58 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.364: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 16:40:42.364: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8skg7 from heptio-sonobuoy started at 2019-04-25 16:36:45 +0000 UTC (2 container statuses recorded)
Apr 25 16:40:42.364: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Apr 25 16:40:42.364: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 16:40:42.364: INFO: do-node-agent-5475d from kube-system started at 2019-04-25 16:16:19 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.364: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 16:40:42.364: INFO: kube-proxy-qntk9 from kube-system started at 2019-04-25 16:15:58 +0000 UTC (1 container statuses recorded)
Apr 25 16:40:42.364: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 16:40:42.364: INFO: csi-do-node-cbct5 from kube-system started at 2019-04-25 16:16:19 +0000 UTC (2 container statuses recorded)
Apr 25 16:40:42.364: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 16:40:42.364: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 16:40:42.364: INFO: sonobuoy-e2e-job-a1b0a7332f284308 from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 16:40:42.364: INFO: 	Container e2e ready: true, restart count 0
Apr 25 16:40:42.364: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dedde312-6778-11e9-9f66-ae72f7f5c328 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dedde312-6778-11e9-9f66-ae72f7f5c328 off the node test113-q3hn
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dedde312-6778-11e9-9f66-ae72f7f5c328
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:40:48.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ldkgj" for this suite.
Apr 25 16:41:08.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:41:08.655: INFO: namespace: e2e-tests-sched-pred-ldkgj, resource: bindings, ignored listing per whitelist
Apr 25 16:41:08.707: INFO: namespace e2e-tests-sched-pred-ldkgj deletion completed in 20.113830019s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:26.450 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:41:08.708: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sszp5
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Apr 25 16:41:08.879: INFO: Found 0 stateful pods, waiting for 3
Apr 25 16:41:18.896: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 16:41:18.896: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 16:41:18.896: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 16:41:18.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-sszp5 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 16:41:19.217: INFO: stderr: ""
Apr 25 16:41:19.217: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 16:41:19.217: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 25 16:41:29.260: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 25 16:41:39.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-sszp5 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 16:41:39.587: INFO: stderr: ""
Apr 25 16:41:39.587: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 16:41:39.587: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Apr 25 16:42:09.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-sszp5 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 16:42:09.909: INFO: stderr: ""
Apr 25 16:42:09.909: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 16:42:09.909: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 16:42:19.941: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 25 16:42:29.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-sszp5 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 16:42:30.234: INFO: stderr: ""
Apr 25 16:42:30.234: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 16:42:30.234: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 25 16:42:50.252: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sszp5
Apr 25 16:42:50.255: INFO: Scaling statefulset ss2 to 0
Apr 25 16:43:10.621: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 16:43:10.624: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:43:10.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sszp5" for this suite.
Apr 25 16:43:16.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:43:16.727: INFO: namespace: e2e-tests-statefulset-sszp5, resource: bindings, ignored listing per whitelist
Apr 25 16:43:16.773: INFO: namespace e2e-tests-statefulset-sszp5 deletion completed in 6.129885682s

• [SLOW TEST:128.066 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:43:16.774: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 16:43:16.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 version --client'
Apr 25 16:43:16.913: INFO: stderr: ""
Apr 25 16:43:16.913: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Apr 25 16:43:16.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kdtmx'
Apr 25 16:43:17.657: INFO: stderr: ""
Apr 25 16:43:17.657: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 25 16:43:17.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kdtmx'
Apr 25 16:43:17.844: INFO: stderr: ""
Apr 25 16:43:17.844: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 25 16:43:18.848: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:43:18.848: INFO: Found 0 / 1
Apr 25 16:43:19.850: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:43:19.851: INFO: Found 1 / 1
Apr 25 16:43:19.851: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 25 16:43:19.853: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:43:19.853: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 25 16:43:19.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 describe pod redis-master-5cw62 --namespace=e2e-tests-kubectl-kdtmx'
Apr 25 16:43:19.948: INFO: stderr: ""
Apr 25 16:43:19.948: INFO: stdout: "Name:               redis-master-5cw62\nNamespace:          e2e-tests-kubectl-kdtmx\nPriority:           0\nPriorityClassName:  <none>\nNode:               test113-q3hn/10.138.46.141\nStart Time:         Thu, 25 Apr 2019 16:43:17 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.1.85\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://18893644b2c9cfa4979381701697f90dae5a65c8ee2f048a38af5267ea7a4154\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 25 Apr 2019 16:43:19 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-drcxl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-drcxl:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-drcxl\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  2s    default-scheduler      Successfully assigned e2e-tests-kubectl-kdtmx/redis-master-5cw62 to test113-q3hn\n  Normal  Pulled     0s    kubelet, test113-q3hn  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, test113-q3hn  Created container\n  Normal  Started    0s    kubelet, test113-q3hn  Started container\n"
Apr 25 16:43:19.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 describe rc redis-master --namespace=e2e-tests-kubectl-kdtmx'
Apr 25 16:43:20.038: INFO: stderr: ""
Apr 25 16:43:20.038: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-kdtmx\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-5cw62\n"
Apr 25 16:43:20.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 describe service redis-master --namespace=e2e-tests-kubectl-kdtmx'
Apr 25 16:43:20.138: INFO: stderr: ""
Apr 25 16:43:20.138: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-kdtmx\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.245.54.109\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.85:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 25 16:43:20.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 describe node test113-q3hn'
Apr 25 16:43:20.255: INFO: stderr: ""
Apr 25 16:43:20.255: INFO: stdout: "Name:               test113-q3hn\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=s-4vcpu-8gb\n                    beta.kubernetes.io/os=linux\n                    doks.digitalocean.com/node-pool=test113\n                    doks.digitalocean.com/node-pool-id=5d166154-0dc1-4043-b13d-6f6b1e247377\n                    failure-domain.beta.kubernetes.io/region=sfo2\n                    kubernetes.io/hostname=test113-q3hn\n                    region=sfo2\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"dobs.csi.digitalocean.com\":\"141494588\"}\n                    io.cilium.network.ipv4-cilium-host: 10.244.1.1\n                    io.cilium.network.ipv4-health-ip: 10.244.1.244\n                    io.cilium.network.ipv4-pod-cidr: 10.244.1.0/24\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 25 Apr 2019 16:15:56 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 25 Apr 2019 16:43:20 +0000   Thu, 25 Apr 2019 16:15:55 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 25 Apr 2019 16:43:20 +0000   Thu, 25 Apr 2019 16:15:55 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 25 Apr 2019 16:43:20 +0000   Thu, 25 Apr 2019 16:15:55 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 25 Apr 2019 16:43:20 +0000   Thu, 25 Apr 2019 16:16:16 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  Hostname:    test113-q3hn\n  InternalIP:  10.138.46.141\n  ExternalIP:  165.22.158.51\nCapacity:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               4\n ephemeral-storage:                                 165105408Ki\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            8170112Ki\n pods:                                              110\nAllocatable:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               4\n ephemeral-storage:                                 152161143761\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            8067712Ki\n pods:                                              110\nSystem Info:\n Machine ID:                 ec90445a98444fbe82459b70a15b4e6b\n System UUID:                ec90445a-9844-4fbe-8245-9b70a15b4e6b\n Boot ID:                    6287c1ca-b52b-4b91-a759-11c3f206966f\n Kernel Version:             4.19.0-0.bpo.2-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.13.5\n Kube-Proxy Version:         v1.13.5\nPodCIDR:                     10.244.1.0/24\nProviderID:                  digitalocean://141494588\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-kdtmx    redis-master-5cw62                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m39s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-39bcd96082344561-wpdwt    0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m36s\n  kube-system                cilium-qrhts                                               300m (7%)     0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                csi-do-node-7jfmk                                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                do-node-agent-jwjhn                                        102m (2%)     102m (2%)   80Mi (1%)        100Mi (1%)     27m\n  kube-system                kube-proxy-dplbd                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                          Requests    Limits\n  --------                                          --------    ------\n  cpu                                               402m (10%)  102m (2%)\n  memory                                            80Mi (1%)   100Mi (1%)\n  ephemeral-storage                                 0 (0%)      0 (0%)\n  attachable-volumes-csi-dobs.csi.digitalocean.com  0           0\nEvents:\n  Type    Reason                   Age                From                      Message\n  ----    ------                   ----               ----                      -------\n  Normal  Starting                 27m                kubelet, test113-q3hn     Starting kubelet.\n  Normal  NodeHasSufficientMemory  27m (x2 over 27m)  kubelet, test113-q3hn     Node test113-q3hn status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    27m (x2 over 27m)  kubelet, test113-q3hn     Node test113-q3hn status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     27m (x2 over 27m)  kubelet, test113-q3hn     Node test113-q3hn status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  27m                kubelet, test113-q3hn     Updated Node Allocatable limit across pods\n  Normal  Starting                 27m                kube-proxy, test113-q3hn  Starting kube-proxy.\n  Normal  NodeReady                27m                kubelet, test113-q3hn     Node test113-q3hn status is now: NodeReady\n"
Apr 25 16:43:20.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 describe namespace e2e-tests-kubectl-kdtmx'
Apr 25 16:43:20.359: INFO: stderr: ""
Apr 25 16:43:20.359: INFO: stdout: "Name:         e2e-tests-kubectl-kdtmx\nLabels:       e2e-framework=kubectl\n              e2e-run=5155ae63-6778-11e9-9f66-ae72f7f5c328\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:43:20.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kdtmx" for this suite.
Apr 25 16:43:42.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:43:42.467: INFO: namespace: e2e-tests-kubectl-kdtmx, resource: bindings, ignored listing per whitelist
Apr 25 16:43:42.678: INFO: namespace e2e-tests-kubectl-kdtmx deletion completed in 22.314863775s

• [SLOW TEST:25.904 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:43:42.678: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4927c411-6779-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 16:43:42.768: INFO: Waiting up to 5m0s for pod "pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-p7hgm" to be "success or failure"
Apr 25 16:43:42.775: INFO: Pod "pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.931559ms
Apr 25 16:43:44.778: INFO: Pod "pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0104639s
Apr 25 16:43:46.782: INFO: Pod "pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014368892s
STEP: Saw pod success
Apr 25 16:43:46.782: INFO: Pod "pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:43:46.785: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 16:43:46.812: INFO: Waiting for pod pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:43:46.816: INFO: Pod pod-configmaps-49284b8e-6779-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:43:46.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p7hgm" for this suite.
Apr 25 16:43:52.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:43:52.887: INFO: namespace: e2e-tests-configmap-p7hgm, resource: bindings, ignored listing per whitelist
Apr 25 16:43:52.934: INFO: namespace e2e-tests-configmap-p7hgm deletion completed in 6.114397393s

• [SLOW TEST:10.256 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:43:52.935: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4f439ca1-6779-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 16:43:53.047: INFO: Waiting up to 5m0s for pod "pod-secrets-4f48b5d5-6779-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-fqwbd" to be "success or failure"
Apr 25 16:43:53.063: INFO: Pod "pod-secrets-4f48b5d5-6779-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 16.169033ms
Apr 25 16:43:55.168: INFO: Pod "pod-secrets-4f48b5d5-6779-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.121775997s
STEP: Saw pod success
Apr 25 16:43:55.168: INFO: Pod "pod-secrets-4f48b5d5-6779-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:43:55.173: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-4f48b5d5-6779-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 16:43:55.196: INFO: Waiting for pod pod-secrets-4f48b5d5-6779-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:43:55.204: INFO: Pod pod-secrets-4f48b5d5-6779-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:43:55.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fqwbd" for this suite.
Apr 25 16:44:01.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:44:01.263: INFO: namespace: e2e-tests-secrets-fqwbd, resource: bindings, ignored listing per whitelist
Apr 25 16:44:01.349: INFO: namespace e2e-tests-secrets-fqwbd deletion completed in 6.141405696s
STEP: Destroying namespace "e2e-tests-secret-namespace-8n2q7" for this suite.
Apr 25 16:44:07.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:44:07.394: INFO: namespace: e2e-tests-secret-namespace-8n2q7, resource: bindings, ignored listing per whitelist
Apr 25 16:44:07.449: INFO: namespace e2e-tests-secret-namespace-8n2q7 deletion completed in 6.100060888s

• [SLOW TEST:14.514 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:44:07.452: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:44:33.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-5v6h4" for this suite.
Apr 25 16:44:39.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:44:39.192: INFO: namespace: e2e-tests-container-runtime-5v6h4, resource: bindings, ignored listing per whitelist
Apr 25 16:44:39.234: INFO: namespace e2e-tests-container-runtime-5v6h4 deletion completed in 6.1938069s

• [SLOW TEST:31.782 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:44:39.234: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 25 16:44:41.949: INFO: Successfully updated pod "labelsupdate6ae79a68-6779-11e9-9f66-ae72f7f5c328"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:44:43.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qmm8z" for this suite.
Apr 25 16:45:06.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:45:06.124: INFO: namespace: e2e-tests-downward-api-qmm8z, resource: bindings, ignored listing per whitelist
Apr 25 16:45:06.148: INFO: namespace e2e-tests-downward-api-qmm8z deletion completed in 22.168284128s

• [SLOW TEST:26.914 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:45:06.150: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 16:45:06.228: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:45:10.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lxvww" for this suite.
Apr 25 16:45:48.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:45:48.521: INFO: namespace: e2e-tests-pods-lxvww, resource: bindings, ignored listing per whitelist
Apr 25 16:45:48.558: INFO: namespace e2e-tests-pods-lxvww deletion completed in 38.121271995s

• [SLOW TEST:42.408 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:45:48.558: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0425 16:45:54.718343      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 25 16:45:54.718: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:45:54.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hjtss" for this suite.
Apr 25 16:46:00.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:46:00.800: INFO: namespace: e2e-tests-gc-hjtss, resource: bindings, ignored listing per whitelist
Apr 25 16:46:00.846: INFO: namespace e2e-tests-gc-hjtss deletion completed in 6.116257758s

• [SLOW TEST:12.288 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:46:00.846: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 25 16:46:01.015: INFO: Number of nodes with available pods: 0
Apr 25 16:46:01.015: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:46:02.026: INFO: Number of nodes with available pods: 0
Apr 25 16:46:02.026: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:46:03.025: INFO: Number of nodes with available pods: 0
Apr 25 16:46:03.026: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 16:46:04.040: INFO: Number of nodes with available pods: 3
Apr 25 16:46:04.040: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 25 16:46:04.104: INFO: Number of nodes with available pods: 2
Apr 25 16:46:04.104: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:05.122: INFO: Number of nodes with available pods: 2
Apr 25 16:46:05.122: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:06.153: INFO: Number of nodes with available pods: 2
Apr 25 16:46:06.153: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:07.112: INFO: Number of nodes with available pods: 2
Apr 25 16:46:07.112: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:08.123: INFO: Number of nodes with available pods: 2
Apr 25 16:46:08.123: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:09.134: INFO: Number of nodes with available pods: 2
Apr 25 16:46:09.134: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:10.126: INFO: Number of nodes with available pods: 2
Apr 25 16:46:10.126: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:11.111: INFO: Number of nodes with available pods: 2
Apr 25 16:46:11.111: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:12.127: INFO: Number of nodes with available pods: 2
Apr 25 16:46:12.127: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:13.112: INFO: Number of nodes with available pods: 2
Apr 25 16:46:13.112: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:14.129: INFO: Number of nodes with available pods: 2
Apr 25 16:46:14.129: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:15.116: INFO: Number of nodes with available pods: 2
Apr 25 16:46:15.116: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:16.126: INFO: Number of nodes with available pods: 2
Apr 25 16:46:16.126: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:17.114: INFO: Number of nodes with available pods: 2
Apr 25 16:46:17.114: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:18.124: INFO: Number of nodes with available pods: 2
Apr 25 16:46:18.124: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:19.113: INFO: Number of nodes with available pods: 2
Apr 25 16:46:19.114: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:20.127: INFO: Number of nodes with available pods: 2
Apr 25 16:46:20.127: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:21.236: INFO: Number of nodes with available pods: 2
Apr 25 16:46:21.236: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:22.123: INFO: Number of nodes with available pods: 2
Apr 25 16:46:22.123: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:23.112: INFO: Number of nodes with available pods: 2
Apr 25 16:46:23.112: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:24.354: INFO: Number of nodes with available pods: 2
Apr 25 16:46:24.354: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:25.111: INFO: Number of nodes with available pods: 2
Apr 25 16:46:25.111: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:26.131: INFO: Number of nodes with available pods: 2
Apr 25 16:46:26.131: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:27.114: INFO: Number of nodes with available pods: 2
Apr 25 16:46:27.114: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:28.123: INFO: Number of nodes with available pods: 2
Apr 25 16:46:28.123: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:29.114: INFO: Number of nodes with available pods: 2
Apr 25 16:46:29.114: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:30.127: INFO: Number of nodes with available pods: 2
Apr 25 16:46:30.127: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:31.111: INFO: Number of nodes with available pods: 2
Apr 25 16:46:31.111: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:32.126: INFO: Number of nodes with available pods: 2
Apr 25 16:46:32.126: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:33.117: INFO: Number of nodes with available pods: 2
Apr 25 16:46:33.117: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:34.149: INFO: Number of nodes with available pods: 2
Apr 25 16:46:34.150: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:35.116: INFO: Number of nodes with available pods: 2
Apr 25 16:46:35.116: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:36.139: INFO: Number of nodes with available pods: 2
Apr 25 16:46:36.139: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:37.111: INFO: Number of nodes with available pods: 2
Apr 25 16:46:37.111: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:38.133: INFO: Number of nodes with available pods: 2
Apr 25 16:46:38.133: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:39.114: INFO: Number of nodes with available pods: 2
Apr 25 16:46:39.114: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:40.122: INFO: Number of nodes with available pods: 2
Apr 25 16:46:40.122: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 16:46:41.111: INFO: Number of nodes with available pods: 3
Apr 25 16:46:41.111: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-fqtq6, will wait for the garbage collector to delete the pods
Apr 25 16:46:41.172: INFO: Deleting DaemonSet.extensions daemon-set took: 5.930426ms
Apr 25 16:46:41.372: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.264572ms
Apr 25 16:47:17.376: INFO: Number of nodes with available pods: 0
Apr 25 16:47:17.376: INFO: Number of running nodes: 0, number of available pods: 0
Apr 25 16:47:17.378: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fqtq6/daemonsets","resourceVersion":"20228"},"items":null}

Apr 25 16:47:17.380: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fqtq6/pods","resourceVersion":"20228"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:47:17.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fqtq6" for this suite.
Apr 25 16:47:23.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:47:23.446: INFO: namespace: e2e-tests-daemonsets-fqtq6, resource: bindings, ignored listing per whitelist
Apr 25 16:47:23.542: INFO: namespace e2e-tests-daemonsets-fqtq6 deletion completed in 6.144941032s

• [SLOW TEST:82.696 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:47:23.542: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ccd3db68-6779-11e9-9f66-ae72f7f5c328
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ccd3db68-6779-11e9-9f66-ae72f7f5c328
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:48:36.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhtlx" for this suite.
Apr 25 16:48:58.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:48:58.263: INFO: namespace: e2e-tests-projected-jhtlx, resource: bindings, ignored listing per whitelist
Apr 25 16:48:58.282: INFO: namespace e2e-tests-projected-jhtlx deletion completed in 22.105526779s

• [SLOW TEST:94.740 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:48:58.285: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 25 16:48:58.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xrsvt'
Apr 25 16:48:58.451: INFO: stderr: ""
Apr 25 16:48:58.451: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Apr 25 16:49:03.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xrsvt -o json'
Apr 25 16:49:03.573: INFO: stderr: ""
Apr 25 16:49:03.573: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-04-25T16:48:58Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-xrsvt\",\n        \"resourceVersion\": \"20470\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-xrsvt/pods/e2e-test-nginx-pod\",\n        \"uid\": \"055226c0-677a-11e9-a8f1-82d29082e60b\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-d2jp6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"test113-q3hn\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-d2jp6\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-d2jp6\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-25T16:48:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-25T16:49:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-25T16:49:00Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-04-25T16:48:58Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://659ec4e872de478d77fd1f641bddf430fdf6261f32e0af3eb8083c0b31937cd4\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-04-25T16:49:00Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.138.46.141\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.162\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-04-25T16:48:58Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 25 16:49:03.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 replace -f - --namespace=e2e-tests-kubectl-xrsvt'
Apr 25 16:49:03.741: INFO: stderr: ""
Apr 25 16:49:03.741: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Apr 25 16:49:03.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xrsvt'
Apr 25 16:49:16.031: INFO: stderr: ""
Apr 25 16:49:16.032: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:49:16.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xrsvt" for this suite.
Apr 25 16:49:22.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:49:22.084: INFO: namespace: e2e-tests-kubectl-xrsvt, resource: bindings, ignored listing per whitelist
Apr 25 16:49:22.165: INFO: namespace e2e-tests-kubectl-xrsvt deletion completed in 6.130165979s

• [SLOW TEST:23.880 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:49:22.166: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-1387f6cd-677a-11e9-9f66-ae72f7f5c328
STEP: Creating configMap with name cm-test-opt-upd-1387f73f-677a-11e9-9f66-ae72f7f5c328
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1387f6cd-677a-11e9-9f66-ae72f7f5c328
STEP: Updating configmap cm-test-opt-upd-1387f73f-677a-11e9-9f66-ae72f7f5c328
STEP: Creating configMap with name cm-test-opt-create-1387f78d-677a-11e9-9f66-ae72f7f5c328
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:49:30.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s7h64" for this suite.
Apr 25 16:49:52.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:49:52.477: INFO: namespace: e2e-tests-projected-s7h64, resource: bindings, ignored listing per whitelist
Apr 25 16:49:52.520: INFO: namespace e2e-tests-projected-s7h64 deletion completed in 22.112013475s

• [SLOW TEST:30.354 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:49:52.521: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-259ee45e-677a-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 16:49:52.648: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-6jrzn" to be "success or failure"
Apr 25 16:49:52.656: INFO: Pod "pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.843917ms
Apr 25 16:49:54.659: INFO: Pod "pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011378806s
Apr 25 16:49:56.663: INFO: Pod "pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015048562s
STEP: Saw pod success
Apr 25 16:49:56.663: INFO: Pod "pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:49:56.665: INFO: Trying to get logs from node test113-q3hn pod pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 16:49:56.708: INFO: Waiting for pod pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:49:56.713: INFO: Pod pod-projected-configmaps-259f849b-677a-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:49:56.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jrzn" for this suite.
Apr 25 16:50:02.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:50:02.779: INFO: namespace: e2e-tests-projected-6jrzn, resource: bindings, ignored listing per whitelist
Apr 25 16:50:02.840: INFO: namespace e2e-tests-projected-6jrzn deletion completed in 6.121679911s

• [SLOW TEST:10.319 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:50:02.840: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2bc5a63e-677a-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 16:50:02.969: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-8gjd4" to be "success or failure"
Apr 25 16:50:02.980: INFO: Pod "pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 11.370557ms
Apr 25 16:50:04.985: INFO: Pod "pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015880925s
Apr 25 16:50:06.989: INFO: Pod "pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020095829s
STEP: Saw pod success
Apr 25 16:50:06.989: INFO: Pod "pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:50:06.991: INFO: Trying to get logs from node test113-q3hn pod pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 25 16:50:07.014: INFO: Waiting for pod pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:50:07.018: INFO: Pod pod-projected-secrets-2bc6238d-677a-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:50:07.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8gjd4" for this suite.
Apr 25 16:50:13.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:50:13.063: INFO: namespace: e2e-tests-projected-8gjd4, resource: bindings, ignored listing per whitelist
Apr 25 16:50:13.123: INFO: namespace e2e-tests-projected-8gjd4 deletion completed in 6.101236592s

• [SLOW TEST:10.283 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:50:13.123: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Apr 25 16:50:13.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-dmw84'
Apr 25 16:50:13.389: INFO: stderr: ""
Apr 25 16:50:13.389: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Apr 25 16:50:14.396: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:50:14.396: INFO: Found 0 / 1
Apr 25 16:50:15.403: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:50:15.404: INFO: Found 1 / 1
Apr 25 16:50:15.404: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 25 16:50:15.412: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:50:15.412: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Apr 25 16:50:15.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 logs redis-master-vxvws redis-master --namespace=e2e-tests-kubectl-dmw84'
Apr 25 16:50:15.502: INFO: stderr: ""
Apr 25 16:50:15.502: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 Apr 16:50:15.114 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 Apr 16:50:15.114 # Server started, Redis version 3.2.12\n1:M 25 Apr 16:50:15.114 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 Apr 16:50:15.114 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Apr 25 16:50:15.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 log redis-master-vxvws redis-master --namespace=e2e-tests-kubectl-dmw84 --tail=1'
Apr 25 16:50:15.604: INFO: stderr: ""
Apr 25 16:50:15.604: INFO: stdout: "1:M 25 Apr 16:50:15.114 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Apr 25 16:50:15.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 log redis-master-vxvws redis-master --namespace=e2e-tests-kubectl-dmw84 --limit-bytes=1'
Apr 25 16:50:15.689: INFO: stderr: ""
Apr 25 16:50:15.689: INFO: stdout: " "
STEP: exposing timestamps
Apr 25 16:50:15.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 log redis-master-vxvws redis-master --namespace=e2e-tests-kubectl-dmw84 --tail=1 --timestamps'
Apr 25 16:50:15.780: INFO: stderr: ""
Apr 25 16:50:15.780: INFO: stdout: "2019-04-25T16:50:15.114514668Z 1:M 25 Apr 16:50:15.114 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Apr 25 16:50:18.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 log redis-master-vxvws redis-master --namespace=e2e-tests-kubectl-dmw84 --since=1s'
Apr 25 16:50:18.377: INFO: stderr: ""
Apr 25 16:50:18.377: INFO: stdout: ""
Apr 25 16:50:18.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 log redis-master-vxvws redis-master --namespace=e2e-tests-kubectl-dmw84 --since=24h'
Apr 25 16:50:18.469: INFO: stderr: ""
Apr 25 16:50:18.469: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 Apr 16:50:15.114 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 Apr 16:50:15.114 # Server started, Redis version 3.2.12\n1:M 25 Apr 16:50:15.114 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 Apr 16:50:15.114 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Apr 25 16:50:18.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dmw84'
Apr 25 16:50:18.561: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 16:50:18.561: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Apr 25 16:50:18.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-dmw84'
Apr 25 16:50:18.646: INFO: stderr: "No resources found.\n"
Apr 25 16:50:18.646: INFO: stdout: ""
Apr 25 16:50:18.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -l name=nginx --namespace=e2e-tests-kubectl-dmw84 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 25 16:50:18.719: INFO: stderr: ""
Apr 25 16:50:18.719: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:50:18.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dmw84" for this suite.
Apr 25 16:50:24.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:50:24.837: INFO: namespace: e2e-tests-kubectl-dmw84, resource: bindings, ignored listing per whitelist
Apr 25 16:50:24.920: INFO: namespace e2e-tests-kubectl-dmw84 deletion completed in 6.197280368s

• [SLOW TEST:11.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:50:24.922: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 16:50:25.052: INFO: Waiting up to 5m0s for pod "downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-fkkbk" to be "success or failure"
Apr 25 16:50:25.060: INFO: Pod "downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.425176ms
Apr 25 16:50:27.065: INFO: Pod "downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012301654s
Apr 25 16:50:29.071: INFO: Pod "downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019140395s
STEP: Saw pod success
Apr 25 16:50:29.072: INFO: Pod "downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:50:29.075: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 16:50:29.117: INFO: Waiting for pod downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:50:29.123: INFO: Pod downwardapi-volume-38f01eae-677a-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:50:29.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fkkbk" for this suite.
Apr 25 16:50:35.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:50:35.274: INFO: namespace: e2e-tests-downward-api-fkkbk, resource: bindings, ignored listing per whitelist
Apr 25 16:50:35.279: INFO: namespace e2e-tests-downward-api-fkkbk deletion completed in 6.149012159s

• [SLOW TEST:10.358 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:50:35.280: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3f14888b-677a-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 16:50:35.368: INFO: Waiting up to 5m0s for pod "pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-gw962" to be "success or failure"
Apr 25 16:50:35.375: INFO: Pod "pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.7409ms
Apr 25 16:50:37.379: INFO: Pod "pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011257282s
Apr 25 16:50:39.383: INFO: Pod "pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015357292s
STEP: Saw pod success
Apr 25 16:50:39.383: INFO: Pod "pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:50:39.387: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 16:50:39.424: INFO: Waiting for pod pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:50:39.427: INFO: Pod pod-secrets-3f1558af-677a-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:50:39.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gw962" for this suite.
Apr 25 16:50:45.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:50:45.521: INFO: namespace: e2e-tests-secrets-gw962, resource: bindings, ignored listing per whitelist
Apr 25 16:50:45.527: INFO: namespace e2e-tests-secrets-gw962 deletion completed in 6.096572872s

• [SLOW TEST:10.247 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:50:45.528: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Apr 25 16:50:45.597: INFO: Waiting up to 5m0s for pod "var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-var-expansion-5zcwq" to be "success or failure"
Apr 25 16:50:45.608: INFO: Pod "var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 10.804265ms
Apr 25 16:50:47.611: INFO: Pod "var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014076253s
Apr 25 16:50:49.615: INFO: Pod "var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017570206s
STEP: Saw pod success
Apr 25 16:50:49.615: INFO: Pod "var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:50:49.617: INFO: Trying to get logs from node test113-q3hn pod var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 16:50:49.647: INFO: Waiting for pod var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:50:49.650: INFO: Pod var-expansion-452f4875-677a-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:50:49.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-5zcwq" for this suite.
Apr 25 16:50:55.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:50:55.706: INFO: namespace: e2e-tests-var-expansion-5zcwq, resource: bindings, ignored listing per whitelist
Apr 25 16:50:55.756: INFO: namespace e2e-tests-var-expansion-5zcwq deletion completed in 6.103381479s

• [SLOW TEST:10.229 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:50:55.757: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4b52f5ca-677a-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 16:50:55.900: INFO: Waiting up to 5m0s for pod "pod-configmaps-4b53796d-677a-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-5slzg" to be "success or failure"
Apr 25 16:50:55.913: INFO: Pod "pod-configmaps-4b53796d-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 12.611426ms
Apr 25 16:50:57.916: INFO: Pod "pod-configmaps-4b53796d-677a-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016130824s
STEP: Saw pod success
Apr 25 16:50:57.916: INFO: Pod "pod-configmaps-4b53796d-677a-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:50:57.918: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-4b53796d-677a-11e9-9f66-ae72f7f5c328 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 16:50:57.941: INFO: Waiting for pod pod-configmaps-4b53796d-677a-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:50:57.945: INFO: Pod pod-configmaps-4b53796d-677a-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:50:57.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5slzg" for this suite.
Apr 25 16:51:03.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:51:04.083: INFO: namespace: e2e-tests-configmap-5slzg, resource: bindings, ignored listing per whitelist
Apr 25 16:51:04.334: INFO: namespace e2e-tests-configmap-5slzg deletion completed in 6.384805635s

• [SLOW TEST:8.577 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:51:04.334: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 25 16:51:09.132: INFO: Successfully updated pod "annotationupdate507b1872-677a-11e9-9f66-ae72f7f5c328"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:51:11.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zkgzt" for this suite.
Apr 25 16:51:33.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:51:33.213: INFO: namespace: e2e-tests-projected-zkgzt, resource: bindings, ignored listing per whitelist
Apr 25 16:51:33.263: INFO: namespace e2e-tests-projected-zkgzt deletion completed in 22.102154529s

• [SLOW TEST:28.929 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:51:33.264: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 16:51:33.398: INFO: Creating deployment "nginx-deployment"
Apr 25 16:51:33.403: INFO: Waiting for observed generation 1
Apr 25 16:51:35.414: INFO: Waiting for all required pods to come up
Apr 25 16:51:35.418: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 25 16:51:39.433: INFO: Waiting for deployment "nginx-deployment" to complete
Apr 25 16:51:39.438: INFO: Updating deployment "nginx-deployment" with a non-existent image
Apr 25 16:51:39.446: INFO: Updating deployment nginx-deployment
Apr 25 16:51:39.446: INFO: Waiting for observed generation 2
Apr 25 16:51:41.460: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 25 16:51:41.463: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 25 16:51:41.465: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 25 16:51:41.473: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 25 16:51:41.473: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 25 16:51:41.475: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Apr 25 16:51:41.479: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Apr 25 16:51:41.480: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Apr 25 16:51:41.488: INFO: Updating deployment nginx-deployment
Apr 25 16:51:41.488: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Apr 25 16:51:41.527: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 25 16:51:43.594: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 25 16:51:43.625: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhlxv/deployments/nginx-deployment,UID:61af3265-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21395,Generation:3,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-04-25 16:51:41 +0000 UTC 2019-04-25 16:51:41 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-25 16:51:41 +0000 UTC 2019-04-25 16:51:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Apr 25 16:51:43.633: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhlxv/replicasets/nginx-deployment-65bbdb5f8,UID:6549dc61-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21391,Generation:3,CreationTimestamp:2019-04-25 16:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 61af3265-677a-11e9-a8f1-82d29082e60b 0xc001192447 0xc001192448}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 25 16:51:43.633: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Apr 25 16:51:43.633: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhlxv/replicasets/nginx-deployment-555b55d965,UID:61afe94c-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21390,Generation:3,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 61af3265-677a-11e9-a8f1-82d29082e60b 0xc001192077 0xc001192078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Apr 25 16:51:43.649: INFO: Pod "nginx-deployment-555b55d965-4lb92" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4lb92,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-4lb92,UID:6686795f-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21389,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc0011933d7 0xc0011933d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001193450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001193470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.650: INFO: Pod "nginx-deployment-555b55d965-5kpft" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5kpft,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-5kpft,UID:669068e0-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21405,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc0011935c7 0xc0011935c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001193650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001193670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.650: INFO: Pod "nginx-deployment-555b55d965-74lpr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-74lpr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-74lpr,UID:66909f12-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21400,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc001193837 0xc001193838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011938b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001193980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.650: INFO: Pod "nginx-deployment-555b55d965-88hxp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-88hxp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-88hxp,UID:61b7b3ed-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21220,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc001193aa7 0xc001193aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001193b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001193bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:10.244.1.215,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d8679af13f86dd1ba33907552293cc6e8137510ca75f65a43a4b677b7beaed18}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.650: INFO: Pod "nginx-deployment-555b55d965-9df5z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9df5z,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-9df5z,UID:66833661-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21350,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc001193ce7 0xc001193ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001193de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001193e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.651: INFO: Pod "nginx-deployment-555b55d965-b7m8c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b7m8c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-b7m8c,UID:6697f35d-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21429,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc001193eb7 0xc001193eb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daa090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daa0b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.651: INFO: Pod "nginx-deployment-555b55d965-fphcc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fphcc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-fphcc,UID:6698ec24-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21466,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daa177 0xc000daa178}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daa2d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daa2f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.651: INFO: Pod "nginx-deployment-555b55d965-g4pfd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g4pfd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-g4pfd,UID:61c7e89f-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21241,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daa667 0xc000daa668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daa6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daa700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:10.244.2.200,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4d660b117bee989d9133033fa4bddb5076379b48826ea91268328a42b5c5e3ff}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.652: INFO: Pod "nginx-deployment-555b55d965-g5fvx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g5fvx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-g5fvx,UID:61b4042e-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21207,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daa7c7 0xc000daa7c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daa840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daa860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:10.244.2.244,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3dd3fe5597fefb4ad1ea4bbe018f25aed9dc98206c12a5033fe737b2e396a8db}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.652: INFO: Pod "nginx-deployment-555b55d965-j558f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j558f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-j558f,UID:6697dfa1-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21420,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daa927 0xc000daa928}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daa9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daa9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.652: INFO: Pod "nginx-deployment-555b55d965-kpx88" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kpx88,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-kpx88,UID:669900c0-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21452,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daaa77 0xc000daaa78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daaaf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daab10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.653: INFO: Pod "nginx-deployment-555b55d965-lfhv2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lfhv2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-lfhv2,UID:61b81984-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21230,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daabc7 0xc000daabc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daac40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daac60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:10.244.0.236,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4d1fb34e57042c5b20a83e2d26ef74050945af747c3c90a58c8916c20b69df77}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.653: INFO: Pod "nginx-deployment-555b55d965-lp75f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lp75f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-lp75f,UID:6690aee7-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21399,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daad27 0xc000daad28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daada0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daadc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.653: INFO: Pod "nginx-deployment-555b55d965-pqpx5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pqpx5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-pqpx5,UID:61b39792-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21232,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000daae77 0xc000daae78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daaef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daaf10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:10.244.0.219,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2f1a3451f73881d5c4edaa5c9b032ec8a7972002f86660631571bd9130f6529e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.653: INFO: Pod "nginx-deployment-555b55d965-qhggj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qhggj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-qhggj,UID:66865f2c-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21378,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000dab037 0xc000dab038}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dab0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dab0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.653: INFO: Pod "nginx-deployment-555b55d965-s7kjd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s7kjd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-s7kjd,UID:61c408bf-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21247,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000dab187 0xc000dab188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dab200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dab220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:10.244.1.10,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://72a8fcff1079cb7790102e00e29da87b019151bee925303430f74898222ec74c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.654: INFO: Pod "nginx-deployment-555b55d965-skbg7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-skbg7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-skbg7,UID:61b1beb6-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21212,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000dab2e0 0xc000dab2e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dab350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dab370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:10.244.1.55,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://63d6a2bb7a9fe8f9b0dd8bb5bd7eb153f0e8808d4d54619ab8f1c98acc070a67}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.654: INFO: Pod "nginx-deployment-555b55d965-xdbpf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xdbpf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-xdbpf,UID:669910a3-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21442,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000dab430 0xc000dab431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dab4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dab4c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.654: INFO: Pod "nginx-deployment-555b55d965-xhv7m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xhv7m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-xhv7m,UID:6690554a-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21396,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000dab577 0xc000dab578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dab6a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dab6c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.654: INFO: Pod "nginx-deployment-555b55d965-xskzs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xskzs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-555b55d965-xskzs,UID:61c45c4a-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21236,Generation:0,CreationTimestamp:2019-04-25 16:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 61afe94c-677a-11e9-a8f1-82d29082e60b 0xc000dab777 0xc000dab778}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dab7f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dab880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:33 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:10.244.0.113,StartTime:2019-04-25 16:51:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 16:51:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://552adaa347c90898847c0ac59bd27ee569b783affe8d843ec19c2264896525ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.654: INFO: Pod "nginx-deployment-65bbdb5f8-2dpsn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2dpsn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-2dpsn,UID:6686e2e3-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21383,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000dab947 0xc000dab948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dab9c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dab9e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.655: INFO: Pod "nginx-deployment-65bbdb5f8-4nsm2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4nsm2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-4nsm2,UID:654eb473-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21281,Generation:0,CreationTimestamp:2019-04-25 16:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000dabaa0 0xc000dabaa1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dabba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dabbc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.655: INFO: Pod "nginx-deployment-65bbdb5f8-5fmwz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5fmwz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-5fmwz,UID:66887983-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21388,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000dabc80 0xc000dabc81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dabd00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dabd20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.655: INFO: Pod "nginx-deployment-65bbdb5f8-9qf7p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9qf7p,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-9qf7p,UID:6562d8e7-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21304,Generation:0,CreationTimestamp:2019-04-25 16:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000dabde0 0xc000dabde1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dabe70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dabe90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.655: INFO: Pod "nginx-deployment-65bbdb5f8-fscjl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fscjl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-fscjl,UID:654e3d4d-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21283,Generation:0,CreationTimestamp:2019-04-25 16:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000dae0c0 0xc000dae0c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dae5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dae5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:,StartTime:2019-04-25 16:51:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.655: INFO: Pod "nginx-deployment-65bbdb5f8-gsmnr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gsmnr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-gsmnr,UID:66935a39-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21406,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000dae6b0 0xc000dae6b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000dae9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000dae9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.655: INFO: Pod "nginx-deployment-65bbdb5f8-kdjvq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-kdjvq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-kdjvq,UID:668412cc-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21369,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000daec50 0xc000daec51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daed20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daee00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.655: INFO: Pod "nginx-deployment-65bbdb5f8-ld8jx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ld8jx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-ld8jx,UID:655f6e44-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21303,Generation:0,CreationTimestamp:2019-04-25 16:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000daeec0 0xc000daeec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daef40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daef60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.656: INFO: Pod "nginx-deployment-65bbdb5f8-p86nm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-p86nm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-p86nm,UID:6693b1a0-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21465,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000daf160 0xc000daf161}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3kz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daf1e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daf200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.142,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.656: INFO: Pod "nginx-deployment-65bbdb5f8-q4p6j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-q4p6j,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-q4p6j,UID:669f1637-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21380,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000daf330 0xc000daf331}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daf3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daf3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.656: INFO: Pod "nginx-deployment-65bbdb5f8-q765r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-q765r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-q765r,UID:66934a30-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21423,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000daf4b0 0xc000daf4b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daf530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daf550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.656: INFO: Pod "nginx-deployment-65bbdb5f8-tpwvf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tpwvf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-tpwvf,UID:654ade82-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21272,Generation:0,CreationTimestamp:2019-04-25 16:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000daf610 0xc000daf611}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daf6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daf710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:39 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 16:51:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 16:51:43.656: INFO: Pod "nginx-deployment-65bbdb5f8-wnkfk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wnkfk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhlxv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhlxv/pods/nginx-deployment-65bbdb5f8-wnkfk,UID:6693f2ec-677a-11e9-a8f1-82d29082e60b,ResourceVersion:21443,Generation:0,CreationTimestamp:2019-04-25 16:51:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 6549dc61-677a-11e9-a8f1-82d29082e60b 0xc000daf7d0 0xc000daf7d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-65494 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-65494,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-65494 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000daf940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000daf960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 16:51:41 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:,StartTime:2019-04-25 16:51:41 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:51:43.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qhlxv" for this suite.
Apr 25 16:51:51.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:51:51.742: INFO: namespace: e2e-tests-deployment-qhlxv, resource: bindings, ignored listing per whitelist
Apr 25 16:51:51.770: INFO: namespace e2e-tests-deployment-qhlxv deletion completed in 8.109632344s

• [SLOW TEST:18.506 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:51:51.773: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6cad397b-677a-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 16:51:51.860: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-qwchb" to be "success or failure"
Apr 25 16:51:51.871: INFO: Pod "pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 11.532028ms
Apr 25 16:51:53.876: INFO: Pod "pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016306723s
Apr 25 16:51:55.892: INFO: Pod "pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03191137s
Apr 25 16:51:57.901: INFO: Pod "pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040673394s
STEP: Saw pod success
Apr 25 16:51:57.901: INFO: Pod "pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 16:51:57.903: INFO: Trying to get logs from node test113-q3hn pod pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 16:51:57.922: INFO: Waiting for pod pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 16:51:57.926: INFO: Pod pod-projected-configmaps-6cadb7e6-677a-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:51:57.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qwchb" for this suite.
Apr 25 16:52:03.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:52:04.377: INFO: namespace: e2e-tests-projected-qwchb, resource: bindings, ignored listing per whitelist
Apr 25 16:52:04.690: INFO: namespace e2e-tests-projected-qwchb deletion completed in 6.760504497s

• [SLOW TEST:12.917 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:52:04.690: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-74995eda-677a-11e9-9f66-ae72f7f5c328
STEP: Creating secret with name s-test-opt-upd-74995f57-677a-11e9-9f66-ae72f7f5c328
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-74995eda-677a-11e9-9f66-ae72f7f5c328
STEP: Updating secret s-test-opt-upd-74995f57-677a-11e9-9f66-ae72f7f5c328
STEP: Creating secret with name s-test-opt-create-74995f88-677a-11e9-9f66-ae72f7f5c328
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:53:15.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-67h27" for this suite.
Apr 25 16:53:37.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:53:37.786: INFO: namespace: e2e-tests-projected-67h27, resource: bindings, ignored listing per whitelist
Apr 25 16:53:37.809: INFO: namespace e2e-tests-projected-67h27 deletion completed in 22.102669751s

• [SLOW TEST:93.119 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:53:37.810: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Apr 25 16:53:37.885: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-8tvzq" to be "success or failure"
Apr 25 16:53:37.915: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 29.585462ms
Apr 25 16:53:39.919: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033722717s
Apr 25 16:53:41.924: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038255s
STEP: Saw pod success
Apr 25 16:53:41.924: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 25 16:53:41.926: INFO: Trying to get logs from node test113-q3k9 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 25 16:53:41.955: INFO: Waiting for pod pod-host-path-test to disappear
Apr 25 16:53:41.958: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:53:41.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-8tvzq" for this suite.
Apr 25 16:53:47.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:53:48.003: INFO: namespace: e2e-tests-hostpath-8tvzq, resource: bindings, ignored listing per whitelist
Apr 25 16:53:48.080: INFO: namespace e2e-tests-hostpath-8tvzq deletion completed in 6.117792323s

• [SLOW TEST:10.270 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:53:48.084: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:53:50.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-8vg69" for this suite.
Apr 25 16:54:42.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:54:42.336: INFO: namespace: e2e-tests-kubelet-test-8vg69, resource: bindings, ignored listing per whitelist
Apr 25 16:54:42.361: INFO: namespace e2e-tests-kubelet-test-8vg69 deletion completed in 52.10325525s

• [SLOW TEST:54.278 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:54:42.361: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Apr 25 16:54:42.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-bgcv6'
Apr 25 16:54:42.882: INFO: stderr: ""
Apr 25 16:54:42.882: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 25 16:54:44.013: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:54:44.013: INFO: Found 0 / 1
Apr 25 16:54:44.888: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:54:44.888: INFO: Found 1 / 1
Apr 25 16:54:44.888: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 25 16:54:44.891: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:54:44.892: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 25 16:54:44.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 patch pod redis-master-2m2zc --namespace=e2e-tests-kubectl-bgcv6 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 25 16:54:44.978: INFO: stderr: ""
Apr 25 16:54:44.978: INFO: stdout: "pod/redis-master-2m2zc patched\n"
STEP: checking annotations
Apr 25 16:54:44.981: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 16:54:44.981: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 16:54:44.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bgcv6" for this suite.
Apr 25 16:55:07.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 16:55:07.042: INFO: namespace: e2e-tests-kubectl-bgcv6, resource: bindings, ignored listing per whitelist
Apr 25 16:55:07.088: INFO: namespace e2e-tests-kubectl-bgcv6 deletion completed in 22.103592399s

• [SLOW TEST:24.727 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 16:55:07.088: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 25 16:55:07.351: INFO: Pod name wrapped-volume-race-e132b1cb-677a-11e9-9f66-ae72f7f5c328: Found 0 pods out of 5
Apr 25 16:55:12.363: INFO: Pod name wrapped-volume-race-e132b1cb-677a-11e9-9f66-ae72f7f5c328: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e132b1cb-677a-11e9-9f66-ae72f7f5c328 in namespace e2e-tests-emptydir-wrapper-ll6kx, will wait for the garbage collector to delete the pods
Apr 25 16:56:54.522: INFO: Deleting ReplicationController wrapped-volume-race-e132b1cb-677a-11e9-9f66-ae72f7f5c328 took: 25.898181ms
Apr 25 16:56:54.923: INFO: Terminating ReplicationController wrapped-volume-race-e132b1cb-677a-11e9-9f66-ae72f7f5c328 pods took: 400.264878ms
STEP: Creating RC which spawns configmap-volume pods
Apr 25 16:57:29.643: INFO: Pod name wrapped-volume-race-3601e05c-677b-11e9-9f66-ae72f7f5c328: Found 0 pods out of 5
Apr 25 16:57:34.651: INFO: Pod name wrapped-volume-race-3601e05c-677b-11e9-9f66-ae72f7f5c328: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3601e05c-677b-11e9-9f66-ae72f7f5c328 in namespace e2e-tests-emptydir-wrapper-ll6kx, will wait for the garbage collector to delete the pods
Apr 25 17:00:22.745: INFO: Deleting ReplicationController wrapped-volume-race-3601e05c-677b-11e9-9f66-ae72f7f5c328 took: 10.46914ms
Apr 25 17:00:22.845: INFO: Terminating ReplicationController wrapped-volume-race-3601e05c-677b-11e9-9f66-ae72f7f5c328 pods took: 100.249775ms
STEP: Creating RC which spawns configmap-volume pods
Apr 25 17:01:06.262: INFO: Pod name wrapped-volume-race-b71fbf28-677b-11e9-9f66-ae72f7f5c328: Found 0 pods out of 5
Apr 25 17:01:11.273: INFO: Pod name wrapped-volume-race-b71fbf28-677b-11e9-9f66-ae72f7f5c328: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b71fbf28-677b-11e9-9f66-ae72f7f5c328 in namespace e2e-tests-emptydir-wrapper-ll6kx, will wait for the garbage collector to delete the pods
Apr 25 17:02:57.368: INFO: Deleting ReplicationController wrapped-volume-race-b71fbf28-677b-11e9-9f66-ae72f7f5c328 took: 13.037616ms
Apr 25 17:02:57.568: INFO: Terminating ReplicationController wrapped-volume-race-b71fbf28-677b-11e9-9f66-ae72f7f5c328 pods took: 200.288706ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:03:36.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-ll6kx" for this suite.
Apr 25 17:03:42.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:03:42.505: INFO: namespace: e2e-tests-emptydir-wrapper-ll6kx, resource: bindings, ignored listing per whitelist
Apr 25 17:03:42.565: INFO: namespace e2e-tests-emptydir-wrapper-ll6kx deletion completed in 6.130004432s

• [SLOW TEST:515.477 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:03:42.566: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0425 17:04:12.741039      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 25 17:04:12.741: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:04:12.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zkjdd" for this suite.
Apr 25 17:04:18.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:04:18.793: INFO: namespace: e2e-tests-gc-zkjdd, resource: bindings, ignored listing per whitelist
Apr 25 17:04:18.842: INFO: namespace e2e-tests-gc-zkjdd deletion completed in 6.098108033s

• [SLOW TEST:36.276 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:04:18.843: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hfc8j.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hfc8j.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hfc8j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-hfc8j.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-hfc8j.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-hfc8j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 25 17:04:23.065: INFO: DNS probes using e2e-tests-dns-hfc8j/dns-test-29f63391-677c-11e9-9f66-ae72f7f5c328 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:04:23.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-hfc8j" for this suite.
Apr 25 17:04:29.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:04:29.220: INFO: namespace: e2e-tests-dns-hfc8j, resource: bindings, ignored listing per whitelist
Apr 25 17:04:29.270: INFO: namespace e2e-tests-dns-hfc8j deletion completed in 6.184959002s

• [SLOW TEST:10.427 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:04:29.271: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:04:29.430: INFO: Waiting up to 5m0s for pod "downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-cmrz4" to be "success or failure"
Apr 25 17:04:29.463: INFO: Pod "downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 33.440882ms
Apr 25 17:04:31.467: INFO: Pod "downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03737678s
Apr 25 17:04:33.471: INFO: Pod "downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041408332s
STEP: Saw pod success
Apr 25 17:04:33.472: INFO: Pod "downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:04:33.474: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:04:33.500: INFO: Waiting for pod downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:04:33.505: INFO: Pod downwardapi-volume-303833e3-677c-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:04:33.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cmrz4" for this suite.
Apr 25 17:04:39.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:04:39.540: INFO: namespace: e2e-tests-projected-cmrz4, resource: bindings, ignored listing per whitelist
Apr 25 17:04:39.648: INFO: namespace e2e-tests-projected-cmrz4 deletion completed in 6.140390359s

• [SLOW TEST:10.377 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:04:39.648: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Apr 25 17:04:39.769: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 25 17:04:39.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:39.988: INFO: stderr: ""
Apr 25 17:04:39.988: INFO: stdout: "service/redis-slave created\n"
Apr 25 17:04:39.989: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 25 17:04:39.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:40.303: INFO: stderr: ""
Apr 25 17:04:40.303: INFO: stdout: "service/redis-master created\n"
Apr 25 17:04:40.303: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 25 17:04:40.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:40.497: INFO: stderr: ""
Apr 25 17:04:40.497: INFO: stdout: "service/frontend created\n"
Apr 25 17:04:40.497: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 25 17:04:40.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:40.671: INFO: stderr: ""
Apr 25 17:04:40.672: INFO: stdout: "deployment.extensions/frontend created\n"
Apr 25 17:04:40.672: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 25 17:04:40.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:40.863: INFO: stderr: ""
Apr 25 17:04:40.863: INFO: stdout: "deployment.extensions/redis-master created\n"
Apr 25 17:04:40.864: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 25 17:04:40.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:41.039: INFO: stderr: ""
Apr 25 17:04:41.039: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Apr 25 17:04:41.039: INFO: Waiting for all frontend pods to be Running.
Apr 25 17:04:46.090: INFO: Waiting for frontend to serve content.
Apr 25 17:04:46.116: INFO: Trying to add a new entry to the guestbook.
Apr 25 17:04:46.137: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 25 17:04:46.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:46.897: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:04:46.897: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 25 17:04:46.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:47.040: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:04:47.040: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 25 17:04:47.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:47.137: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:04:47.137: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 25 17:04:47.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:47.225: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:04:47.225: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 25 17:04:47.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:47.400: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:04:47.400: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 25 17:04:47.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kbf6d'
Apr 25 17:04:47.505: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:04:47.505: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:04:47.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kbf6d" for this suite.
Apr 25 17:05:27.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:05:27.609: INFO: namespace: e2e-tests-kubectl-kbf6d, resource: bindings, ignored listing per whitelist
Apr 25 17:05:27.632: INFO: namespace e2e-tests-kubectl-kbf6d deletion completed in 40.11852654s

• [SLOW TEST:47.984 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:05:27.634: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 25 17:05:27.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-4hg4w'
Apr 25 17:05:27.860: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 25 17:05:27.860: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Apr 25 17:05:29.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-4hg4w'
Apr 25 17:05:29.968: INFO: stderr: ""
Apr 25 17:05:29.968: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:05:29.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4hg4w" for this suite.
Apr 25 17:05:51.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:05:52.029: INFO: namespace: e2e-tests-kubectl-4hg4w, resource: bindings, ignored listing per whitelist
Apr 25 17:05:52.100: INFO: namespace e2e-tests-kubectl-4hg4w deletion completed in 22.123718684s

• [SLOW TEST:24.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:05:52.100: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 25 17:05:52.249: INFO: Waiting up to 5m0s for pod "pod-61973a29-677c-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-kqctg" to be "success or failure"
Apr 25 17:05:52.256: INFO: Pod "pod-61973a29-677c-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.378071ms
Apr 25 17:05:54.272: INFO: Pod "pod-61973a29-677c-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.022494064s
Apr 25 17:05:56.276: INFO: Pod "pod-61973a29-677c-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0270541s
STEP: Saw pod success
Apr 25 17:05:56.276: INFO: Pod "pod-61973a29-677c-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:05:56.281: INFO: Trying to get logs from node test113-q3hn pod pod-61973a29-677c-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:05:56.309: INFO: Waiting for pod pod-61973a29-677c-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:05:56.312: INFO: Pod pod-61973a29-677c-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:05:56.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kqctg" for this suite.
Apr 25 17:06:02.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:06:02.376: INFO: namespace: e2e-tests-emptydir-kqctg, resource: bindings, ignored listing per whitelist
Apr 25 17:06:02.419: INFO: namespace e2e-tests-emptydir-kqctg deletion completed in 6.103871788s

• [SLOW TEST:10.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:06:02.420: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 25 17:06:02.560: INFO: Waiting up to 5m0s for pod "pod-67bc6063-677c-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-w8h25" to be "success or failure"
Apr 25 17:06:02.569: INFO: Pod "pod-67bc6063-677c-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.332722ms
Apr 25 17:06:04.576: INFO: Pod "pod-67bc6063-677c-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01523731s
STEP: Saw pod success
Apr 25 17:06:04.576: INFO: Pod "pod-67bc6063-677c-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:06:04.580: INFO: Trying to get logs from node test113-q3hn pod pod-67bc6063-677c-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:06:04.616: INFO: Waiting for pod pod-67bc6063-677c-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:06:04.622: INFO: Pod pod-67bc6063-677c-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:06:04.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w8h25" for this suite.
Apr 25 17:06:10.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:06:10.712: INFO: namespace: e2e-tests-emptydir-w8h25, resource: bindings, ignored listing per whitelist
Apr 25 17:06:10.742: INFO: namespace e2e-tests-emptydir-w8h25 deletion completed in 6.114683062s

• [SLOW TEST:8.323 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:06:10.743: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Apr 25 17:06:10.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-v7848'
Apr 25 17:06:11.043: INFO: stderr: ""
Apr 25 17:06:11.043: INFO: stdout: "pod/pause created\n"
Apr 25 17:06:11.043: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 25 17:06:11.043: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-v7848" to be "running and ready"
Apr 25 17:06:11.049: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.125403ms
Apr 25 17:06:13.053: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010138937s
Apr 25 17:06:13.053: INFO: Pod "pause" satisfied condition "running and ready"
Apr 25 17:06:13.053: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 25 17:06:13.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-v7848'
Apr 25 17:06:13.157: INFO: stderr: ""
Apr 25 17:06:13.157: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 25 17:06:13.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pod pause -L testing-label --namespace=e2e-tests-kubectl-v7848'
Apr 25 17:06:13.223: INFO: stderr: ""
Apr 25 17:06:13.223: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 25 17:06:13.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 label pods pause testing-label- --namespace=e2e-tests-kubectl-v7848'
Apr 25 17:06:13.314: INFO: stderr: ""
Apr 25 17:06:13.314: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 25 17:06:13.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pod pause -L testing-label --namespace=e2e-tests-kubectl-v7848'
Apr 25 17:06:13.403: INFO: stderr: ""
Apr 25 17:06:13.403: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Apr 25 17:06:13.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v7848'
Apr 25 17:06:13.496: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:06:13.497: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 25 17:06:13.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-v7848'
Apr 25 17:06:13.579: INFO: stderr: "No resources found.\n"
Apr 25 17:06:13.579: INFO: stdout: ""
Apr 25 17:06:13.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -l name=pause --namespace=e2e-tests-kubectl-v7848 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 25 17:06:13.660: INFO: stderr: ""
Apr 25 17:06:13.660: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:06:13.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v7848" for this suite.
Apr 25 17:06:19.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:06:19.718: INFO: namespace: e2e-tests-kubectl-v7848, resource: bindings, ignored listing per whitelist
Apr 25 17:06:19.767: INFO: namespace e2e-tests-kubectl-v7848 deletion completed in 6.1027647s

• [SLOW TEST:9.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:06:19.768: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-7208d6b6-677c-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:06:19.839: INFO: Waiting up to 5m0s for pod "pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-nmjln" to be "success or failure"
Apr 25 17:06:19.852: INFO: Pod "pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 12.334812ms
Apr 25 17:06:21.856: INFO: Pod "pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01693483s
Apr 25 17:06:23.860: INFO: Pod "pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020699627s
STEP: Saw pod success
Apr 25 17:06:23.860: INFO: Pod "pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:06:23.863: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:06:23.890: INFO: Waiting for pod pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:06:23.893: INFO: Pod pod-secrets-72095232-677c-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:06:23.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nmjln" for this suite.
Apr 25 17:06:29.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:06:30.018: INFO: namespace: e2e-tests-secrets-nmjln, resource: bindings, ignored listing per whitelist
Apr 25 17:06:30.030: INFO: namespace e2e-tests-secrets-nmjln deletion completed in 6.129588491s

• [SLOW TEST:10.263 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:06:30.030: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-78301c01-677c-11e9-9f66-ae72f7f5c328
STEP: Creating secret with name s-test-opt-upd-78301c78-677c-11e9-9f66-ae72f7f5c328
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-78301c01-677c-11e9-9f66-ae72f7f5c328
STEP: Updating secret s-test-opt-upd-78301c78-677c-11e9-9f66-ae72f7f5c328
STEP: Creating secret with name s-test-opt-create-78301caa-677c-11e9-9f66-ae72f7f5c328
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:07:52.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m77zz" for this suite.
Apr 25 17:08:14.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:08:14.890: INFO: namespace: e2e-tests-secrets-m77zz, resource: bindings, ignored listing per whitelist
Apr 25 17:08:15.036: INFO: namespace e2e-tests-secrets-m77zz deletion completed in 22.188120367s

• [SLOW TEST:105.006 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:08:15.036: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0425 17:08:25.161494      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 25 17:08:25.161: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:08:25.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-srrr4" for this suite.
Apr 25 17:08:31.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:08:31.248: INFO: namespace: e2e-tests-gc-srrr4, resource: bindings, ignored listing per whitelist
Apr 25 17:08:31.291: INFO: namespace e2e-tests-gc-srrr4 deletion completed in 6.126336734s

• [SLOW TEST:16.255 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:08:31.294: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 25 17:08:31.414: INFO: PodSpec: initContainers in spec.initContainers
Apr 25 17:09:16.662: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c0770b04-677c-11e9-9f66-ae72f7f5c328", GenerateName:"", Namespace:"e2e-tests-init-container-4x7s8", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-4x7s8/pods/pod-init-c0770b04-677c-11e9-9f66-ae72f7f5c328", UID:"c0789c0b-677c-11e9-a8f1-82d29082e60b", ResourceVersion:"25201", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691808911, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"414419189"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5d8sv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0013839c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5d8sv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5d8sv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5d8sv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0019acd88), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"test113-q3hn", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001211aa0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0019acf20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0019acf40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0019acf48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0019acf4c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691808911, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691808911, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691808911, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691808911, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.138.46.141", PodIP:"10.244.1.235", StartTime:(*v1.Time)(0xc000d50220), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ca7ce0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ca7d50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://0c79e831b96c1c0d50799aa0ad1d4a7d365dd0ab03ef5815345e66cf3cf96e31"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000d50260), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000d50240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:09:16.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4x7s8" for this suite.
Apr 25 17:09:38.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:09:38.746: INFO: namespace: e2e-tests-init-container-4x7s8, resource: bindings, ignored listing per whitelist
Apr 25 17:09:38.782: INFO: namespace e2e-tests-init-container-4x7s8 deletion completed in 22.114918546s

• [SLOW TEST:67.489 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:09:38.782: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-e8b06395-677c-11e9-9f66-ae72f7f5c328
STEP: Creating configMap with name cm-test-opt-upd-e8b063d7-677c-11e9-9f66-ae72f7f5c328
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e8b06395-677c-11e9-9f66-ae72f7f5c328
STEP: Updating configmap cm-test-opt-upd-e8b063d7-677c-11e9-9f66-ae72f7f5c328
STEP: Creating configMap with name cm-test-opt-create-e8b06400-677c-11e9-9f66-ae72f7f5c328
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:09:45.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6wzp4" for this suite.
Apr 25 17:10:07.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:10:07.202: INFO: namespace: e2e-tests-configmap-6wzp4, resource: bindings, ignored listing per whitelist
Apr 25 17:10:07.234: INFO: namespace e2e-tests-configmap-6wzp4 deletion completed in 22.133794869s

• [SLOW TEST:28.452 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:10:07.234: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-g4gnw/secret-test-f9a5b836-677c-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:10:07.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9a67552-677c-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-g4gnw" to be "success or failure"
Apr 25 17:10:07.380: INFO: Pod "pod-configmaps-f9a67552-677c-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 15.805227ms
Apr 25 17:10:09.390: INFO: Pod "pod-configmaps-f9a67552-677c-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025313039s
STEP: Saw pod success
Apr 25 17:10:09.390: INFO: Pod "pod-configmaps-f9a67552-677c-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:10:09.396: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-f9a67552-677c-11e9-9f66-ae72f7f5c328 container env-test: <nil>
STEP: delete the pod
Apr 25 17:10:09.433: INFO: Waiting for pod pod-configmaps-f9a67552-677c-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:10:09.436: INFO: Pod pod-configmaps-f9a67552-677c-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:10:09.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g4gnw" for this suite.
Apr 25 17:10:15.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:10:15.528: INFO: namespace: e2e-tests-secrets-g4gnw, resource: bindings, ignored listing per whitelist
Apr 25 17:10:15.547: INFO: namespace e2e-tests-secrets-g4gnw deletion completed in 6.107677028s

• [SLOW TEST:8.313 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:10:15.547: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:10:15.689: INFO: Creating ReplicaSet my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328
Apr 25 17:10:15.698: INFO: Pod name my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328: Found 0 pods out of 1
Apr 25 17:10:20.702: INFO: Pod name my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328: Found 1 pods out of 1
Apr 25 17:10:20.702: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328" is running
Apr 25 17:10:20.704: INFO: Pod "my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328-r9ssn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:10:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:10:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:10:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:10:15 +0000 UTC Reason: Message:}])
Apr 25 17:10:20.705: INFO: Trying to dial the pod
Apr 25 17:10:25.719: INFO: Controller my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328: Got expected result from replica 1 [my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328-r9ssn]: "my-hostname-basic-fe9e2bd2-677c-11e9-9f66-ae72f7f5c328-r9ssn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:10:25.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-4pll4" for this suite.
Apr 25 17:10:31.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:10:31.780: INFO: namespace: e2e-tests-replicaset-4pll4, resource: bindings, ignored listing per whitelist
Apr 25 17:10:31.834: INFO: namespace e2e-tests-replicaset-4pll4 deletion completed in 6.110774963s

• [SLOW TEST:16.287 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:10:31.836: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 25 17:10:31.957: INFO: Waiting up to 5m0s for pod "pod-084f34ab-677d-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-hsf8p" to be "success or failure"
Apr 25 17:10:31.965: INFO: Pod "pod-084f34ab-677d-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.338859ms
Apr 25 17:10:33.969: INFO: Pod "pod-084f34ab-677d-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011598844s
Apr 25 17:10:35.974: INFO: Pod "pod-084f34ab-677d-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016415371s
STEP: Saw pod success
Apr 25 17:10:35.974: INFO: Pod "pod-084f34ab-677d-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:10:35.976: INFO: Trying to get logs from node test113-q3hn pod pod-084f34ab-677d-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:10:36.003: INFO: Waiting for pod pod-084f34ab-677d-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:10:36.006: INFO: Pod pod-084f34ab-677d-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:10:36.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hsf8p" for this suite.
Apr 25 17:10:42.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:10:42.074: INFO: namespace: e2e-tests-emptydir-hsf8p, resource: bindings, ignored listing per whitelist
Apr 25 17:10:42.117: INFO: namespace e2e-tests-emptydir-hsf8p deletion completed in 6.107821905s

• [SLOW TEST:10.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:10:42.119: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:10:42.247: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 25 17:10:47.251: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 25 17:10:47.251: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 25 17:10:47.285: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-7t9qh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7t9qh/deployments/test-cleanup-deployment,UID:116fe250-677d-11e9-a8f1-82d29082e60b,ResourceVersion:25543,Generation:1,CreationTimestamp:2019-04-25 17:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Apr 25 17:10:47.313: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-7t9qh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7t9qh/replicasets/test-cleanup-deployment-7dbbfcf846,UID:11727357-677d-11e9-a8f1-82d29082e60b,ResourceVersion:25545,Generation:1,CreationTimestamp:2019-04-25 17:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 116fe250-677d-11e9-a8f1-82d29082e60b 0xc000d9e1d7 0xc000d9e1d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 25 17:10:47.313: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 25 17:10:47.313: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-7t9qh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7t9qh/replicasets/test-cleanup-controller,UID:0e725a24-677d-11e9-a8f1-82d29082e60b,ResourceVersion:25544,Generation:1,CreationTimestamp:2019-04-25 17:10:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 116fe250-677d-11e9-a8f1-82d29082e60b 0xc000d9e117 0xc000d9e118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 25 17:10:47.330: INFO: Pod "test-cleanup-controller-lwjh6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-lwjh6,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-7t9qh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7t9qh/pods/test-cleanup-controller-lwjh6,UID:0e739a09-677d-11e9-a8f1-82d29082e60b,ResourceVersion:25536,Generation:0,CreationTimestamp:2019-04-25 17:10:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 0e725a24-677d-11e9-a8f1-82d29082e60b 0xc001c8a187 0xc001c8a188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zf9j9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zf9j9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zf9j9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c8a200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c8a220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:42 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:10.244.1.34,StartTime:2019-04-25 17:10:42 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-04-25 17:10:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d8fb606836cad9f13dd6b0ad670045402d8d1178993ff7282ac2c540d4b6d8c9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Apr 25 17:10:47.330: INFO: Pod "test-cleanup-deployment-7dbbfcf846-sjkqd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-sjkqd,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-7t9qh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7t9qh/pods/test-cleanup-deployment-7dbbfcf846-sjkqd,UID:11741db3-677d-11e9-a8f1-82d29082e60b,ResourceVersion:25550,Generation:0,CreationTimestamp:2019-04-25 17:10:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 11727357-677d-11e9-a8f1-82d29082e60b 0xc001c8a2e7 0xc001c8a2e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zf9j9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zf9j9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zf9j9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c8a360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c8a380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:10:47.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7t9qh" for this suite.
Apr 25 17:10:53.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:10:53.415: INFO: namespace: e2e-tests-deployment-7t9qh, resource: bindings, ignored listing per whitelist
Apr 25 17:10:53.469: INFO: namespace e2e-tests-deployment-7t9qh deletion completed in 6.131615725s

• [SLOW TEST:11.350 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:10:53.473: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-5hgtw
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-5hgtw
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-5hgtw
Apr 25 17:10:53.625: INFO: Found 0 stateful pods, waiting for 1
Apr 25 17:11:03.629: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 25 17:11:03.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:11:03.897: INFO: stderr: ""
Apr 25 17:11:03.897: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:11:03.898: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:11:03.902: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:11:03.902: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:11:03.968: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:03.969: INFO: ss-0  test113-q3hn  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:03.969: INFO: ss-1                Pending         []
Apr 25 17:11:03.969: INFO: 
Apr 25 17:11:03.970: INFO: StatefulSet ss has not reached scale 3, at 2
Apr 25 17:11:04.974: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.956353718s
Apr 25 17:11:05.978: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.952537807s
Apr 25 17:11:06.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.948068058s
Apr 25 17:11:07.987: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.943645109s
Apr 25 17:11:08.992: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.939525375s
Apr 25 17:11:09.996: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.934003426s
Apr 25 17:11:11.001: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.929821954s
Apr 25 17:11:12.005: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.925337077s
Apr 25 17:11:13.009: INFO: Verifying statefulset ss doesn't scale past 3 for another 921.16708ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-5hgtw
Apr 25 17:11:14.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:11:14.363: INFO: stderr: ""
Apr 25 17:11:14.363: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 17:11:14.363: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 25 17:11:14.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:11:14.737: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Apr 25 17:11:14.737: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 17:11:14.737: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 25 17:11:14.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:11:15.024: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Apr 25 17:11:15.025: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 17:11:15.025: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 25 17:11:15.028: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:11:15.028: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:11:15.028: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 25 17:11:15.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:11:15.323: INFO: stderr: ""
Apr 25 17:11:15.323: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:11:15.323: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:11:15.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:11:15.586: INFO: stderr: ""
Apr 25 17:11:15.586: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:11:15.586: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:11:15.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:11:15.860: INFO: stderr: ""
Apr 25 17:11:15.860: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:11:15.860: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:11:15.860: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:11:15.863: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 25 17:11:25.885: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:11:25.885: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:11:25.885: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:11:25.905: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:25.905: INFO: ss-0  test113-q3hn  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:25.905: INFO: ss-1  test113-q3kz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:25.905: INFO: ss-2  test113-q3k9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:25.905: INFO: 
Apr 25 17:11:25.905: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 25 17:11:26.908: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:26.908: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:26.908: INFO: ss-1  test113-q3kz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:26.908: INFO: ss-2  test113-q3k9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:26.908: INFO: 
Apr 25 17:11:26.908: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 25 17:11:27.913: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:27.913: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:27.913: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:27.913: INFO: ss-2  test113-q3k9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:27.913: INFO: 
Apr 25 17:11:27.913: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 25 17:11:28.924: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:28.924: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:28.924: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:28.924: INFO: 
Apr 25 17:11:28.924: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 25 17:11:29.928: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:29.928: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:29.928: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:29.928: INFO: 
Apr 25 17:11:29.928: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 25 17:11:30.933: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:30.933: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:30.933: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:30.933: INFO: 
Apr 25 17:11:30.934: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 25 17:11:31.940: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:31.940: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:31.940: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:31.940: INFO: 
Apr 25 17:11:31.940: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 25 17:11:32.944: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:32.944: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:32.944: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:32.944: INFO: 
Apr 25 17:11:32.944: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 25 17:11:33.949: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:33.949: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:33.949: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:33.949: INFO: 
Apr 25 17:11:33.949: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 25 17:11:34.954: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Apr 25 17:11:34.954: INFO: ss-0  test113-q3hn  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:10:53 +0000 UTC  }]
Apr 25 17:11:34.954: INFO: ss-1  test113-q3kz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:11:03 +0000 UTC  }]
Apr 25 17:11:34.954: INFO: 
Apr 25 17:11:34.954: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-5hgtw
Apr 25 17:11:35.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:11:36.052: INFO: rc: 1
Apr 25 17:11:36.052: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001cb0330 exit status 1 <nil> <nil> true [0xc001545ae8 0xc001545b18 0xc001545b58] [0xc001545ae8 0xc001545b18 0xc001545b58] [0xc001545af8 0xc001545b38] [0x92f8e0 0x92f8e0] 0xc0008dc2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:11:46.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:11:46.129: INFO: rc: 1
Apr 25 17:11:46.129: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00056dcb0 exit status 1 <nil> <nil> true [0xc0019686f0 0xc001968720 0xc001968748] [0xc0019686f0 0xc001968720 0xc001968748] [0xc001968700 0xc001968740] [0x92f8e0 0x92f8e0] 0xc000ec50e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:11:56.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:11:56.216: INFO: rc: 1
Apr 25 17:11:56.217: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001cb0780 exit status 1 <nil> <nil> true [0xc001545b70 0xc001545bb0 0xc001545bf0] [0xc001545b70 0xc001545bb0 0xc001545bf0] [0xc001545ba8 0xc001545bd8] [0x92f8e0 0x92f8e0] 0xc0008dc840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:12:06.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:12:06.283: INFO: rc: 1
Apr 25 17:12:06.283: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0010fc1e0 exit status 1 <nil> <nil> true [0xc001968750 0xc001968768 0xc001968788] [0xc001968750 0xc001968768 0xc001968788] [0xc001968760 0xc001968778] [0x92f8e0 0x92f8e0] 0xc000ec5560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:12:16.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:12:16.350: INFO: rc: 1
Apr 25 17:12:16.350: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0009eedb0 exit status 1 <nil> <nil> true [0xc0019a15c0 0xc0019a1620 0xc0019a1650] [0xc0019a15c0 0xc0019a1620 0xc0019a1650] [0xc0019a15f0 0xc0019a1640] [0x92f8e0 0x92f8e0] 0xc000bb1c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:12:26.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:12:26.440: INFO: rc: 1
Apr 25 17:12:26.440: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0009ef230 exit status 1 <nil> <nil> true [0xc0019a1668 0xc0019a16c8 0xc0019a1710] [0xc0019a1668 0xc0019a16c8 0xc0019a1710] [0xc0019a1698 0xc0019a16f8] [0x92f8e0 0x92f8e0] 0xc000bb1f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:12:36.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:12:36.522: INFO: rc: 1
Apr 25 17:12:36.522: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0009ef5c0 exit status 1 <nil> <nil> true [0xc0019a1720 0xc0019a1768 0xc0019a17a0] [0xc0019a1720 0xc0019a1768 0xc0019a17a0] [0xc0019a1748 0xc0019a1790] [0x92f8e0 0x92f8e0] 0xc0015d8480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:12:46.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:12:46.593: INFO: rc: 1
Apr 25 17:12:46.593: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0009e0ba0 exit status 1 <nil> <nil> true [0xc000e49460 0xc000e49488 0xc000e494a8] [0xc000e49460 0xc000e49488 0xc000e494a8] [0xc000e49478 0xc000e494a0] [0x92f8e0 0x92f8e0] 0xc001b23da0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:12:56.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:12:56.665: INFO: rc: 1
Apr 25 17:12:56.665: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00056da70 exit status 1 <nil> <nil> true [0xc000166098 0xc000166190 0xc0001662c0] [0xc000166098 0xc000166190 0xc0001662c0] [0xc000166168 0xc0001662a0] [0x92f8e0 0x92f8e0] 0xc000dc8480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:13:06.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:13:06.729: INFO: rc: 1
Apr 25 17:13:06.729: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0019cd6e0 exit status 1 <nil> <nil> true [0xc00000e100 0xc00000e178 0xc00000e260] [0xc00000e100 0xc00000e178 0xc00000e260] [0xc00000e158 0xc00000e240] [0x92f8e0 0x92f8e0] 0xc000dba6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:13:16.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:13:16.813: INFO: rc: 1
Apr 25 17:13:16.813: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0019cdad0 exit status 1 <nil> <nil> true [0xc00000e2d8 0xc00000e338 0xc00000e3d0] [0xc00000e2d8 0xc00000e338 0xc00000e3d0] [0xc00000e300 0xc00000e3b0] [0x92f8e0 0x92f8e0] 0xc000dbafc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:13:26.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:13:26.896: INFO: rc: 1
Apr 25 17:13:26.896: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0019cde60 exit status 1 <nil> <nil> true [0xc00000e3d8 0xc00000e470 0xc00000e548] [0xc00000e3d8 0xc00000e470 0xc00000e548] [0xc00000e438 0xc00000e4a0] [0x92f8e0 0x92f8e0] 0xc000dbba40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:13:36.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:13:36.986: INFO: rc: 1
Apr 25 17:13:36.986: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d43c0 exit status 1 <nil> <nil> true [0xc0000ca0d0 0xc0000ca178 0xc0000ca268] [0xc0000ca0d0 0xc0000ca178 0xc0000ca268] [0xc0000ca140 0xc0000ca208] [0x92f8e0 0x92f8e0] 0xc000bb0540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:13:46.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:13:47.066: INFO: rc: 1
Apr 25 17:13:47.066: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000808420 exit status 1 <nil> <nil> true [0xc00000e740 0xc00000e818 0xc00000e8e0] [0xc00000e740 0xc00000e818 0xc00000e8e0] [0xc00000e7b8 0xc00000e8c0] [0x92f8e0 0x92f8e0] 0xc0022280c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:13:57.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:13:57.137: INFO: rc: 1
Apr 25 17:13:57.137: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00218e480 exit status 1 <nil> <nil> true [0xc001544008 0xc001544028 0xc001544060] [0xc001544008 0xc001544028 0xc001544060] [0xc001544020 0xc001544050] [0x92f8e0 0x92f8e0] 0xc0016ec960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:14:07.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:14:07.210: INFO: rc: 1
Apr 25 17:14:07.210: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d4780 exit status 1 <nil> <nil> true [0xc0000cbd30 0xc0000cbf30 0xc0000cbff0] [0xc0000cbd30 0xc0000cbf30 0xc0000cbff0] [0xc0000cbe50 0xc0000cbfe8] [0x92f8e0 0x92f8e0] 0xc000bb0ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:14:17.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:14:17.292: INFO: rc: 1
Apr 25 17:14:17.293: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d4bd0 exit status 1 <nil> <nil> true [0xc000e48000 0xc000e480c8 0xc000e48200] [0xc000e48000 0xc000e480c8 0xc000e48200] [0xc000e48070 0xc000e48158] [0x92f8e0 0x92f8e0] 0xc000bb0f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:14:27.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:14:27.366: INFO: rc: 1
Apr 25 17:14:27.366: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d5260 exit status 1 <nil> <nil> true [0xc000e48220 0xc000e48320 0xc000e483f8] [0xc000e48220 0xc000e48320 0xc000e483f8] [0xc000e482c8 0xc000e483e0] [0x92f8e0 0x92f8e0] 0xc000bb1380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:14:37.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:14:37.424: INFO: rc: 1
Apr 25 17:14:37.424: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00218eab0 exit status 1 <nil> <nil> true [0xc001544068 0xc0015440a8 0xc0015440c8] [0xc001544068 0xc0015440a8 0xc0015440c8] [0xc0015440a0 0xc0015440b8] [0x92f8e0 0x92f8e0] 0xc0016ed320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:14:47.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:14:47.504: INFO: rc: 1
Apr 25 17:14:47.504: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00119e630 exit status 1 <nil> <nil> true [0xc000e48470 0xc000e48570 0xc000e48668] [0xc000e48470 0xc000e48570 0xc000e48668] [0xc000e484e0 0xc000e485c0] [0x92f8e0 0x92f8e0] 0xc000bb1740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:14:57.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:14:57.576: INFO: rc: 1
Apr 25 17:14:57.576: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d4390 exit status 1 <nil> <nil> true [0xc0000ca0e8 0xc0000ca1d8 0xc0000cbd30] [0xc0000ca0e8 0xc0000ca1d8 0xc0000cbd30] [0xc0000ca178 0xc0000ca268] [0x92f8e0 0x92f8e0] 0xc000dba6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:15:07.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:15:07.639: INFO: rc: 1
Apr 25 17:15:07.639: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00218e3f0 exit status 1 <nil> <nil> true [0xc001544008 0xc001544028 0xc001544060] [0xc001544008 0xc001544028 0xc001544060] [0xc001544020 0xc001544050] [0x92f8e0 0x92f8e0] 0xc0016ec960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:15:17.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:15:17.724: INFO: rc: 1
Apr 25 17:15:17.724: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00218e9c0 exit status 1 <nil> <nil> true [0xc001544068 0xc0015440a8 0xc0015440c8] [0xc001544068 0xc0015440a8 0xc0015440c8] [0xc0015440a0 0xc0015440b8] [0x92f8e0 0x92f8e0] 0xc0016ed320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:15:27.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:15:27.801: INFO: rc: 1
Apr 25 17:15:27.801: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d4750 exit status 1 <nil> <nil> true [0xc0000cbe38 0xc0000cbfa8 0xc000e48000] [0xc0000cbe38 0xc0000cbfa8 0xc000e48000] [0xc0000cbf30 0xc0000cbff0] [0x92f8e0 0x92f8e0] 0xc000dbafc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:15:37.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:15:37.863: INFO: rc: 1
Apr 25 17:15:37.863: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00119e870 exit status 1 <nil> <nil> true [0xc000166000 0xc000166168 0xc0001662a0] [0xc000166000 0xc000166168 0xc0001662a0] [0xc0001660c0 0xc0001661e8] [0x92f8e0 0x92f8e0] 0xc000bb0540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:15:47.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:15:47.933: INFO: rc: 1
Apr 25 17:15:47.933: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d4c00 exit status 1 <nil> <nil> true [0xc000e48060 0xc000e48140 0xc000e48220] [0xc000e48060 0xc000e48140 0xc000e48220] [0xc000e480c8 0xc000e48200] [0x92f8e0 0x92f8e0] 0xc000dbba40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:15:57.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:15:58.003: INFO: rc: 1
Apr 25 17:15:58.003: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00218eea0 exit status 1 <nil> <nil> true [0xc001544100 0xc001544190 0xc0015441c8] [0xc001544100 0xc001544190 0xc0015441c8] [0xc001544180 0xc0015441c0] [0x92f8e0 0x92f8e0] 0xc0016ed920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:16:08.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:16:08.065: INFO: rc: 1
Apr 25 17:16:08.065: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0013d52f0 exit status 1 <nil> <nil> true [0xc000e48288 0xc000e483b8 0xc000e48470] [0xc000e48288 0xc000e483b8 0xc000e48470] [0xc000e48320 0xc000e483f8] [0x92f8e0 0x92f8e0] 0xc000dc8120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:16:18.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:16:18.152: INFO: rc: 1
Apr 25 17:16:18.152: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00119ec60 exit status 1 <nil> <nil> true [0xc0001662c0 0xc000166360 0xc000166520] [0xc0001662c0 0xc000166360 0xc000166520] [0xc000166318 0xc0001664d8] [0x92f8e0 0x92f8e0] 0xc000bb0ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:16:28.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:16:28.222: INFO: rc: 1
Apr 25 17:16:28.222: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0019cd710 exit status 1 <nil> <nil> true [0xc00000e100 0xc00000e178 0xc00000e260] [0xc00000e100 0xc00000e178 0xc00000e260] [0xc00000e158 0xc00000e240] [0x92f8e0 0x92f8e0] 0xc002228420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Apr 25 17:16:38.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-5hgtw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:16:38.306: INFO: rc: 1
Apr 25 17:16:38.306: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Apr 25 17:16:38.306: INFO: Scaling statefulset ss to 0
Apr 25 17:16:38.315: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 25 17:16:38.318: INFO: Deleting all statefulset in ns e2e-tests-statefulset-5hgtw
Apr 25 17:16:38.320: INFO: Scaling statefulset ss to 0
Apr 25 17:16:38.327: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:16:38.329: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:16:38.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-5hgtw" for this suite.
Apr 25 17:16:46.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:16:46.415: INFO: namespace: e2e-tests-statefulset-5hgtw, resource: bindings, ignored listing per whitelist
Apr 25 17:16:46.447: INFO: namespace e2e-tests-statefulset-5hgtw deletion completed in 8.097866779s

• [SLOW TEST:352.975 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:16:46.448: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:16:46.576: INFO: (0) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.753236ms)
Apr 25 17:16:46.583: INFO: (1) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.172726ms)
Apr 25 17:16:46.596: INFO: (2) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.032207ms)
Apr 25 17:16:46.600: INFO: (3) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.951679ms)
Apr 25 17:16:46.603: INFO: (4) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.404513ms)
Apr 25 17:16:46.607: INFO: (5) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.668471ms)
Apr 25 17:16:46.610: INFO: (6) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.266491ms)
Apr 25 17:16:46.614: INFO: (7) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.895961ms)
Apr 25 17:16:46.619: INFO: (8) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.377852ms)
Apr 25 17:16:46.623: INFO: (9) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.452413ms)
Apr 25 17:16:46.627: INFO: (10) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.023676ms)
Apr 25 17:16:46.631: INFO: (11) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.355868ms)
Apr 25 17:16:46.636: INFO: (12) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.331778ms)
Apr 25 17:16:46.641: INFO: (13) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.863573ms)
Apr 25 17:16:46.644: INFO: (14) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.544404ms)
Apr 25 17:16:46.648: INFO: (15) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.60676ms)
Apr 25 17:16:46.651: INFO: (16) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.532222ms)
Apr 25 17:16:46.656: INFO: (17) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.532898ms)
Apr 25 17:16:46.663: INFO: (18) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.511807ms)
Apr 25 17:16:46.667: INFO: (19) /api/v1/nodes/test113-q3hn/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.313188ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:16:46.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-46crp" for this suite.
Apr 25 17:16:52.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:16:52.769: INFO: namespace: e2e-tests-proxy-46crp, resource: bindings, ignored listing per whitelist
Apr 25 17:16:52.801: INFO: namespace e2e-tests-proxy-46crp deletion completed in 6.130136116s

• [SLOW TEST:6.353 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:16:52.801: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Apr 25 17:16:52.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:53.519: INFO: stderr: ""
Apr 25 17:16:53.519: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 25 17:16:53.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:53.626: INFO: stderr: ""
Apr 25 17:16:53.626: INFO: stdout: "update-demo-nautilus-qzzc7 update-demo-nautilus-s8pzh "
Apr 25 17:16:53.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qzzc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:53.709: INFO: stderr: ""
Apr 25 17:16:53.709: INFO: stdout: ""
Apr 25 17:16:53.709: INFO: update-demo-nautilus-qzzc7 is created but not running
Apr 25 17:16:58.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:58.802: INFO: stderr: ""
Apr 25 17:16:58.802: INFO: stdout: "update-demo-nautilus-qzzc7 update-demo-nautilus-s8pzh "
Apr 25 17:16:58.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qzzc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:58.874: INFO: stderr: ""
Apr 25 17:16:58.874: INFO: stdout: "true"
Apr 25 17:16:58.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qzzc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:58.995: INFO: stderr: ""
Apr 25 17:16:58.996: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:16:58.996: INFO: validating pod update-demo-nautilus-qzzc7
Apr 25 17:16:59.010: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:16:59.010: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:16:59.010: INFO: update-demo-nautilus-qzzc7 is verified up and running
Apr 25 17:16:59.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-s8pzh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:59.107: INFO: stderr: ""
Apr 25 17:16:59.107: INFO: stdout: "true"
Apr 25 17:16:59.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-s8pzh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:16:59.186: INFO: stderr: ""
Apr 25 17:16:59.186: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:16:59.186: INFO: validating pod update-demo-nautilus-s8pzh
Apr 25 17:16:59.202: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:16:59.202: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:16:59.202: INFO: update-demo-nautilus-s8pzh is verified up and running
STEP: scaling down the replication controller
Apr 25 17:16:59.204: INFO: scanned /root for discovery docs: <nil>
Apr 25 17:16:59.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:00.432: INFO: stderr: ""
Apr 25 17:17:00.432: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 25 17:17:00.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:00.501: INFO: stderr: ""
Apr 25 17:17:00.501: INFO: stdout: "update-demo-nautilus-qzzc7 update-demo-nautilus-s8pzh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 25 17:17:05.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:05.588: INFO: stderr: ""
Apr 25 17:17:05.588: INFO: stdout: "update-demo-nautilus-qzzc7 update-demo-nautilus-s8pzh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 25 17:17:10.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:10.665: INFO: stderr: ""
Apr 25 17:17:10.665: INFO: stdout: "update-demo-nautilus-qzzc7 "
Apr 25 17:17:10.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qzzc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:10.734: INFO: stderr: ""
Apr 25 17:17:10.734: INFO: stdout: "true"
Apr 25 17:17:10.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qzzc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:10.817: INFO: stderr: ""
Apr 25 17:17:10.817: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:17:10.817: INFO: validating pod update-demo-nautilus-qzzc7
Apr 25 17:17:10.825: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:17:10.825: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:17:10.825: INFO: update-demo-nautilus-qzzc7 is verified up and running
STEP: scaling up the replication controller
Apr 25 17:17:10.829: INFO: scanned /root for discovery docs: <nil>
Apr 25 17:17:10.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:11.929: INFO: stderr: ""
Apr 25 17:17:11.929: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 25 17:17:11.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:12.008: INFO: stderr: ""
Apr 25 17:17:12.008: INFO: stdout: "update-demo-nautilus-9tj7x update-demo-nautilus-qzzc7 "
Apr 25 17:17:12.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-9tj7x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:12.120: INFO: stderr: ""
Apr 25 17:17:12.120: INFO: stdout: ""
Apr 25 17:17:12.120: INFO: update-demo-nautilus-9tj7x is created but not running
Apr 25 17:17:17.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:17.210: INFO: stderr: ""
Apr 25 17:17:17.210: INFO: stdout: "update-demo-nautilus-9tj7x update-demo-nautilus-qzzc7 "
Apr 25 17:17:17.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-9tj7x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:17.278: INFO: stderr: ""
Apr 25 17:17:17.278: INFO: stdout: "true"
Apr 25 17:17:17.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-9tj7x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:17.351: INFO: stderr: ""
Apr 25 17:17:17.351: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:17:17.351: INFO: validating pod update-demo-nautilus-9tj7x
Apr 25 17:17:17.360: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:17:17.360: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:17:17.360: INFO: update-demo-nautilus-9tj7x is verified up and running
Apr 25 17:17:17.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qzzc7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:17.439: INFO: stderr: ""
Apr 25 17:17:17.439: INFO: stdout: "true"
Apr 25 17:17:17.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qzzc7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:17.520: INFO: stderr: ""
Apr 25 17:17:17.520: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:17:17.520: INFO: validating pod update-demo-nautilus-qzzc7
Apr 25 17:17:17.524: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:17:17.524: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:17:17.524: INFO: update-demo-nautilus-qzzc7 is verified up and running
STEP: using delete to clean up resources
Apr 25 17:17:17.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:17.620: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:17:17.620: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 25 17:17:17.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-95s9v'
Apr 25 17:17:17.719: INFO: stderr: "No resources found.\n"
Apr 25 17:17:17.719: INFO: stdout: ""
Apr 25 17:17:17.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -l name=update-demo --namespace=e2e-tests-kubectl-95s9v -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 25 17:17:17.820: INFO: stderr: ""
Apr 25 17:17:17.820: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:17:17.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-95s9v" for this suite.
Apr 25 17:17:39.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:17:39.920: INFO: namespace: e2e-tests-kubectl-95s9v, resource: bindings, ignored listing per whitelist
Apr 25 17:17:39.926: INFO: namespace e2e-tests-kubectl-95s9v deletion completed in 22.101716012s

• [SLOW TEST:47.125 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:17:39.931: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-f9655
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Apr 25 17:17:40.042: INFO: Found 0 stateful pods, waiting for 3
Apr 25 17:17:50.051: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:17:50.051: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:17:50.051: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Apr 25 17:17:50.093: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 25 17:18:00.153: INFO: Updating stateful set ss2
Apr 25 17:18:00.189: INFO: Waiting for Pod e2e-tests-statefulset-f9655/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Apr 25 17:18:10.340: INFO: Found 2 stateful pods, waiting for 3
Apr 25 17:18:20.345: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:18:20.345: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:18:20.345: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 25 17:18:20.378: INFO: Updating stateful set ss2
Apr 25 17:18:20.395: INFO: Waiting for Pod e2e-tests-statefulset-f9655/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Apr 25 17:18:30.433: INFO: Updating stateful set ss2
Apr 25 17:18:30.444: INFO: Waiting for StatefulSet e2e-tests-statefulset-f9655/ss2 to complete update
Apr 25 17:18:30.444: INFO: Waiting for Pod e2e-tests-statefulset-f9655/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 25 17:18:40.451: INFO: Deleting all statefulset in ns e2e-tests-statefulset-f9655
Apr 25 17:18:40.454: INFO: Scaling statefulset ss2 to 0
Apr 25 17:19:00.495: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:19:00.497: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:19:00.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-f9655" for this suite.
Apr 25 17:19:06.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:19:06.641: INFO: namespace: e2e-tests-statefulset-f9655, resource: bindings, ignored listing per whitelist
Apr 25 17:19:06.669: INFO: namespace e2e-tests-statefulset-f9655 deletion completed in 6.139289332s

• [SLOW TEST:86.738 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:19:06.669: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Apr 25 17:19:06.750: INFO: Waiting up to 5m0s for pod "client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-containers-mmqpn" to be "success or failure"
Apr 25 17:19:06.760: INFO: Pod "client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.870653ms
Apr 25 17:19:08.765: INFO: Pod "client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014650721s
Apr 25 17:19:10.769: INFO: Pod "client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018576058s
STEP: Saw pod success
Apr 25 17:19:10.769: INFO: Pod "client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:19:10.771: INFO: Trying to get logs from node test113-q3hn pod client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:19:10.793: INFO: Waiting for pod client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:19:10.796: INFO: Pod client-containers-3b267d35-677e-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:19:10.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mmqpn" for this suite.
Apr 25 17:19:16.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:19:16.905: INFO: namespace: e2e-tests-containers-mmqpn, resource: bindings, ignored listing per whitelist
Apr 25 17:19:16.916: INFO: namespace e2e-tests-containers-mmqpn deletion completed in 6.116285835s

• [SLOW TEST:10.247 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:19:16.919: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 25 17:19:17.129: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 25 17:19:22.133: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:19:22.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-vdlsg" for this suite.
Apr 25 17:19:28.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:19:28.308: INFO: namespace: e2e-tests-replication-controller-vdlsg, resource: bindings, ignored listing per whitelist
Apr 25 17:19:28.352: INFO: namespace e2e-tests-replication-controller-vdlsg deletion completed in 6.162767518s

• [SLOW TEST:11.433 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:19:28.353: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mnwwd
Apr 25 17:19:32.442: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mnwwd
STEP: checking the pod's current state and verifying that restartCount is present
Apr 25 17:19:32.444: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:23:33.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mnwwd" for this suite.
Apr 25 17:23:39.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:23:39.108: INFO: namespace: e2e-tests-container-probe-mnwwd, resource: bindings, ignored listing per whitelist
Apr 25 17:23:39.247: INFO: namespace e2e-tests-container-probe-mnwwd deletion completed in 6.20830316s

• [SLOW TEST:250.895 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:23:39.249: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ddaab125-677e-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:23:39.427: INFO: Waiting up to 5m0s for pod "pod-secrets-ddacaac1-677e-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-86jqg" to be "success or failure"
Apr 25 17:23:39.444: INFO: Pod "pod-secrets-ddacaac1-677e-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 17.038198ms
Apr 25 17:23:41.448: INFO: Pod "pod-secrets-ddacaac1-677e-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020632838s
STEP: Saw pod success
Apr 25 17:23:41.448: INFO: Pod "pod-secrets-ddacaac1-677e-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:23:41.451: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-ddacaac1-677e-11e9-9f66-ae72f7f5c328 container secret-env-test: <nil>
STEP: delete the pod
Apr 25 17:23:41.479: INFO: Waiting for pod pod-secrets-ddacaac1-677e-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:23:41.485: INFO: Pod pod-secrets-ddacaac1-677e-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:23:41.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-86jqg" for this suite.
Apr 25 17:23:47.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:23:47.594: INFO: namespace: e2e-tests-secrets-86jqg, resource: bindings, ignored listing per whitelist
Apr 25 17:23:47.608: INFO: namespace e2e-tests-secrets-86jqg deletion completed in 6.117520959s

• [SLOW TEST:8.360 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:23:47.609: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-m99gt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m99gt to expose endpoints map[]
Apr 25 17:23:47.756: INFO: Get endpoints failed (8.38218ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Apr 25 17:23:48.760: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m99gt exposes endpoints map[] (1.011993581s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-m99gt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m99gt to expose endpoints map[pod1:[100]]
Apr 25 17:23:50.789: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m99gt exposes endpoints map[pod1:[100]] (2.021673868s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-m99gt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m99gt to expose endpoints map[pod2:[101] pod1:[100]]
Apr 25 17:23:52.980: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m99gt exposes endpoints map[pod1:[100] pod2:[101]] (2.18523836s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-m99gt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m99gt to expose endpoints map[pod2:[101]]
Apr 25 17:23:53.002: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m99gt exposes endpoints map[pod2:[101]] (14.92638ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-m99gt
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-m99gt to expose endpoints map[]
Apr 25 17:23:53.022: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-m99gt exposes endpoints map[] (10.62745ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:23:53.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-m99gt" for this suite.
Apr 25 17:24:15.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:24:15.165: INFO: namespace: e2e-tests-services-m99gt, resource: bindings, ignored listing per whitelist
Apr 25 17:24:15.218: INFO: namespace e2e-tests-services-m99gt deletion completed in 22.146120338s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.609 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:24:15.218: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 25 17:24:15.311: INFO: Waiting up to 5m0s for pod "pod-f3112b22-677e-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-kqzfn" to be "success or failure"
Apr 25 17:24:15.319: INFO: Pod "pod-f3112b22-677e-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.334313ms
Apr 25 17:24:17.322: INFO: Pod "pod-f3112b22-677e-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010988038s
STEP: Saw pod success
Apr 25 17:24:17.323: INFO: Pod "pod-f3112b22-677e-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:24:17.325: INFO: Trying to get logs from node test113-q3hn pod pod-f3112b22-677e-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:24:17.346: INFO: Waiting for pod pod-f3112b22-677e-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:24:17.352: INFO: Pod pod-f3112b22-677e-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:24:17.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kqzfn" for this suite.
Apr 25 17:24:23.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:24:23.410: INFO: namespace: e2e-tests-emptydir-kqzfn, resource: bindings, ignored listing per whitelist
Apr 25 17:24:23.466: INFO: namespace e2e-tests-emptydir-kqzfn deletion completed in 6.109210279s

• [SLOW TEST:8.248 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:24:23.467: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Apr 25 17:24:23.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 cluster-info'
Apr 25 17:24:23.837: INFO: stderr: ""
Apr 25 17:24:23.838: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:24:23.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p24hv" for this suite.
Apr 25 17:24:29.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:24:29.936: INFO: namespace: e2e-tests-kubectl-p24hv, resource: bindings, ignored listing per whitelist
Apr 25 17:24:29.945: INFO: namespace e2e-tests-kubectl-p24hv deletion completed in 6.102995565s

• [SLOW TEST:6.479 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:24:29.949: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:24:34.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-h8tqk" for this suite.
Apr 25 17:24:40.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:24:40.286: INFO: namespace: e2e-tests-kubelet-test-h8tqk, resource: bindings, ignored listing per whitelist
Apr 25 17:24:40.323: INFO: namespace e2e-tests-kubelet-test-h8tqk deletion completed in 6.131132062s

• [SLOW TEST:10.374 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:24:40.323: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 25 17:24:40.393: INFO: Waiting up to 5m0s for pod "pod-020408d8-677f-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-htwxn" to be "success or failure"
Apr 25 17:24:40.582: INFO: Pod "pod-020408d8-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 188.534854ms
Apr 25 17:24:42.586: INFO: Pod "pod-020408d8-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.192607234s
Apr 25 17:24:44.596: INFO: Pod "pod-020408d8-677f-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.202908278s
STEP: Saw pod success
Apr 25 17:24:44.596: INFO: Pod "pod-020408d8-677f-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:24:44.605: INFO: Trying to get logs from node test113-q3hn pod pod-020408d8-677f-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:24:44.662: INFO: Waiting for pod pod-020408d8-677f-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:24:44.668: INFO: Pod pod-020408d8-677f-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:24:44.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-htwxn" for this suite.
Apr 25 17:24:50.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:24:50.709: INFO: namespace: e2e-tests-emptydir-htwxn, resource: bindings, ignored listing per whitelist
Apr 25 17:24:50.820: INFO: namespace e2e-tests-emptydir-htwxn deletion completed in 6.146684145s

• [SLOW TEST:10.496 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:24:50.820: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Apr 25 17:24:52.996: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:25:17.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-8xkp5" for this suite.
Apr 25 17:25:23.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:25:23.187: INFO: namespace: e2e-tests-namespaces-8xkp5, resource: bindings, ignored listing per whitelist
Apr 25 17:25:23.229: INFO: namespace e2e-tests-namespaces-8xkp5 deletion completed in 6.134524097s
STEP: Destroying namespace "e2e-tests-nsdeletetest-k85gx" for this suite.
Apr 25 17:25:23.231: INFO: Namespace e2e-tests-nsdeletetest-k85gx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-xsngl" for this suite.
Apr 25 17:25:29.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:25:29.280: INFO: namespace: e2e-tests-nsdeletetest-xsngl, resource: bindings, ignored listing per whitelist
Apr 25 17:25:29.438: INFO: namespace e2e-tests-nsdeletetest-xsngl deletion completed in 6.207724169s

• [SLOW TEST:38.619 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:25:29.440: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-1f4db2ad-677f-11e9-9f66-ae72f7f5c328
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1f4db2ad-677f-11e9-9f66-ae72f7f5c328
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:25:33.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4tzbz" for this suite.
Apr 25 17:25:55.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:25:55.670: INFO: namespace: e2e-tests-configmap-4tzbz, resource: bindings, ignored listing per whitelist
Apr 25 17:25:55.687: INFO: namespace e2e-tests-configmap-4tzbz deletion completed in 22.095087057s

• [SLOW TEST:26.247 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:25:55.689: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:25:55.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qplxp" for this suite.
Apr 25 17:26:01.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:26:01.911: INFO: namespace: e2e-tests-services-qplxp, resource: bindings, ignored listing per whitelist
Apr 25 17:26:01.931: INFO: namespace e2e-tests-services-qplxp deletion completed in 6.109995981s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.242 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:26:01.932: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:26:02.067: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32b2253c-677f-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-ht5qc" to be "success or failure"
Apr 25 17:26:02.080: INFO: Pod "downwardapi-volume-32b2253c-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 13.081814ms
Apr 25 17:26:04.085: INFO: Pod "downwardapi-volume-32b2253c-677f-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018626413s
STEP: Saw pod success
Apr 25 17:26:04.085: INFO: Pod "downwardapi-volume-32b2253c-677f-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:26:04.090: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-32b2253c-677f-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:26:04.171: INFO: Waiting for pod downwardapi-volume-32b2253c-677f-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:26:04.186: INFO: Pod downwardapi-volume-32b2253c-677f-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:26:04.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ht5qc" for this suite.
Apr 25 17:26:10.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:26:10.273: INFO: namespace: e2e-tests-projected-ht5qc, resource: bindings, ignored listing per whitelist
Apr 25 17:26:10.327: INFO: namespace e2e-tests-projected-ht5qc deletion completed in 6.126086823s

• [SLOW TEST:8.394 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:26:10.327: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-t42ft
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-t42ft
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-t42ft
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-t42ft
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-t42ft
Apr 25 17:26:12.498: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-t42ft, name: ss-0, uid: 37c4c008-677f-11e9-a8f1-82d29082e60b, status phase: Pending. Waiting for statefulset controller to delete.
Apr 25 17:26:16.015: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-t42ft, name: ss-0, uid: 37c4c008-677f-11e9-a8f1-82d29082e60b, status phase: Failed. Waiting for statefulset controller to delete.
Apr 25 17:26:16.027: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-t42ft, name: ss-0, uid: 37c4c008-677f-11e9-a8f1-82d29082e60b, status phase: Failed. Waiting for statefulset controller to delete.
Apr 25 17:26:16.035: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-t42ft
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-t42ft
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-t42ft and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 25 17:26:30.173: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t42ft
Apr 25 17:26:30.176: INFO: Scaling statefulset ss to 0
Apr 25 17:26:40.191: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:26:40.194: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:26:40.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t42ft" for this suite.
Apr 25 17:26:46.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:26:46.253: INFO: namespace: e2e-tests-statefulset-t42ft, resource: bindings, ignored listing per whitelist
Apr 25 17:26:46.316: INFO: namespace e2e-tests-statefulset-t42ft deletion completed in 6.100772066s

• [SLOW TEST:35.989 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:26:46.316: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:26:46.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-mwrnp" to be "success or failure"
Apr 25 17:26:46.400: INFO: Pod "downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.416682ms
Apr 25 17:26:48.404: INFO: Pod "downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013797771s
Apr 25 17:26:50.408: INFO: Pod "downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017757491s
STEP: Saw pod success
Apr 25 17:26:50.408: INFO: Pod "downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:26:50.411: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:26:50.436: INFO: Waiting for pod downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:26:50.441: INFO: Pod downwardapi-volume-4d1e0fba-677f-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:26:50.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mwrnp" for this suite.
Apr 25 17:26:56.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:26:56.540: INFO: namespace: e2e-tests-downward-api-mwrnp, resource: bindings, ignored listing per whitelist
Apr 25 17:26:56.553: INFO: namespace e2e-tests-downward-api-mwrnp deletion completed in 6.108052691s

• [SLOW TEST:10.237 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:26:56.553: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-dmv8
STEP: Creating a pod to test atomic-volume-subpath
Apr 25 17:26:56.701: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dmv8" in namespace "e2e-tests-subpath-g8qd5" to be "success or failure"
Apr 25 17:26:56.710: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.361974ms
Apr 25 17:26:58.713: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011835739s
Apr 25 17:27:00.718: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 4.015961168s
Apr 25 17:27:02.722: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 6.020037936s
Apr 25 17:27:04.725: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 8.023887182s
Apr 25 17:27:06.730: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 10.028117825s
Apr 25 17:27:08.734: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 12.032131242s
Apr 25 17:27:10.737: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 14.035872612s
Apr 25 17:27:12.741: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 16.039885081s
Apr 25 17:27:14.746: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 18.04404867s
Apr 25 17:27:16.749: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 20.047555231s
Apr 25 17:27:18.754: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Running", Reason="", readiness=false. Elapsed: 22.051949944s
Apr 25 17:27:20.758: INFO: Pod "pod-subpath-test-projected-dmv8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.056100252s
STEP: Saw pod success
Apr 25 17:27:20.758: INFO: Pod "pod-subpath-test-projected-dmv8" satisfied condition "success or failure"
Apr 25 17:27:20.760: INFO: Trying to get logs from node test113-q3k9 pod pod-subpath-test-projected-dmv8 container test-container-subpath-projected-dmv8: <nil>
STEP: delete the pod
Apr 25 17:27:20.783: INFO: Waiting for pod pod-subpath-test-projected-dmv8 to disappear
Apr 25 17:27:20.788: INFO: Pod pod-subpath-test-projected-dmv8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-dmv8
Apr 25 17:27:20.788: INFO: Deleting pod "pod-subpath-test-projected-dmv8" in namespace "e2e-tests-subpath-g8qd5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:27:20.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-g8qd5" for this suite.
Apr 25 17:27:26.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:27:26.855: INFO: namespace: e2e-tests-subpath-g8qd5, resource: bindings, ignored listing per whitelist
Apr 25 17:27:26.895: INFO: namespace e2e-tests-subpath-g8qd5 deletion completed in 6.095872654s

• [SLOW TEST:30.342 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:27:26.895: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:27:27.019: INFO: (0) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.145532ms)
Apr 25 17:27:27.024: INFO: (1) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.997152ms)
Apr 25 17:27:27.028: INFO: (2) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.713913ms)
Apr 25 17:27:27.037: INFO: (3) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.05461ms)
Apr 25 17:27:27.040: INFO: (4) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.74837ms)
Apr 25 17:27:27.044: INFO: (5) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.485636ms)
Apr 25 17:27:27.047: INFO: (6) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.525825ms)
Apr 25 17:27:27.052: INFO: (7) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.08712ms)
Apr 25 17:27:27.055: INFO: (8) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.544875ms)
Apr 25 17:27:27.059: INFO: (9) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.43792ms)
Apr 25 17:27:27.062: INFO: (10) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.338681ms)
Apr 25 17:27:27.066: INFO: (11) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.39254ms)
Apr 25 17:27:27.069: INFO: (12) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.536691ms)
Apr 25 17:27:27.073: INFO: (13) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.593463ms)
Apr 25 17:27:27.076: INFO: (14) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.089334ms)
Apr 25 17:27:27.079: INFO: (15) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.457012ms)
Apr 25 17:27:27.083: INFO: (16) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.385561ms)
Apr 25 17:27:27.086: INFO: (17) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.472212ms)
Apr 25 17:27:27.091: INFO: (18) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.537116ms)
Apr 25 17:27:27.094: INFO: (19) /api/v1/nodes/test113-q3hn:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.397737ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:27:27.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-x5w4s" for this suite.
Apr 25 17:27:33.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:27:33.189: INFO: namespace: e2e-tests-proxy-x5w4s, resource: bindings, ignored listing per whitelist
Apr 25 17:27:33.199: INFO: namespace e2e-tests-proxy-x5w4s deletion completed in 6.101986642s

• [SLOW TEST:6.304 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:27:33.200: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-69185359-677f-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:27:33.334: INFO: Waiting up to 5m0s for pod "pod-configmaps-69190c07-677f-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-lt5wm" to be "success or failure"
Apr 25 17:27:33.347: INFO: Pod "pod-configmaps-69190c07-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 13.346868ms
Apr 25 17:27:35.352: INFO: Pod "pod-configmaps-69190c07-677f-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018242999s
STEP: Saw pod success
Apr 25 17:27:35.352: INFO: Pod "pod-configmaps-69190c07-677f-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:27:35.356: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-69190c07-677f-11e9-9f66-ae72f7f5c328 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 17:27:35.379: INFO: Waiting for pod pod-configmaps-69190c07-677f-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:27:35.382: INFO: Pod pod-configmaps-69190c07-677f-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:27:35.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lt5wm" for this suite.
Apr 25 17:27:41.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:27:41.463: INFO: namespace: e2e-tests-configmap-lt5wm, resource: bindings, ignored listing per whitelist
Apr 25 17:27:41.518: INFO: namespace e2e-tests-configmap-lt5wm deletion completed in 6.133063724s

• [SLOW TEST:8.318 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:27:41.518: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:27:41.682: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Apr 25 17:27:41.687: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kt5z4/daemonsets","resourceVersion":"28750"},"items":null}

Apr 25 17:27:41.689: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kt5z4/pods","resourceVersion":"28750"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:27:41.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kt5z4" for this suite.
Apr 25 17:27:47.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:27:47.793: INFO: namespace: e2e-tests-daemonsets-kt5z4, resource: bindings, ignored listing per whitelist
Apr 25 17:27:47.811: INFO: namespace e2e-tests-daemonsets-kt5z4 deletion completed in 6.109224966s

S [SKIPPING] [6.293 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Apr 25 17:27:41.682: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:27:47.814: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-wjrv
STEP: Creating a pod to test atomic-volume-subpath
Apr 25 17:27:47.905: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wjrv" in namespace "e2e-tests-subpath-6rrn2" to be "success or failure"
Apr 25 17:27:47.923: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Pending", Reason="", readiness=false. Elapsed: 18.334193ms
Apr 25 17:27:49.926: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021592858s
Apr 25 17:27:51.934: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 4.029178079s
Apr 25 17:27:53.938: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 6.0327046s
Apr 25 17:27:55.941: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 8.03632593s
Apr 25 17:27:57.945: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 10.039728185s
Apr 25 17:27:59.948: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 12.04312028s
Apr 25 17:28:01.958: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 14.052854915s
Apr 25 17:28:03.961: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 16.056512074s
Apr 25 17:28:05.965: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 18.060071721s
Apr 25 17:28:07.969: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 20.063812255s
Apr 25 17:28:09.972: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Running", Reason="", readiness=false. Elapsed: 22.067304316s
Apr 25 17:28:11.976: INFO: Pod "pod-subpath-test-configmap-wjrv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.071109669s
STEP: Saw pod success
Apr 25 17:28:11.976: INFO: Pod "pod-subpath-test-configmap-wjrv" satisfied condition "success or failure"
Apr 25 17:28:11.979: INFO: Trying to get logs from node test113-q3kz pod pod-subpath-test-configmap-wjrv container test-container-subpath-configmap-wjrv: <nil>
STEP: delete the pod
Apr 25 17:28:12.027: INFO: Waiting for pod pod-subpath-test-configmap-wjrv to disappear
Apr 25 17:28:12.038: INFO: Pod pod-subpath-test-configmap-wjrv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wjrv
Apr 25 17:28:12.038: INFO: Deleting pod "pod-subpath-test-configmap-wjrv" in namespace "e2e-tests-subpath-6rrn2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:28:12.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6rrn2" for this suite.
Apr 25 17:28:18.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:28:18.261: INFO: namespace: e2e-tests-subpath-6rrn2, resource: bindings, ignored listing per whitelist
Apr 25 17:28:18.332: INFO: namespace e2e-tests-subpath-6rrn2 deletion completed in 6.273351202s

• [SLOW TEST:30.518 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:28:18.332: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:28:18.431: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-9mlfk" to be "success or failure"
Apr 25 17:28:18.441: INFO: Pod "downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.82245ms
Apr 25 17:28:20.444: INFO: Pod "downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012809675s
Apr 25 17:28:22.448: INFO: Pod "downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016506318s
STEP: Saw pod success
Apr 25 17:28:22.448: INFO: Pod "downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:28:22.450: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:28:22.476: INFO: Waiting for pod downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:28:22.479: INFO: Pod downwardapi-volume-83f8da98-677f-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:28:22.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9mlfk" for this suite.
Apr 25 17:28:28.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:28:28.510: INFO: namespace: e2e-tests-projected-9mlfk, resource: bindings, ignored listing per whitelist
Apr 25 17:28:28.579: INFO: namespace e2e-tests-projected-9mlfk deletion completed in 6.09637464s

• [SLOW TEST:10.247 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:28:28.579: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jdrsd
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jdrsd
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jdrsd
Apr 25 17:28:28.721: INFO: Found 0 stateful pods, waiting for 1
Apr 25 17:28:38.725: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 25 17:28:38.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:28:38.980: INFO: stderr: ""
Apr 25 17:28:38.980: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:28:38.980: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:28:38.986: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 25 17:28:48.994: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:28:48.994: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:28:49.020: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999685s
Apr 25 17:28:50.024: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993954375s
Apr 25 17:28:51.035: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989607123s
Apr 25 17:28:52.039: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.979083764s
Apr 25 17:28:53.043: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.975175874s
Apr 25 17:28:54.051: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.971094668s
Apr 25 17:28:55.056: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.962668s
Apr 25 17:28:56.072: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.958080111s
Apr 25 17:28:57.078: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.941937783s
Apr 25 17:28:58.083: INFO: Verifying statefulset ss doesn't scale past 1 for another 935.978585ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jdrsd
Apr 25 17:28:59.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:28:59.362: INFO: stderr: ""
Apr 25 17:28:59.362: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 17:28:59.362: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 25 17:28:59.366: INFO: Found 1 stateful pods, waiting for 3
Apr 25 17:29:09.370: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:29:09.370: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 25 17:29:09.370: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 25 17:29:09.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:29:09.628: INFO: stderr: ""
Apr 25 17:29:09.628: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:29:09.628: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:29:09.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:29:09.912: INFO: stderr: ""
Apr 25 17:29:09.912: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:29:09.912: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:29:09.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Apr 25 17:29:10.202: INFO: stderr: ""
Apr 25 17:29:10.202: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Apr 25 17:29:10.202: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Apr 25 17:29:10.202: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:29:10.205: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 25 17:29:20.212: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:29:20.212: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:29:20.212: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 25 17:29:20.224: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999503s
Apr 25 17:29:21.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993929974s
Apr 25 17:29:22.233: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989727395s
Apr 25 17:29:23.237: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98549368s
Apr 25 17:29:24.243: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980876643s
Apr 25 17:29:25.248: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974830319s
Apr 25 17:29:26.252: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97016606s
Apr 25 17:29:27.257: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965820146s
Apr 25 17:29:28.263: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96115926s
Apr 25 17:29:29.269: INFO: Verifying statefulset ss doesn't scale past 3 for another 955.598975ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jdrsd
Apr 25 17:29:30.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:29:30.532: INFO: stderr: ""
Apr 25 17:29:30.532: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 17:29:30.532: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 25 17:29:30.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:29:30.831: INFO: stderr: ""
Apr 25 17:29:30.831: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 17:29:30.831: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 25 17:29:30.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 exec --namespace=e2e-tests-statefulset-jdrsd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Apr 25 17:29:31.089: INFO: stderr: ""
Apr 25 17:29:31.089: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Apr 25 17:29:31.089: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Apr 25 17:29:31.089: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Apr 25 17:29:51.107: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jdrsd
Apr 25 17:29:51.110: INFO: Scaling statefulset ss to 0
Apr 25 17:29:51.118: INFO: Waiting for statefulset status.replicas updated to 0
Apr 25 17:29:51.124: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:29:51.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jdrsd" for this suite.
Apr 25 17:29:57.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:29:57.202: INFO: namespace: e2e-tests-statefulset-jdrsd, resource: bindings, ignored listing per whitelist
Apr 25 17:29:57.261: INFO: namespace e2e-tests-statefulset-jdrsd deletion completed in 6.110441071s

• [SLOW TEST:88.682 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:29:57.262: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 25 17:30:05.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 25 17:30:05.465: INFO: Pod pod-with-poststart-http-hook still exists
Apr 25 17:30:07.466: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 25 17:30:07.469: INFO: Pod pod-with-poststart-http-hook still exists
Apr 25 17:30:09.466: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 25 17:30:09.468: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:30:09.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jx6pf" for this suite.
Apr 25 17:30:31.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:30:31.605: INFO: namespace: e2e-tests-container-lifecycle-hook-jx6pf, resource: bindings, ignored listing per whitelist
Apr 25 17:30:31.666: INFO: namespace e2e-tests-container-lifecycle-hook-jx6pf deletion completed in 22.194301237s

• [SLOW TEST:34.404 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:30:31.666: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d3747a5e-677f-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:30:31.776: INFO: Waiting up to 5m0s for pod "pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-qb54c" to be "success or failure"
Apr 25 17:30:31.783: INFO: Pod "pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.201633ms
Apr 25 17:30:33.786: INFO: Pod "pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010936435s
Apr 25 17:30:35.790: INFO: Pod "pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014689944s
STEP: Saw pod success
Apr 25 17:30:35.790: INFO: Pod "pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:30:35.793: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:30:35.812: INFO: Waiting for pod pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:30:35.815: INFO: Pod pod-secrets-d374ffe8-677f-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:30:35.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qb54c" for this suite.
Apr 25 17:30:41.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:30:41.857: INFO: namespace: e2e-tests-secrets-qb54c, resource: bindings, ignored listing per whitelist
Apr 25 17:30:41.921: INFO: namespace e2e-tests-secrets-qb54c deletion completed in 6.102043169s

• [SLOW TEST:10.255 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:30:41.921: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-6p9r
STEP: Creating a pod to test atomic-volume-subpath
Apr 25 17:30:42.060: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-6p9r" in namespace "e2e-tests-subpath-9zdd6" to be "success or failure"
Apr 25 17:30:42.067: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Pending", Reason="", readiness=false. Elapsed: 6.932507ms
Apr 25 17:30:44.078: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017695774s
Apr 25 17:30:46.082: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 4.021754998s
Apr 25 17:30:48.086: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 6.026215108s
Apr 25 17:30:50.091: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 8.030511837s
Apr 25 17:30:52.095: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 10.034714106s
Apr 25 17:30:54.101: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 12.040502655s
Apr 25 17:30:56.108: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 14.048136997s
Apr 25 17:30:58.117: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 16.056679987s
Apr 25 17:31:00.121: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 18.060575417s
Apr 25 17:31:02.130: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 20.069673197s
Apr 25 17:31:04.138: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Running", Reason="", readiness=false. Elapsed: 22.078324815s
Apr 25 17:31:06.143: INFO: Pod "pod-subpath-test-downwardapi-6p9r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.083210465s
STEP: Saw pod success
Apr 25 17:31:06.143: INFO: Pod "pod-subpath-test-downwardapi-6p9r" satisfied condition "success or failure"
Apr 25 17:31:06.147: INFO: Trying to get logs from node test113-q3hn pod pod-subpath-test-downwardapi-6p9r container test-container-subpath-downwardapi-6p9r: <nil>
STEP: delete the pod
Apr 25 17:31:06.183: INFO: Waiting for pod pod-subpath-test-downwardapi-6p9r to disappear
Apr 25 17:31:06.188: INFO: Pod pod-subpath-test-downwardapi-6p9r no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-6p9r
Apr 25 17:31:06.188: INFO: Deleting pod "pod-subpath-test-downwardapi-6p9r" in namespace "e2e-tests-subpath-9zdd6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:31:06.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9zdd6" for this suite.
Apr 25 17:31:12.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:31:12.253: INFO: namespace: e2e-tests-subpath-9zdd6, resource: bindings, ignored listing per whitelist
Apr 25 17:31:12.309: INFO: namespace e2e-tests-subpath-9zdd6 deletion completed in 6.114601987s

• [SLOW TEST:30.388 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:31:12.309: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 25 17:31:12.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7cphh'
Apr 25 17:31:12.948: INFO: stderr: ""
Apr 25 17:31:12.948: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Apr 25 17:31:12.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7cphh'
Apr 25 17:31:16.026: INFO: stderr: ""
Apr 25 17:31:16.026: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:31:16.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7cphh" for this suite.
Apr 25 17:31:22.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:31:22.077: INFO: namespace: e2e-tests-kubectl-7cphh, resource: bindings, ignored listing per whitelist
Apr 25 17:31:22.166: INFO: namespace e2e-tests-kubectl-7cphh deletion completed in 6.130683828s

• [SLOW TEST:9.857 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:31:22.166: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Apr 25 17:31:22.290: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-806739710 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:31:22.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t4g4c" for this suite.
Apr 25 17:31:28.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:31:28.495: INFO: namespace: e2e-tests-kubectl-t4g4c, resource: bindings, ignored listing per whitelist
Apr 25 17:31:28.506: INFO: namespace e2e-tests-kubectl-t4g4c deletion completed in 6.130498368s

• [SLOW TEST:6.340 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:31:28.507: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-f55c11ef-677f-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:31:28.660: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-g27lm" to be "success or failure"
Apr 25 17:31:28.669: INFO: Pod "pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.418211ms
Apr 25 17:31:30.673: INFO: Pod "pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013114704s
Apr 25 17:31:32.677: INFO: Pod "pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017125465s
STEP: Saw pod success
Apr 25 17:31:32.677: INFO: Pod "pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:31:32.679: INFO: Trying to get logs from node test113-q3hn pod pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:31:32.709: INFO: Waiting for pod pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:31:32.712: INFO: Pod pod-projected-secrets-f55ca6a9-677f-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:31:32.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g27lm" for this suite.
Apr 25 17:31:38.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:31:38.782: INFO: namespace: e2e-tests-projected-g27lm, resource: bindings, ignored listing per whitelist
Apr 25 17:31:38.833: INFO: namespace e2e-tests-projected-g27lm deletion completed in 6.116780506s

• [SLOW TEST:10.326 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:31:38.833: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gb2p8
Apr 25 17:31:43.022: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gb2p8
STEP: checking the pod's current state and verifying that restartCount is present
Apr 25 17:31:43.032: INFO: Initial restart count of pod liveness-http is 0
Apr 25 17:31:55.062: INFO: Restart count of pod e2e-tests-container-probe-gb2p8/liveness-http is now 1 (12.029673863s elapsed)
Apr 25 17:32:17.118: INFO: Restart count of pod e2e-tests-container-probe-gb2p8/liveness-http is now 2 (34.08589717s elapsed)
Apr 25 17:32:35.161: INFO: Restart count of pod e2e-tests-container-probe-gb2p8/liveness-http is now 3 (52.129196793s elapsed)
Apr 25 17:32:55.205: INFO: Restart count of pod e2e-tests-container-probe-gb2p8/liveness-http is now 4 (1m12.172922646s elapsed)
Apr 25 17:34:07.363: INFO: Restart count of pod e2e-tests-container-probe-gb2p8/liveness-http is now 5 (2m24.331502406s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:34:07.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gb2p8" for this suite.
Apr 25 17:34:13.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:34:13.436: INFO: namespace: e2e-tests-container-probe-gb2p8, resource: bindings, ignored listing per whitelist
Apr 25 17:34:13.498: INFO: namespace e2e-tests-container-probe-gb2p8 deletion completed in 6.111868892s

• [SLOW TEST:154.665 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:34:13.498: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 25 17:34:13.618: INFO: Waiting up to 5m0s for pod "pod-57afa2da-6780-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-f5rg2" to be "success or failure"
Apr 25 17:34:13.624: INFO: Pod "pod-57afa2da-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.122529ms
Apr 25 17:34:15.628: INFO: Pod "pod-57afa2da-6780-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009551005s
STEP: Saw pod success
Apr 25 17:34:15.628: INFO: Pod "pod-57afa2da-6780-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:34:15.630: INFO: Trying to get logs from node test113-q3hn pod pod-57afa2da-6780-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:34:15.655: INFO: Waiting for pod pod-57afa2da-6780-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:34:15.658: INFO: Pod pod-57afa2da-6780-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:34:15.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f5rg2" for this suite.
Apr 25 17:34:21.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:34:21.729: INFO: namespace: e2e-tests-emptydir-f5rg2, resource: bindings, ignored listing per whitelist
Apr 25 17:34:21.772: INFO: namespace e2e-tests-emptydir-f5rg2 deletion completed in 6.107374699s

• [SLOW TEST:8.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:34:21.773: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 25 17:34:24.394: INFO: Successfully updated pod "labelsupdate5c96efd3-6780-11e9-9f66-ae72f7f5c328"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:34:26.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fx72n" for this suite.
Apr 25 17:34:48.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:34:48.486: INFO: namespace: e2e-tests-projected-fx72n, resource: bindings, ignored listing per whitelist
Apr 25 17:34:48.544: INFO: namespace e2e-tests-projected-fx72n deletion completed in 22.099381615s

• [SLOW TEST:26.771 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:34:48.544: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6c9f5d9b-6780-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:34:48.749: INFO: Waiting up to 5m0s for pod "pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-krxtk" to be "success or failure"
Apr 25 17:34:48.759: INFO: Pod "pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.919617ms
Apr 25 17:34:50.870: INFO: Pod "pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121149666s
Apr 25 17:34:52.874: INFO: Pod "pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.124517712s
STEP: Saw pod success
Apr 25 17:34:52.874: INFO: Pod "pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:34:52.876: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:34:52.897: INFO: Waiting for pod pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:34:52.903: INFO: Pod pod-secrets-6c9fcd75-6780-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:34:52.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-krxtk" for this suite.
Apr 25 17:34:58.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:34:58.947: INFO: namespace: e2e-tests-secrets-krxtk, resource: bindings, ignored listing per whitelist
Apr 25 17:34:59.110: INFO: namespace e2e-tests-secrets-krxtk deletion completed in 6.203109929s

• [SLOW TEST:10.566 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:34:59.115: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-r2p4r
Apr 25 17:35:01.370: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-r2p4r
STEP: checking the pod's current state and verifying that restartCount is present
Apr 25 17:35:01.373: INFO: Initial restart count of pod liveness-exec is 0
Apr 25 17:35:55.493: INFO: Restart count of pod e2e-tests-container-probe-r2p4r/liveness-exec is now 1 (54.120736177s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:35:55.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-r2p4r" for this suite.
Apr 25 17:36:01.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:36:01.601: INFO: namespace: e2e-tests-container-probe-r2p4r, resource: bindings, ignored listing per whitelist
Apr 25 17:36:01.614: INFO: namespace e2e-tests-container-probe-r2p4r deletion completed in 6.106252677s

• [SLOW TEST:62.499 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:36:01.614: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Apr 25 17:36:01.758: INFO: Waiting up to 5m0s for pod "client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-containers-6wdbn" to be "success or failure"
Apr 25 17:36:01.770: INFO: Pod "client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 11.548504ms
Apr 25 17:36:03.774: INFO: Pod "client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015267506s
Apr 25 17:36:05.777: INFO: Pod "client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019084696s
STEP: Saw pod success
Apr 25 17:36:05.777: INFO: Pod "client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:36:05.779: INFO: Trying to get logs from node test113-q3hn pod client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:36:05.802: INFO: Waiting for pod client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:36:05.806: INFO: Pod client-containers-98245efb-6780-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:36:05.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6wdbn" for this suite.
Apr 25 17:36:11.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:36:11.840: INFO: namespace: e2e-tests-containers-6wdbn, resource: bindings, ignored listing per whitelist
Apr 25 17:36:11.923: INFO: namespace e2e-tests-containers-6wdbn deletion completed in 6.113659622s

• [SLOW TEST:10.308 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:36:11.923: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9e48b34d-6780-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:36:12.077: INFO: Waiting up to 5m0s for pod "pod-configmaps-9e4954be-6780-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-qlw4z" to be "success or failure"
Apr 25 17:36:12.085: INFO: Pod "pod-configmaps-9e4954be-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.584505ms
Apr 25 17:36:14.100: INFO: Pod "pod-configmaps-9e4954be-6780-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023176634s
STEP: Saw pod success
Apr 25 17:36:14.100: INFO: Pod "pod-configmaps-9e4954be-6780-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:36:14.129: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-9e4954be-6780-11e9-9f66-ae72f7f5c328 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 17:36:14.205: INFO: Waiting for pod pod-configmaps-9e4954be-6780-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:36:14.223: INFO: Pod pod-configmaps-9e4954be-6780-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:36:14.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qlw4z" for this suite.
Apr 25 17:36:20.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:36:20.292: INFO: namespace: e2e-tests-configmap-qlw4z, resource: bindings, ignored listing per whitelist
Apr 25 17:36:20.336: INFO: namespace e2e-tests-configmap-qlw4z deletion completed in 6.106565316s

• [SLOW TEST:8.413 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:36:20.339: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 25 17:36:20.413: INFO: Waiting up to 5m0s for pod "pod-a342d961-6780-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-54llt" to be "success or failure"
Apr 25 17:36:20.421: INFO: Pod "pod-a342d961-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.264479ms
Apr 25 17:36:22.425: INFO: Pod "pod-a342d961-6780-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01230164s
STEP: Saw pod success
Apr 25 17:36:22.425: INFO: Pod "pod-a342d961-6780-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:36:22.428: INFO: Trying to get logs from node test113-q3hn pod pod-a342d961-6780-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:36:22.451: INFO: Waiting for pod pod-a342d961-6780-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:36:22.454: INFO: Pod pod-a342d961-6780-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:36:22.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-54llt" for this suite.
Apr 25 17:36:28.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:36:28.572: INFO: namespace: e2e-tests-emptydir-54llt, resource: bindings, ignored listing per whitelist
Apr 25 17:36:28.584: INFO: namespace e2e-tests-emptydir-54llt deletion completed in 6.123738257s

• [SLOW TEST:8.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:36:28.584: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-r8995 in namespace e2e-tests-proxy-8nh4q
I0425 17:36:28.761434      18 runners.go:184] Created replication controller with name: proxy-service-r8995, namespace: e2e-tests-proxy-8nh4q, replica count: 1
I0425 17:36:29.812125      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 17:36:30.812345      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 17:36:31.812555      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 17:36:32.812825      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0425 17:36:33.813097      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0425 17:36:34.813452      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0425 17:36:35.813714      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0425 17:36:36.813971      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0425 17:36:37.814258      18 runners.go:184] proxy-service-r8995 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 17:36:37.817: INFO: setup took 9.103777418s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 25 17:36:37.857: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 38.712091ms)
Apr 25 17:36:37.859: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 41.063548ms)
Apr 25 17:36:37.859: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 41.313997ms)
Apr 25 17:36:37.860: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 42.687332ms)
Apr 25 17:36:37.860: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 42.902684ms)
Apr 25 17:36:37.860: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 42.68742ms)
Apr 25 17:36:37.860: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 42.537671ms)
Apr 25 17:36:37.861: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 42.997378ms)
Apr 25 17:36:37.863: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 45.374557ms)
Apr 25 17:36:37.863: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 45.499437ms)
Apr 25 17:36:37.866: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 48.73512ms)
Apr 25 17:36:37.867: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 48.941568ms)
Apr 25 17:36:37.868: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 50.406374ms)
Apr 25 17:36:37.868: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 50.638301ms)
Apr 25 17:36:37.869: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 51.281578ms)
Apr 25 17:36:37.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 52.374305ms)
Apr 25 17:36:37.884: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 13.509287ms)
Apr 25 17:36:37.891: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 20.259963ms)
Apr 25 17:36:37.891: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 20.331599ms)
Apr 25 17:36:37.891: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 20.621369ms)
Apr 25 17:36:37.891: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 20.761626ms)
Apr 25 17:36:37.891: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 21.161966ms)
Apr 25 17:36:37.891: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 21.140122ms)
Apr 25 17:36:37.891: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 21.24475ms)
Apr 25 17:36:37.892: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 21.302626ms)
Apr 25 17:36:37.892: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 21.10116ms)
Apr 25 17:36:37.892: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 22.115817ms)
Apr 25 17:36:37.893: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 22.207841ms)
Apr 25 17:36:37.893: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 22.366872ms)
Apr 25 17:36:37.893: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 23.076432ms)
Apr 25 17:36:37.894: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 23.103061ms)
Apr 25 17:36:37.894: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 23.154361ms)
Apr 25 17:36:37.915: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 20.937128ms)
Apr 25 17:36:37.917: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 23.528865ms)
Apr 25 17:36:37.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 24.388918ms)
Apr 25 17:36:37.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 24.401974ms)
Apr 25 17:36:37.918: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 24.591506ms)
Apr 25 17:36:37.919: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 24.826857ms)
Apr 25 17:36:37.919: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 24.936518ms)
Apr 25 17:36:37.919: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 24.802819ms)
Apr 25 17:36:37.919: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 24.891675ms)
Apr 25 17:36:37.919: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 25.388981ms)
Apr 25 17:36:37.920: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 26.513131ms)
Apr 25 17:36:37.921: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 26.782008ms)
Apr 25 17:36:37.921: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 26.842098ms)
Apr 25 17:36:37.921: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 26.852249ms)
Apr 25 17:36:37.922: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 27.678363ms)
Apr 25 17:36:37.922: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 27.916876ms)
Apr 25 17:36:37.934: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 11.895752ms)
Apr 25 17:36:37.937: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 13.915409ms)
Apr 25 17:36:37.939: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 16.94039ms)
Apr 25 17:36:37.939: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 16.869356ms)
Apr 25 17:36:37.939: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 16.834544ms)
Apr 25 17:36:37.940: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 17.195736ms)
Apr 25 17:36:37.940: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 17.675671ms)
Apr 25 17:36:37.940: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 17.518878ms)
Apr 25 17:36:37.941: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 18.058249ms)
Apr 25 17:36:37.941: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 18.138292ms)
Apr 25 17:36:37.944: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 21.50612ms)
Apr 25 17:36:37.950: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 26.996826ms)
Apr 25 17:36:37.950: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 27.013675ms)
Apr 25 17:36:37.950: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 27.135032ms)
Apr 25 17:36:37.950: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 27.970953ms)
Apr 25 17:36:37.950: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 27.82386ms)
Apr 25 17:36:37.974: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 23.206607ms)
Apr 25 17:36:37.974: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 23.801655ms)
Apr 25 17:36:37.975: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 23.87453ms)
Apr 25 17:36:37.975: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 24.257491ms)
Apr 25 17:36:37.975: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 23.761417ms)
Apr 25 17:36:37.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 39.38134ms)
Apr 25 17:36:37.991: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 39.707501ms)
Apr 25 17:36:37.992: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 40.822885ms)
Apr 25 17:36:37.992: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 40.841344ms)
Apr 25 17:36:37.992: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 41.157621ms)
Apr 25 17:36:38.014: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 63.141736ms)
Apr 25 17:36:38.016: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 64.361456ms)
Apr 25 17:36:38.016: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 64.593282ms)
Apr 25 17:36:38.016: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 64.418648ms)
Apr 25 17:36:38.016: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 65.120408ms)
Apr 25 17:36:38.016: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 65.578253ms)
Apr 25 17:36:38.033: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 16.458278ms)
Apr 25 17:36:38.041: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 24.920136ms)
Apr 25 17:36:38.041: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 25.087668ms)
Apr 25 17:36:38.041: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 24.98907ms)
Apr 25 17:36:38.041: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 24.978843ms)
Apr 25 17:36:38.042: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 25.053499ms)
Apr 25 17:36:38.042: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 25.150526ms)
Apr 25 17:36:38.042: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 25.171735ms)
Apr 25 17:36:38.042: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 25.107684ms)
Apr 25 17:36:38.042: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 25.160335ms)
Apr 25 17:36:38.042: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 25.443335ms)
Apr 25 17:36:38.042: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 25.781487ms)
Apr 25 17:36:38.044: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 27.13375ms)
Apr 25 17:36:38.044: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 27.384153ms)
Apr 25 17:36:38.044: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 27.477492ms)
Apr 25 17:36:38.044: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 27.607326ms)
Apr 25 17:36:38.067: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 22.481865ms)
Apr 25 17:36:38.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 25.181815ms)
Apr 25 17:36:38.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 25.314919ms)
Apr 25 17:36:38.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 25.45129ms)
Apr 25 17:36:38.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 26.130191ms)
Apr 25 17:36:38.070: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 26.023475ms)
Apr 25 17:36:38.071: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 26.370641ms)
Apr 25 17:36:38.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 27.232249ms)
Apr 25 17:36:38.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 27.225325ms)
Apr 25 17:36:38.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 27.422986ms)
Apr 25 17:36:38.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 27.290288ms)
Apr 25 17:36:38.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 27.411675ms)
Apr 25 17:36:38.072: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 27.779415ms)
Apr 25 17:36:38.074: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 29.209279ms)
Apr 25 17:36:38.074: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 29.242892ms)
Apr 25 17:36:38.074: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 29.203887ms)
Apr 25 17:36:38.090: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 15.34629ms)
Apr 25 17:36:38.094: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 19.601996ms)
Apr 25 17:36:38.096: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 21.666699ms)
Apr 25 17:36:38.096: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 21.743778ms)
Apr 25 17:36:38.096: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 22.168175ms)
Apr 25 17:36:38.096: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 22.136711ms)
Apr 25 17:36:38.096: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 22.094343ms)
Apr 25 17:36:38.097: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 22.58216ms)
Apr 25 17:36:38.097: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 23.023705ms)
Apr 25 17:36:38.097: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 23.081432ms)
Apr 25 17:36:38.097: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 23.041683ms)
Apr 25 17:36:38.097: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 23.266625ms)
Apr 25 17:36:38.098: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 23.590003ms)
Apr 25 17:36:38.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 24.569321ms)
Apr 25 17:36:38.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 24.619023ms)
Apr 25 17:36:38.099: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 24.773641ms)
Apr 25 17:36:38.149: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 49.797374ms)
Apr 25 17:36:38.149: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 50.087486ms)
Apr 25 17:36:38.150: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 50.308688ms)
Apr 25 17:36:38.155: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 56.235843ms)
Apr 25 17:36:38.157: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 57.639994ms)
Apr 25 17:36:38.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 61.98446ms)
Apr 25 17:36:38.161: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 61.988779ms)
Apr 25 17:36:38.162: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 62.427938ms)
Apr 25 17:36:38.162: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 62.91451ms)
Apr 25 17:36:38.162: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 62.922876ms)
Apr 25 17:36:38.162: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 62.918338ms)
Apr 25 17:36:38.163: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 63.49949ms)
Apr 25 17:36:38.164: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 64.548862ms)
Apr 25 17:36:38.164: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 64.547002ms)
Apr 25 17:36:38.168: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 68.577057ms)
Apr 25 17:36:38.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 69.336962ms)
Apr 25 17:36:38.185: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 16.348712ms)
Apr 25 17:36:38.186: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 16.861418ms)
Apr 25 17:36:38.189: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 19.570835ms)
Apr 25 17:36:38.191: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 21.438796ms)
Apr 25 17:36:38.192: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 22.111134ms)
Apr 25 17:36:38.192: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 23.149076ms)
Apr 25 17:36:38.194: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 25.318023ms)
Apr 25 17:36:38.194: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 25.144766ms)
Apr 25 17:36:38.195: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 26.053231ms)
Apr 25 17:36:38.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 26.241945ms)
Apr 25 17:36:38.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 26.495139ms)
Apr 25 17:36:38.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 26.286372ms)
Apr 25 17:36:38.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 26.680549ms)
Apr 25 17:36:38.196: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 26.787073ms)
Apr 25 17:36:38.197: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 27.420285ms)
Apr 25 17:36:38.197: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 27.360709ms)
Apr 25 17:36:38.216: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 18.404066ms)
Apr 25 17:36:38.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 21.479639ms)
Apr 25 17:36:38.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 21.968351ms)
Apr 25 17:36:38.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 21.974129ms)
Apr 25 17:36:38.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 22.366271ms)
Apr 25 17:36:38.220: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 22.811467ms)
Apr 25 17:36:38.220: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 22.797951ms)
Apr 25 17:36:38.220: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 22.965176ms)
Apr 25 17:36:38.220: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 23.010094ms)
Apr 25 17:36:38.220: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 23.166814ms)
Apr 25 17:36:38.222: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 24.904137ms)
Apr 25 17:36:38.222: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 24.885786ms)
Apr 25 17:36:38.222: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 25.018073ms)
Apr 25 17:36:38.222: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 25.363639ms)
Apr 25 17:36:38.222: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 25.43143ms)
Apr 25 17:36:38.223: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 25.427263ms)
Apr 25 17:36:38.234: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 11.28239ms)
Apr 25 17:36:38.235: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 12.068028ms)
Apr 25 17:36:38.235: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 11.937033ms)
Apr 25 17:36:38.237: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 14.465442ms)
Apr 25 17:36:38.240: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 17.559272ms)
Apr 25 17:36:38.241: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 17.975794ms)
Apr 25 17:36:38.243: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 20.129616ms)
Apr 25 17:36:38.243: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 20.214581ms)
Apr 25 17:36:38.243: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 19.991842ms)
Apr 25 17:36:38.243: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 20.054422ms)
Apr 25 17:36:38.243: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 20.4302ms)
Apr 25 17:36:38.247: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 23.898593ms)
Apr 25 17:36:38.247: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 24.336991ms)
Apr 25 17:36:38.248: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 24.973893ms)
Apr 25 17:36:38.248: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 25.443204ms)
Apr 25 17:36:38.248: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 25.319969ms)
Apr 25 17:36:38.260: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 11.454293ms)
Apr 25 17:36:38.261: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 12.886532ms)
Apr 25 17:36:38.269: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 20.339374ms)
Apr 25 17:36:38.269: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 19.93254ms)
Apr 25 17:36:38.269: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 20.959477ms)
Apr 25 17:36:38.271: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 22.217853ms)
Apr 25 17:36:38.271: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 22.555533ms)
Apr 25 17:36:38.271: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 22.106088ms)
Apr 25 17:36:38.273: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 24.318823ms)
Apr 25 17:36:38.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 24.648924ms)
Apr 25 17:36:38.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 24.632941ms)
Apr 25 17:36:38.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 24.547493ms)
Apr 25 17:36:38.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 24.69187ms)
Apr 25 17:36:38.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 24.900098ms)
Apr 25 17:36:38.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 25.492868ms)
Apr 25 17:36:38.274: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 25.435069ms)
Apr 25 17:36:38.292: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 17.484308ms)
Apr 25 17:36:38.292: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 17.598226ms)
Apr 25 17:36:38.292: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 17.995187ms)
Apr 25 17:36:38.292: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 18.187535ms)
Apr 25 17:36:38.293: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 18.440368ms)
Apr 25 17:36:38.293: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 18.632219ms)
Apr 25 17:36:38.294: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 19.277084ms)
Apr 25 17:36:38.295: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 20.84297ms)
Apr 25 17:36:38.296: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 21.399841ms)
Apr 25 17:36:38.296: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 21.870993ms)
Apr 25 17:36:38.297: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 22.278503ms)
Apr 25 17:36:38.297: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 22.52411ms)
Apr 25 17:36:38.303: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 28.275951ms)
Apr 25 17:36:38.303: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 28.467481ms)
Apr 25 17:36:38.303: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 28.696474ms)
Apr 25 17:36:38.303: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 28.802136ms)
Apr 25 17:36:38.322: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 19.043571ms)
Apr 25 17:36:38.324: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 20.774517ms)
Apr 25 17:36:38.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 21.336086ms)
Apr 25 17:36:38.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 21.204022ms)
Apr 25 17:36:38.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 21.489066ms)
Apr 25 17:36:38.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 21.501545ms)
Apr 25 17:36:38.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 21.749013ms)
Apr 25 17:36:38.325: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 21.639949ms)
Apr 25 17:36:38.326: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 22.498626ms)
Apr 25 17:36:38.326: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 22.880268ms)
Apr 25 17:36:38.327: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 23.941802ms)
Apr 25 17:36:38.328: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 24.216207ms)
Apr 25 17:36:38.328: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 24.701655ms)
Apr 25 17:36:38.329: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 25.207972ms)
Apr 25 17:36:38.329: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 25.70758ms)
Apr 25 17:36:38.329: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 25.632724ms)
Apr 25 17:36:38.348: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 18.210626ms)
Apr 25 17:36:38.348: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 18.319279ms)
Apr 25 17:36:38.348: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 18.306576ms)
Apr 25 17:36:38.348: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 18.888104ms)
Apr 25 17:36:38.348: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 18.675072ms)
Apr 25 17:36:38.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 19.448948ms)
Apr 25 17:36:38.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 19.555312ms)
Apr 25 17:36:38.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 19.758641ms)
Apr 25 17:36:38.349: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 19.641507ms)
Apr 25 17:36:38.350: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 20.302568ms)
Apr 25 17:36:38.355: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 25.232722ms)
Apr 25 17:36:38.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 26.478574ms)
Apr 25 17:36:38.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 26.691823ms)
Apr 25 17:36:38.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 26.644192ms)
Apr 25 17:36:38.356: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 27.064296ms)
Apr 25 17:36:38.357: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 27.574042ms)
Apr 25 17:36:38.366: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 9.441213ms)
Apr 25 17:36:38.376: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 18.532638ms)
Apr 25 17:36:38.377: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 19.356902ms)
Apr 25 17:36:38.377: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 20.384776ms)
Apr 25 17:36:38.377: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 20.144616ms)
Apr 25 17:36:38.377: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 20.031615ms)
Apr 25 17:36:38.379: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 21.308949ms)
Apr 25 17:36:38.379: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 22.182181ms)
Apr 25 17:36:38.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 22.663233ms)
Apr 25 17:36:38.380: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 23.17424ms)
Apr 25 17:36:38.382: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 24.787138ms)
Apr 25 17:36:38.382: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 25.053652ms)
Apr 25 17:36:38.383: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 25.957533ms)
Apr 25 17:36:38.384: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 26.327809ms)
Apr 25 17:36:38.384: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 26.722366ms)
Apr 25 17:36:38.384: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 26.651303ms)
Apr 25 17:36:38.399: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 15.035271ms)
Apr 25 17:36:38.401: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 16.677123ms)
Apr 25 17:36:38.401: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 17.162961ms)
Apr 25 17:36:38.407: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 22.325269ms)
Apr 25 17:36:38.407: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 22.642547ms)
Apr 25 17:36:38.407: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 22.684187ms)
Apr 25 17:36:38.409: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 25.114885ms)
Apr 25 17:36:38.410: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 25.942384ms)
Apr 25 17:36:38.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 26.411943ms)
Apr 25 17:36:38.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 26.628073ms)
Apr 25 17:36:38.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 26.970802ms)
Apr 25 17:36:38.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 26.80216ms)
Apr 25 17:36:38.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 26.798327ms)
Apr 25 17:36:38.411: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 26.930463ms)
Apr 25 17:36:38.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 27.457409ms)
Apr 25 17:36:38.412: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 27.706812ms)
Apr 25 17:36:38.427: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 15.059815ms)
Apr 25 17:36:38.429: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 15.769219ms)
Apr 25 17:36:38.431: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 18.659019ms)
Apr 25 17:36:38.431: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 19.242508ms)
Apr 25 17:36:38.432: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 19.465764ms)
Apr 25 17:36:38.435: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 22.525011ms)
Apr 25 17:36:38.436: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 23.401254ms)
Apr 25 17:36:38.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 24.492258ms)
Apr 25 17:36:38.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 24.102152ms)
Apr 25 17:36:38.437: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 24.962621ms)
Apr 25 17:36:38.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 25.372624ms)
Apr 25 17:36:38.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 25.113881ms)
Apr 25 17:36:38.438: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 25.679472ms)
Apr 25 17:36:38.439: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 26.904495ms)
Apr 25 17:36:38.440: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 27.502243ms)
Apr 25 17:36:38.440: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 27.728841ms)
Apr 25 17:36:38.457: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:1080/proxy/rewri... (200; 16.35011ms)
Apr 25 17:36:38.457: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:160/proxy/: foo (200; 16.821385ms)
Apr 25 17:36:38.457: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:443/proxy/... (200; 17.073904ms)
Apr 25 17:36:38.469: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:460/proxy/: tls baz (200; 28.05378ms)
Apr 25 17:36:38.469: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5/proxy/rewriteme"... (200; 28.077633ms)
Apr 25 17:36:38.470: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname2/proxy/: tls qux (200; 29.366725ms)
Apr 25 17:36:38.470: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:1080/proxy/... (200; 29.734393ms)
Apr 25 17:36:38.471: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:162/proxy/: bar (200; 30.084527ms)
Apr 25 17:36:38.471: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/proxy-service-r8995-257s5:160/proxy/: foo (200; 30.047032ms)
Apr 25 17:36:38.471: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/http:proxy-service-r8995-257s5:162/proxy/: bar (200; 30.519023ms)
Apr 25 17:36:38.471: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/pods/https:proxy-service-r8995-257s5:462/proxy/: tls qux (200; 30.095363ms)
Apr 25 17:36:38.471: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname1/proxy/: foo (200; 30.267053ms)
Apr 25 17:36:38.472: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/https:proxy-service-r8995:tlsportname1/proxy/: tls baz (200; 31.080927ms)
Apr 25 17:36:38.472: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/http:proxy-service-r8995:portname2/proxy/: bar (200; 31.655605ms)
Apr 25 17:36:38.472: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname2/proxy/: bar (200; 31.390727ms)
Apr 25 17:36:38.472: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8nh4q/services/proxy-service-r8995:portname1/proxy/: foo (200; 31.657323ms)
STEP: deleting ReplicationController proxy-service-r8995 in namespace e2e-tests-proxy-8nh4q, will wait for the garbage collector to delete the pods
Apr 25 17:36:38.532: INFO: Deleting ReplicationController proxy-service-r8995 took: 6.993753ms
Apr 25 17:36:38.633: INFO: Terminating ReplicationController proxy-service-r8995 pods took: 100.214109ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:36:40.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8nh4q" for this suite.
Apr 25 17:36:46.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:36:47.069: INFO: namespace: e2e-tests-proxy-8nh4q, resource: bindings, ignored listing per whitelist
Apr 25 17:36:47.079: INFO: namespace e2e-tests-proxy-8nh4q deletion completed in 6.134704714s

• [SLOW TEST:18.495 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:36:47.079: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Apr 25 17:36:47.766: INFO: created pod pod-service-account-defaultsa
Apr 25 17:36:47.766: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 25 17:36:47.955: INFO: created pod pod-service-account-mountsa
Apr 25 17:36:47.956: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 25 17:36:47.969: INFO: created pod pod-service-account-nomountsa
Apr 25 17:36:47.969: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 25 17:36:47.986: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 25 17:36:47.986: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 25 17:36:48.008: INFO: created pod pod-service-account-mountsa-mountspec
Apr 25 17:36:48.008: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 25 17:36:48.036: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 25 17:36:48.037: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 25 17:36:48.073: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 25 17:36:48.073: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 25 17:36:48.087: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 25 17:36:48.087: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 25 17:36:48.115: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 25 17:36:48.115: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:36:48.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-xlc24" for this suite.
Apr 25 17:36:54.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:36:54.283: INFO: namespace: e2e-tests-svcaccounts-xlc24, resource: bindings, ignored listing per whitelist
Apr 25 17:36:54.458: INFO: namespace e2e-tests-svcaccounts-xlc24 deletion completed in 6.295823753s

• [SLOW TEST:7.379 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:36:54.459: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-llb9w;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-llb9w;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-llb9w.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-llb9w.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-llb9w.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 66.120.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.120.66_udp@PTR;check="$$(dig +tcp +noall +answer +search 66.120.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.120.66_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-llb9w;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-llb9w;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-llb9w.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-llb9w.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-llb9w.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-llb9w.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-llb9w.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 66.120.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.120.66_udp@PTR;check="$$(dig +tcp +noall +answer +search 66.120.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.120.66_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 25 17:37:06.899: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.903: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.907: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-llb9w from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.910: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-llb9w from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.914: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.917: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.920: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.924: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.950: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.953: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.957: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-llb9w from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.961: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-llb9w from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.964: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.968: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.972: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.975: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc from pod e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328: the server could not find the requested resource (get pods dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328)
Apr 25 17:37:06.996: INFO: Lookups using e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-llb9w wheezy_tcp@dns-test-service.e2e-tests-dns-llb9w wheezy_udp@dns-test-service.e2e-tests-dns-llb9w.svc wheezy_tcp@dns-test-service.e2e-tests-dns-llb9w.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-llb9w jessie_tcp@dns-test-service.e2e-tests-dns-llb9w jessie_udp@dns-test-service.e2e-tests-dns-llb9w.svc jessie_tcp@dns-test-service.e2e-tests-dns-llb9w.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-llb9w.svc]

Apr 25 17:37:12.121: INFO: DNS probes using e2e-tests-dns-llb9w/dns-test-b7c1ae00-6780-11e9-9f66-ae72f7f5c328 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:37:12.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-llb9w" for this suite.
Apr 25 17:37:18.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:37:18.409: INFO: namespace: e2e-tests-dns-llb9w, resource: bindings, ignored listing per whitelist
Apr 25 17:37:18.422: INFO: namespace e2e-tests-dns-llb9w deletion completed in 6.112057588s

• [SLOW TEST:23.963 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:37:18.423: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c5ea0cd0-6780-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:37:18.553: INFO: Waiting up to 5m0s for pod "pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-njhf2" to be "success or failure"
Apr 25 17:37:18.562: INFO: Pod "pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.780336ms
Apr 25 17:37:20.566: INFO: Pod "pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01272497s
Apr 25 17:37:22.571: INFO: Pod "pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017393304s
STEP: Saw pod success
Apr 25 17:37:22.571: INFO: Pod "pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:37:22.574: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:37:22.601: INFO: Waiting for pod pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:37:22.603: INFO: Pod pod-secrets-c5ea927d-6780-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:37:22.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-njhf2" for this suite.
Apr 25 17:37:28.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:37:28.712: INFO: namespace: e2e-tests-secrets-njhf2, resource: bindings, ignored listing per whitelist
Apr 25 17:37:28.721: INFO: namespace e2e-tests-secrets-njhf2 deletion completed in 6.113044054s

• [SLOW TEST:10.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:37:28.721: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:38:28.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dvgf7" for this suite.
Apr 25 17:38:50.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:38:50.906: INFO: namespace: e2e-tests-container-probe-dvgf7, resource: bindings, ignored listing per whitelist
Apr 25 17:38:50.984: INFO: namespace e2e-tests-container-probe-dvgf7 deletion completed in 22.112400634s

• [SLOW TEST:82.263 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:38:50.985: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fd0f9771-6780-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:38:51.078: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd1019ee-6780-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-vwgdx" to be "success or failure"
Apr 25 17:38:51.088: INFO: Pod "pod-projected-configmaps-fd1019ee-6780-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.814577ms
Apr 25 17:38:53.091: INFO: Pod "pod-projected-configmaps-fd1019ee-6780-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013246544s
STEP: Saw pod success
Apr 25 17:38:53.091: INFO: Pod "pod-projected-configmaps-fd1019ee-6780-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:38:53.096: INFO: Trying to get logs from node test113-q3hn pod pod-projected-configmaps-fd1019ee-6780-11e9-9f66-ae72f7f5c328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 17:38:53.125: INFO: Waiting for pod pod-projected-configmaps-fd1019ee-6780-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:38:53.129: INFO: Pod pod-projected-configmaps-fd1019ee-6780-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:38:53.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vwgdx" for this suite.
Apr 25 17:38:59.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:38:59.311: INFO: namespace: e2e-tests-projected-vwgdx, resource: bindings, ignored listing per whitelist
Apr 25 17:38:59.366: INFO: namespace e2e-tests-projected-vwgdx deletion completed in 6.233337506s

• [SLOW TEST:8.381 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:38:59.366: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Apr 25 17:39:00.020: INFO: Waiting up to 5m0s for pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6" in namespace "e2e-tests-svcaccounts-ts4r6" to be "success or failure"
Apr 25 17:39:00.026: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.860896ms
Apr 25 17:39:02.140: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.119424479s
Apr 25 17:39:04.158: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.137325242s
STEP: Saw pod success
Apr 25 17:39:04.158: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6" satisfied condition "success or failure"
Apr 25 17:39:04.168: INFO: Trying to get logs from node test113-q3kz pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6 container token-test: <nil>
STEP: delete the pod
Apr 25 17:39:04.223: INFO: Waiting for pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6 to disappear
Apr 25 17:39:04.445: INFO: Pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-hj2w6 no longer exists
STEP: Creating a pod to test consume service account root CA
Apr 25 17:39:04.455: INFO: Waiting up to 5m0s for pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx" in namespace "e2e-tests-svcaccounts-ts4r6" to be "success or failure"
Apr 25 17:39:04.486: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx": Phase="Pending", Reason="", readiness=false. Elapsed: 30.650315ms
Apr 25 17:39:06.490: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034533771s
Apr 25 17:39:08.493: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038319568s
STEP: Saw pod success
Apr 25 17:39:08.493: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx" satisfied condition "success or failure"
Apr 25 17:39:08.496: INFO: Trying to get logs from node test113-q3k9 pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx container root-ca-test: <nil>
STEP: delete the pod
Apr 25 17:39:08.525: INFO: Waiting for pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx to disappear
Apr 25 17:39:08.537: INFO: Pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-7lkxx no longer exists
STEP: Creating a pod to test consume service account namespace
Apr 25 17:39:08.557: INFO: Waiting up to 5m0s for pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f" in namespace "e2e-tests-svcaccounts-ts4r6" to be "success or failure"
Apr 25 17:39:08.579: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.896789ms
Apr 25 17:39:10.585: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027993719s
Apr 25 17:39:12.589: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031793561s
STEP: Saw pod success
Apr 25 17:39:12.589: INFO: Pod "pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f" satisfied condition "success or failure"
Apr 25 17:39:12.592: INFO: Trying to get logs from node test113-q3hn pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f container namespace-test: <nil>
STEP: delete the pod
Apr 25 17:39:12.626: INFO: Waiting for pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f to disappear
Apr 25 17:39:12.630: INFO: Pod pod-service-account-0264d516-6781-11e9-9f66-ae72f7f5c328-v8g2f no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:39:12.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-ts4r6" for this suite.
Apr 25 17:39:18.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:39:18.715: INFO: namespace: e2e-tests-svcaccounts-ts4r6, resource: bindings, ignored listing per whitelist
Apr 25 17:39:18.744: INFO: namespace e2e-tests-svcaccounts-ts4r6 deletion completed in 6.111350784s

• [SLOW TEST:19.379 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:39:18.744: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Apr 25 17:39:20.896: INFO: Pod pod-hostip-0da26258-6781-11e9-9f66-ae72f7f5c328 has hostIP: 10.138.46.141
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:39:20.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ts5h2" for this suite.
Apr 25 17:39:42.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:39:42.989: INFO: namespace: e2e-tests-pods-ts5h2, resource: bindings, ignored listing per whitelist
Apr 25 17:39:43.023: INFO: namespace e2e-tests-pods-ts5h2 deletion completed in 22.122977252s

• [SLOW TEST:24.279 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:39:43.023: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1c116f19-6781-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:39:43.096: INFO: Waiting up to 5m0s for pod "pod-configmaps-1c11eab5-6781-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-4tq8f" to be "success or failure"
Apr 25 17:39:43.104: INFO: Pod "pod-configmaps-1c11eab5-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.66811ms
Apr 25 17:39:45.109: INFO: Pod "pod-configmaps-1c11eab5-6781-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012235735s
STEP: Saw pod success
Apr 25 17:39:45.109: INFO: Pod "pod-configmaps-1c11eab5-6781-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:39:45.112: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-1c11eab5-6781-11e9-9f66-ae72f7f5c328 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 17:39:45.142: INFO: Waiting for pod pod-configmaps-1c11eab5-6781-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:39:45.147: INFO: Pod pod-configmaps-1c11eab5-6781-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:39:45.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4tq8f" for this suite.
Apr 25 17:39:51.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:39:51.207: INFO: namespace: e2e-tests-configmap-4tq8f, resource: bindings, ignored listing per whitelist
Apr 25 17:39:51.259: INFO: namespace e2e-tests-configmap-4tq8f deletion completed in 6.105159266s

• [SLOW TEST:8.235 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:39:51.259: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:39:51.402: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21047da6-6781-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-x7bmt" to be "success or failure"
Apr 25 17:39:51.421: INFO: Pod "downwardapi-volume-21047da6-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 18.908725ms
Apr 25 17:39:53.425: INFO: Pod "downwardapi-volume-21047da6-6781-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022428902s
STEP: Saw pod success
Apr 25 17:39:53.425: INFO: Pod "downwardapi-volume-21047da6-6781-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:39:53.427: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-21047da6-6781-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:39:53.450: INFO: Waiting for pod downwardapi-volume-21047da6-6781-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:39:53.460: INFO: Pod downwardapi-volume-21047da6-6781-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:39:53.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x7bmt" for this suite.
Apr 25 17:39:59.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:39:59.575: INFO: namespace: e2e-tests-downward-api-x7bmt, resource: bindings, ignored listing per whitelist
Apr 25 17:39:59.581: INFO: namespace e2e-tests-downward-api-x7bmt deletion completed in 6.116580129s

• [SLOW TEST:8.322 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:39:59.581: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 25 17:39:59.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-8h7pg'
Apr 25 17:39:59.748: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 25 17:39:59.748: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Apr 25 17:39:59.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-8h7pg'
Apr 25 17:39:59.853: INFO: stderr: ""
Apr 25 17:39:59.853: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:39:59.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8h7pg" for this suite.
Apr 25 17:40:21.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:40:21.919: INFO: namespace: e2e-tests-kubectl-8h7pg, resource: bindings, ignored listing per whitelist
Apr 25 17:40:21.965: INFO: namespace e2e-tests-kubectl-8h7pg deletion completed in 22.101377733s

• [SLOW TEST:22.384 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:40:21.966: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:40:48.046: INFO: Container started at 2019-04-25 17:40:23 +0000 UTC, pod became ready at 2019-04-25 17:40:47 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:40:48.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zrq8z" for this suite.
Apr 25 17:41:10.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:41:10.140: INFO: namespace: e2e-tests-container-probe-zrq8z, resource: bindings, ignored listing per whitelist
Apr 25 17:41:10.224: INFO: namespace e2e-tests-container-probe-zrq8z deletion completed in 22.172433713s

• [SLOW TEST:48.258 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:41:10.227: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Apr 25 17:41:10.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:10.488: INFO: stderr: ""
Apr 25 17:41:10.488: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 25 17:41:10.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:10.568: INFO: stderr: ""
Apr 25 17:41:10.568: INFO: stdout: "update-demo-nautilus-5sxcb update-demo-nautilus-vjtbm "
Apr 25 17:41:10.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-5sxcb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:10.641: INFO: stderr: ""
Apr 25 17:41:10.641: INFO: stdout: ""
Apr 25 17:41:10.641: INFO: update-demo-nautilus-5sxcb is created but not running
Apr 25 17:41:15.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:15.968: INFO: stderr: ""
Apr 25 17:41:15.968: INFO: stdout: "update-demo-nautilus-5sxcb update-demo-nautilus-vjtbm "
Apr 25 17:41:15.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-5sxcb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:16.053: INFO: stderr: ""
Apr 25 17:41:16.053: INFO: stdout: "true"
Apr 25 17:41:16.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-5sxcb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:16.140: INFO: stderr: ""
Apr 25 17:41:16.140: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:41:16.140: INFO: validating pod update-demo-nautilus-5sxcb
Apr 25 17:41:16.149: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:41:16.149: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:41:16.149: INFO: update-demo-nautilus-5sxcb is verified up and running
Apr 25 17:41:16.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-vjtbm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:16.247: INFO: stderr: ""
Apr 25 17:41:16.247: INFO: stdout: "true"
Apr 25 17:41:16.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-vjtbm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:16.334: INFO: stderr: ""
Apr 25 17:41:16.334: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:41:16.334: INFO: validating pod update-demo-nautilus-vjtbm
Apr 25 17:41:16.342: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:41:16.342: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:41:16.342: INFO: update-demo-nautilus-vjtbm is verified up and running
STEP: using delete to clean up resources
Apr 25 17:41:16.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:16.447: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 25 17:41:16.447: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 25 17:41:16.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-p4kw7'
Apr 25 17:41:16.541: INFO: stderr: "No resources found.\n"
Apr 25 17:41:16.541: INFO: stdout: ""
Apr 25 17:41:16.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -l name=update-demo --namespace=e2e-tests-kubectl-p4kw7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 25 17:41:16.622: INFO: stderr: ""
Apr 25 17:41:16.622: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:41:16.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p4kw7" for this suite.
Apr 25 17:41:38.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:41:38.709: INFO: namespace: e2e-tests-kubectl-p4kw7, resource: bindings, ignored listing per whitelist
Apr 25 17:41:38.719: INFO: namespace e2e-tests-kubectl-p4kw7 deletion completed in 22.093255191s

• [SLOW TEST:28.493 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:41:38.719: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-mzgkm/configmap-test-61114e18-6781-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:41:38.861: INFO: Waiting up to 5m0s for pod "pod-configmaps-6111cbe8-6781-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-mzgkm" to be "success or failure"
Apr 25 17:41:38.867: INFO: Pod "pod-configmaps-6111cbe8-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 5.663298ms
Apr 25 17:41:40.871: INFO: Pod "pod-configmaps-6111cbe8-6781-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009632557s
STEP: Saw pod success
Apr 25 17:41:40.871: INFO: Pod "pod-configmaps-6111cbe8-6781-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:41:40.873: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-6111cbe8-6781-11e9-9f66-ae72f7f5c328 container env-test: <nil>
STEP: delete the pod
Apr 25 17:41:40.898: INFO: Waiting for pod pod-configmaps-6111cbe8-6781-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:41:40.900: INFO: Pod pod-configmaps-6111cbe8-6781-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:41:40.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mzgkm" for this suite.
Apr 25 17:41:46.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:41:46.974: INFO: namespace: e2e-tests-configmap-mzgkm, resource: bindings, ignored listing per whitelist
Apr 25 17:41:47.014: INFO: namespace e2e-tests-configmap-mzgkm deletion completed in 6.110152419s

• [SLOW TEST:8.294 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:41:47.014: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 25 17:41:47.081: INFO: Waiting up to 5m0s for pod "pod-65f89955-6781-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-qqmbb" to be "success or failure"
Apr 25 17:41:47.087: INFO: Pod "pod-65f89955-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 5.476977ms
Apr 25 17:41:49.094: INFO: Pod "pod-65f89955-6781-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012753537s
STEP: Saw pod success
Apr 25 17:41:49.094: INFO: Pod "pod-65f89955-6781-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:41:49.099: INFO: Trying to get logs from node test113-q3hn pod pod-65f89955-6781-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:41:49.130: INFO: Waiting for pod pod-65f89955-6781-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:41:49.136: INFO: Pod pod-65f89955-6781-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:41:49.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qqmbb" for this suite.
Apr 25 17:41:55.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:41:55.191: INFO: namespace: e2e-tests-emptydir-qqmbb, resource: bindings, ignored listing per whitelist
Apr 25 17:41:55.258: INFO: namespace e2e-tests-emptydir-qqmbb deletion completed in 6.117432673s

• [SLOW TEST:8.244 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:41:55.259: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:41:57.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-x9k4h" for this suite.
Apr 25 17:42:35.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:42:35.506: INFO: namespace: e2e-tests-kubelet-test-x9k4h, resource: bindings, ignored listing per whitelist
Apr 25 17:42:35.515: INFO: namespace e2e-tests-kubelet-test-x9k4h deletion completed in 38.10010521s

• [SLOW TEST:40.256 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:42:35.515: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:42:35.641: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:42:36.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-kfbn2" for this suite.
Apr 25 17:42:42.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:42:42.942: INFO: namespace: e2e-tests-custom-resource-definition-kfbn2, resource: bindings, ignored listing per whitelist
Apr 25 17:42:42.944: INFO: namespace e2e-tests-custom-resource-definition-kfbn2 deletion completed in 6.250250387s

• [SLOW TEST:7.429 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:42:42.945: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 25 17:42:47.146: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:42:47.149: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:42:49.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:42:49.154: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:42:51.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:42:51.161: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:42:53.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:42:53.153: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:42:55.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:42:55.154: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:42:57.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:42:57.153: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:42:59.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:42:59.155: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:43:01.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:43:01.155: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:43:03.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:43:03.155: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:43:05.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:43:05.154: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 25 17:43:07.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 25 17:43:07.154: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:43:07.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-kd8mb" for this suite.
Apr 25 17:43:29.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:43:29.369: INFO: namespace: e2e-tests-container-lifecycle-hook-kd8mb, resource: bindings, ignored listing per whitelist
Apr 25 17:43:29.378: INFO: namespace e2e-tests-container-lifecycle-hook-kd8mb deletion completed in 22.210970445s

• [SLOW TEST:46.433 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:43:29.379: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:43:29.480: INFO: Creating deployment "test-recreate-deployment"
Apr 25 17:43:29.485: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 25 17:43:29.523: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 25 17:43:31.531: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 25 17:43:31.533: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 25 17:43:31.541: INFO: Updating deployment test-recreate-deployment
Apr 25 17:43:31.541: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 25 17:43:31.671: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-9rv5g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rv5g/deployments/test-recreate-deployment,UID:a30426a5-6781-11e9-a8f1-82d29082e60b,ResourceVersion:32187,Generation:2,CreationTimestamp:2019-04-25 17:43:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-04-25 17:43:31 +0000 UTC 2019-04-25 17:43:31 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-04-25 17:43:31 +0000 UTC 2019-04-25 17:43:29 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Apr 25 17:43:31.675: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-9rv5g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rv5g/replicasets/test-recreate-deployment-697fbf54bf,UID:a44588f1-6781-11e9-a8f1-82d29082e60b,ResourceVersion:32186,Generation:1,CreationTimestamp:2019-04-25 17:43:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a30426a5-6781-11e9-a8f1-82d29082e60b 0xc000df9e67 0xc000df9e68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 25 17:43:31.675: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 25 17:43:31.675: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-9rv5g,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rv5g/replicasets/test-recreate-deployment-5dfdcc846d,UID:a30501d9-6781-11e9-a8f1-82d29082e60b,ResourceVersion:32175,Generation:2,CreationTimestamp:2019-04-25 17:43:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a30426a5-6781-11e9-a8f1-82d29082e60b 0xc000df9da7 0xc000df9da8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 25 17:43:31.678: INFO: Pod "test-recreate-deployment-697fbf54bf-qml6g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-qml6g,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-9rv5g,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rv5g/pods/test-recreate-deployment-697fbf54bf-qml6g,UID:a446523c-6781-11e9-a8f1-82d29082e60b,ResourceVersion:32185,Generation:0,CreationTimestamp:2019-04-25 17:43:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf a44588f1-6781-11e9-a8f1-82d29082e60b 0xc0020bb427 0xc0020bb428}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gjwtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gjwtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gjwtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020bb4a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020bb4c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:43:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:43:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:43:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:43:31 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:,StartTime:2019-04-25 17:43:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:43:31.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9rv5g" for this suite.
Apr 25 17:43:37.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:43:37.732: INFO: namespace: e2e-tests-deployment-9rv5g, resource: bindings, ignored listing per whitelist
Apr 25 17:43:37.787: INFO: namespace e2e-tests-deployment-9rv5g deletion completed in 6.105095762s

• [SLOW TEST:8.408 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:43:37.787: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0425 17:43:48.012052      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 25 17:43:48.012: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:43:48.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-z4v4b" for this suite.
Apr 25 17:43:54.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:43:54.339: INFO: namespace: e2e-tests-gc-z4v4b, resource: bindings, ignored listing per whitelist
Apr 25 17:43:54.415: INFO: namespace e2e-tests-gc-z4v4b deletion completed in 6.399847645s

• [SLOW TEST:16.628 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:43:54.416: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 25 17:43:54.652: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 25 17:43:54.672: INFO: Waiting for terminating namespaces to be deleted...
Apr 25 17:43:54.679: INFO: 
Logging pods the kubelet thinks is on node test113-q3hn before test
Apr 25 17:43:54.698: INFO: cilium-qrhts from kube-system started at 2019-04-25 16:15:55 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.698: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 17:43:54.698: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-25 16:36:41 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.698: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 25 17:43:54.698: INFO: kube-proxy-dplbd from kube-system started at 2019-04-25 16:15:55 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.698: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 17:43:54.698: INFO: csi-do-node-7jfmk from kube-system started at 2019-04-25 16:16:16 +0000 UTC (2 container statuses recorded)
Apr 25 17:43:54.698: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 17:43:54.698: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 17:43:54.699: INFO: do-node-agent-jwjhn from kube-system started at 2019-04-25 16:16:16 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.699: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 17:43:54.699: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-wpdwt from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 17:43:54.699: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 25 17:43:54.699: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 25 17:43:54.699: INFO: 
Logging pods the kubelet thinks is on node test113-q3k9 before test
Apr 25 17:43:54.743: INFO: kube-proxy-v8p4s from kube-system started at 2019-04-25 16:15:37 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 17:43:54.743: INFO: cilium-operator-7c9bd57c88-lstbs from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 25 17:43:54.743: INFO: do-node-agent-fxrn4 from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 17:43:54.743: INFO: coredns-5d668bd598-xfpfd from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container coredns ready: true, restart count 0
Apr 25 17:43:54.743: INFO: csi-do-node-dznmp from kube-system started at 2019-04-25 16:15:57 +0000 UTC (2 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 17:43:54.743: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 17:43:54.743: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8kx8h from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 25 17:43:54.743: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 25 17:43:54.743: INFO: coredns-5d668bd598-pmwb2 from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container coredns ready: true, restart count 0
Apr 25 17:43:54.743: INFO: cilium-rcnl7 from kube-system started at 2019-04-25 16:15:37 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.743: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 17:43:54.743: INFO: 
Logging pods the kubelet thinks is on node test113-q3kz before test
Apr 25 17:43:54.767: INFO: cilium-jsp4p from kube-system started at 2019-04-25 16:15:58 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.768: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 17:43:54.768: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8skg7 from heptio-sonobuoy started at 2019-04-25 16:36:45 +0000 UTC (2 container statuses recorded)
Apr 25 17:43:54.768: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 25 17:43:54.768: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 25 17:43:54.768: INFO: do-node-agent-5475d from kube-system started at 2019-04-25 16:16:19 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.768: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 17:43:54.768: INFO: kube-proxy-qntk9 from kube-system started at 2019-04-25 16:15:58 +0000 UTC (1 container statuses recorded)
Apr 25 17:43:54.768: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 17:43:54.768: INFO: csi-do-node-cbct5 from kube-system started at 2019-04-25 16:16:19 +0000 UTC (2 container statuses recorded)
Apr 25 17:43:54.768: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 17:43:54.768: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 17:43:54.768: INFO: sonobuoy-e2e-job-a1b0a7332f284308 from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 17:43:54.768: INFO: 	Container e2e ready: true, restart count 0
Apr 25 17:43:54.768: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node test113-q3hn
STEP: verifying the node has the label node test113-q3k9
STEP: verifying the node has the label node test113-q3kz
Apr 25 17:43:54.996: INFO: Pod sonobuoy requesting resource cpu=0m on Node test113-q3hn
Apr 25 17:43:54.996: INFO: Pod sonobuoy-e2e-job-a1b0a7332f284308 requesting resource cpu=0m on Node test113-q3kz
Apr 25 17:43:54.996: INFO: Pod sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8kx8h requesting resource cpu=0m on Node test113-q3k9
Apr 25 17:43:54.996: INFO: Pod sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8skg7 requesting resource cpu=0m on Node test113-q3kz
Apr 25 17:43:54.996: INFO: Pod sonobuoy-systemd-logs-daemon-set-39bcd96082344561-wpdwt requesting resource cpu=0m on Node test113-q3hn
Apr 25 17:43:54.996: INFO: Pod cilium-jsp4p requesting resource cpu=300m on Node test113-q3kz
Apr 25 17:43:54.996: INFO: Pod cilium-operator-7c9bd57c88-lstbs requesting resource cpu=0m on Node test113-q3k9
Apr 25 17:43:54.996: INFO: Pod cilium-qrhts requesting resource cpu=300m on Node test113-q3hn
Apr 25 17:43:54.996: INFO: Pod cilium-rcnl7 requesting resource cpu=300m on Node test113-q3k9
Apr 25 17:43:54.996: INFO: Pod coredns-5d668bd598-pmwb2 requesting resource cpu=100m on Node test113-q3k9
Apr 25 17:43:54.996: INFO: Pod coredns-5d668bd598-xfpfd requesting resource cpu=100m on Node test113-q3k9
Apr 25 17:43:54.996: INFO: Pod csi-do-node-7jfmk requesting resource cpu=0m on Node test113-q3hn
Apr 25 17:43:54.996: INFO: Pod csi-do-node-cbct5 requesting resource cpu=0m on Node test113-q3kz
Apr 25 17:43:54.996: INFO: Pod csi-do-node-dznmp requesting resource cpu=0m on Node test113-q3k9
Apr 25 17:43:54.996: INFO: Pod do-node-agent-5475d requesting resource cpu=102m on Node test113-q3kz
Apr 25 17:43:54.996: INFO: Pod do-node-agent-fxrn4 requesting resource cpu=102m on Node test113-q3k9
Apr 25 17:43:54.997: INFO: Pod do-node-agent-jwjhn requesting resource cpu=102m on Node test113-q3hn
Apr 25 17:43:54.997: INFO: Pod kube-proxy-dplbd requesting resource cpu=0m on Node test113-q3hn
Apr 25 17:43:54.997: INFO: Pod kube-proxy-qntk9 requesting resource cpu=0m on Node test113-q3kz
Apr 25 17:43:54.997: INFO: Pod kube-proxy-v8p4s requesting resource cpu=0m on Node test113-q3k9
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b2381114-6781-11e9-9f66-ae72f7f5c328.1598c89a016da920], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-c2vrl/filler-pod-b2381114-6781-11e9-9f66-ae72f7f5c328 to test113-q3hn]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b2381114-6781-11e9-9f66-ae72f7f5c328.1598c89a5527f235], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b2381114-6781-11e9-9f66-ae72f7f5c328.1598c89a5a0d4352], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b2381114-6781-11e9-9f66-ae72f7f5c328.1598c89a67d4966b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23a8068-6781-11e9-9f66-ae72f7f5c328.1598c89a04583406], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-c2vrl/filler-pod-b23a8068-6781-11e9-9f66-ae72f7f5c328 to test113-q3k9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23a8068-6781-11e9-9f66-ae72f7f5c328.1598c89a615af65c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23a8068-6781-11e9-9f66-ae72f7f5c328.1598c89a6667cdc2], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23a8068-6781-11e9-9f66-ae72f7f5c328.1598c89a74977e7c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23d6263-6781-11e9-9f66-ae72f7f5c328.1598c89a0504b3b1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-c2vrl/filler-pod-b23d6263-6781-11e9-9f66-ae72f7f5c328 to test113-q3kz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23d6263-6781-11e9-9f66-ae72f7f5c328.1598c89a5c77b0a4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23d6263-6781-11e9-9f66-ae72f7f5c328.1598c89a61a0597b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b23d6263-6781-11e9-9f66-ae72f7f5c328.1598c89a6efad2e8], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1598c89af75ba219], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node test113-q3k9
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node test113-q3kz
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node test113-q3hn
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:44:00.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-c2vrl" for this suite.
Apr 25 17:44:06.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:44:06.347: INFO: namespace: e2e-tests-sched-pred-c2vrl, resource: bindings, ignored listing per whitelist
Apr 25 17:44:06.353: INFO: namespace e2e-tests-sched-pred-c2vrl deletion completed in 6.108088279s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.938 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:44:06.355: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:44:10.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-7p54s" for this suite.
Apr 25 17:44:16.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:44:16.593: INFO: namespace: e2e-tests-emptydir-wrapper-7p54s, resource: bindings, ignored listing per whitelist
Apr 25 17:44:16.621: INFO: namespace e2e-tests-emptydir-wrapper-7p54s deletion completed in 6.119656361s

• [SLOW TEST:10.266 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:44:16.622: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 25 17:44:23.794: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:44:23.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-lqkjc" for this suite.
Apr 25 17:44:45.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:44:45.958: INFO: namespace: e2e-tests-replicaset-lqkjc, resource: bindings, ignored listing per whitelist
Apr 25 17:44:45.968: INFO: namespace e2e-tests-replicaset-lqkjc deletion completed in 22.127412505s

• [SLOW TEST:29.346 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:44:45.968: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 25 17:44:46.049: INFO: Waiting up to 5m0s for pod "pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-9ss4t" to be "success or failure"
Apr 25 17:44:46.056: INFO: Pod "pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.555383ms
Apr 25 17:44:48.060: INFO: Pod "pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011133393s
Apr 25 17:44:50.064: INFO: Pod "pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015244186s
STEP: Saw pod success
Apr 25 17:44:50.065: INFO: Pod "pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:44:50.068: INFO: Trying to get logs from node test113-q3hn pod pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:44:50.097: INFO: Waiting for pod pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:44:50.105: INFO: Pod pod-d0a4b241-6781-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:44:50.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9ss4t" for this suite.
Apr 25 17:44:56.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:44:56.321: INFO: namespace: e2e-tests-emptydir-9ss4t, resource: bindings, ignored listing per whitelist
Apr 25 17:44:56.396: INFO: namespace e2e-tests-emptydir-9ss4t deletion completed in 6.113611255s

• [SLOW TEST:10.428 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:44:56.396: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5n64v
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 25 17:44:56.453: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 25 17:45:22.572: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.18:8080/dial?request=hostName&protocol=http&host=10.244.2.159&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5n64v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 17:45:22.572: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 17:45:22.766: INFO: Waiting for endpoints: map[]
Apr 25 17:45:22.771: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.18:8080/dial?request=hostName&protocol=http&host=10.244.0.98&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5n64v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 17:45:22.771: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 17:45:22.977: INFO: Waiting for endpoints: map[]
Apr 25 17:45:22.980: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.18:8080/dial?request=hostName&protocol=http&host=10.244.1.36&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5n64v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 17:45:22.980: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 17:45:23.171: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:45:23.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5n64v" for this suite.
Apr 25 17:45:45.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:45:45.231: INFO: namespace: e2e-tests-pod-network-test-5n64v, resource: bindings, ignored listing per whitelist
Apr 25 17:45:45.315: INFO: namespace e2e-tests-pod-network-test-5n64v deletion completed in 22.138550194s

• [SLOW TEST:48.919 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:45:45.316: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 25 17:45:49.917: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f403fc76-6781-11e9-9f66-ae72f7f5c328"
Apr 25 17:45:49.917: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f403fc76-6781-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-pods-57td5" to be "terminated due to deadline exceeded"
Apr 25 17:45:49.926: INFO: Pod "pod-update-activedeadlineseconds-f403fc76-6781-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 9.434357ms
Apr 25 17:45:51.930: INFO: Pod "pod-update-activedeadlineseconds-f403fc76-6781-11e9-9f66-ae72f7f5c328": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.013634506s
Apr 25 17:45:51.930: INFO: Pod "pod-update-activedeadlineseconds-f403fc76-6781-11e9-9f66-ae72f7f5c328" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:45:51.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-57td5" for this suite.
Apr 25 17:45:57.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:45:58.022: INFO: namespace: e2e-tests-pods-57td5, resource: bindings, ignored listing per whitelist
Apr 25 17:45:58.038: INFO: namespace e2e-tests-pods-57td5 deletion completed in 6.102576477s

• [SLOW TEST:12.723 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:45:58.038: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-fba2bf97-6781-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:45:58.181: INFO: Waiting up to 5m0s for pod "pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-zb2lp" to be "success or failure"
Apr 25 17:45:58.190: INFO: Pod "pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.150022ms
Apr 25 17:46:00.195: INFO: Pod "pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013924564s
Apr 25 17:46:02.200: INFO: Pod "pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018853629s
STEP: Saw pod success
Apr 25 17:46:02.200: INFO: Pod "pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:46:02.203: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 17:46:02.237: INFO: Waiting for pod pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:46:02.242: INFO: Pod pod-configmaps-fba34d73-6781-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:46:02.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zb2lp" for this suite.
Apr 25 17:46:08.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:46:08.353: INFO: namespace: e2e-tests-configmap-zb2lp, resource: bindings, ignored listing per whitelist
Apr 25 17:46:08.360: INFO: namespace e2e-tests-configmap-zb2lp deletion completed in 6.106298123s

• [SLOW TEST:10.322 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:46:08.360: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-01c77807-6782-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:46:08.487: INFO: Waiting up to 5m0s for pod "pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-secrets-fm5bn" to be "success or failure"
Apr 25 17:46:08.494: INFO: Pod "pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.493924ms
Apr 25 17:46:10.498: INFO: Pod "pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011386085s
Apr 25 17:46:12.508: INFO: Pod "pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021291565s
STEP: Saw pod success
Apr 25 17:46:12.508: INFO: Pod "pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:46:12.511: INFO: Trying to get logs from node test113-q3hn pod pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328 container secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:46:12.533: INFO: Waiting for pod pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:46:12.536: INFO: Pod pod-secrets-01c7eb90-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:46:12.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fm5bn" for this suite.
Apr 25 17:46:18.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:46:18.612: INFO: namespace: e2e-tests-secrets-fm5bn, resource: bindings, ignored listing per whitelist
Apr 25 17:46:18.648: INFO: namespace e2e-tests-secrets-fm5bn deletion completed in 6.108305066s

• [SLOW TEST:10.288 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:46:18.650: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 25 17:46:18.772: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:46:22.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-j2jzs" for this suite.
Apr 25 17:46:28.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:46:28.836: INFO: namespace: e2e-tests-init-container-j2jzs, resource: bindings, ignored listing per whitelist
Apr 25 17:46:28.836: INFO: namespace e2e-tests-init-container-j2jzs deletion completed in 6.122246343s

• [SLOW TEST:10.187 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:46:28.836: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:46:31.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-vxztj" for this suite.
Apr 25 17:47:09.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:47:09.570: INFO: namespace: e2e-tests-kubelet-test-vxztj, resource: bindings, ignored listing per whitelist
Apr 25 17:47:09.572: INFO: namespace e2e-tests-kubelet-test-vxztj deletion completed in 38.554759142s

• [SLOW TEST:40.736 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:47:09.572: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:47:09.772: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"264dcc2a-6782-11e9-a8f1-82d29082e60b", Controller:(*bool)(0xc0015dede6), BlockOwnerDeletion:(*bool)(0xc0015dede7)}}
Apr 25 17:47:09.789: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"264a7f41-6782-11e9-a8f1-82d29082e60b", Controller:(*bool)(0xc0015df056), BlockOwnerDeletion:(*bool)(0xc0015df057)}}
Apr 25 17:47:09.800: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"264b6417-6782-11e9-a8f1-82d29082e60b", Controller:(*bool)(0xc001b57f36), BlockOwnerDeletion:(*bool)(0xc001b57f37)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:47:14.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-p2ctm" for this suite.
Apr 25 17:47:20.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:47:20.899: INFO: namespace: e2e-tests-gc-p2ctm, resource: bindings, ignored listing per whitelist
Apr 25 17:47:20.921: INFO: namespace e2e-tests-gc-p2ctm deletion completed in 6.10515343s

• [SLOW TEST:11.349 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:47:20.922: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 25 17:47:21.003: INFO: Waiting up to 5m0s for pod "pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-4hlh7" to be "success or failure"
Apr 25 17:47:21.011: INFO: Pod "pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.329677ms
Apr 25 17:47:23.015: INFO: Pod "pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011922534s
Apr 25 17:47:25.020: INFO: Pod "pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017332897s
STEP: Saw pod success
Apr 25 17:47:25.021: INFO: Pod "pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:47:25.023: INFO: Trying to get logs from node test113-q3hn pod pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 17:47:25.049: INFO: Waiting for pod pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:47:25.055: INFO: Pod pod-2d010bfb-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:47:25.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4hlh7" for this suite.
Apr 25 17:47:31.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:47:31.185: INFO: namespace: e2e-tests-emptydir-4hlh7, resource: bindings, ignored listing per whitelist
Apr 25 17:47:31.189: INFO: namespace e2e-tests-emptydir-4hlh7 deletion completed in 6.128556955s

• [SLOW TEST:10.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:47:31.190: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Apr 25 17:47:31.323: INFO: namespace e2e-tests-kubectl-zqk48
Apr 25 17:47:31.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-zqk48'
Apr 25 17:47:31.506: INFO: stderr: ""
Apr 25 17:47:31.506: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 25 17:47:32.513: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 17:47:32.513: INFO: Found 0 / 1
Apr 25 17:47:33.509: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 17:47:33.509: INFO: Found 0 / 1
Apr 25 17:47:34.516: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 17:47:34.516: INFO: Found 1 / 1
Apr 25 17:47:34.516: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 25 17:47:34.524: INFO: Selector matched 1 pods for map[app:redis]
Apr 25 17:47:34.524: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 25 17:47:34.524: INFO: wait on redis-master startup in e2e-tests-kubectl-zqk48 
Apr 25 17:47:34.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 logs redis-master-fbwdn redis-master --namespace=e2e-tests-kubectl-zqk48'
Apr 25 17:47:34.633: INFO: stderr: ""
Apr 25 17:47:34.633: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 25 Apr 17:47:33.136 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 25 Apr 17:47:33.136 # Server started, Redis version 3.2.12\n1:M 25 Apr 17:47:33.136 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 25 Apr 17:47:33.136 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Apr 25 17:47:34.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-zqk48'
Apr 25 17:47:34.751: INFO: stderr: ""
Apr 25 17:47:34.751: INFO: stdout: "service/rm2 exposed\n"
Apr 25 17:47:34.764: INFO: Service rm2 in namespace e2e-tests-kubectl-zqk48 found.
STEP: exposing service
Apr 25 17:47:36.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-zqk48'
Apr 25 17:47:36.868: INFO: stderr: ""
Apr 25 17:47:36.868: INFO: stdout: "service/rm3 exposed\n"
Apr 25 17:47:36.876: INFO: Service rm3 in namespace e2e-tests-kubectl-zqk48 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:47:38.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zqk48" for this suite.
Apr 25 17:48:02.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:48:02.947: INFO: namespace: e2e-tests-kubectl-zqk48, resource: bindings, ignored listing per whitelist
Apr 25 17:48:03.009: INFO: namespace e2e-tests-kubectl-zqk48 deletion completed in 24.119140597s

• [SLOW TEST:31.819 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:48:03.009: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-461523ed-6782-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:48:03.083: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4615d01c-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-zg85v" to be "success or failure"
Apr 25 17:48:03.118: INFO: Pod "pod-projected-secrets-4615d01c-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 35.159213ms
Apr 25 17:48:05.122: INFO: Pod "pod-projected-secrets-4615d01c-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039104973s
STEP: Saw pod success
Apr 25 17:48:05.122: INFO: Pod "pod-projected-secrets-4615d01c-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:48:05.125: INFO: Trying to get logs from node test113-q3hn pod pod-projected-secrets-4615d01c-6782-11e9-9f66-ae72f7f5c328 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:48:05.148: INFO: Waiting for pod pod-projected-secrets-4615d01c-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:48:05.152: INFO: Pod pod-projected-secrets-4615d01c-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:48:05.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zg85v" for this suite.
Apr 25 17:48:11.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:48:11.259: INFO: namespace: e2e-tests-projected-zg85v, resource: bindings, ignored listing per whitelist
Apr 25 17:48:11.273: INFO: namespace e2e-tests-projected-zg85v deletion completed in 6.117340594s

• [SLOW TEST:8.264 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:48:11.273: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:48:13.402: INFO: Waiting up to 5m0s for pod "client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-pods-x7xd2" to be "success or failure"
Apr 25 17:48:13.420: INFO: Pod "client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 17.763251ms
Apr 25 17:48:15.424: INFO: Pod "client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021873176s
Apr 25 17:48:17.428: INFO: Pod "client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025739643s
STEP: Saw pod success
Apr 25 17:48:17.428: INFO: Pod "client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:48:17.431: INFO: Trying to get logs from node test113-q3kz pod client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328 container env3cont: <nil>
STEP: delete the pod
Apr 25 17:48:17.453: INFO: Waiting for pod client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:48:17.461: INFO: Pod client-envvars-4c3a4430-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:48:17.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-x7xd2" for this suite.
Apr 25 17:48:55.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:48:55.508: INFO: namespace: e2e-tests-pods-x7xd2, resource: bindings, ignored listing per whitelist
Apr 25 17:48:55.561: INFO: namespace e2e-tests-pods-x7xd2 deletion completed in 38.097294974s

• [SLOW TEST:44.288 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:48:55.562: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 25 17:48:55.639: INFO: Waiting up to 5m0s for pod "downward-api-656929c5-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-shwmv" to be "success or failure"
Apr 25 17:48:55.651: INFO: Pod "downward-api-656929c5-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 11.81248ms
Apr 25 17:48:57.655: INFO: Pod "downward-api-656929c5-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01578119s
STEP: Saw pod success
Apr 25 17:48:57.655: INFO: Pod "downward-api-656929c5-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:48:57.659: INFO: Trying to get logs from node test113-q3hn pod downward-api-656929c5-6782-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 17:48:57.687: INFO: Waiting for pod downward-api-656929c5-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:48:57.693: INFO: Pod downward-api-656929c5-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:48:57.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-shwmv" for this suite.
Apr 25 17:49:03.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:49:03.744: INFO: namespace: e2e-tests-downward-api-shwmv, resource: bindings, ignored listing per whitelist
Apr 25 17:49:03.821: INFO: namespace e2e-tests-downward-api-shwmv deletion completed in 6.124880219s

• [SLOW TEST:8.259 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:49:03.821: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:49:04.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qxb7k" for this suite.
Apr 25 17:49:26.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:49:26.141: INFO: namespace: e2e-tests-kubelet-test-qxb7k, resource: bindings, ignored listing per whitelist
Apr 25 17:49:26.175: INFO: namespace e2e-tests-kubelet-test-qxb7k deletion completed in 22.136701392s

• [SLOW TEST:22.354 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:49:26.176: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0425 17:50:06.344226      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 25 17:50:06.344: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:50:06.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mqn2g" for this suite.
Apr 25 17:50:14.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:50:14.637: INFO: namespace: e2e-tests-gc-mqn2g, resource: bindings, ignored listing per whitelist
Apr 25 17:50:14.693: INFO: namespace e2e-tests-gc-mqn2g deletion completed in 8.34663838s

• [SLOW TEST:48.517 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:50:14.694: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328
Apr 25 17:50:14.836: INFO: Pod name my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328: Found 0 pods out of 1
Apr 25 17:50:19.840: INFO: Pod name my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328: Found 1 pods out of 1
Apr 25 17:50:19.840: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328" are running
Apr 25 17:50:19.842: INFO: Pod "my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328-8hvp2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:50:14 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:50:16 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:50:16 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-04-25 17:50:14 +0000 UTC Reason: Message:}])
Apr 25 17:50:19.842: INFO: Trying to dial the pod
Apr 25 17:50:24.882: INFO: Controller my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328: Got expected result from replica 1 [my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328-8hvp2]: "my-hostname-basic-949c34db-6782-11e9-9f66-ae72f7f5c328-8hvp2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:50:24.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-rzsgh" for this suite.
Apr 25 17:50:30.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:50:31.012: INFO: namespace: e2e-tests-replication-controller-rzsgh, resource: bindings, ignored listing per whitelist
Apr 25 17:50:31.017: INFO: namespace e2e-tests-replication-controller-rzsgh deletion completed in 6.12710631s

• [SLOW TEST:16.323 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:50:31.019: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:50:31.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-9hc24" to be "success or failure"
Apr 25 17:50:31.156: INFO: Pod "downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.800312ms
Apr 25 17:50:33.162: INFO: Pod "downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013302766s
Apr 25 17:50:35.166: INFO: Pod "downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01733951s
STEP: Saw pod success
Apr 25 17:50:35.166: INFO: Pod "downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:50:35.168: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:50:35.188: INFO: Waiting for pod downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:50:35.191: INFO: Pod downwardapi-volume-9e567846-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:50:35.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9hc24" for this suite.
Apr 25 17:50:41.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:50:41.256: INFO: namespace: e2e-tests-projected-9hc24, resource: bindings, ignored listing per whitelist
Apr 25 17:50:41.300: INFO: namespace e2e-tests-projected-9hc24 deletion completed in 6.104389189s

• [SLOW TEST:10.282 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:50:41.301: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:50:41.380: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-2gjp9" to be "success or failure"
Apr 25 17:50:41.395: INFO: Pod "downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 15.323675ms
Apr 25 17:50:43.399: INFO: Pod "downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.019139214s
Apr 25 17:50:45.403: INFO: Pod "downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023424969s
STEP: Saw pod success
Apr 25 17:50:45.403: INFO: Pod "downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:50:45.406: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:50:45.427: INFO: Waiting for pod downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:50:45.431: INFO: Pod downwardapi-volume-a46f0026-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:50:45.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2gjp9" for this suite.
Apr 25 17:50:51.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:50:51.496: INFO: namespace: e2e-tests-downward-api-2gjp9, resource: bindings, ignored listing per whitelist
Apr 25 17:50:51.542: INFO: namespace e2e-tests-downward-api-2gjp9 deletion completed in 6.107343206s

• [SLOW TEST:10.242 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:50:51.544: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:50:51.685: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aa920264-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-khwll" to be "success or failure"
Apr 25 17:50:51.695: INFO: Pod "downwardapi-volume-aa920264-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.555089ms
Apr 25 17:50:53.699: INFO: Pod "downwardapi-volume-aa920264-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0136884s
STEP: Saw pod success
Apr 25 17:50:53.699: INFO: Pod "downwardapi-volume-aa920264-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:50:53.702: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-aa920264-6782-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:50:53.727: INFO: Waiting for pod downwardapi-volume-aa920264-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:50:53.731: INFO: Pod downwardapi-volume-aa920264-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:50:53.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-khwll" for this suite.
Apr 25 17:50:59.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:50:59.822: INFO: namespace: e2e-tests-downward-api-khwll, resource: bindings, ignored listing per whitelist
Apr 25 17:50:59.848: INFO: namespace e2e-tests-downward-api-khwll deletion completed in 6.113030012s

• [SLOW TEST:8.304 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:50:59.849: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-ggdz7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ggdz7 to expose endpoints map[]
Apr 25 17:50:59.999: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ggdz7 exposes endpoints map[] (16.415023ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ggdz7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ggdz7 to expose endpoints map[pod1:[80]]
Apr 25 17:51:02.066: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ggdz7 exposes endpoints map[pod1:[80]] (2.050726748s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ggdz7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ggdz7 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 25 17:51:04.146: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ggdz7 exposes endpoints map[pod1:[80] pod2:[80]] (2.073263808s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ggdz7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ggdz7 to expose endpoints map[pod2:[80]]
Apr 25 17:51:05.233: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ggdz7 exposes endpoints map[pod2:[80]] (1.067643651s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ggdz7
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-ggdz7 to expose endpoints map[]
Apr 25 17:51:05.248: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-ggdz7 exposes endpoints map[] (9.520787ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:51:05.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ggdz7" for this suite.
Apr 25 17:51:27.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:51:27.326: INFO: namespace: e2e-tests-services-ggdz7, resource: bindings, ignored listing per whitelist
Apr 25 17:51:27.393: INFO: namespace e2e-tests-services-ggdz7 deletion completed in 22.098213064s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.544 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:51:27.394: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 25 17:51:27.476: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-sf5t9,SelfLink:/api/v1/namespaces/e2e-tests-watch-sf5t9/configmaps/e2e-watch-test-resource-version,UID:bfe9aa3d-6782-11e9-a8f1-82d29082e60b,ResourceVersion:34739,Generation:0,CreationTimestamp:2019-04-25 17:51:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 25 17:51:27.476: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-sf5t9,SelfLink:/api/v1/namespaces/e2e-tests-watch-sf5t9/configmaps/e2e-watch-test-resource-version,UID:bfe9aa3d-6782-11e9-a8f1-82d29082e60b,ResourceVersion:34740,Generation:0,CreationTimestamp:2019-04-25 17:51:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:51:27.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-sf5t9" for this suite.
Apr 25 17:51:33.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:51:33.559: INFO: namespace: e2e-tests-watch-sf5t9, resource: bindings, ignored listing per whitelist
Apr 25 17:51:33.597: INFO: namespace e2e-tests-watch-sf5t9 deletion completed in 6.118063327s

• [SLOW TEST:6.204 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:51:33.598: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:51:33.719: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-wxlgn" to be "success or failure"
Apr 25 17:51:33.745: INFO: Pod "downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 26.501155ms
Apr 25 17:51:35.750: INFO: Pod "downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.030940659s
Apr 25 17:51:37.754: INFO: Pod "downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035183954s
STEP: Saw pod success
Apr 25 17:51:37.754: INFO: Pod "downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:51:37.757: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:51:37.989: INFO: Waiting for pod downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:51:37.992: INFO: Pod downwardapi-volume-c3a23d91-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:51:37.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wxlgn" for this suite.
Apr 25 17:51:44.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:51:44.372: INFO: namespace: e2e-tests-projected-wxlgn, resource: bindings, ignored listing per whitelist
Apr 25 17:51:44.401: INFO: namespace e2e-tests-projected-wxlgn deletion completed in 6.405375609s

• [SLOW TEST:10.804 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:51:44.402: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:51:44.814: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-zjnnl" to be "success or failure"
Apr 25 17:51:44.855: INFO: Pod "downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 40.501989ms
Apr 25 17:51:46.859: INFO: Pod "downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.04500825s
Apr 25 17:51:48.863: INFO: Pod "downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048603819s
STEP: Saw pod success
Apr 25 17:51:48.863: INFO: Pod "downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:51:48.865: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:51:48.890: INFO: Waiting for pod downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:51:48.894: INFO: Pod downwardapi-volume-ca3d7078-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:51:48.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjnnl" for this suite.
Apr 25 17:51:54.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:51:54.949: INFO: namespace: e2e-tests-projected-zjnnl, resource: bindings, ignored listing per whitelist
Apr 25 17:51:55.071: INFO: namespace e2e-tests-projected-zjnnl deletion completed in 6.174274175s

• [SLOW TEST:10.670 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:51:55.072: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 25 17:51:55.189: INFO: Waiting up to 5m0s for pod "downward-api-d06e8d7e-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-878d8" to be "success or failure"
Apr 25 17:51:55.196: INFO: Pod "downward-api-d06e8d7e-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.558931ms
Apr 25 17:51:57.199: INFO: Pod "downward-api-d06e8d7e-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010234577s
STEP: Saw pod success
Apr 25 17:51:57.199: INFO: Pod "downward-api-d06e8d7e-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:51:57.202: INFO: Trying to get logs from node test113-q3hn pod downward-api-d06e8d7e-6782-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 17:51:57.225: INFO: Waiting for pod downward-api-d06e8d7e-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:51:57.229: INFO: Pod downward-api-d06e8d7e-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:51:57.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-878d8" for this suite.
Apr 25 17:52:03.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:52:03.327: INFO: namespace: e2e-tests-downward-api-878d8, resource: bindings, ignored listing per whitelist
Apr 25 17:52:03.357: INFO: namespace e2e-tests-downward-api-878d8 deletion completed in 6.125409181s

• [SLOW TEST:8.286 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:52:03.359: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-xqhnl/configmap-test-d5591637-6782-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:52:03.442: INFO: Waiting up to 5m0s for pod "pod-configmaps-d559b8db-6782-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-xqhnl" to be "success or failure"
Apr 25 17:52:03.453: INFO: Pod "pod-configmaps-d559b8db-6782-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 11.015837ms
Apr 25 17:52:05.458: INFO: Pod "pod-configmaps-d559b8db-6782-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015513869s
STEP: Saw pod success
Apr 25 17:52:05.458: INFO: Pod "pod-configmaps-d559b8db-6782-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:52:05.462: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-d559b8db-6782-11e9-9f66-ae72f7f5c328 container env-test: <nil>
STEP: delete the pod
Apr 25 17:52:05.492: INFO: Waiting for pod pod-configmaps-d559b8db-6782-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:52:05.497: INFO: Pod pod-configmaps-d559b8db-6782-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:52:05.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xqhnl" for this suite.
Apr 25 17:52:11.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:52:11.567: INFO: namespace: e2e-tests-configmap-xqhnl, resource: bindings, ignored listing per whitelist
Apr 25 17:52:11.630: INFO: namespace e2e-tests-configmap-xqhnl deletion completed in 6.128437975s

• [SLOW TEST:8.271 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:52:11.630: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:52:11.746: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 25 17:52:16.750: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 25 17:52:16.750: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 25 17:52:18.754: INFO: Creating deployment "test-rollover-deployment"
Apr 25 17:52:18.764: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 25 17:52:20.774: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 25 17:52:20.779: INFO: Ensure that both replica sets have 1 created replica
Apr 25 17:52:20.783: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 25 17:52:20.790: INFO: Updating deployment test-rollover-deployment
Apr 25 17:52:20.790: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 25 17:52:22.800: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 25 17:52:22.807: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 25 17:52:22.811: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 17:52:22.812: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811540, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 17:52:24.819: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 17:52:24.819: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811543, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 17:52:26.818: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 17:52:26.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811543, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 17:52:28.818: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 17:52:28.819: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811543, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 17:52:30.819: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 17:52:30.819: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811543, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 17:52:32.830: INFO: all replica sets need to contain the pod-template-hash label
Apr 25 17:52:32.830: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811543, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811538, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 17:52:34.819: INFO: 
Apr 25 17:52:34.819: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 25 17:52:34.827: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-9cfwz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9cfwz/deployments/test-rollover-deployment,UID:de7cdf1a-6782-11e9-a8f1-82d29082e60b,ResourceVersion:35086,Generation:2,CreationTimestamp:2019-04-25 17:52:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-25 17:52:18 +0000 UTC 2019-04-25 17:52:18 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-25 17:52:33 +0000 UTC 2019-04-25 17:52:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 25 17:52:34.830: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-9cfwz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9cfwz/replicasets/test-rollover-deployment-6b7f9d6597,UID:dfb36ccd-6782-11e9-a8f1-82d29082e60b,ResourceVersion:35076,Generation:2,CreationTimestamp:2019-04-25 17:52:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment de7cdf1a-6782-11e9-a8f1-82d29082e60b 0xc0015de4b7 0xc0015de4b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 25 17:52:34.830: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 25 17:52:34.830: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-9cfwz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9cfwz/replicasets/test-rollover-controller,UID:da48c192-6782-11e9-a8f1-82d29082e60b,ResourceVersion:35084,Generation:2,CreationTimestamp:2019-04-25 17:52:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment de7cdf1a-6782-11e9-a8f1-82d29082e60b 0xc0015de327 0xc0015de328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 25 17:52:34.830: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-9cfwz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9cfwz/replicasets/test-rollover-deployment-6586df867b,UID:de7ed76f-6782-11e9-a8f1-82d29082e60b,ResourceVersion:35035,Generation:2,CreationTimestamp:2019-04-25 17:52:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment de7cdf1a-6782-11e9-a8f1-82d29082e60b 0xc0015de3e7 0xc0015de3e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 25 17:52:34.834: INFO: Pod "test-rollover-deployment-6b7f9d6597-xlwpq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-xlwpq,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-9cfwz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9cfwz/pods/test-rollover-deployment-6b7f9d6597-xlwpq,UID:dfba701d-6782-11e9-a8f1-82d29082e60b,ResourceVersion:35055,Generation:0,CreationTimestamp:2019-04-25 17:52:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 dfb36ccd-6782-11e9-a8f1-82d29082e60b 0xc000ab4a47 0xc000ab4a48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-n9jbd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n9jbd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-n9jbd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ab4ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ab4ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:52:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:52:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:52:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 17:52:20 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:10.244.0.55,StartTime:2019-04-25 17:52:20 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-25 17:52:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://46935398466fd737a4a7c8f45bb278b9a8879b15d60ed900650c5dbc94f308fd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:52:34.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9cfwz" for this suite.
Apr 25 17:52:40.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:52:40.934: INFO: namespace: e2e-tests-deployment-9cfwz, resource: bindings, ignored listing per whitelist
Apr 25 17:52:40.976: INFO: namespace e2e-tests-deployment-9cfwz deletion completed in 6.139721728s

• [SLOW TEST:29.346 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:52:40.977: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 17:52:41.047: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:52:43.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-869xw" for this suite.
Apr 25 17:53:21.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:53:21.188: INFO: namespace: e2e-tests-pods-869xw, resource: bindings, ignored listing per whitelist
Apr 25 17:53:21.215: INFO: namespace e2e-tests-pods-869xw deletion completed in 38.115832931s

• [SLOW TEST:40.239 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:53:21.216: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-03c9572e-6783-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:53:21.367: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-03ca1fad-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-vtqbb" to be "success or failure"
Apr 25 17:53:21.389: INFO: Pod "pod-projected-configmaps-03ca1fad-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 22.235205ms
Apr 25 17:53:23.394: INFO: Pod "pod-projected-configmaps-03ca1fad-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027259199s
STEP: Saw pod success
Apr 25 17:53:23.394: INFO: Pod "pod-projected-configmaps-03ca1fad-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:53:23.397: INFO: Trying to get logs from node test113-q3hn pod pod-projected-configmaps-03ca1fad-6783-11e9-9f66-ae72f7f5c328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 17:53:23.424: INFO: Waiting for pod pod-projected-configmaps-03ca1fad-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:53:23.428: INFO: Pod pod-projected-configmaps-03ca1fad-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:53:23.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vtqbb" for this suite.
Apr 25 17:53:29.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:53:29.480: INFO: namespace: e2e-tests-projected-vtqbb, resource: bindings, ignored listing per whitelist
Apr 25 17:53:29.547: INFO: namespace e2e-tests-projected-vtqbb deletion completed in 6.114714324s

• [SLOW TEST:8.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:53:29.549: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 25 17:53:29.644: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l2c6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-l2c6n/configmaps/e2e-watch-test-label-changed,UID:08bb9393-6783-11e9-a8f1-82d29082e60b,ResourceVersion:35290,Generation:0,CreationTimestamp:2019-04-25 17:53:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 25 17:53:29.644: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l2c6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-l2c6n/configmaps/e2e-watch-test-label-changed,UID:08bb9393-6783-11e9-a8f1-82d29082e60b,ResourceVersion:35291,Generation:0,CreationTimestamp:2019-04-25 17:53:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 25 17:53:29.644: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l2c6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-l2c6n/configmaps/e2e-watch-test-label-changed,UID:08bb9393-6783-11e9-a8f1-82d29082e60b,ResourceVersion:35292,Generation:0,CreationTimestamp:2019-04-25 17:53:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 25 17:53:39.716: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l2c6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-l2c6n/configmaps/e2e-watch-test-label-changed,UID:08bb9393-6783-11e9-a8f1-82d29082e60b,ResourceVersion:35308,Generation:0,CreationTimestamp:2019-04-25 17:53:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 25 17:53:39.716: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l2c6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-l2c6n/configmaps/e2e-watch-test-label-changed,UID:08bb9393-6783-11e9-a8f1-82d29082e60b,ResourceVersion:35309,Generation:0,CreationTimestamp:2019-04-25 17:53:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 25 17:53:39.716: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-l2c6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-l2c6n/configmaps/e2e-watch-test-label-changed,UID:08bb9393-6783-11e9-a8f1-82d29082e60b,ResourceVersion:35310,Generation:0,CreationTimestamp:2019-04-25 17:53:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:53:39.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-l2c6n" for this suite.
Apr 25 17:53:45.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:53:45.823: INFO: namespace: e2e-tests-watch-l2c6n, resource: bindings, ignored listing per whitelist
Apr 25 17:53:45.838: INFO: namespace e2e-tests-watch-l2c6n deletion completed in 6.118004969s

• [SLOW TEST:16.289 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:53:45.839: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:53:45.997: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-b7844" to be "success or failure"
Apr 25 17:53:46.008: INFO: Pod "downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 11.278285ms
Apr 25 17:53:48.012: INFO: Pod "downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01514136s
Apr 25 17:53:50.016: INFO: Pod "downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018751452s
STEP: Saw pod success
Apr 25 17:53:50.016: INFO: Pod "downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:53:50.018: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:53:50.041: INFO: Waiting for pod downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:53:50.044: INFO: Pod downwardapi-volume-12798c98-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:53:50.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b7844" for this suite.
Apr 25 17:53:56.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:53:56.093: INFO: namespace: e2e-tests-downward-api-b7844, resource: bindings, ignored listing per whitelist
Apr 25 17:53:56.171: INFO: namespace e2e-tests-downward-api-b7844 deletion completed in 6.12335315s

• [SLOW TEST:10.332 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:53:56.171: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-189fac6c-6783-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:53:56.316: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-kqlpx" to be "success or failure"
Apr 25 17:53:56.324: INFO: Pod "pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.790071ms
Apr 25 17:53:58.329: INFO: Pod "pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.013317958s
Apr 25 17:54:00.335: INFO: Pod "pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018695928s
STEP: Saw pod success
Apr 25 17:54:00.335: INFO: Pod "pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:54:00.341: INFO: Trying to get logs from node test113-q3hn pod pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:54:00.391: INFO: Waiting for pod pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:54:00.405: INFO: Pod pod-projected-secrets-18a042e1-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:54:00.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kqlpx" for this suite.
Apr 25 17:54:06.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:54:06.483: INFO: namespace: e2e-tests-projected-kqlpx, resource: bindings, ignored listing per whitelist
Apr 25 17:54:06.536: INFO: namespace e2e-tests-projected-kqlpx deletion completed in 6.12503095s

• [SLOW TEST:10.365 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:54:06.536: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-1ecb4e7c-6783-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 17:54:06.666: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1ecbf159-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-v68pm" to be "success or failure"
Apr 25 17:54:06.684: INFO: Pod "pod-projected-configmaps-1ecbf159-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 17.70945ms
Apr 25 17:54:08.687: INFO: Pod "pod-projected-configmaps-1ecbf159-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021136631s
STEP: Saw pod success
Apr 25 17:54:08.687: INFO: Pod "pod-projected-configmaps-1ecbf159-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:54:08.690: INFO: Trying to get logs from node test113-q3hn pod pod-projected-configmaps-1ecbf159-6783-11e9-9f66-ae72f7f5c328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 17:54:08.747: INFO: Waiting for pod pod-projected-configmaps-1ecbf159-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:54:08.750: INFO: Pod pod-projected-configmaps-1ecbf159-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:54:08.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v68pm" for this suite.
Apr 25 17:54:14.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:54:14.847: INFO: namespace: e2e-tests-projected-v68pm, resource: bindings, ignored listing per whitelist
Apr 25 17:54:15.026: INFO: namespace e2e-tests-projected-v68pm deletion completed in 6.271873395s

• [SLOW TEST:8.490 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:54:15.028: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0425 17:54:16.594606      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 25 17:54:16.594: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:54:16.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-977qn" for this suite.
Apr 25 17:54:22.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:54:22.778: INFO: namespace: e2e-tests-gc-977qn, resource: bindings, ignored listing per whitelist
Apr 25 17:54:22.915: INFO: namespace e2e-tests-gc-977qn deletion completed in 6.317024338s

• [SLOW TEST:7.888 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:54:22.916: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-28954562-6783-11e9-9f66-ae72f7f5c328
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:54:27.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kttsj" for this suite.
Apr 25 17:54:49.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:54:49.298: INFO: namespace: e2e-tests-configmap-kttsj, resource: bindings, ignored listing per whitelist
Apr 25 17:54:49.321: INFO: namespace e2e-tests-configmap-kttsj deletion completed in 22.194236805s

• [SLOW TEST:26.405 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:54:49.321: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-jslnc
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-jslnc
STEP: Deleting pre-stop pod
Apr 25 17:55:00.514: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:55:00.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-jslnc" for this suite.
Apr 25 17:55:38.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:55:38.638: INFO: namespace: e2e-tests-prestop-jslnc, resource: bindings, ignored listing per whitelist
Apr 25 17:55:38.645: INFO: namespace e2e-tests-prestop-jslnc deletion completed in 38.120852197s

• [SLOW TEST:49.324 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:55:38.645: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:55:38.797: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55b554a3-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-s5nfh" to be "success or failure"
Apr 25 17:55:38.806: INFO: Pod "downwardapi-volume-55b554a3-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.606786ms
Apr 25 17:55:40.812: INFO: Pod "downwardapi-volume-55b554a3-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015423467s
STEP: Saw pod success
Apr 25 17:55:40.812: INFO: Pod "downwardapi-volume-55b554a3-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:55:40.815: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-55b554a3-6783-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:55:40.844: INFO: Waiting for pod downwardapi-volume-55b554a3-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:55:40.847: INFO: Pod downwardapi-volume-55b554a3-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:55:40.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s5nfh" for this suite.
Apr 25 17:55:46.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:55:46.943: INFO: namespace: e2e-tests-projected-s5nfh, resource: bindings, ignored listing per whitelist
Apr 25 17:55:46.967: INFO: namespace e2e-tests-projected-s5nfh deletion completed in 6.115834024s

• [SLOW TEST:8.322 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:55:46.968: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-fssck
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 25 17:55:47.038: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 25 17:56:11.167: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.0.59 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fssck PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 17:56:11.167: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 17:56:12.349: INFO: Found all expected endpoints: [netserver-0]
Apr 25 17:56:12.353: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.2.130 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fssck PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 17:56:12.353: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 17:56:13.562: INFO: Found all expected endpoints: [netserver-1]
Apr 25 17:56:13.566: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.244.1.27 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fssck PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 17:56:13.566: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 17:56:14.772: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:56:14.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-fssck" for this suite.
Apr 25 17:56:36.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:56:36.864: INFO: namespace: e2e-tests-pod-network-test-fssck, resource: bindings, ignored listing per whitelist
Apr 25 17:56:36.873: INFO: namespace e2e-tests-pod-network-test-fssck deletion completed in 22.096113s

• [SLOW TEST:49.905 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:56:36.874: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-6k4sm
I0425 17:56:36.939142      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-6k4sm, replica count: 1
I0425 17:56:37.989921      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0425 17:56:38.990344      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 25 17:56:39.113: INFO: Created: latency-svc-kk9rr
Apr 25 17:56:39.123: INFO: Got endpoints: latency-svc-kk9rr [32.965746ms]
Apr 25 17:56:39.174: INFO: Created: latency-svc-6k9d8
Apr 25 17:56:39.196: INFO: Created: latency-svc-qfv9f
Apr 25 17:56:39.210: INFO: Got endpoints: latency-svc-6k9d8 [85.987178ms]
Apr 25 17:56:39.232: INFO: Created: latency-svc-h4mbg
Apr 25 17:56:39.232: INFO: Got endpoints: latency-svc-qfv9f [107.903002ms]
Apr 25 17:56:39.252: INFO: Got endpoints: latency-svc-h4mbg [128.458845ms]
Apr 25 17:56:39.270: INFO: Created: latency-svc-2fk97
Apr 25 17:56:39.284: INFO: Got endpoints: latency-svc-2fk97 [160.408081ms]
Apr 25 17:56:39.303: INFO: Created: latency-svc-pqk4z
Apr 25 17:56:39.315: INFO: Got endpoints: latency-svc-pqk4z [82.919608ms]
Apr 25 17:56:39.347: INFO: Created: latency-svc-cx8g6
Apr 25 17:56:39.361: INFO: Created: latency-svc-qq9nj
Apr 25 17:56:39.363: INFO: Got endpoints: latency-svc-cx8g6 [239.076685ms]
Apr 25 17:56:39.382: INFO: Got endpoints: latency-svc-qq9nj [258.432752ms]
Apr 25 17:56:39.426: INFO: Created: latency-svc-khgtg
Apr 25 17:56:39.445: INFO: Got endpoints: latency-svc-khgtg [321.516188ms]
Apr 25 17:56:39.476: INFO: Created: latency-svc-vgz7x
Apr 25 17:56:39.516: INFO: Got endpoints: latency-svc-vgz7x [391.807922ms]
Apr 25 17:56:39.530: INFO: Created: latency-svc-b7mws
Apr 25 17:56:39.544: INFO: Got endpoints: latency-svc-b7mws [420.078501ms]
Apr 25 17:56:39.588: INFO: Created: latency-svc-h6l95
Apr 25 17:56:39.630: INFO: Created: latency-svc-v5sh2
Apr 25 17:56:39.656: INFO: Got endpoints: latency-svc-h6l95 [532.403046ms]
Apr 25 17:56:39.669: INFO: Got endpoints: latency-svc-v5sh2 [544.758804ms]
Apr 25 17:56:39.712: INFO: Created: latency-svc-btxzg
Apr 25 17:56:39.716: INFO: Got endpoints: latency-svc-btxzg [592.27702ms]
Apr 25 17:56:39.746: INFO: Created: latency-svc-hd4pb
Apr 25 17:56:39.800: INFO: Created: latency-svc-nr472
Apr 25 17:56:39.800: INFO: Got endpoints: latency-svc-hd4pb [675.69758ms]
Apr 25 17:56:39.811: INFO: Created: latency-svc-fj8ht
Apr 25 17:56:39.841: INFO: Got endpoints: latency-svc-fj8ht [716.982127ms]
Apr 25 17:56:39.841: INFO: Got endpoints: latency-svc-nr472 [717.105201ms]
Apr 25 17:56:39.871: INFO: Created: latency-svc-2lgls
Apr 25 17:56:39.882: INFO: Got endpoints: latency-svc-2lgls [672.782512ms]
Apr 25 17:56:39.890: INFO: Created: latency-svc-mxmj2
Apr 25 17:56:39.911: INFO: Got endpoints: latency-svc-mxmj2 [659.158753ms]
Apr 25 17:56:39.921: INFO: Created: latency-svc-ws5sq
Apr 25 17:56:39.952: INFO: Got endpoints: latency-svc-ws5sq [667.228393ms]
Apr 25 17:56:39.952: INFO: Created: latency-svc-mctxj
Apr 25 17:56:39.973: INFO: Created: latency-svc-h8wcg
Apr 25 17:56:39.990: INFO: Got endpoints: latency-svc-mctxj [674.616487ms]
Apr 25 17:56:39.993: INFO: Got endpoints: latency-svc-h8wcg [629.687915ms]
Apr 25 17:56:40.011: INFO: Created: latency-svc-c8fw6
Apr 25 17:56:40.024: INFO: Created: latency-svc-g9xwv
Apr 25 17:56:40.032: INFO: Got endpoints: latency-svc-c8fw6 [648.657757ms]
Apr 25 17:56:40.043: INFO: Got endpoints: latency-svc-g9xwv [597.019669ms]
Apr 25 17:56:40.068: INFO: Created: latency-svc-jcxr2
Apr 25 17:56:40.086: INFO: Created: latency-svc-5ctbv
Apr 25 17:56:40.091: INFO: Got endpoints: latency-svc-jcxr2 [575.39628ms]
Apr 25 17:56:40.106: INFO: Got endpoints: latency-svc-5ctbv [561.887441ms]
Apr 25 17:56:40.145: INFO: Created: latency-svc-lvkmm
Apr 25 17:56:40.175: INFO: Created: latency-svc-7mjrt
Apr 25 17:56:40.176: INFO: Got endpoints: latency-svc-lvkmm [519.340367ms]
Apr 25 17:56:40.187: INFO: Got endpoints: latency-svc-7mjrt [518.253387ms]
Apr 25 17:56:40.210: INFO: Created: latency-svc-825w9
Apr 25 17:56:40.228: INFO: Got endpoints: latency-svc-825w9 [511.344187ms]
Apr 25 17:56:40.238: INFO: Created: latency-svc-9z9p6
Apr 25 17:56:40.252: INFO: Got endpoints: latency-svc-9z9p6 [452.596749ms]
Apr 25 17:56:40.271: INFO: Created: latency-svc-lsbls
Apr 25 17:56:40.289: INFO: Created: latency-svc-pns89
Apr 25 17:56:40.299: INFO: Got endpoints: latency-svc-lsbls [458.043566ms]
Apr 25 17:56:40.323: INFO: Created: latency-svc-bcxvg
Apr 25 17:56:40.330: INFO: Got endpoints: latency-svc-pns89 [489.15569ms]
Apr 25 17:56:40.355: INFO: Got endpoints: latency-svc-bcxvg [472.492819ms]
Apr 25 17:56:40.362: INFO: Created: latency-svc-6tmcg
Apr 25 17:56:40.366: INFO: Got endpoints: latency-svc-6tmcg [454.151166ms]
Apr 25 17:56:40.374: INFO: Created: latency-svc-f47bt
Apr 25 17:56:40.386: INFO: Got endpoints: latency-svc-f47bt [434.323657ms]
Apr 25 17:56:40.392: INFO: Created: latency-svc-wkz7k
Apr 25 17:56:40.413: INFO: Created: latency-svc-6f7cf
Apr 25 17:56:40.419: INFO: Got endpoints: latency-svc-wkz7k [429.107779ms]
Apr 25 17:56:40.440: INFO: Created: latency-svc-5ph8r
Apr 25 17:56:40.442: INFO: Got endpoints: latency-svc-6f7cf [449.079711ms]
Apr 25 17:56:40.462: INFO: Got endpoints: latency-svc-5ph8r [430.299864ms]
Apr 25 17:56:40.477: INFO: Created: latency-svc-8f8kt
Apr 25 17:56:40.488: INFO: Got endpoints: latency-svc-8f8kt [445.517206ms]
Apr 25 17:56:40.499: INFO: Created: latency-svc-fkdq5
Apr 25 17:56:40.513: INFO: Got endpoints: latency-svc-fkdq5 [422.104603ms]
Apr 25 17:56:40.522: INFO: Created: latency-svc-6d2px
Apr 25 17:56:40.550: INFO: Got endpoints: latency-svc-6d2px [444.320605ms]
Apr 25 17:56:40.556: INFO: Created: latency-svc-vbldg
Apr 25 17:56:40.570: INFO: Got endpoints: latency-svc-vbldg [392.987132ms]
Apr 25 17:56:40.583: INFO: Created: latency-svc-8mmkc
Apr 25 17:56:40.602: INFO: Got endpoints: latency-svc-8mmkc [414.906712ms]
Apr 25 17:56:40.605: INFO: Created: latency-svc-hd2nd
Apr 25 17:56:40.609: INFO: Got endpoints: latency-svc-hd2nd [381.537607ms]
Apr 25 17:56:40.623: INFO: Created: latency-svc-tb226
Apr 25 17:56:40.632: INFO: Got endpoints: latency-svc-tb226 [379.771329ms]
Apr 25 17:56:40.652: INFO: Created: latency-svc-b4mfb
Apr 25 17:56:40.682: INFO: Got endpoints: latency-svc-b4mfb [382.455745ms]
Apr 25 17:56:40.682: INFO: Created: latency-svc-69dcm
Apr 25 17:56:40.696: INFO: Got endpoints: latency-svc-69dcm [365.547412ms]
Apr 25 17:56:40.712: INFO: Created: latency-svc-lcdlj
Apr 25 17:56:40.729: INFO: Got endpoints: latency-svc-lcdlj [374.176378ms]
Apr 25 17:56:40.739: INFO: Created: latency-svc-w4hqt
Apr 25 17:56:40.758: INFO: Got endpoints: latency-svc-w4hqt [392.597067ms]
Apr 25 17:56:40.769: INFO: Created: latency-svc-p6hff
Apr 25 17:56:40.786: INFO: Got endpoints: latency-svc-p6hff [399.764698ms]
Apr 25 17:56:40.801: INFO: Created: latency-svc-fg99m
Apr 25 17:56:40.818: INFO: Got endpoints: latency-svc-fg99m [399.505394ms]
Apr 25 17:56:40.831: INFO: Created: latency-svc-5vr4w
Apr 25 17:56:40.866: INFO: Got endpoints: latency-svc-5vr4w [423.978191ms]
Apr 25 17:56:40.866: INFO: Created: latency-svc-294p7
Apr 25 17:56:40.874: INFO: Got endpoints: latency-svc-294p7 [411.701129ms]
Apr 25 17:56:40.901: INFO: Created: latency-svc-w5fsg
Apr 25 17:56:40.918: INFO: Got endpoints: latency-svc-w5fsg [429.394095ms]
Apr 25 17:56:40.928: INFO: Created: latency-svc-2c9vd
Apr 25 17:56:40.946: INFO: Created: latency-svc-szt8s
Apr 25 17:56:40.952: INFO: Got endpoints: latency-svc-2c9vd [438.574715ms]
Apr 25 17:56:40.963: INFO: Got endpoints: latency-svc-szt8s [412.891938ms]
Apr 25 17:56:40.978: INFO: Created: latency-svc-d5ms8
Apr 25 17:56:40.999: INFO: Created: latency-svc-lwtt8
Apr 25 17:56:41.006: INFO: Got endpoints: latency-svc-d5ms8 [436.181196ms]
Apr 25 17:56:41.028: INFO: Created: latency-svc-g87vc
Apr 25 17:56:41.033: INFO: Got endpoints: latency-svc-lwtt8 [430.844324ms]
Apr 25 17:56:41.052: INFO: Created: latency-svc-d4trw
Apr 25 17:56:41.066: INFO: Got endpoints: latency-svc-g87vc [456.224043ms]
Apr 25 17:56:41.072: INFO: Got endpoints: latency-svc-d4trw [439.565338ms]
Apr 25 17:56:41.087: INFO: Created: latency-svc-xbg6z
Apr 25 17:56:41.098: INFO: Got endpoints: latency-svc-xbg6z [416.318836ms]
Apr 25 17:56:41.117: INFO: Created: latency-svc-knvc6
Apr 25 17:56:41.133: INFO: Created: latency-svc-kzrp6
Apr 25 17:56:41.139: INFO: Got endpoints: latency-svc-knvc6 [443.14429ms]
Apr 25 17:56:41.151: INFO: Created: latency-svc-ctjv9
Apr 25 17:56:41.161: INFO: Got endpoints: latency-svc-kzrp6 [431.961552ms]
Apr 25 17:56:41.172: INFO: Got endpoints: latency-svc-ctjv9 [413.592872ms]
Apr 25 17:56:41.185: INFO: Created: latency-svc-zwb5g
Apr 25 17:56:41.194: INFO: Got endpoints: latency-svc-zwb5g [408.194159ms]
Apr 25 17:56:41.207: INFO: Created: latency-svc-jxp8v
Apr 25 17:56:41.219: INFO: Created: latency-svc-p8nhg
Apr 25 17:56:41.230: INFO: Got endpoints: latency-svc-p8nhg [363.789593ms]
Apr 25 17:56:41.230: INFO: Got endpoints: latency-svc-jxp8v [411.180899ms]
Apr 25 17:56:41.240: INFO: Created: latency-svc-f97cv
Apr 25 17:56:41.273: INFO: Got endpoints: latency-svc-f97cv [398.41506ms]
Apr 25 17:56:41.286: INFO: Created: latency-svc-7cn5x
Apr 25 17:56:41.293: INFO: Got endpoints: latency-svc-7cn5x [375.497835ms]
Apr 25 17:56:41.308: INFO: Created: latency-svc-jdlgv
Apr 25 17:56:41.318: INFO: Created: latency-svc-2wc5q
Apr 25 17:56:41.329: INFO: Got endpoints: latency-svc-jdlgv [376.327335ms]
Apr 25 17:56:41.340: INFO: Got endpoints: latency-svc-2wc5q [376.877023ms]
Apr 25 17:56:41.361: INFO: Created: latency-svc-9v858
Apr 25 17:56:41.368: INFO: Created: latency-svc-v7pg8
Apr 25 17:56:41.386: INFO: Got endpoints: latency-svc-v7pg8 [352.413569ms]
Apr 25 17:56:41.386: INFO: Got endpoints: latency-svc-9v858 [379.506193ms]
Apr 25 17:56:41.400: INFO: Created: latency-svc-9dnnd
Apr 25 17:56:41.409: INFO: Got endpoints: latency-svc-9dnnd [342.712756ms]
Apr 25 17:56:41.418: INFO: Created: latency-svc-xhzvq
Apr 25 17:56:41.438: INFO: Got endpoints: latency-svc-xhzvq [366.077437ms]
Apr 25 17:56:41.449: INFO: Created: latency-svc-n8kts
Apr 25 17:56:41.471: INFO: Got endpoints: latency-svc-n8kts [372.274914ms]
Apr 25 17:56:41.484: INFO: Created: latency-svc-6k2hh
Apr 25 17:56:41.487: INFO: Got endpoints: latency-svc-6k2hh [347.522659ms]
Apr 25 17:56:41.507: INFO: Created: latency-svc-fm9nt
Apr 25 17:56:41.525: INFO: Created: latency-svc-x9vnj
Apr 25 17:56:41.534: INFO: Created: latency-svc-s2m67
Apr 25 17:56:41.537: INFO: Got endpoints: latency-svc-fm9nt [376.046003ms]
Apr 25 17:56:41.564: INFO: Created: latency-svc-7qcs5
Apr 25 17:56:41.581: INFO: Created: latency-svc-n8r6n
Apr 25 17:56:41.593: INFO: Got endpoints: latency-svc-x9vnj [420.90457ms]
Apr 25 17:56:41.616: INFO: Created: latency-svc-mgt6n
Apr 25 17:56:41.635: INFO: Created: latency-svc-cfvhs
Apr 25 17:56:41.638: INFO: Got endpoints: latency-svc-s2m67 [443.772181ms]
Apr 25 17:56:41.668: INFO: Created: latency-svc-8j8hb
Apr 25 17:56:41.693: INFO: Created: latency-svc-hzjvs
Apr 25 17:56:41.697: INFO: Got endpoints: latency-svc-7qcs5 [467.4917ms]
Apr 25 17:56:41.719: INFO: Created: latency-svc-pwxd5
Apr 25 17:56:41.733: INFO: Got endpoints: latency-svc-n8r6n [503.066487ms]
Apr 25 17:56:41.752: INFO: Created: latency-svc-wp269
Apr 25 17:56:41.766: INFO: Created: latency-svc-28qlw
Apr 25 17:56:41.792: INFO: Got endpoints: latency-svc-mgt6n [519.387713ms]
Apr 25 17:56:41.807: INFO: Created: latency-svc-fsbkq
Apr 25 17:56:41.826: INFO: Created: latency-svc-xr4l4
Apr 25 17:56:41.844: INFO: Created: latency-svc-jkmjr
Apr 25 17:56:41.849: INFO: Got endpoints: latency-svc-cfvhs [555.786571ms]
Apr 25 17:56:41.871: INFO: Created: latency-svc-72dnl
Apr 25 17:56:41.885: INFO: Created: latency-svc-hhpcv
Apr 25 17:56:41.897: INFO: Created: latency-svc-2wlvc
Apr 25 17:56:41.899: INFO: Got endpoints: latency-svc-8j8hb [570.13008ms]
Apr 25 17:56:41.930: INFO: Created: latency-svc-tztqv
Apr 25 17:56:41.935: INFO: Got endpoints: latency-svc-hzjvs [594.200283ms]
Apr 25 17:56:41.966: INFO: Created: latency-svc-s6298
Apr 25 17:56:41.980: INFO: Created: latency-svc-n748m
Apr 25 17:56:41.993: INFO: Created: latency-svc-d4pmv
Apr 25 17:56:41.999: INFO: Got endpoints: latency-svc-pwxd5 [613.141916ms]
Apr 25 17:56:42.014: INFO: Created: latency-svc-2t484
Apr 25 17:56:42.032: INFO: Created: latency-svc-d6tx2
Apr 25 17:56:42.045: INFO: Got endpoints: latency-svc-wp269 [659.032616ms]
Apr 25 17:56:42.055: INFO: Created: latency-svc-css9d
Apr 25 17:56:42.082: INFO: Created: latency-svc-4gj8r
Apr 25 17:56:42.094: INFO: Got endpoints: latency-svc-28qlw [685.577484ms]
Apr 25 17:56:42.150: INFO: Got endpoints: latency-svc-fsbkq [711.961747ms]
Apr 25 17:56:42.189: INFO: Created: latency-svc-4whtq
Apr 25 17:56:42.207: INFO: Got endpoints: latency-svc-xr4l4 [736.590847ms]
Apr 25 17:56:42.219: INFO: Created: latency-svc-6vx45
Apr 25 17:56:42.242: INFO: Got endpoints: latency-svc-jkmjr [755.339017ms]
Apr 25 17:56:42.254: INFO: Created: latency-svc-wcxrm
Apr 25 17:56:42.275: INFO: Created: latency-svc-vdrhr
Apr 25 17:56:42.285: INFO: Got endpoints: latency-svc-72dnl [747.364466ms]
Apr 25 17:56:42.344: INFO: Got endpoints: latency-svc-hhpcv [750.795262ms]
Apr 25 17:56:42.372: INFO: Created: latency-svc-fqn8l
Apr 25 17:56:42.409: INFO: Got endpoints: latency-svc-2wlvc [770.664625ms]
Apr 25 17:56:42.440: INFO: Created: latency-svc-zj7zw
Apr 25 17:56:42.451: INFO: Got endpoints: latency-svc-tztqv [753.378098ms]
Apr 25 17:56:42.488: INFO: Got endpoints: latency-svc-s6298 [754.862343ms]
Apr 25 17:56:42.507: INFO: Created: latency-svc-rnmgw
Apr 25 17:56:42.544: INFO: Created: latency-svc-6x4zd
Apr 25 17:56:42.550: INFO: Got endpoints: latency-svc-n748m [757.371133ms]
Apr 25 17:56:42.566: INFO: Created: latency-svc-mlnfk
Apr 25 17:56:42.582: INFO: Created: latency-svc-xqj2d
Apr 25 17:56:42.584: INFO: Got endpoints: latency-svc-d4pmv [735.271507ms]
Apr 25 17:56:42.616: INFO: Created: latency-svc-cqwng
Apr 25 17:56:42.627: INFO: Got endpoints: latency-svc-2t484 [728.416459ms]
Apr 25 17:56:42.666: INFO: Created: latency-svc-qvpjj
Apr 25 17:56:42.684: INFO: Got endpoints: latency-svc-d6tx2 [749.01979ms]
Apr 25 17:56:42.704: INFO: Created: latency-svc-s8x2f
Apr 25 17:56:42.733: INFO: Got endpoints: latency-svc-css9d [734.197348ms]
Apr 25 17:56:42.784: INFO: Created: latency-svc-rzrgv
Apr 25 17:56:42.785: INFO: Got endpoints: latency-svc-4gj8r [740.273979ms]
Apr 25 17:56:42.837: INFO: Created: latency-svc-c2mqg
Apr 25 17:56:42.843: INFO: Got endpoints: latency-svc-4whtq [748.637189ms]
Apr 25 17:56:42.868: INFO: Created: latency-svc-mbvhh
Apr 25 17:56:42.884: INFO: Got endpoints: latency-svc-6vx45 [733.975296ms]
Apr 25 17:56:42.908: INFO: Created: latency-svc-q74l7
Apr 25 17:56:42.926: INFO: Got endpoints: latency-svc-wcxrm [719.178178ms]
Apr 25 17:56:42.961: INFO: Created: latency-svc-vs9sw
Apr 25 17:56:42.987: INFO: Got endpoints: latency-svc-vdrhr [745.183256ms]
Apr 25 17:56:43.012: INFO: Created: latency-svc-cj22h
Apr 25 17:56:43.030: INFO: Got endpoints: latency-svc-fqn8l [745.019948ms]
Apr 25 17:56:43.068: INFO: Created: latency-svc-n55cg
Apr 25 17:56:43.081: INFO: Got endpoints: latency-svc-zj7zw [737.450461ms]
Apr 25 17:56:43.117: INFO: Created: latency-svc-7vfkc
Apr 25 17:56:43.128: INFO: Got endpoints: latency-svc-rnmgw [718.970347ms]
Apr 25 17:56:43.155: INFO: Created: latency-svc-b5nfg
Apr 25 17:56:43.183: INFO: Got endpoints: latency-svc-6x4zd [732.395914ms]
Apr 25 17:56:43.222: INFO: Created: latency-svc-wflfh
Apr 25 17:56:43.228: INFO: Got endpoints: latency-svc-mlnfk [739.730806ms]
Apr 25 17:56:43.261: INFO: Created: latency-svc-qjcb8
Apr 25 17:56:43.281: INFO: Got endpoints: latency-svc-xqj2d [731.38304ms]
Apr 25 17:56:43.324: INFO: Created: latency-svc-cjbnf
Apr 25 17:56:43.336: INFO: Got endpoints: latency-svc-cqwng [751.243967ms]
Apr 25 17:56:43.362: INFO: Created: latency-svc-7pf75
Apr 25 17:56:43.379: INFO: Got endpoints: latency-svc-qvpjj [752.012498ms]
Apr 25 17:56:43.407: INFO: Created: latency-svc-4ssdg
Apr 25 17:56:43.431: INFO: Got endpoints: latency-svc-s8x2f [746.986856ms]
Apr 25 17:56:43.503: INFO: Got endpoints: latency-svc-rzrgv [770.267317ms]
Apr 25 17:56:43.511: INFO: Created: latency-svc-pkq7m
Apr 25 17:56:43.545: INFO: Got endpoints: latency-svc-c2mqg [760.404538ms]
Apr 25 17:56:43.574: INFO: Created: latency-svc-hd55c
Apr 25 17:56:43.600: INFO: Created: latency-svc-qqwls
Apr 25 17:56:43.609: INFO: Got endpoints: latency-svc-mbvhh [765.98852ms]
Apr 25 17:56:43.630: INFO: Created: latency-svc-7glnw
Apr 25 17:56:43.642: INFO: Got endpoints: latency-svc-q74l7 [757.475248ms]
Apr 25 17:56:43.667: INFO: Created: latency-svc-mw2lg
Apr 25 17:56:43.713: INFO: Got endpoints: latency-svc-vs9sw [786.088145ms]
Apr 25 17:56:43.737: INFO: Created: latency-svc-rr7f5
Apr 25 17:56:43.742: INFO: Got endpoints: latency-svc-cj22h [754.240335ms]
Apr 25 17:56:43.767: INFO: Created: latency-svc-79b2f
Apr 25 17:56:43.778: INFO: Got endpoints: latency-svc-n55cg [747.704187ms]
Apr 25 17:56:43.806: INFO: Created: latency-svc-966qz
Apr 25 17:56:43.834: INFO: Got endpoints: latency-svc-7vfkc [752.805494ms]
Apr 25 17:56:43.860: INFO: Created: latency-svc-7brkq
Apr 25 17:56:43.880: INFO: Got endpoints: latency-svc-b5nfg [751.782426ms]
Apr 25 17:56:43.914: INFO: Created: latency-svc-jrnwq
Apr 25 17:56:43.951: INFO: Got endpoints: latency-svc-wflfh [767.523902ms]
Apr 25 17:56:44.006: INFO: Got endpoints: latency-svc-qjcb8 [777.285044ms]
Apr 25 17:56:44.063: INFO: Got endpoints: latency-svc-cjbnf [782.389462ms]
Apr 25 17:56:44.101: INFO: Created: latency-svc-j7r6x
Apr 25 17:56:44.133: INFO: Got endpoints: latency-svc-7pf75 [796.892892ms]
Apr 25 17:56:44.258: INFO: Got endpoints: latency-svc-4ssdg [878.839638ms]
Apr 25 17:56:44.287: INFO: Got endpoints: latency-svc-pkq7m [856.239546ms]
Apr 25 17:56:44.288: INFO: Created: latency-svc-7gzb7
Apr 25 17:56:44.350: INFO: Got endpoints: latency-svc-hd55c [846.597572ms]
Apr 25 17:56:44.351: INFO: Created: latency-svc-kzfkg
Apr 25 17:56:44.361: INFO: Got endpoints: latency-svc-qqwls [815.908325ms]
Apr 25 17:56:44.375: INFO: Got endpoints: latency-svc-7glnw [765.87926ms]
Apr 25 17:56:44.399: INFO: Created: latency-svc-vqftj
Apr 25 17:56:44.407: INFO: Got endpoints: latency-svc-mw2lg [765.669ms]
Apr 25 17:56:44.434: INFO: Created: latency-svc-cv5wl
Apr 25 17:56:44.449: INFO: Got endpoints: latency-svc-rr7f5 [736.732176ms]
Apr 25 17:56:44.460: INFO: Created: latency-svc-vg9ps
Apr 25 17:56:44.490: INFO: Got endpoints: latency-svc-79b2f [748.11783ms]
Apr 25 17:56:44.534: INFO: Created: latency-svc-5btwn
Apr 25 17:56:44.580: INFO: Got endpoints: latency-svc-966qz [801.975858ms]
Apr 25 17:56:44.600: INFO: Created: latency-svc-cgqfj
Apr 25 17:56:44.600: INFO: Got endpoints: latency-svc-7brkq [765.479556ms]
Apr 25 17:56:44.624: INFO: Created: latency-svc-99d6h
Apr 25 17:56:44.681: INFO: Created: latency-svc-c9jxb
Apr 25 17:56:44.699: INFO: Got endpoints: latency-svc-j7r6x [747.314975ms]
Apr 25 17:56:44.699: INFO: Got endpoints: latency-svc-jrnwq [818.895366ms]
Apr 25 17:56:44.726: INFO: Created: latency-svc-vgnfk
Apr 25 17:56:44.740: INFO: Got endpoints: latency-svc-7gzb7 [677.010304ms]
Apr 25 17:56:44.757: INFO: Created: latency-svc-6xl92
Apr 25 17:56:44.771: INFO: Created: latency-svc-7nws7
Apr 25 17:56:44.787: INFO: Got endpoints: latency-svc-kzfkg [780.824868ms]
Apr 25 17:56:44.823: INFO: Created: latency-svc-6cqzs
Apr 25 17:56:44.842: INFO: Got endpoints: latency-svc-vqftj [708.83016ms]
Apr 25 17:56:44.872: INFO: Created: latency-svc-g76js
Apr 25 17:56:44.886: INFO: Created: latency-svc-l8tn9
Apr 25 17:56:44.894: INFO: Got endpoints: latency-svc-cv5wl [635.224525ms]
Apr 25 17:56:44.949: INFO: Created: latency-svc-dj9ts
Apr 25 17:56:44.954: INFO: Got endpoints: latency-svc-vg9ps [666.641232ms]
Apr 25 17:56:44.982: INFO: Created: latency-svc-rz8h6
Apr 25 17:56:44.992: INFO: Got endpoints: latency-svc-5btwn [642.008507ms]
Apr 25 17:56:45.020: INFO: Created: latency-svc-nnzrv
Apr 25 17:56:45.044: INFO: Got endpoints: latency-svc-cgqfj [594.451731ms]
Apr 25 17:56:45.063: INFO: Created: latency-svc-mjjrd
Apr 25 17:56:45.076: INFO: Created: latency-svc-6rwws
Apr 25 17:56:45.087: INFO: Got endpoints: latency-svc-99d6h [726.020701ms]
Apr 25 17:56:45.099: INFO: Created: latency-svc-f8dgp
Apr 25 17:56:45.122: INFO: Created: latency-svc-ksxf5
Apr 25 17:56:45.151: INFO: Got endpoints: latency-svc-c9jxb [775.819186ms]
Apr 25 17:56:45.165: INFO: Created: latency-svc-dpzzz
Apr 25 17:56:45.194: INFO: Got endpoints: latency-svc-vgnfk [786.513554ms]
Apr 25 17:56:45.203: INFO: Created: latency-svc-c6s29
Apr 25 17:56:45.238: INFO: Created: latency-svc-5z6wt
Apr 25 17:56:45.255: INFO: Got endpoints: latency-svc-6xl92 [764.980279ms]
Apr 25 17:56:45.292: INFO: Got endpoints: latency-svc-7nws7 [712.046412ms]
Apr 25 17:56:45.294: INFO: Created: latency-svc-kdw8h
Apr 25 17:56:45.319: INFO: Created: latency-svc-cn6m4
Apr 25 17:56:45.354: INFO: Got endpoints: latency-svc-6cqzs [754.71627ms]
Apr 25 17:56:45.423: INFO: Got endpoints: latency-svc-g76js [724.164391ms]
Apr 25 17:56:45.436: INFO: Created: latency-svc-hzmzn
Apr 25 17:56:45.466: INFO: Got endpoints: latency-svc-l8tn9 [767.287816ms]
Apr 25 17:56:45.545: INFO: Got endpoints: latency-svc-dj9ts [804.309879ms]
Apr 25 17:56:45.572: INFO: Created: latency-svc-hm2px
Apr 25 17:56:45.581: INFO: Got endpoints: latency-svc-rz8h6 [793.915487ms]
Apr 25 17:56:45.677: INFO: Got endpoints: latency-svc-nnzrv [834.580417ms]
Apr 25 17:56:45.689: INFO: Created: latency-svc-wh5f9
Apr 25 17:56:45.709: INFO: Got endpoints: latency-svc-mjjrd [815.153776ms]
Apr 25 17:56:45.732: INFO: Got endpoints: latency-svc-6rwws [778.388202ms]
Apr 25 17:56:45.753: INFO: Created: latency-svc-hcwg9
Apr 25 17:56:45.785: INFO: Got endpoints: latency-svc-f8dgp [792.171762ms]
Apr 25 17:56:45.816: INFO: Got endpoints: latency-svc-ksxf5 [771.996801ms]
Apr 25 17:56:45.833: INFO: Created: latency-svc-x6pzh
Apr 25 17:56:45.906: INFO: Got endpoints: latency-svc-dpzzz [818.209545ms]
Apr 25 17:56:45.927: INFO: Created: latency-svc-bkfh2
Apr 25 17:56:45.942: INFO: Got endpoints: latency-svc-c6s29 [790.723146ms]
Apr 25 17:56:45.962: INFO: Got endpoints: latency-svc-5z6wt [768.421627ms]
Apr 25 17:56:45.972: INFO: Created: latency-svc-rjmx2
Apr 25 17:56:45.993: INFO: Created: latency-svc-7knfs
Apr 25 17:56:45.994: INFO: Got endpoints: latency-svc-kdw8h [739.487294ms]
Apr 25 17:56:46.019: INFO: Created: latency-svc-gd4qp
Apr 25 17:56:46.036: INFO: Created: latency-svc-6x58h
Apr 25 17:56:46.041: INFO: Got endpoints: latency-svc-cn6m4 [749.08714ms]
Apr 25 17:56:46.072: INFO: Created: latency-svc-rkcps
Apr 25 17:56:46.083: INFO: Got endpoints: latency-svc-hzmzn [728.506945ms]
Apr 25 17:56:46.095: INFO: Created: latency-svc-4xfq9
Apr 25 17:56:46.130: INFO: Created: latency-svc-qj6bg
Apr 25 17:56:46.147: INFO: Got endpoints: latency-svc-hm2px [724.104332ms]
Apr 25 17:56:46.161: INFO: Created: latency-svc-hv97k
Apr 25 17:56:46.179: INFO: Created: latency-svc-hz7ht
Apr 25 17:56:46.191: INFO: Got endpoints: latency-svc-wh5f9 [724.829789ms]
Apr 25 17:56:46.202: INFO: Created: latency-svc-wxx5t
Apr 25 17:56:46.224: INFO: Created: latency-svc-vqhjs
Apr 25 17:56:46.260: INFO: Created: latency-svc-sf5fb
Apr 25 17:56:46.260: INFO: Got endpoints: latency-svc-hcwg9 [714.95438ms]
Apr 25 17:56:46.301: INFO: Got endpoints: latency-svc-x6pzh [719.863465ms]
Apr 25 17:56:46.301: INFO: Created: latency-svc-prdzj
Apr 25 17:56:46.346: INFO: Created: latency-svc-k85zm
Apr 25 17:56:46.350: INFO: Got endpoints: latency-svc-bkfh2 [673.275553ms]
Apr 25 17:56:46.378: INFO: Created: latency-svc-vqt7b
Apr 25 17:56:46.387: INFO: Got endpoints: latency-svc-rjmx2 [570.185245ms]
Apr 25 17:56:46.417: INFO: Created: latency-svc-2xlvv
Apr 25 17:56:46.427: INFO: Got endpoints: latency-svc-7knfs [717.829109ms]
Apr 25 17:56:46.458: INFO: Created: latency-svc-vg4xh
Apr 25 17:56:46.479: INFO: Got endpoints: latency-svc-gd4qp [746.893969ms]
Apr 25 17:56:46.508: INFO: Created: latency-svc-2kn54
Apr 25 17:56:46.527: INFO: Got endpoints: latency-svc-6x58h [742.712736ms]
Apr 25 17:56:46.558: INFO: Created: latency-svc-pmkfw
Apr 25 17:56:46.584: INFO: Got endpoints: latency-svc-rkcps [678.217238ms]
Apr 25 17:56:46.613: INFO: Created: latency-svc-xj5mz
Apr 25 17:56:46.634: INFO: Got endpoints: latency-svc-4xfq9 [691.228312ms]
Apr 25 17:56:46.662: INFO: Created: latency-svc-dptn9
Apr 25 17:56:46.694: INFO: Got endpoints: latency-svc-qj6bg [731.007445ms]
Apr 25 17:56:46.720: INFO: Created: latency-svc-gtdj5
Apr 25 17:56:46.727: INFO: Got endpoints: latency-svc-hv97k [732.614343ms]
Apr 25 17:56:46.756: INFO: Created: latency-svc-5c7cp
Apr 25 17:56:46.780: INFO: Got endpoints: latency-svc-hz7ht [738.752302ms]
Apr 25 17:56:46.804: INFO: Created: latency-svc-kxcl8
Apr 25 17:56:46.830: INFO: Got endpoints: latency-svc-wxx5t [746.554045ms]
Apr 25 17:56:46.870: INFO: Created: latency-svc-c7pp4
Apr 25 17:56:46.879: INFO: Got endpoints: latency-svc-vqhjs [731.831888ms]
Apr 25 17:56:46.926: INFO: Created: latency-svc-xvv4q
Apr 25 17:56:46.931: INFO: Got endpoints: latency-svc-sf5fb [739.57368ms]
Apr 25 17:56:46.959: INFO: Created: latency-svc-9bmvx
Apr 25 17:56:46.982: INFO: Got endpoints: latency-svc-prdzj [721.712181ms]
Apr 25 17:56:47.031: INFO: Got endpoints: latency-svc-k85zm [730.143901ms]
Apr 25 17:56:47.085: INFO: Got endpoints: latency-svc-vqt7b [735.239788ms]
Apr 25 17:56:47.134: INFO: Got endpoints: latency-svc-2xlvv [747.614305ms]
Apr 25 17:56:47.182: INFO: Got endpoints: latency-svc-vg4xh [754.946655ms]
Apr 25 17:56:47.228: INFO: Got endpoints: latency-svc-2kn54 [748.936366ms]
Apr 25 17:56:47.286: INFO: Got endpoints: latency-svc-pmkfw [758.389832ms]
Apr 25 17:56:47.328: INFO: Got endpoints: latency-svc-xj5mz [744.33117ms]
Apr 25 17:56:47.383: INFO: Got endpoints: latency-svc-dptn9 [749.346151ms]
Apr 25 17:56:47.432: INFO: Got endpoints: latency-svc-gtdj5 [738.281778ms]
Apr 25 17:56:47.479: INFO: Got endpoints: latency-svc-5c7cp [751.800562ms]
Apr 25 17:56:47.532: INFO: Got endpoints: latency-svc-kxcl8 [751.577804ms]
Apr 25 17:56:47.586: INFO: Got endpoints: latency-svc-c7pp4 [756.211565ms]
Apr 25 17:56:47.630: INFO: Got endpoints: latency-svc-xvv4q [750.865345ms]
Apr 25 17:56:47.679: INFO: Got endpoints: latency-svc-9bmvx [748.685445ms]
Apr 25 17:56:47.680: INFO: Latencies: [82.919608ms 85.987178ms 107.903002ms 128.458845ms 160.408081ms 239.076685ms 258.432752ms 321.516188ms 342.712756ms 347.522659ms 352.413569ms 363.789593ms 365.547412ms 366.077437ms 372.274914ms 374.176378ms 375.497835ms 376.046003ms 376.327335ms 376.877023ms 379.506193ms 379.771329ms 381.537607ms 382.455745ms 391.807922ms 392.597067ms 392.987132ms 398.41506ms 399.505394ms 399.764698ms 408.194159ms 411.180899ms 411.701129ms 412.891938ms 413.592872ms 414.906712ms 416.318836ms 420.078501ms 420.90457ms 422.104603ms 423.978191ms 429.107779ms 429.394095ms 430.299864ms 430.844324ms 431.961552ms 434.323657ms 436.181196ms 438.574715ms 439.565338ms 443.14429ms 443.772181ms 444.320605ms 445.517206ms 449.079711ms 452.596749ms 454.151166ms 456.224043ms 458.043566ms 467.4917ms 472.492819ms 489.15569ms 503.066487ms 511.344187ms 518.253387ms 519.340367ms 519.387713ms 532.403046ms 544.758804ms 555.786571ms 561.887441ms 570.13008ms 570.185245ms 575.39628ms 592.27702ms 594.200283ms 594.451731ms 597.019669ms 613.141916ms 629.687915ms 635.224525ms 642.008507ms 648.657757ms 659.032616ms 659.158753ms 666.641232ms 667.228393ms 672.782512ms 673.275553ms 674.616487ms 675.69758ms 677.010304ms 678.217238ms 685.577484ms 691.228312ms 708.83016ms 711.961747ms 712.046412ms 714.95438ms 716.982127ms 717.105201ms 717.829109ms 718.970347ms 719.178178ms 719.863465ms 721.712181ms 724.104332ms 724.164391ms 724.829789ms 726.020701ms 728.416459ms 728.506945ms 730.143901ms 731.007445ms 731.38304ms 731.831888ms 732.395914ms 732.614343ms 733.975296ms 734.197348ms 735.239788ms 735.271507ms 736.590847ms 736.732176ms 737.450461ms 738.281778ms 738.752302ms 739.487294ms 739.57368ms 739.730806ms 740.273979ms 742.712736ms 744.33117ms 745.019948ms 745.183256ms 746.554045ms 746.893969ms 746.986856ms 747.314975ms 747.364466ms 747.614305ms 747.704187ms 748.11783ms 748.637189ms 748.685445ms 748.936366ms 749.01979ms 749.08714ms 749.346151ms 750.795262ms 750.865345ms 751.243967ms 751.577804ms 751.782426ms 751.800562ms 752.012498ms 752.805494ms 753.378098ms 754.240335ms 754.71627ms 754.862343ms 754.946655ms 755.339017ms 756.211565ms 757.371133ms 757.475248ms 758.389832ms 760.404538ms 764.980279ms 765.479556ms 765.669ms 765.87926ms 765.98852ms 767.287816ms 767.523902ms 768.421627ms 770.267317ms 770.664625ms 771.996801ms 775.819186ms 777.285044ms 778.388202ms 780.824868ms 782.389462ms 786.088145ms 786.513554ms 790.723146ms 792.171762ms 793.915487ms 796.892892ms 801.975858ms 804.309879ms 815.153776ms 815.908325ms 818.209545ms 818.895366ms 834.580417ms 846.597572ms 856.239546ms 878.839638ms]
Apr 25 17:56:47.680: INFO: 50 %ile: 717.105201ms
Apr 25 17:56:47.680: INFO: 90 %ile: 777.285044ms
Apr 25 17:56:47.680: INFO: 99 %ile: 856.239546ms
Apr 25 17:56:47.680: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:56:47.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-6k4sm" for this suite.
Apr 25 17:57:07.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:57:07.743: INFO: namespace: e2e-tests-svc-latency-6k4sm, resource: bindings, ignored listing per whitelist
Apr 25 17:57:07.804: INFO: namespace e2e-tests-svc-latency-6k4sm deletion completed in 20.106280257s

• [SLOW TEST:30.930 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:57:07.805: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-8ad63c26-6783-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 17:57:07.928: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-psstg" to be "success or failure"
Apr 25 17:57:07.935: INFO: Pod "pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.318842ms
Apr 25 17:57:09.938: INFO: Pod "pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010540878s
Apr 25 17:57:11.942: INFO: Pod "pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014227553s
STEP: Saw pod success
Apr 25 17:57:11.942: INFO: Pod "pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:57:11.945: INFO: Trying to get logs from node test113-q3hn pod pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 25 17:57:11.978: INFO: Waiting for pod pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:57:11.982: INFO: Pod pod-projected-secrets-8ad6c419-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:57:11.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-psstg" for this suite.
Apr 25 17:57:17.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:57:18.015: INFO: namespace: e2e-tests-projected-psstg, resource: bindings, ignored listing per whitelist
Apr 25 17:57:18.080: INFO: namespace e2e-tests-projected-psstg deletion completed in 6.093853128s

• [SLOW TEST:10.275 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:57:18.080: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Apr 25 17:57:18.213: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:57:22.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8mb29" for this suite.
Apr 25 17:57:28.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:57:28.761: INFO: namespace: e2e-tests-init-container-8mb29, resource: bindings, ignored listing per whitelist
Apr 25 17:57:28.828: INFO: namespace e2e-tests-init-container-8mb29 deletion completed in 6.156290796s

• [SLOW TEST:10.748 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:57:28.829: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 17:57:29.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-977c73b7-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-6586t" to be "success or failure"
Apr 25 17:57:29.172: INFO: Pod "downwardapi-volume-977c73b7-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 14.368215ms
Apr 25 17:57:31.175: INFO: Pod "downwardapi-volume-977c73b7-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01758112s
STEP: Saw pod success
Apr 25 17:57:31.175: INFO: Pod "downwardapi-volume-977c73b7-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:57:31.177: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-977c73b7-6783-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 17:57:31.199: INFO: Waiting for pod downwardapi-volume-977c73b7-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:57:31.202: INFO: Pod downwardapi-volume-977c73b7-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:57:31.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6586t" for this suite.
Apr 25 17:57:37.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:57:37.278: INFO: namespace: e2e-tests-downward-api-6586t, resource: bindings, ignored listing per whitelist
Apr 25 17:57:37.367: INFO: namespace e2e-tests-downward-api-6586t deletion completed in 6.161881169s

• [SLOW TEST:8.539 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:57:37.368: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qfwqd
Apr 25 17:57:41.616: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qfwqd
STEP: checking the pod's current state and verifying that restartCount is present
Apr 25 17:57:41.619: INFO: Initial restart count of pod liveness-http is 0
Apr 25 17:58:01.660: INFO: Restart count of pod e2e-tests-container-probe-qfwqd/liveness-http is now 1 (20.041491105s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:58:01.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qfwqd" for this suite.
Apr 25 17:58:07.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:58:07.746: INFO: namespace: e2e-tests-container-probe-qfwqd, resource: bindings, ignored listing per whitelist
Apr 25 17:58:07.806: INFO: namespace e2e-tests-container-probe-qfwqd deletion completed in 6.110861206s

• [SLOW TEST:30.438 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:58:07.806: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Apr 25 17:58:09.964: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-ae9b68ad-6783-11e9-9f66-ae72f7f5c328", GenerateName:"", Namespace:"e2e-tests-pods-xbvqm", SelfLink:"/api/v1/namespaces/e2e-tests-pods-xbvqm/pods/pod-submit-remove-ae9b68ad-6783-11e9-9f66-ae72f7f5c328", UID:"ae9de410-6783-11e9-a8f1-82d29082e60b", ResourceVersion:"37842", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691811887, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"930800697"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5vzlm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002483500), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5vzlm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0027ae668), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"test113-q3hn", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0027d2a80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0027ae6b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0027ae6d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0027ae6d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0027ae6dc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811887, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811889, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811889, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691811887, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.138.46.141", PodIP:"10.244.1.112", StartTime:(*v1.Time)(0xc00299b2c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00299b2e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://9122276aa8308235397e2f35e4af53f1a95b2c7b01d9dde16a4fa2aa7f34972a"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:58:16.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xbvqm" for this suite.
Apr 25 17:58:22.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:58:22.086: INFO: namespace: e2e-tests-pods-xbvqm, resource: bindings, ignored listing per whitelist
Apr 25 17:58:22.148: INFO: namespace e2e-tests-pods-xbvqm deletion completed in 6.115482707s

• [SLOW TEST:14.342 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:58:22.149: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Apr 25 17:58:22.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 api-versions'
Apr 25 17:58:22.307: INFO: stderr: ""
Apr 25 17:58:22.307: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncilium.io/v2\ncoordination.k8s.io/v1beta1\ncsi.storage.k8s.io/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:58:22.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hx5m5" for this suite.
Apr 25 17:58:28.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:58:28.346: INFO: namespace: e2e-tests-kubectl-hx5m5, resource: bindings, ignored listing per whitelist
Apr 25 17:58:28.409: INFO: namespace e2e-tests-kubectl-hx5m5 deletion completed in 6.098443533s

• [SLOW TEST:6.261 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:58:28.410: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-kclb
STEP: Creating a pod to test atomic-volume-subpath
Apr 25 17:58:28.540: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-kclb" in namespace "e2e-tests-subpath-c7ntt" to be "success or failure"
Apr 25 17:58:28.551: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.780825ms
Apr 25 17:58:30.555: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014671551s
Apr 25 17:58:32.560: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 4.019700262s
Apr 25 17:58:34.568: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 6.027438133s
Apr 25 17:58:36.571: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 8.031082367s
Apr 25 17:58:38.575: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 10.035046805s
Apr 25 17:58:40.579: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 12.038934291s
Apr 25 17:58:42.583: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 14.04309606s
Apr 25 17:58:44.587: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 16.047161013s
Apr 25 17:58:46.664: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 18.123452667s
Apr 25 17:58:48.667: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 20.127118365s
Apr 25 17:58:50.671: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Running", Reason="", readiness=false. Elapsed: 22.131156091s
Apr 25 17:58:52.675: INFO: Pod "pod-subpath-test-secret-kclb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.13494724s
STEP: Saw pod success
Apr 25 17:58:52.675: INFO: Pod "pod-subpath-test-secret-kclb" satisfied condition "success or failure"
Apr 25 17:58:52.678: INFO: Trying to get logs from node test113-q3kz pod pod-subpath-test-secret-kclb container test-container-subpath-secret-kclb: <nil>
STEP: delete the pod
Apr 25 17:58:52.929: INFO: Waiting for pod pod-subpath-test-secret-kclb to disappear
Apr 25 17:58:52.934: INFO: Pod pod-subpath-test-secret-kclb no longer exists
STEP: Deleting pod pod-subpath-test-secret-kclb
Apr 25 17:58:52.934: INFO: Deleting pod "pod-subpath-test-secret-kclb" in namespace "e2e-tests-subpath-c7ntt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:58:52.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-c7ntt" for this suite.
Apr 25 17:58:58.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:58:59.021: INFO: namespace: e2e-tests-subpath-c7ntt, resource: bindings, ignored listing per whitelist
Apr 25 17:58:59.184: INFO: namespace e2e-tests-subpath-c7ntt deletion completed in 6.244533825s

• [SLOW TEST:30.774 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:58:59.184: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Apr 25 17:58:59.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 create -f - --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:00.062: INFO: stderr: ""
Apr 25 17:59:00.062: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 25 17:59:00.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:00.143: INFO: stderr: ""
Apr 25 17:59:00.143: INFO: stdout: "update-demo-nautilus-jtzwt update-demo-nautilus-qgqvg "
Apr 25 17:59:00.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-jtzwt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:00.228: INFO: stderr: ""
Apr 25 17:59:00.228: INFO: stdout: ""
Apr 25 17:59:00.228: INFO: update-demo-nautilus-jtzwt is created but not running
Apr 25 17:59:05.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:05.309: INFO: stderr: ""
Apr 25 17:59:05.309: INFO: stdout: "update-demo-nautilus-jtzwt update-demo-nautilus-qgqvg "
Apr 25 17:59:05.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-jtzwt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:05.392: INFO: stderr: ""
Apr 25 17:59:05.392: INFO: stdout: "true"
Apr 25 17:59:05.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-jtzwt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:05.473: INFO: stderr: ""
Apr 25 17:59:05.473: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:59:05.473: INFO: validating pod update-demo-nautilus-jtzwt
Apr 25 17:59:05.482: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:59:05.482: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:59:05.482: INFO: update-demo-nautilus-jtzwt is verified up and running
Apr 25 17:59:05.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qgqvg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:05.562: INFO: stderr: ""
Apr 25 17:59:05.562: INFO: stdout: "true"
Apr 25 17:59:05.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-nautilus-qgqvg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:05.647: INFO: stderr: ""
Apr 25 17:59:05.647: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 25 17:59:05.647: INFO: validating pod update-demo-nautilus-qgqvg
Apr 25 17:59:05.657: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 25 17:59:05.657: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 25 17:59:05.657: INFO: update-demo-nautilus-qgqvg is verified up and running
STEP: rolling-update to new replication controller
Apr 25 17:59:05.658: INFO: scanned /root for discovery docs: <nil>
Apr 25 17:59:05.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:28.162: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 25 17:59:28.162: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 25 17:59:28.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:28.231: INFO: stderr: ""
Apr 25 17:59:28.231: INFO: stdout: "update-demo-kitten-2wl79 update-demo-kitten-lgbzk "
Apr 25 17:59:28.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-kitten-2wl79 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:28.320: INFO: stderr: ""
Apr 25 17:59:28.320: INFO: stdout: "true"
Apr 25 17:59:28.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-kitten-2wl79 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:28.421: INFO: stderr: ""
Apr 25 17:59:28.421: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 25 17:59:28.421: INFO: validating pod update-demo-kitten-2wl79
Apr 25 17:59:28.430: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 25 17:59:28.430: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 25 17:59:28.430: INFO: update-demo-kitten-2wl79 is verified up and running
Apr 25 17:59:28.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-kitten-lgbzk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:28.513: INFO: stderr: ""
Apr 25 17:59:28.513: INFO: stdout: "true"
Apr 25 17:59:28.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods update-demo-kitten-lgbzk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sdt9l'
Apr 25 17:59:28.589: INFO: stderr: ""
Apr 25 17:59:28.589: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 25 17:59:28.589: INFO: validating pod update-demo-kitten-lgbzk
Apr 25 17:59:28.597: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 25 17:59:28.598: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 25 17:59:28.598: INFO: update-demo-kitten-lgbzk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:59:28.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sdt9l" for this suite.
Apr 25 17:59:50.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 17:59:50.680: INFO: namespace: e2e-tests-kubectl-sdt9l, resource: bindings, ignored listing per whitelist
Apr 25 17:59:50.706: INFO: namespace e2e-tests-kubectl-sdt9l deletion completed in 22.102664048s

• [SLOW TEST:51.522 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 17:59:50.706: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Apr 25 17:59:50.849: INFO: Waiting up to 5m0s for pod "downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-kmmmj" to be "success or failure"
Apr 25 17:59:50.862: INFO: Pod "downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 12.891512ms
Apr 25 17:59:52.866: INFO: Pod "downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017040148s
Apr 25 17:59:54.871: INFO: Pod "downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022161003s
STEP: Saw pod success
Apr 25 17:59:54.872: INFO: Pod "downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 17:59:54.885: INFO: Trying to get logs from node test113-q3hn pod downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 17:59:54.909: INFO: Waiting for pod downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 17:59:54.912: INFO: Pod downward-api-ebf1c2a1-6783-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 17:59:54.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kmmmj" for this suite.
Apr 25 18:00:00.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:00:00.961: INFO: namespace: e2e-tests-downward-api-kmmmj, resource: bindings, ignored listing per whitelist
Apr 25 18:00:01.020: INFO: namespace e2e-tests-downward-api-kmmmj deletion completed in 6.104159435s

• [SLOW TEST:10.314 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:00:01.020: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 25 18:00:03.136: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-f2113e75-6783-11e9-9f66-ae72f7f5c328,GenerateName:,Namespace:e2e-tests-events-fqjgj,SelfLink:/api/v1/namespaces/e2e-tests-events-fqjgj/pods/send-events-f2113e75-6783-11e9-9f66-ae72f7f5c328,UID:f2135afb-6783-11e9-a8f1-82d29082e60b,ResourceVersion:38324,Generation:0,CreationTimestamp:2019-04-25 18:00:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 110391202,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-78mv9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-78mv9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-78mv9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3hn,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022a9830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a9850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:00:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:00:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:00:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:00:01 +0000 UTC  }],Message:,Reason:,HostIP:10.138.46.141,PodIP:10.244.1.152,StartTime:2019-04-25 18:00:01 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-04-25 18:00:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://5df3877e590859a721234fec875f10b5876503b2569920bf03ecdab54b6199c8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Apr 25 18:00:05.140: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 25 18:00:07.150: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:00:07.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-fqjgj" for this suite.
Apr 25 18:00:47.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:00:47.216: INFO: namespace: e2e-tests-events-fqjgj, resource: bindings, ignored listing per whitelist
Apr 25 18:00:47.277: INFO: namespace e2e-tests-events-fqjgj deletion completed in 40.107063201s

• [SLOW TEST:46.258 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:00:47.280: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Apr 25 18:00:51.911: INFO: Successfully updated pod "annotationupdate0da0b9d1-6784-11e9-9f66-ae72f7f5c328"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:00:53.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-84dp7" for this suite.
Apr 25 18:01:15.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:01:16.054: INFO: namespace: e2e-tests-downward-api-84dp7, resource: bindings, ignored listing per whitelist
Apr 25 18:01:16.060: INFO: namespace e2e-tests-downward-api-84dp7 deletion completed in 22.117860708s

• [SLOW TEST:28.781 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:01:16.061: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Apr 25 18:01:16.193: INFO: Waiting up to 5m0s for pod "client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-containers-jlxsp" to be "success or failure"
Apr 25 18:01:16.206: INFO: Pod "client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 13.093164ms
Apr 25 18:01:18.210: INFO: Pod "client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017050013s
Apr 25 18:01:20.215: INFO: Pod "client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021534921s
STEP: Saw pod success
Apr 25 18:01:20.215: INFO: Pod "client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:01:20.218: INFO: Trying to get logs from node test113-q3hn pod client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 18:01:20.249: INFO: Waiting for pod client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:01:20.256: INFO: Pod client-containers-1ed0df8c-6784-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:01:20.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jlxsp" for this suite.
Apr 25 18:01:26.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:01:26.349: INFO: namespace: e2e-tests-containers-jlxsp, resource: bindings, ignored listing per whitelist
Apr 25 18:01:26.382: INFO: namespace e2e-tests-containers-jlxsp deletion completed in 6.10854741s

• [SLOW TEST:10.321 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:01:26.383: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Apr 25 18:01:26.512: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 25 18:01:26.520: INFO: Waiting for terminating namespaces to be deleted...
Apr 25 18:01:26.523: INFO: 
Logging pods the kubelet thinks is on node test113-q3hn before test
Apr 25 18:01:26.531: INFO: kube-proxy-dplbd from kube-system started at 2019-04-25 16:15:55 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.531: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 18:01:26.531: INFO: csi-do-node-7jfmk from kube-system started at 2019-04-25 16:16:16 +0000 UTC (2 container statuses recorded)
Apr 25 18:01:26.531: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 18:01:26.532: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 18:01:26.532: INFO: do-node-agent-jwjhn from kube-system started at 2019-04-25 16:16:16 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.532: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 18:01:26.532: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-wpdwt from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 18:01:26.532: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 25 18:01:26.532: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 25 18:01:26.532: INFO: cilium-qrhts from kube-system started at 2019-04-25 16:15:55 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.532: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 18:01:26.532: INFO: sonobuoy from heptio-sonobuoy started at 2019-04-25 16:36:41 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.532: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 25 18:01:26.532: INFO: 
Logging pods the kubelet thinks is on node test113-q3k9 before test
Apr 25 18:01:26.542: INFO: cilium-operator-7c9bd57c88-lstbs from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 25 18:01:26.542: INFO: do-node-agent-fxrn4 from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 18:01:26.542: INFO: csi-do-node-dznmp from kube-system started at 2019-04-25 16:15:57 +0000 UTC (2 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 18:01:26.542: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 25 18:01:26.542: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8kx8h from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 25 18:01:26.542: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 25 18:01:26.542: INFO: coredns-5d668bd598-xfpfd from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container coredns ready: true, restart count 0
Apr 25 18:01:26.542: INFO: coredns-5d668bd598-pmwb2 from kube-system started at 2019-04-25 16:15:57 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container coredns ready: true, restart count 0
Apr 25 18:01:26.542: INFO: cilium-rcnl7 from kube-system started at 2019-04-25 16:15:37 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 18:01:26.542: INFO: kube-proxy-v8p4s from kube-system started at 2019-04-25 16:15:37 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.542: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 18:01:26.542: INFO: 
Logging pods the kubelet thinks is on node test113-q3kz before test
Apr 25 18:01:26.552: INFO: sonobuoy-e2e-job-a1b0a7332f284308 from heptio-sonobuoy started at 2019-04-25 16:36:44 +0000 UTC (2 container statuses recorded)
Apr 25 18:01:26.552: INFO: 	Container e2e ready: true, restart count 0
Apr 25 18:01:26.552: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 25 18:01:26.552: INFO: cilium-jsp4p from kube-system started at 2019-04-25 16:15:58 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.552: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 25 18:01:26.552: INFO: sonobuoy-systemd-logs-daemon-set-39bcd96082344561-8skg7 from heptio-sonobuoy started at 2019-04-25 16:36:45 +0000 UTC (2 container statuses recorded)
Apr 25 18:01:26.552: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Apr 25 18:01:26.552: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 25 18:01:26.552: INFO: do-node-agent-5475d from kube-system started at 2019-04-25 16:16:19 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.552: INFO: 	Container do-node-agent ready: true, restart count 0
Apr 25 18:01:26.552: INFO: kube-proxy-qntk9 from kube-system started at 2019-04-25 16:15:58 +0000 UTC (1 container statuses recorded)
Apr 25 18:01:26.552: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 25 18:01:26.552: INFO: csi-do-node-cbct5 from kube-system started at 2019-04-25 16:16:19 +0000 UTC (2 container statuses recorded)
Apr 25 18:01:26.552: INFO: 	Container csi-do-plugin ready: true, restart count 0
Apr 25 18:01:26.552: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1598c98ed73d9f21], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:01:27.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mpf6m" for this suite.
Apr 25 18:01:33.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:01:33.653: INFO: namespace: e2e-tests-sched-pred-mpf6m, resource: bindings, ignored listing per whitelist
Apr 25 18:01:33.695: INFO: namespace e2e-tests-sched-pred-mpf6m deletion completed in 6.106450823s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.312 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:01:33.695: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Apr 25 18:01:33.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 --namespace=e2e-tests-kubectl-wpp7v run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 25 18:01:35.876: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 25 18:01:35.876: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:01:37.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wpp7v" for this suite.
Apr 25 18:01:47.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:01:47.978: INFO: namespace: e2e-tests-kubectl-wpp7v, resource: bindings, ignored listing per whitelist
Apr 25 18:01:48.012: INFO: namespace e2e-tests-kubectl-wpp7v deletion completed in 10.125896782s

• [SLOW TEST:14.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:01:48.012: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 25 18:01:48.148: INFO: Waiting up to 5m0s for pod "pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-tpw8r" to be "success or failure"
Apr 25 18:01:48.158: INFO: Pod "pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.887484ms
Apr 25 18:01:50.162: INFO: Pod "pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.013807699s
Apr 25 18:01:52.166: INFO: Pod "pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018079466s
STEP: Saw pod success
Apr 25 18:01:52.166: INFO: Pod "pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:01:52.169: INFO: Trying to get logs from node test113-q3hn pod pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 18:01:52.196: INFO: Waiting for pod pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:01:52.202: INFO: Pod pod-31dcc7d7-6784-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:01:52.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tpw8r" for this suite.
Apr 25 18:01:58.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:01:58.301: INFO: namespace: e2e-tests-emptydir-tpw8r, resource: bindings, ignored listing per whitelist
Apr 25 18:01:58.309: INFO: namespace e2e-tests-emptydir-tpw8r deletion completed in 6.10146656s

• [SLOW TEST:10.297 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:01:58.310: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 25 18:02:00.966: INFO: Successfully updated pod "pod-update-37fef0fe-6784-11e9-9f66-ae72f7f5c328"
STEP: verifying the updated pod is in kubernetes
Apr 25 18:02:00.980: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:02:00.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6jpwg" for this suite.
Apr 25 18:02:23.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:02:23.055: INFO: namespace: e2e-tests-pods-6jpwg, resource: bindings, ignored listing per whitelist
Apr 25 18:02:23.106: INFO: namespace e2e-tests-pods-6jpwg deletion completed in 22.119528687s

• [SLOW TEST:24.796 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:02:23.106: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 25 18:02:23.259: INFO: Number of nodes with available pods: 0
Apr 25 18:02:23.259: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 18:02:24.277: INFO: Number of nodes with available pods: 0
Apr 25 18:02:24.277: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 18:02:25.279: INFO: Number of nodes with available pods: 0
Apr 25 18:02:25.279: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 18:02:26.268: INFO: Number of nodes with available pods: 2
Apr 25 18:02:26.268: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 18:02:27.266: INFO: Number of nodes with available pods: 3
Apr 25 18:02:27.266: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 25 18:02:27.296: INFO: Number of nodes with available pods: 2
Apr 25 18:02:27.296: INFO: Node test113-q3kz is running more than one daemon pod
Apr 25 18:02:28.307: INFO: Number of nodes with available pods: 2
Apr 25 18:02:28.307: INFO: Node test113-q3kz is running more than one daemon pod
Apr 25 18:02:29.306: INFO: Number of nodes with available pods: 2
Apr 25 18:02:29.306: INFO: Node test113-q3kz is running more than one daemon pod
Apr 25 18:02:30.304: INFO: Number of nodes with available pods: 3
Apr 25 18:02:30.304: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-bshkm, will wait for the garbage collector to delete the pods
Apr 25 18:02:30.370: INFO: Deleting DaemonSet.extensions daemon-set took: 8.327872ms
Apr 25 18:02:30.471: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.453676ms
Apr 25 18:03:09.374: INFO: Number of nodes with available pods: 0
Apr 25 18:03:09.374: INFO: Number of running nodes: 0, number of available pods: 0
Apr 25 18:03:09.376: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bshkm/daemonsets","resourceVersion":"38959"},"items":null}

Apr 25 18:03:09.378: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bshkm/pods","resourceVersion":"38959"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:03:09.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bshkm" for this suite.
Apr 25 18:03:15.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:03:15.511: INFO: namespace: e2e-tests-daemonsets-bshkm, resource: bindings, ignored listing per whitelist
Apr 25 18:03:15.526: INFO: namespace e2e-tests-daemonsets-bshkm deletion completed in 6.133779972s

• [SLOW TEST:52.420 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:03:15.527: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 25 18:03:15.602: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8lnnp,SelfLink:/api/v1/namespaces/e2e-tests-watch-8lnnp/configmaps/e2e-watch-test-watch-closed,UID:65febff1-6784-11e9-a8f1-82d29082e60b,ResourceVersion:39005,Generation:0,CreationTimestamp:2019-04-25 18:03:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 25 18:03:15.602: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8lnnp,SelfLink:/api/v1/namespaces/e2e-tests-watch-8lnnp/configmaps/e2e-watch-test-watch-closed,UID:65febff1-6784-11e9-a8f1-82d29082e60b,ResourceVersion:39006,Generation:0,CreationTimestamp:2019-04-25 18:03:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 25 18:03:15.613: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8lnnp,SelfLink:/api/v1/namespaces/e2e-tests-watch-8lnnp/configmaps/e2e-watch-test-watch-closed,UID:65febff1-6784-11e9-a8f1-82d29082e60b,ResourceVersion:39007,Generation:0,CreationTimestamp:2019-04-25 18:03:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 25 18:03:15.613: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8lnnp,SelfLink:/api/v1/namespaces/e2e-tests-watch-8lnnp/configmaps/e2e-watch-test-watch-closed,UID:65febff1-6784-11e9-a8f1-82d29082e60b,ResourceVersion:39008,Generation:0,CreationTimestamp:2019-04-25 18:03:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:03:15.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8lnnp" for this suite.
Apr 25 18:03:21.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:03:21.670: INFO: namespace: e2e-tests-watch-8lnnp, resource: bindings, ignored listing per whitelist
Apr 25 18:03:21.723: INFO: namespace e2e-tests-watch-8lnnp deletion completed in 6.105823229s

• [SLOW TEST:6.196 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:03:21.724: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-vjmh9
Apr 25 18:03:25.879: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-vjmh9
STEP: checking the pod's current state and verifying that restartCount is present
Apr 25 18:03:25.881: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:07:26.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vjmh9" for this suite.
Apr 25 18:07:32.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:07:32.637: INFO: namespace: e2e-tests-container-probe-vjmh9, resource: bindings, ignored listing per whitelist
Apr 25 18:07:32.673: INFO: namespace e2e-tests-container-probe-vjmh9 deletion completed in 6.09455249s

• [SLOW TEST:250.950 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:07:32.673: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 25 18:07:32.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-5tgsv'
Apr 25 18:07:32.872: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 25 18:07:32.872: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Apr 25 18:07:32.892: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-mpvr5]
Apr 25 18:07:32.892: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-mpvr5" in namespace "e2e-tests-kubectl-5tgsv" to be "running and ready"
Apr 25 18:07:32.903: INFO: Pod "e2e-test-nginx-rc-mpvr5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.291122ms
Apr 25 18:07:34.907: INFO: Pod "e2e-test-nginx-rc-mpvr5": Phase="Running", Reason="", readiness=true. Elapsed: 2.015118361s
Apr 25 18:07:34.907: INFO: Pod "e2e-test-nginx-rc-mpvr5" satisfied condition "running and ready"
Apr 25 18:07:34.908: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-mpvr5]
Apr 25 18:07:34.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5tgsv'
Apr 25 18:07:35.021: INFO: stderr: ""
Apr 25 18:07:35.022: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Apr 25 18:07:35.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5tgsv'
Apr 25 18:07:35.113: INFO: stderr: ""
Apr 25 18:07:35.113: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:07:35.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5tgsv" for this suite.
Apr 25 18:07:41.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:07:41.214: INFO: namespace: e2e-tests-kubectl-5tgsv, resource: bindings, ignored listing per whitelist
Apr 25 18:07:41.225: INFO: namespace e2e-tests-kubectl-5tgsv deletion completed in 6.108087836s

• [SLOW TEST:8.552 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:07:41.230: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 18:07:41.391: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 25 18:07:41.411: INFO: Number of nodes with available pods: 0
Apr 25 18:07:41.411: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 18:07:42.420: INFO: Number of nodes with available pods: 0
Apr 25 18:07:42.420: INFO: Node test113-q3hn is running more than one daemon pod
Apr 25 18:07:43.418: INFO: Number of nodes with available pods: 1
Apr 25 18:07:43.418: INFO: Node test113-q3k9 is running more than one daemon pod
Apr 25 18:07:44.431: INFO: Number of nodes with available pods: 3
Apr 25 18:07:44.431: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 25 18:07:44.530: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:44.530: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:44.530: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:45.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:45.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:45.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:46.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:46.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:46.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:47.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:47.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:47.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:48.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:48.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:48.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:49.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:49.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:49.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:50.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:50.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:50.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:51.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:51.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:51.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:52.566: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:52.566: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:52.566: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:53.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:53.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:53.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:54.567: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:54.567: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:54.567: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:55.565: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:55.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:55.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:56.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:56.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:56.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:57.565: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:57.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:57.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:58.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:58.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:58.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:59.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:59.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:07:59.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:00.570: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:00.570: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:00.570: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:01.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:01.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:01.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:02.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:02.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:02.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:03.565: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:03.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:03.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:04.571: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:04.571: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:04.571: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:05.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:05.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:05.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:06.571: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:06.571: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:06.571: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:07.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:07.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:07.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:08.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:08.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:08.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:09.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:09.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:09.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:10.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:10.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:10.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:11.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:11.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:11.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:12.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:12.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:12.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:13.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:13.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:13.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:14.573: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:14.573: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:14.573: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:15.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:15.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:15.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:16.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:16.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:16.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:17.565: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:17.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:17.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:18.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:18.564: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:18.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:18.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:19.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:19.563: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:19.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:19.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:20.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:20.563: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:20.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:20.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:21.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:21.563: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:21.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:21.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:22.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:22.563: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:22.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:22.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:23.564: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:23.564: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:23.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:23.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:24.571: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:24.571: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:24.571: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:24.571: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:25.565: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:25.565: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:25.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:25.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:26.563: INFO: Wrong image for pod: daemon-set-k78ln. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:26.563: INFO: Pod daemon-set-k78ln is not available
Apr 25 18:08:26.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:26.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:27.564: INFO: Pod daemon-set-jlw48 is not available
Apr 25 18:08:27.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:27.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:28.563: INFO: Pod daemon-set-jlw48 is not available
Apr 25 18:08:28.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:28.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:29.563: INFO: Pod daemon-set-jlw48 is not available
Apr 25 18:08:29.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:29.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:30.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:30.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:31.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:31.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:32.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:32.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:33.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:33.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:34.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:34.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:35.566: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:35.566: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:36.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:36.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:37.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:37.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:38.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:38.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:39.566: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:39.566: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:40.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:40.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:41.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:41.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:42.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:42.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:43.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:43.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:44.571: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:44.571: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:45.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:45.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:46.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:46.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:47.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:47.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:48.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:48.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:49.565: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:49.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:50.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:50.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:51.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:51.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:52.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:52.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:53.564: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:53.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:54.593: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:54.593: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:55.567: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:55.567: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:56.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:56.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:57.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:57.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:58.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:58.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:59.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:08:59.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:00.568: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:00.568: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:01.563: INFO: Wrong image for pod: daemon-set-qv58p. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:01.563: INFO: Pod daemon-set-qv58p is not available
Apr 25 18:09:01.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:02.564: INFO: Pod daemon-set-x42vk is not available
Apr 25 18:09:02.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:03.563: INFO: Pod daemon-set-x42vk is not available
Apr 25 18:09:03.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:04.569: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:05.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:06.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:07.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:08.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:09.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:10.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:11.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:12.566: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:13.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:14.577: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:15.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:16.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:17.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:18.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:19.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:20.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:21.564: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:22.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:23.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:24.568: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:25.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:26.565: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:27.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:28.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:29.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:30.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:31.649: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:32.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:33.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:34.585: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:35.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:36.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:36.563: INFO: Pod daemon-set-z54rx is not available
Apr 25 18:09:37.563: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:37.563: INFO: Pod daemon-set-z54rx is not available
Apr 25 18:09:38.566: INFO: Wrong image for pod: daemon-set-z54rx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Apr 25 18:09:38.566: INFO: Pod daemon-set-z54rx is not available
Apr 25 18:09:39.564: INFO: Pod daemon-set-8gvsr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 25 18:09:39.590: INFO: Number of nodes with available pods: 2
Apr 25 18:09:39.590: INFO: Node test113-q3kz is running more than one daemon pod
Apr 25 18:09:40.598: INFO: Number of nodes with available pods: 2
Apr 25 18:09:40.598: INFO: Node test113-q3kz is running more than one daemon pod
Apr 25 18:09:41.610: INFO: Number of nodes with available pods: 3
Apr 25 18:09:41.610: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-mcr8t, will wait for the garbage collector to delete the pods
Apr 25 18:09:41.689: INFO: Deleting DaemonSet.extensions daemon-set took: 6.555834ms
Apr 25 18:09:41.789: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.239111ms
Apr 25 18:09:49.394: INFO: Number of nodes with available pods: 0
Apr 25 18:09:49.394: INFO: Number of running nodes: 0, number of available pods: 0
Apr 25 18:09:49.413: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mcr8t/daemonsets","resourceVersion":"39974"},"items":null}

Apr 25 18:09:49.416: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mcr8t/pods","resourceVersion":"39974"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:09:49.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mcr8t" for this suite.
Apr 25 18:09:55.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:09:55.523: INFO: namespace: e2e-tests-daemonsets-mcr8t, resource: bindings, ignored listing per whitelist
Apr 25 18:09:55.538: INFO: namespace e2e-tests-daemonsets-mcr8t deletion completed in 6.103279465s

• [SLOW TEST:134.309 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:09:55.539: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 18:09:55.607: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-downward-api-qd2j7" to be "success or failure"
Apr 25 18:09:55.615: INFO: Pod "downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.645542ms
Apr 25 18:09:57.619: INFO: Pod "downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011416551s
Apr 25 18:09:59.623: INFO: Pod "downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015600209s
STEP: Saw pod success
Apr 25 18:09:59.623: INFO: Pod "downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:09:59.625: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 18:09:59.649: INFO: Waiting for pod downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:09:59.651: INFO: Pod downwardapi-volume-54691ec4-6785-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:09:59.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qd2j7" for this suite.
Apr 25 18:10:05.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:10:05.688: INFO: namespace: e2e-tests-downward-api-qd2j7, resource: bindings, ignored listing per whitelist
Apr 25 18:10:05.767: INFO: namespace e2e-tests-downward-api-qd2j7 deletion completed in 6.112490292s

• [SLOW TEST:10.229 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:10:05.769: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Apr 25 18:10:05.914: INFO: Waiting up to 5m0s for pod "var-expansion-5a8de8a2-6785-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-var-expansion-2f8tv" to be "success or failure"
Apr 25 18:10:05.923: INFO: Pod "var-expansion-5a8de8a2-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.60717ms
Apr 25 18:10:07.928: INFO: Pod "var-expansion-5a8de8a2-6785-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013604347s
STEP: Saw pod success
Apr 25 18:10:07.928: INFO: Pod "var-expansion-5a8de8a2-6785-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:10:07.931: INFO: Trying to get logs from node test113-q3hn pod var-expansion-5a8de8a2-6785-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 18:10:07.958: INFO: Waiting for pod var-expansion-5a8de8a2-6785-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:10:07.961: INFO: Pod var-expansion-5a8de8a2-6785-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:10:07.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-2f8tv" for this suite.
Apr 25 18:10:13.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:10:14.216: INFO: namespace: e2e-tests-var-expansion-2f8tv, resource: bindings, ignored listing per whitelist
Apr 25 18:10:14.261: INFO: namespace e2e-tests-var-expansion-2f8tv deletion completed in 6.29077934s

• [SLOW TEST:8.493 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:10:14.267: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 25 18:10:14.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-m9t6n'
Apr 25 18:10:14.834: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 25 18:10:14.834: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Apr 25 18:10:18.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-m9t6n'
Apr 25 18:10:19.005: INFO: stderr: ""
Apr 25 18:10:19.006: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:10:19.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m9t6n" for this suite.
Apr 25 18:10:43.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:10:43.134: INFO: namespace: e2e-tests-kubectl-m9t6n, resource: bindings, ignored listing per whitelist
Apr 25 18:10:43.153: INFO: namespace e2e-tests-kubectl-m9t6n deletion completed in 24.131072245s

• [SLOW TEST:28.886 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:10:43.154: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Apr 25 18:10:43.234: INFO: Waiting up to 5m0s for pod "var-expansion-70cb26a0-6785-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-var-expansion-4mrpf" to be "success or failure"
Apr 25 18:10:43.242: INFO: Pod "var-expansion-70cb26a0-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.594177ms
Apr 25 18:10:45.247: INFO: Pod "var-expansion-70cb26a0-6785-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012325616s
STEP: Saw pod success
Apr 25 18:10:45.247: INFO: Pod "var-expansion-70cb26a0-6785-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:10:45.249: INFO: Trying to get logs from node test113-q3hn pod var-expansion-70cb26a0-6785-11e9-9f66-ae72f7f5c328 container dapi-container: <nil>
STEP: delete the pod
Apr 25 18:10:45.272: INFO: Waiting for pod var-expansion-70cb26a0-6785-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:10:45.276: INFO: Pod var-expansion-70cb26a0-6785-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:10:45.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4mrpf" for this suite.
Apr 25 18:10:51.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:10:51.408: INFO: namespace: e2e-tests-var-expansion-4mrpf, resource: bindings, ignored listing per whitelist
Apr 25 18:10:51.422: INFO: namespace e2e-tests-var-expansion-4mrpf deletion completed in 6.140323101s

• [SLOW TEST:8.268 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:10:51.422: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 25 18:10:57.609: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 25 18:10:57.616: INFO: Pod pod-with-prestop-http-hook still exists
Apr 25 18:10:59.619: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 25 18:10:59.622: INFO: Pod pod-with-prestop-http-hook still exists
Apr 25 18:11:01.617: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 25 18:11:01.622: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:11:01.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9w9r6" for this suite.
Apr 25 18:11:23.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:11:23.682: INFO: namespace: e2e-tests-container-lifecycle-hook-9w9r6, resource: bindings, ignored listing per whitelist
Apr 25 18:11:23.736: INFO: namespace e2e-tests-container-lifecycle-hook-9w9r6 deletion completed in 22.096125208s

• [SLOW TEST:32.314 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:11:23.736: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:11:30.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-lz2wf" for this suite.
Apr 25 18:11:52.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:11:52.988: INFO: namespace: e2e-tests-replication-controller-lz2wf, resource: bindings, ignored listing per whitelist
Apr 25 18:11:53.018: INFO: namespace e2e-tests-replication-controller-lz2wf deletion completed in 22.106484537s

• [SLOW TEST:29.282 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:11:53.018: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 25 18:11:53.093: INFO: Waiting up to 5m0s for pod "pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-gx68b" to be "success or failure"
Apr 25 18:11:53.109: INFO: Pod "pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 16.546373ms
Apr 25 18:11:55.114: INFO: Pod "pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021030063s
Apr 25 18:11:57.118: INFO: Pod "pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025313535s
STEP: Saw pod success
Apr 25 18:11:57.118: INFO: Pod "pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:11:57.121: INFO: Trying to get logs from node test113-q3hn pod pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 18:11:57.158: INFO: Waiting for pod pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:11:57.160: INFO: Pod pod-9a702ca4-6785-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:11:57.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gx68b" for this suite.
Apr 25 18:12:03.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:12:03.294: INFO: namespace: e2e-tests-emptydir-gx68b, resource: bindings, ignored listing per whitelist
Apr 25 18:12:03.312: INFO: namespace e2e-tests-emptydir-gx68b deletion completed in 6.144571992s

• [SLOW TEST:10.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:12:03.312: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Apr 25 18:12:03.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a093ba5f-6785-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-ndgmv" to be "success or failure"
Apr 25 18:12:03.408: INFO: Pod "downwardapi-volume-a093ba5f-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 14.38815ms
Apr 25 18:12:05.412: INFO: Pod "downwardapi-volume-a093ba5f-6785-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01843513s
STEP: Saw pod success
Apr 25 18:12:05.412: INFO: Pod "downwardapi-volume-a093ba5f-6785-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:12:05.418: INFO: Trying to get logs from node test113-q3hn pod downwardapi-volume-a093ba5f-6785-11e9-9f66-ae72f7f5c328 container client-container: <nil>
STEP: delete the pod
Apr 25 18:12:05.445: INFO: Waiting for pod downwardapi-volume-a093ba5f-6785-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:12:05.448: INFO: Pod downwardapi-volume-a093ba5f-6785-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:12:05.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ndgmv" for this suite.
Apr 25 18:12:11.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:12:11.553: INFO: namespace: e2e-tests-projected-ndgmv, resource: bindings, ignored listing per whitelist
Apr 25 18:12:11.558: INFO: namespace e2e-tests-projected-ndgmv deletion completed in 6.105744524s

• [SLOW TEST:8.246 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:12:11.558: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 25 18:12:11.658: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40575,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 25 18:12:11.658: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40575,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 25 18:12:21.667: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40592,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 25 18:12:21.667: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40592,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 25 18:12:31.677: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40608,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 25 18:12:31.677: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40608,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 25 18:12:41.684: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40623,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 25 18:12:41.684: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-a,UID:a582f64e-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40623,Generation:0,CreationTimestamp:2019-04-25 18:12:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 25 18:12:51.696: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-b,UID:bd603f68-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40638,Generation:0,CreationTimestamp:2019-04-25 18:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 25 18:12:51.696: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-b,UID:bd603f68-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40638,Generation:0,CreationTimestamp:2019-04-25 18:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 25 18:13:01.704: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-b,UID:bd603f68-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40654,Generation:0,CreationTimestamp:2019-04-25 18:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 25 18:13:01.704: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fk6xf,SelfLink:/api/v1/namespaces/e2e-tests-watch-fk6xf/configmaps/e2e-watch-test-configmap-b,UID:bd603f68-6785-11e9-a8f1-82d29082e60b,ResourceVersion:40654,Generation:0,CreationTimestamp:2019-04-25 18:12:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:13:11.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fk6xf" for this suite.
Apr 25 18:13:17.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:13:17.764: INFO: namespace: e2e-tests-watch-fk6xf, resource: bindings, ignored listing per whitelist
Apr 25 18:13:17.816: INFO: namespace e2e-tests-watch-fk6xf deletion completed in 6.105463294s

• [SLOW TEST:66.258 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:13:17.818: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 25 18:13:24.218: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:24.218: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:24.418: INFO: Exec stderr: ""
Apr 25 18:13:24.418: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:24.418: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:24.645: INFO: Exec stderr: ""
Apr 25 18:13:24.645: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:24.645: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:24.828: INFO: Exec stderr: ""
Apr 25 18:13:24.828: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:24.828: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:25.042: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 25 18:13:25.042: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:25.042: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:25.221: INFO: Exec stderr: ""
Apr 25 18:13:25.222: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:25.222: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:25.395: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 25 18:13:25.396: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:25.396: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:25.579: INFO: Exec stderr: ""
Apr 25 18:13:25.579: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:25.579: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:25.770: INFO: Exec stderr: ""
Apr 25 18:13:25.770: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:25.770: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:25.938: INFO: Exec stderr: ""
Apr 25 18:13:25.938: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-5l5t2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:13:25.938: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:13:26.135: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:13:26.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-5l5t2" for this suite.
Apr 25 18:14:12.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:14:12.228: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-5l5t2, resource: bindings, ignored listing per whitelist
Apr 25 18:14:12.262: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-5l5t2 deletion completed in 46.117888074s

• [SLOW TEST:54.444 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:14:12.262: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-ed6f9f63-6785-11e9-9f66-ae72f7f5c328
STEP: Creating secret with name secret-projected-all-test-volume-ed6f9f49-6785-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 25 18:14:12.348: INFO: Waiting up to 5m0s for pod "projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-lm422" to be "success or failure"
Apr 25 18:14:12.360: INFO: Pod "projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 11.748516ms
Apr 25 18:14:14.365: INFO: Pod "projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328": Phase="Running", Reason="", readiness=true. Elapsed: 2.016742909s
Apr 25 18:14:16.371: INFO: Pod "projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022590472s
STEP: Saw pod success
Apr 25 18:14:16.371: INFO: Pod "projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:14:16.373: INFO: Trying to get logs from node test113-q3hn pod projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 25 18:14:16.396: INFO: Waiting for pod projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:14:16.403: INFO: Pod projected-volume-ed6f9f12-6785-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:14:16.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lm422" for this suite.
Apr 25 18:14:22.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:14:22.444: INFO: namespace: e2e-tests-projected-lm422, resource: bindings, ignored listing per whitelist
Apr 25 18:14:22.516: INFO: namespace e2e-tests-projected-lm422 deletion completed in 6.109685229s

• [SLOW TEST:10.255 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:14:22.517: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f38cdba2-6785-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 18:14:22.603: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f38d4b63-6785-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-h4fbr" to be "success or failure"
Apr 25 18:14:22.610: INFO: Pod "pod-projected-configmaps-f38d4b63-6785-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.044309ms
Apr 25 18:14:24.621: INFO: Pod "pod-projected-configmaps-f38d4b63-6785-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018552235s
STEP: Saw pod success
Apr 25 18:14:24.621: INFO: Pod "pod-projected-configmaps-f38d4b63-6785-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:14:24.633: INFO: Trying to get logs from node test113-q3hn pod pod-projected-configmaps-f38d4b63-6785-11e9-9f66-ae72f7f5c328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 18:14:24.699: INFO: Waiting for pod pod-projected-configmaps-f38d4b63-6785-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:14:24.706: INFO: Pod pod-projected-configmaps-f38d4b63-6785-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:14:24.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h4fbr" for this suite.
Apr 25 18:14:30.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:14:30.803: INFO: namespace: e2e-tests-projected-h4fbr, resource: bindings, ignored listing per whitelist
Apr 25 18:14:30.972: INFO: namespace e2e-tests-projected-h4fbr deletion completed in 6.249520477s

• [SLOW TEST:8.456 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:14:30.972: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 18:14:31.058: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 25 18:14:31.081: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 25 18:14:36.085: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 25 18:14:36.085: INFO: Creating deployment "test-rolling-update-deployment"
Apr 25 18:14:36.090: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 25 18:14:36.122: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 25 18:14:38.129: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 25 18:14:38.144: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691812876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691812876, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63691812876, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691812876, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 25 18:14:40.148: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Apr 25 18:14:40.157: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-z47zm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z47zm/deployments/test-rolling-update-deployment,UID:fb99af76-6785-11e9-a8f1-82d29082e60b,ResourceVersion:41061,Generation:1,CreationTimestamp:2019-04-25 18:14:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-04-25 18:14:36 +0000 UTC 2019-04-25 18:14:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-04-25 18:14:38 +0000 UTC 2019-04-25 18:14:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Apr 25 18:14:40.160: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-z47zm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z47zm/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:fb9bc0b8-6785-11e9-a8f1-82d29082e60b,ResourceVersion:41052,Generation:1,CreationTimestamp:2019-04-25 18:14:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment fb99af76-6785-11e9-a8f1-82d29082e60b 0xc0011939c7 0xc0011939c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Apr 25 18:14:40.161: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 25 18:14:40.161: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-z47zm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z47zm/replicasets/test-rolling-update-controller,UID:f89aa4df-6785-11e9-a8f1-82d29082e60b,ResourceVersion:41060,Generation:2,CreationTimestamp:2019-04-25 18:14:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment fb99af76-6785-11e9-a8f1-82d29082e60b 0xc0011937d7 0xc0011937d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Apr 25 18:14:40.164: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-lrxdb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-lrxdb,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-z47zm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z47zm/pods/test-rolling-update-deployment-68b55d7bc6-lrxdb,UID:fba051ba-6785-11e9-a8f1-82d29082e60b,ResourceVersion:41051,Generation:0,CreationTimestamp:2019-04-25 18:14:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 fb9bc0b8-6785-11e9-a8f1-82d29082e60b 0xc001ac8e47 0xc001ac8e48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5ph6k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5ph6k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5ph6k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:test113-q3k9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:14:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:14:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:14:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-04-25 18:14:36 +0000 UTC  }],Message:,Reason:,HostIP:10.138.26.32,PodIP:10.244.0.96,StartTime:2019-04-25 18:14:36 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-04-25 18:14:38 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9d439e33615ce985f761a0ad4d397493d7e6c8f2ebdb5d2e20268cd79def4f7d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:14:40.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z47zm" for this suite.
Apr 25 18:14:46.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:14:46.254: INFO: namespace: e2e-tests-deployment-z47zm, resource: bindings, ignored listing per whitelist
Apr 25 18:14:46.292: INFO: namespace e2e-tests-deployment-z47zm deletion completed in 6.122495298s

• [SLOW TEST:15.319 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:14:46.292: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 25 18:14:46.413: INFO: Waiting up to 5m0s for pod "pod-01bf0366-6786-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-wdnp6" to be "success or failure"
Apr 25 18:14:46.423: INFO: Pod "pod-01bf0366-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.739563ms
Apr 25 18:14:48.429: INFO: Pod "pod-01bf0366-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015815955s
Apr 25 18:14:50.433: INFO: Pod "pod-01bf0366-6786-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019784785s
STEP: Saw pod success
Apr 25 18:14:50.433: INFO: Pod "pod-01bf0366-6786-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:14:50.435: INFO: Trying to get logs from node test113-q3hn pod pod-01bf0366-6786-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 18:14:50.457: INFO: Waiting for pod pod-01bf0366-6786-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:14:50.461: INFO: Pod pod-01bf0366-6786-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:14:50.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wdnp6" for this suite.
Apr 25 18:14:56.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:14:56.599: INFO: namespace: e2e-tests-emptydir-wdnp6, resource: bindings, ignored listing per whitelist
Apr 25 18:14:56.636: INFO: namespace e2e-tests-emptydir-wdnp6 deletion completed in 6.172198298s

• [SLOW TEST:10.344 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:14:56.637: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-07e9dbe2-6786-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume secrets
Apr 25 18:14:56.768: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-8sm68" to be "success or failure"
Apr 25 18:14:56.777: INFO: Pod "pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 8.781042ms
Apr 25 18:14:58.782: INFO: Pod "pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013225484s
Apr 25 18:15:00.786: INFO: Pod "pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017316498s
STEP: Saw pod success
Apr 25 18:15:00.786: INFO: Pod "pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:15:00.788: INFO: Trying to get logs from node test113-q3hn pod pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 25 18:15:00.811: INFO: Waiting for pod pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:15:00.815: INFO: Pod pod-projected-secrets-07ea8c2c-6786-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:15:00.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8sm68" for this suite.
Apr 25 18:15:06.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:15:06.886: INFO: namespace: e2e-tests-projected-8sm68, resource: bindings, ignored listing per whitelist
Apr 25 18:15:06.932: INFO: namespace e2e-tests-projected-8sm68 deletion completed in 6.107404543s

• [SLOW TEST:10.295 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:15:06.932: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ndqv
STEP: Creating a pod to test atomic-volume-subpath
Apr 25 18:15:07.158: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ndqv" in namespace "e2e-tests-subpath-898c9" to be "success or failure"
Apr 25 18:15:07.166: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Pending", Reason="", readiness=false. Elapsed: 7.778801ms
Apr 25 18:15:09.172: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013916868s
Apr 25 18:15:11.176: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018076833s
Apr 25 18:15:13.181: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 6.023326035s
Apr 25 18:15:15.185: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 8.027140422s
Apr 25 18:15:17.190: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 10.031572869s
Apr 25 18:15:19.194: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 12.035361995s
Apr 25 18:15:21.198: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 14.040114446s
Apr 25 18:15:23.202: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 16.043792228s
Apr 25 18:15:25.206: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 18.047754799s
Apr 25 18:15:27.210: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 20.051862079s
Apr 25 18:15:29.219: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 22.060956648s
Apr 25 18:15:31.224: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Running", Reason="", readiness=false. Elapsed: 24.065480094s
Apr 25 18:15:33.228: INFO: Pod "pod-subpath-test-configmap-ndqv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.069536203s
STEP: Saw pod success
Apr 25 18:15:33.228: INFO: Pod "pod-subpath-test-configmap-ndqv" satisfied condition "success or failure"
Apr 25 18:15:33.231: INFO: Trying to get logs from node test113-q3k9 pod pod-subpath-test-configmap-ndqv container test-container-subpath-configmap-ndqv: <nil>
STEP: delete the pod
Apr 25 18:15:33.256: INFO: Waiting for pod pod-subpath-test-configmap-ndqv to disappear
Apr 25 18:15:33.260: INFO: Pod pod-subpath-test-configmap-ndqv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ndqv
Apr 25 18:15:33.261: INFO: Deleting pod "pod-subpath-test-configmap-ndqv" in namespace "e2e-tests-subpath-898c9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:15:33.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-898c9" for this suite.
Apr 25 18:15:39.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:15:39.336: INFO: namespace: e2e-tests-subpath-898c9, resource: bindings, ignored listing per whitelist
Apr 25 18:15:39.430: INFO: namespace e2e-tests-subpath-898c9 deletion completed in 6.163361173s

• [SLOW TEST:32.499 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:15:39.430: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Apr 25 18:15:39.506: INFO: Waiting up to 5m0s for pod "client-containers-2164147f-6786-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-containers-5fqpd" to be "success or failure"
Apr 25 18:15:39.518: INFO: Pod "client-containers-2164147f-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 12.179345ms
Apr 25 18:15:41.523: INFO: Pod "client-containers-2164147f-6786-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016824374s
STEP: Saw pod success
Apr 25 18:15:41.523: INFO: Pod "client-containers-2164147f-6786-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:15:41.525: INFO: Trying to get logs from node test113-q3hn pod client-containers-2164147f-6786-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 18:15:41.566: INFO: Waiting for pod client-containers-2164147f-6786-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:15:41.571: INFO: Pod client-containers-2164147f-6786-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:15:41.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5fqpd" for this suite.
Apr 25 18:15:47.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:15:47.689: INFO: namespace: e2e-tests-containers-5fqpd, resource: bindings, ignored listing per whitelist
Apr 25 18:15:47.915: INFO: namespace e2e-tests-containers-5fqpd deletion completed in 6.339292822s

• [SLOW TEST:8.485 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:15:47.916: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 25 18:15:48.001: INFO: Waiting up to 5m0s for pod "pod-2674734d-6786-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-emptydir-6wn7m" to be "success or failure"
Apr 25 18:15:48.010: INFO: Pod "pod-2674734d-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 9.003016ms
Apr 25 18:15:50.014: INFO: Pod "pod-2674734d-6786-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013094693s
STEP: Saw pod success
Apr 25 18:15:50.014: INFO: Pod "pod-2674734d-6786-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:15:50.017: INFO: Trying to get logs from node test113-q3hn pod pod-2674734d-6786-11e9-9f66-ae72f7f5c328 container test-container: <nil>
STEP: delete the pod
Apr 25 18:15:50.037: INFO: Waiting for pod pod-2674734d-6786-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:15:50.040: INFO: Pod pod-2674734d-6786-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:15:50.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6wn7m" for this suite.
Apr 25 18:15:56.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:15:56.157: INFO: namespace: e2e-tests-emptydir-6wn7m, resource: bindings, ignored listing per whitelist
Apr 25 18:15:56.181: INFO: namespace e2e-tests-emptydir-6wn7m deletion completed in 6.136457168s

• [SLOW TEST:8.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:15:56.181: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-94dr6
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 25 18:15:56.285: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 25 18:16:22.509: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.7:8080/dial?request=hostName&protocol=udp&host=10.244.2.164&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-94dr6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:16:22.509: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:16:22.691: INFO: Waiting for endpoints: map[]
Apr 25 18:16:22.694: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.7:8080/dial?request=hostName&protocol=udp&host=10.244.0.81&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-94dr6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:16:22.694: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:16:22.893: INFO: Waiting for endpoints: map[]
Apr 25 18:16:22.896: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.7:8080/dial?request=hostName&protocol=udp&host=10.244.1.149&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-94dr6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 25 18:16:22.896: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
Apr 25 18:16:23.074: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:16:23.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-94dr6" for this suite.
Apr 25 18:16:45.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:16:45.134: INFO: namespace: e2e-tests-pod-network-test-94dr6, resource: bindings, ignored listing per whitelist
Apr 25 18:16:45.190: INFO: namespace e2e-tests-pod-network-test-94dr6 deletion completed in 22.109652658s

• [SLOW TEST:49.009 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:16:45.191: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Apr 25 18:16:45.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 version'
Apr 25 18:16:45.371: INFO: stderr: ""
Apr 25 18:16:45.371: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.5\", GitCommit:\"2166946f41b36dea2c4626f90a77706f426cdea2\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:19:22Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:16:45.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hfgfw" for this suite.
Apr 25 18:16:51.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:16:51.474: INFO: namespace: e2e-tests-kubectl-hfgfw, resource: bindings, ignored listing per whitelist
Apr 25 18:16:51.485: INFO: namespace e2e-tests-kubectl-hfgfw deletion completed in 6.109952113s

• [SLOW TEST:6.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:16:51.485: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Apr 25 18:16:51.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-lg9ld'
Apr 25 18:16:51.696: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 25 18:16:51.696: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Apr 25 18:16:51.721: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr 25 18:16:51.731: INFO: scanned /root for discovery docs: <nil>
Apr 25 18:16:51.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-lg9ld'
Apr 25 18:17:07.531: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 25 18:17:07.531: INFO: stdout: "Created e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f\nScaling up e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Apr 25 18:17:07.531: INFO: stdout: "Created e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f\nScaling up e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Apr 25 18:17:07.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lg9ld'
Apr 25 18:17:07.599: INFO: stderr: ""
Apr 25 18:17:07.599: INFO: stdout: "e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f-cj9v9 "
Apr 25 18:17:07.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f-cj9v9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lg9ld'
Apr 25 18:17:07.682: INFO: stderr: ""
Apr 25 18:17:07.682: INFO: stdout: "true"
Apr 25 18:17:07.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 get pods e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f-cj9v9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lg9ld'
Apr 25 18:17:07.752: INFO: stderr: ""
Apr 25 18:17:07.752: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Apr 25 18:17:07.752: INFO: e2e-test-nginx-rc-895f435a97b4fc452c7467a4d47de96f-cj9v9 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Apr 25 18:17:07.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-806739710 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lg9ld'
Apr 25 18:17:07.833: INFO: stderr: ""
Apr 25 18:17:07.833: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:17:07.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lg9ld" for this suite.
Apr 25 18:17:13.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:17:13.936: INFO: namespace: e2e-tests-kubectl-lg9ld, resource: bindings, ignored listing per whitelist
Apr 25 18:17:14.039: INFO: namespace e2e-tests-kubectl-lg9ld deletion completed in 6.198335553s

• [SLOW TEST:22.554 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:17:14.039: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Apr 25 18:17:14.310: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-806739710 proxy --unix-socket=/tmp/kubectl-proxy-unix933262917/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:17:14.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-szqjh" for this suite.
Apr 25 18:17:20.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:17:20.488: INFO: namespace: e2e-tests-kubectl-szqjh, resource: bindings, ignored listing per whitelist
Apr 25 18:17:20.494: INFO: namespace e2e-tests-kubectl-szqjh deletion completed in 6.117757576s

• [SLOW TEST:6.455 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:17:20.495: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 25 18:17:26.679: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:26.684: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:28.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:28.688: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:30.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:30.688: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:32.685: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:32.689: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:34.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:34.693: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:36.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:36.689: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:38.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:38.689: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:40.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:40.688: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:42.685: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:42.690: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 25 18:17:44.684: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 25 18:17:44.691: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:17:44.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gmnmp" for this suite.
Apr 25 18:18:06.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:18:06.762: INFO: namespace: e2e-tests-container-lifecycle-hook-gmnmp, resource: bindings, ignored listing per whitelist
Apr 25 18:18:06.829: INFO: namespace e2e-tests-container-lifecycle-hook-gmnmp deletion completed in 22.133299143s

• [SLOW TEST:46.334 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:18:06.829: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-794032ba-6786-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 18:18:06.917: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7940bbeb-6786-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-projected-8mjc6" to be "success or failure"
Apr 25 18:18:06.925: INFO: Pod "pod-projected-configmaps-7940bbeb-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 7.763235ms
Apr 25 18:18:08.941: INFO: Pod "pod-projected-configmaps-7940bbeb-6786-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023868222s
STEP: Saw pod success
Apr 25 18:18:08.941: INFO: Pod "pod-projected-configmaps-7940bbeb-6786-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:18:08.946: INFO: Trying to get logs from node test113-q3hn pod pod-projected-configmaps-7940bbeb-6786-11e9-9f66-ae72f7f5c328 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 18:18:09.003: INFO: Waiting for pod pod-projected-configmaps-7940bbeb-6786-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:18:09.021: INFO: Pod pod-projected-configmaps-7940bbeb-6786-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:18:09.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8mjc6" for this suite.
Apr 25 18:18:15.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:18:15.153: INFO: namespace: e2e-tests-projected-8mjc6, resource: bindings, ignored listing per whitelist
Apr 25 18:18:15.191: INFO: namespace e2e-tests-projected-8mjc6 deletion completed in 6.152885667s

• [SLOW TEST:8.363 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Apr 25 18:18:15.191: INFO: >>> kubeConfig: /tmp/kubeconfig-806739710
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-7e43311e-6786-11e9-9f66-ae72f7f5c328
STEP: Creating a pod to test consume configMaps
Apr 25 18:18:15.322: INFO: Waiting up to 5m0s for pod "pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328" in namespace "e2e-tests-configmap-cpwb7" to be "success or failure"
Apr 25 18:18:15.329: INFO: Pod "pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 6.65197ms
Apr 25 18:18:17.430: INFO: Pod "pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107495404s
Apr 25 18:18:19.435: INFO: Pod "pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.112701328s
STEP: Saw pod success
Apr 25 18:18:19.435: INFO: Pod "pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328" satisfied condition "success or failure"
Apr 25 18:18:19.439: INFO: Trying to get logs from node test113-q3hn pod pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 25 18:18:19.460: INFO: Waiting for pod pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328 to disappear
Apr 25 18:18:19.468: INFO: Pod pod-configmaps-7e439e32-6786-11e9-9f66-ae72f7f5c328 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Apr 25 18:18:19.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cpwb7" for this suite.
Apr 25 18:18:25.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 25 18:18:25.545: INFO: namespace: e2e-tests-configmap-cpwb7, resource: bindings, ignored listing per whitelist
Apr 25 18:18:25.578: INFO: namespace e2e-tests-configmap-cpwb7 deletion completed in 6.10637901s

• [SLOW TEST:10.387 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSApr 25 18:18:25.578: INFO: Running AfterSuite actions on all nodes
Apr 25 18:18:25.578: INFO: Running AfterSuite actions on node 1
Apr 25 18:18:25.578: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6097.912 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h41m38.676951634s
Test Suite Passed
