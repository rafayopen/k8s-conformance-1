I0201 22:54:02.313644      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-249251776
I0201 22:54:02.313940      17 e2e.go:224] Starting e2e run "44797ce5-2674-11e9-a68a-f677bb5aadde" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1549061641 - Will randomize all specs
Will run 201 of 1946 specs

Feb  1 22:54:02.469: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  1 22:54:02.471: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  1 22:54:02.479: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  1 22:54:02.502: INFO: 7 / 7 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  1 22:54:02.502: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Feb  1 22:54:02.502: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  1 22:54:02.509: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb  1 22:54:02.509: INFO: e2e test version: v1.13.0
Feb  1 22:54:02.510: INFO: kube-apiserver version: v1.13.0
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 22:54:02.511: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-probe
Feb  1 22:54:02.573: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-b22hf
Feb  1 22:54:08.554: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-b22hf
STEP: checking the pod's current state and verifying that restartCount is present
Feb  1 22:54:08.557: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 22:58:08.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-b22hf" for this suite.
Feb  1 22:58:14.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 22:58:14.962: INFO: namespace: e2e-tests-container-probe-b22hf, resource: bindings, ignored listing per whitelist
Feb  1 22:58:14.964: INFO: namespace e2e-tests-container-probe-b22hf deletion completed in 6.0898989s

â€¢ [SLOW TEST:252.762 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 22:58:14.964: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  1 22:58:15.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 version --client'
Feb  1 22:58:15.079: INFO: stderr: ""
Feb  1 22:58:15.079: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb  1 22:58:15.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-7gd9z'
Feb  1 22:58:15.345: INFO: stderr: ""
Feb  1 22:58:15.345: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  1 22:58:15.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-7gd9z'
Feb  1 22:58:15.499: INFO: stderr: ""
Feb  1 22:58:15.499: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  1 22:58:16.505: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:58:16.505: INFO: Found 0 / 1
Feb  1 22:58:17.507: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:58:17.507: INFO: Found 0 / 1
Feb  1 22:58:18.502: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:58:18.502: INFO: Found 0 / 1
Feb  1 22:58:19.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:58:19.507: INFO: Found 1 / 1
Feb  1 22:58:19.507: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  1 22:58:19.510: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:58:19.510: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  1 22:58:19.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 describe pod redis-master-mz5pg --namespace=e2e-tests-kubectl-7gd9z'
Feb  1 22:58:19.611: INFO: stderr: ""
Feb  1 22:58:19.611: INFO: stdout: "Name:               redis-master-mz5pg\nNamespace:          e2e-tests-kubectl-7gd9z\nPriority:           0\nPriorityClassName:  <none>\nNode:               docker-desktop/192.168.65.3\nStart Time:         Fri, 01 Feb 2019 22:58:15 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.1.0.8\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://72241258aa7a1889f9cf3463ae243c74d96779985e918aa4a5b553a04be3b897\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 01 Feb 2019 22:58:18 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-4g9qv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-4g9qv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-4g9qv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  4s    default-scheduler        Successfully assigned e2e-tests-kubectl-7gd9z/redis-master-mz5pg to docker-desktop\n  Normal  Pulling    3s    kubelet, docker-desktop  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, docker-desktop  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, docker-desktop  Created container\n  Normal  Started    1s    kubelet, docker-desktop  Started container\n"
Feb  1 22:58:19.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 describe rc redis-master --namespace=e2e-tests-kubectl-7gd9z'
Feb  1 22:58:19.692: INFO: stderr: ""
Feb  1 22:58:19.692: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-7gd9z\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-mz5pg\n"
Feb  1 22:58:19.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 describe service redis-master --namespace=e2e-tests-kubectl-7gd9z'
Feb  1 22:58:19.766: INFO: stderr: ""
Feb  1 22:58:19.766: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-7gd9z\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.99.170.125\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.0.8:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  1 22:58:19.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 describe node docker-desktop'
Feb  1 22:58:19.846: INFO: stderr: ""
Feb  1 22:58:19.846: INFO: stdout: "Name:               docker-desktop\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=docker-desktop\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 01 Feb 2019 15:56:01 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 01 Feb 2019 22:58:01 +0000   Fri, 01 Feb 2019 15:55:53 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 01 Feb 2019 22:58:01 +0000   Fri, 01 Feb 2019 15:55:53 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 01 Feb 2019 22:58:01 +0000   Fri, 01 Feb 2019 15:55:53 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 01 Feb 2019 22:58:01 +0000   Fri, 01 Feb 2019 15:55:53 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.65.3\n  Hostname:    docker-desktop\nCapacity:\n cpu:                6\n ephemeral-storage:  61255492Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2046460Ki\n pods:               50\nAllocatable:\n cpu:                6\n ephemeral-storage:  56453061334\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1944060Ki\n pods:               50\nSystem Info:\n Machine ID:                 \n System UUID:                7C6B44A3-0000-0000-897F-07B769A12762\n Boot ID:                    56b59c13-466a-4925-a076-69bc028f5108\n Kernel Version:             4.9.125-linuxkit\n OS Image:                   Docker Desktop\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.1\n Kubelet Version:            v1.13.0\n Kube-Proxy Version:         v1.13.0\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  docker                     compose-56897cc96b-gnrcd                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         7h\n  docker                     compose-api-5fb5fd58d-fjvcj                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7h\n  e2e-tests-kubectl-7gd9z    redis-master-mz5pg                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         4m44s\n  heptio-sonobuoy            sonobuoy-e2e-job-bb494af789db4143                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         4m39s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-2081b0686f0449ba-4wdch    0 (0%)        0 (0%)      0 (0%)           0 (0%)         4m39s\n  kube-system                coredns-86c58d9df4-492hj                                   100m (1%)     0 (0%)      70Mi (3%)        170Mi (8%)     7h2m\n  kube-system                coredns-86c58d9df4-zxg7j                                   100m (1%)     0 (0%)      70Mi (3%)        170Mi (8%)     7h2m\n  kube-system                etcd-docker-desktop                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         7h1m\n  kube-system                kube-apiserver-docker-desktop                              250m (4%)     0 (0%)      0 (0%)           0 (0%)         7h1m\n  kube-system                kube-controller-manager-docker-desktop                     200m (3%)     0 (0%)      0 (0%)           0 (0%)         7h\n  kube-system                kube-proxy-hzvvt                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         7h2m\n  kube-system                kube-scheduler-docker-desktop                              100m (1%)     0 (0%)      0 (0%)           0 (0%)         7h1m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                750m (12%)  0 (0%)\n  memory             140Mi (7%)  340Mi (17%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Feb  1 22:58:19.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 describe namespace e2e-tests-kubectl-7gd9z'
Feb  1 22:58:19.917: INFO: stderr: ""
Feb  1 22:58:19.917: INFO: stdout: "Name:         e2e-tests-kubectl-7gd9z\nLabels:       e2e-framework=kubectl\n              e2e-run=44797ce5-2674-11e9-a68a-f677bb5aadde\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 22:58:19.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7gd9z" for this suite.
Feb  1 22:58:41.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 22:58:41.954: INFO: namespace: e2e-tests-kubectl-7gd9z, resource: bindings, ignored listing per whitelist
Feb  1 22:58:41.961: INFO: namespace e2e-tests-kubectl-7gd9z deletion completed in 22.0757114s

â€¢ [SLOW TEST:27.031 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 22:58:41.962: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb  1 22:58:42.012: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-249251776 proxy --unix-socket=/tmp/kubectl-proxy-unix575491615/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 22:58:42.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nd4xw" for this suite.
Feb  1 22:58:48.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 22:58:48.105: INFO: namespace: e2e-tests-kubectl-nd4xw, resource: bindings, ignored listing per whitelist
Feb  1 22:58:48.174: INFO: namespace e2e-tests-kubectl-nd4xw deletion completed in 6.1092346s

â€¢ [SLOW TEST:6.212 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 22:58:48.174: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb  1 22:58:57.248: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 22:58:58.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-djsn2" for this suite.
Feb  1 22:59:20.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 22:59:20.298: INFO: namespace: e2e-tests-replicaset-djsn2, resource: bindings, ignored listing per whitelist
Feb  1 22:59:20.311: INFO: namespace e2e-tests-replicaset-djsn2 deletion completed in 22.0796441s

â€¢ [SLOW TEST:32.171 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 22:59:20.311: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  1 22:59:20.372: INFO: Creating ReplicaSet my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde
Feb  1 22:59:20.379: INFO: Pod name my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde: Found 0 pods out of 1
Feb  1 22:59:25.383: INFO: Pod name my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde: Found 1 pods out of 1
Feb  1 22:59:25.383: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde" is running
Feb  1 22:59:25.386: INFO: Pod "my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde-kgmx8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-01 22:59:20 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-01 22:59:23 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-01 22:59:23 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-01 22:59:20 +0000 UTC Reason: Message:}])
Feb  1 22:59:25.386: INFO: Trying to dial the pod
Feb  1 22:59:30.397: INFO: Controller my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde: Got expected result from replica 1 [my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde-kgmx8]: "my-hostname-basic-0255e45b-2675-11e9-a68a-f677bb5aadde-kgmx8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 22:59:30.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-8ztss" for this suite.
Feb  1 22:59:36.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 22:59:36.445: INFO: namespace: e2e-tests-replicaset-8ztss, resource: bindings, ignored listing per whitelist
Feb  1 22:59:36.477: INFO: namespace e2e-tests-replicaset-8ztss deletion completed in 6.0778414s

â€¢ [SLOW TEST:16.166 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 22:59:36.478: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-0bf75589-2675-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  1 22:59:36.538: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-gls7f" to be "success or failure"
Feb  1 22:59:36.541: INFO: Pod "pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.8614ms
Feb  1 22:59:38.511: INFO: Pod "pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0067019s
Feb  1 22:59:40.514: INFO: Pod "pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0102846s
STEP: Saw pod success
Feb  1 22:59:40.514: INFO: Pod "pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 22:59:40.517: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  1 22:59:40.539: INFO: Waiting for pod pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde to disappear
Feb  1 22:59:40.543: INFO: Pod pod-projected-secrets-0bf7d62a-2675-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 22:59:40.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gls7f" for this suite.
Feb  1 22:59:46.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 22:59:46.625: INFO: namespace: e2e-tests-projected-gls7f, resource: bindings, ignored listing per whitelist
Feb  1 22:59:46.631: INFO: namespace e2e-tests-projected-gls7f deletion completed in 6.0854608s

â€¢ [SLOW TEST:10.188 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 22:59:46.631: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb  1 22:59:46.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-97h9b'
Feb  1 22:59:46.819: INFO: stderr: ""
Feb  1 22:59:46.819: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb  1 22:59:47.823: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:59:47.823: INFO: Found 0 / 1
Feb  1 22:59:48.824: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:59:48.824: INFO: Found 0 / 1
Feb  1 22:59:49.824: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:59:49.824: INFO: Found 1 / 1
Feb  1 22:59:49.824: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  1 22:59:49.826: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 22:59:49.826: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb  1 22:59:49.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 logs redis-master-jmkl4 redis-master --namespace=e2e-tests-kubectl-97h9b'
Feb  1 22:59:49.909: INFO: stderr: ""
Feb  1 22:59:49.909: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Feb 22:59:48.152 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Feb 22:59:48.152 # Server started, Redis version 3.2.12\n1:M 01 Feb 22:59:48.152 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Feb 22:59:48.153 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb  1 22:59:49.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 log redis-master-jmkl4 redis-master --namespace=e2e-tests-kubectl-97h9b --tail=1'
Feb  1 22:59:49.983: INFO: stderr: ""
Feb  1 22:59:49.983: INFO: stdout: "1:M 01 Feb 22:59:48.153 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb  1 22:59:49.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 log redis-master-jmkl4 redis-master --namespace=e2e-tests-kubectl-97h9b --limit-bytes=1'
Feb  1 22:59:50.062: INFO: stderr: ""
Feb  1 22:59:50.062: INFO: stdout: " "
STEP: exposing timestamps
Feb  1 22:59:50.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 log redis-master-jmkl4 redis-master --namespace=e2e-tests-kubectl-97h9b --tail=1 --timestamps'
Feb  1 22:59:50.135: INFO: stderr: ""
Feb  1 22:59:50.135: INFO: stdout: "2019-02-01T22:59:48.1531741Z 1:M 01 Feb 22:59:48.153 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb  1 22:59:52.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 log redis-master-jmkl4 redis-master --namespace=e2e-tests-kubectl-97h9b --since=1s'
Feb  1 22:59:52.724: INFO: stderr: ""
Feb  1 22:59:52.724: INFO: stdout: ""
Feb  1 22:59:52.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 log redis-master-jmkl4 redis-master --namespace=e2e-tests-kubectl-97h9b --since=24h'
Feb  1 22:59:52.795: INFO: stderr: ""
Feb  1 22:59:52.795: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Feb 22:59:48.152 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Feb 22:59:48.152 # Server started, Redis version 3.2.12\n1:M 01 Feb 22:59:48.152 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Feb 22:59:48.153 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb  1 22:59:52.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-97h9b'
Feb  1 22:59:52.866: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  1 22:59:52.866: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb  1 22:59:52.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-97h9b'
Feb  1 22:59:52.962: INFO: stderr: "No resources found.\n"
Feb  1 22:59:52.962: INFO: stdout: ""
Feb  1 22:59:52.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -l name=nginx --namespace=e2e-tests-kubectl-97h9b -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  1 22:59:53.056: INFO: stderr: ""
Feb  1 22:59:53.056: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 22:59:53.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-97h9b" for this suite.
Feb  1 23:00:15.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:00:15.093: INFO: namespace: e2e-tests-kubectl-97h9b, resource: bindings, ignored listing per whitelist
Feb  1 23:00:15.097: INFO: namespace e2e-tests-kubectl-97h9b deletion completed in 22.0712288s

â€¢ [SLOW TEST:28.500 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:00:15.097: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  1 23:00:15.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:15.262: INFO: stderr: ""
Feb  1 23:00:15.262: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  1 23:00:15.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:15.376: INFO: stderr: ""
Feb  1 23:00:15.376: INFO: stdout: "update-demo-nautilus-gfw4r update-demo-nautilus-mgqz6 "
Feb  1 23:00:15.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-gfw4r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:15.442: INFO: stderr: ""
Feb  1 23:00:15.442: INFO: stdout: ""
Feb  1 23:00:15.442: INFO: update-demo-nautilus-gfw4r is created but not running
Feb  1 23:00:20.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:20.528: INFO: stderr: ""
Feb  1 23:00:20.528: INFO: stdout: "update-demo-nautilus-gfw4r update-demo-nautilus-mgqz6 "
Feb  1 23:00:20.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-gfw4r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:20.596: INFO: stderr: ""
Feb  1 23:00:20.596: INFO: stdout: "true"
Feb  1 23:00:20.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-gfw4r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:20.666: INFO: stderr: ""
Feb  1 23:00:20.666: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  1 23:00:20.666: INFO: validating pod update-demo-nautilus-gfw4r
Feb  1 23:00:20.670: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  1 23:00:20.670: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  1 23:00:20.670: INFO: update-demo-nautilus-gfw4r is verified up and running
Feb  1 23:00:20.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-mgqz6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:20.739: INFO: stderr: ""
Feb  1 23:00:20.739: INFO: stdout: "true"
Feb  1 23:00:20.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-mgqz6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:20.805: INFO: stderr: ""
Feb  1 23:00:20.805: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  1 23:00:20.805: INFO: validating pod update-demo-nautilus-mgqz6
Feb  1 23:00:20.810: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  1 23:00:20.810: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  1 23:00:20.810: INFO: update-demo-nautilus-mgqz6 is verified up and running
STEP: using delete to clean up resources
Feb  1 23:00:20.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:20.878: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  1 23:00:20.879: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  1 23:00:20.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-n6pmc'
Feb  1 23:00:20.980: INFO: stderr: "No resources found.\n"
Feb  1 23:00:20.981: INFO: stdout: ""
Feb  1 23:00:20.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -l name=update-demo --namespace=e2e-tests-kubectl-n6pmc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  1 23:00:21.063: INFO: stderr: ""
Feb  1 23:00:21.063: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:00:21.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n6pmc" for this suite.
Feb  1 23:00:43.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:00:43.081: INFO: namespace: e2e-tests-kubectl-n6pmc, resource: bindings, ignored listing per whitelist
Feb  1 23:00:43.112: INFO: namespace e2e-tests-kubectl-n6pmc deletion completed in 22.0782698s

â€¢ [SLOW TEST:28.049 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:00:43.112: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  1 23:00:43.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-zk26n'
Feb  1 23:00:43.246: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  1 23:00:43.246: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb  1 23:00:43.257: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb  1 23:00:43.266: INFO: scanned /root for discovery docs: <nil>
Feb  1 23:00:43.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-zk26n'
Feb  1 23:01:02.078: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  1 23:01:02.078: INFO: stdout: "Created e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a\nScaling up e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb  1 23:01:02.078: INFO: stdout: "Created e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a\nScaling up e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb  1 23:01:02.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-zk26n'
Feb  1 23:01:02.157: INFO: stderr: ""
Feb  1 23:01:02.157: INFO: stdout: "e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a-wjwqd "
Feb  1 23:01:02.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a-wjwqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zk26n'
Feb  1 23:01:02.225: INFO: stderr: ""
Feb  1 23:01:02.225: INFO: stdout: "true"
Feb  1 23:01:02.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a-wjwqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zk26n'
Feb  1 23:01:02.290: INFO: stderr: ""
Feb  1 23:01:02.290: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb  1 23:01:02.290: INFO: e2e-test-nginx-rc-9d985cd536d260718743581a6b98007a-wjwqd is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb  1 23:01:02.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-zk26n'
Feb  1 23:01:02.368: INFO: stderr: ""
Feb  1 23:01:02.368: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:01:02.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zk26n" for this suite.
Feb  1 23:01:24.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:01:24.393: INFO: namespace: e2e-tests-kubectl-zk26n, resource: bindings, ignored listing per whitelist
Feb  1 23:01:24.421: INFO: namespace e2e-tests-kubectl-zk26n deletion completed in 22.0821055s

â€¢ [SLOW TEST:41.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:01:24.422: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  1 23:01:32.514: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:32.516: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:34.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:34.521: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:36.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:36.521: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:38.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:38.487: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:40.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:40.486: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:42.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:42.486: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:44.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:44.487: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:46.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:46.487: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:48.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:48.487: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:50.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:50.486: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  1 23:01:52.483: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  1 23:01:52.487: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:01:52.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-97xqx" for this suite.
Feb  1 23:02:14.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:02:14.546: INFO: namespace: e2e-tests-container-lifecycle-hook-97xqx, resource: bindings, ignored listing per whitelist
Feb  1 23:02:14.551: INFO: namespace e2e-tests-container-lifecycle-hook-97xqx deletion completed in 22.0866667s

â€¢ [SLOW TEST:50.198 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:02:14.551: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kgsp9
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb  1 23:02:14.617: INFO: Found 0 stateful pods, waiting for 3
Feb  1 23:02:24.623: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  1 23:02:24.623: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  1 23:02:24.623: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  1 23:02:24.647: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  1 23:02:34.684: INFO: Updating stateful set ss2
Feb  1 23:02:34.693: INFO: Waiting for Pod e2e-tests-statefulset-kgsp9/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb  1 23:02:44.753: INFO: Found 2 stateful pods, waiting for 3
Feb  1 23:02:54.756: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  1 23:02:54.756: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  1 23:02:54.756: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  1 23:02:54.776: INFO: Updating stateful set ss2
Feb  1 23:02:54.780: INFO: Waiting for Pod e2e-tests-statefulset-kgsp9/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  1 23:03:04.808: INFO: Updating stateful set ss2
Feb  1 23:03:04.813: INFO: Waiting for StatefulSet e2e-tests-statefulset-kgsp9/ss2 to complete update
Feb  1 23:03:04.813: INFO: Waiting for Pod e2e-tests-statefulset-kgsp9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  1 23:03:14.786: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kgsp9
Feb  1 23:03:14.788: INFO: Scaling statefulset ss2 to 0
Feb  1 23:03:24.803: INFO: Waiting for statefulset status.replicas updated to 0
Feb  1 23:03:24.806: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:03:24.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kgsp9" for this suite.
Feb  1 23:03:30.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:03:30.869: INFO: namespace: e2e-tests-statefulset-kgsp9, resource: bindings, ignored listing per whitelist
Feb  1 23:03:30.904: INFO: namespace e2e-tests-statefulset-kgsp9 deletion completed in 6.0824442s

â€¢ [SLOW TEST:76.422 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:03:30.908: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-97b25789-2675-11e9-a68a-f677bb5aadde
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-97b25789-2675-11e9-a68a-f677bb5aadde
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:04:57.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5mx9d" for this suite.
Feb  1 23:05:19.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:05:19.434: INFO: namespace: e2e-tests-projected-5mx9d, resource: bindings, ignored listing per whitelist
Feb  1 23:05:19.451: INFO: namespace e2e-tests-projected-5mx9d deletion completed in 22.0871156s

â€¢ [SLOW TEST:108.681 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:05:19.453: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  1 23:05:19.508: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d864fb47-2675-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-cr4xz" to be "success or failure"
Feb  1 23:05:19.510: INFO: Pod "downwardapi-volume-d864fb47-2675-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.6447ms
Feb  1 23:05:21.513: INFO: Pod "downwardapi-volume-d864fb47-2675-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0049437s
STEP: Saw pod success
Feb  1 23:05:21.513: INFO: Pod "downwardapi-volume-d864fb47-2675-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:05:21.515: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-d864fb47-2675-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  1 23:05:21.529: INFO: Waiting for pod downwardapi-volume-d864fb47-2675-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:05:21.543: INFO: Pod downwardapi-volume-d864fb47-2675-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:05:21.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cr4xz" for this suite.
Feb  1 23:05:27.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:05:27.595: INFO: namespace: e2e-tests-projected-cr4xz, resource: bindings, ignored listing per whitelist
Feb  1 23:05:27.620: INFO: namespace e2e-tests-projected-cr4xz deletion completed in 6.0727768s

â€¢ [SLOW TEST:8.167 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:05:27.620: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  1 23:05:27.663: INFO: Creating deployment "test-recreate-deployment"
Feb  1 23:05:27.666: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  1 23:05:27.671: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb  1 23:05:29.680: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  1 23:05:29.684: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  1 23:05:29.691: INFO: Updating deployment test-recreate-deployment
Feb  1 23:05:29.691: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  1 23:05:29.760: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-5whcj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5whcj/deployments/test-recreate-deployment,UID:dd42471e-2675-11e9-b4dc-025000000001,ResourceVersion:11802,Generation:2,CreationTimestamp:2019-02-01 23:05:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-01 23:05:29 +0000 UTC 2019-02-01 23:05:29 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-01 23:05:29 +0000 UTC 2019-02-01 23:05:27 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb  1 23:05:29.762: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-5whcj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5whcj/replicasets/test-recreate-deployment-697fbf54bf,UID:de7be256-2675-11e9-b4dc-025000000001,ResourceVersion:11800,Generation:1,CreationTimestamp:2019-02-01 23:05:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd42471e-2675-11e9-b4dc-025000000001 0xc001a43527 0xc001a43528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  1 23:05:29.762: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  1 23:05:29.762: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-5whcj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5whcj/replicasets/test-recreate-deployment-5dfdcc846d,UID:dd4376f9-2675-11e9-b4dc-025000000001,ResourceVersion:11791,Generation:2,CreationTimestamp:2019-02-01 23:05:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd42471e-2675-11e9-b4dc-025000000001 0xc001a43467 0xc001a43468}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  1 23:05:29.764: INFO: Pod "test-recreate-deployment-697fbf54bf-sx8fz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-sx8fz,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-5whcj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5whcj/pods/test-recreate-deployment-697fbf54bf-sx8fz,UID:de7c5c5a-2675-11e9-b4dc-025000000001,ResourceVersion:11803,Generation:0,CreationTimestamp:2019-02-01 23:05:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf de7be256-2675-11e9-b4dc-025000000001 0xc001a43d97 0xc001a43d98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hx4pm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hx4pm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hx4pm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a43e10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a43e30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:05:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:05:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:05:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:05:29 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-02-01 23:05:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:05:29.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5whcj" for this suite.
Feb  1 23:05:35.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:05:35.825: INFO: namespace: e2e-tests-deployment-5whcj, resource: bindings, ignored listing per whitelist
Feb  1 23:05:35.849: INFO: namespace e2e-tests-deployment-5whcj deletion completed in 6.0822801s

â€¢ [SLOW TEST:8.229 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:05:35.849: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:05:41.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-j7l9n" for this suite.
Feb  1 23:05:47.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:05:48.000: INFO: namespace: e2e-tests-namespaces-j7l9n, resource: bindings, ignored listing per whitelist
Feb  1 23:05:48.023: INFO: namespace e2e-tests-namespaces-j7l9n deletion completed in 6.0799283s
STEP: Destroying namespace "e2e-tests-nsdeletetest-85k4r" for this suite.
Feb  1 23:05:48.025: INFO: Namespace e2e-tests-nsdeletetest-85k4r was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-cmsgq" for this suite.
Feb  1 23:05:54.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:05:54.061: INFO: namespace: e2e-tests-nsdeletetest-cmsgq, resource: bindings, ignored listing per whitelist
Feb  1 23:05:54.096: INFO: namespace e2e-tests-nsdeletetest-cmsgq deletion completed in 6.0714106s

â€¢ [SLOW TEST:18.282 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:05:54.097: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  1 23:05:54.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-9zpqt'
Feb  1 23:05:54.222: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  1 23:05:54.223: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb  1 23:05:54.235: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-9hf5g]
Feb  1 23:05:54.236: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-9hf5g" in namespace "e2e-tests-kubectl-9zpqt" to be "running and ready"
Feb  1 23:05:54.241: INFO: Pod "e2e-test-nginx-rc-9hf5g": Phase="Pending", Reason="", readiness=false. Elapsed: 4.997ms
Feb  1 23:05:56.245: INFO: Pod "e2e-test-nginx-rc-9hf5g": Phase="Running", Reason="", readiness=true. Elapsed: 2.0095724s
Feb  1 23:05:56.245: INFO: Pod "e2e-test-nginx-rc-9hf5g" satisfied condition "running and ready"
Feb  1 23:05:56.245: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-9hf5g]
Feb  1 23:05:56.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9zpqt'
Feb  1 23:05:56.332: INFO: stderr: ""
Feb  1 23:05:56.332: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb  1 23:05:56.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9zpqt'
Feb  1 23:05:56.401: INFO: stderr: ""
Feb  1 23:05:56.401: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:05:56.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9zpqt" for this suite.
Feb  1 23:06:18.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:06:18.435: INFO: namespace: e2e-tests-kubectl-9zpqt, resource: bindings, ignored listing per whitelist
Feb  1 23:06:18.454: INFO: namespace e2e-tests-kubectl-9zpqt deletion completed in 22.0824912s

â€¢ [SLOW TEST:24.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:06:18.455: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:06:20.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-25mt7" for this suite.
Feb  1 23:07:02.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:07:02.572: INFO: namespace: e2e-tests-kubelet-test-25mt7, resource: bindings, ignored listing per whitelist
Feb  1 23:07:02.586: INFO: namespace e2e-tests-kubelet-test-25mt7 deletion completed in 42.0804515s

â€¢ [SLOW TEST:44.166 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:07:02.586: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  1 23:07:02.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-qmsbg'
Feb  1 23:07:02.786: INFO: stderr: ""
Feb  1 23:07:02.787: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  1 23:07:03.790: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:07:03.790: INFO: Found 0 / 1
Feb  1 23:07:04.792: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:07:04.792: INFO: Found 0 / 1
Feb  1 23:07:05.792: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:07:05.792: INFO: Found 1 / 1
Feb  1 23:07:05.792: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  1 23:07:05.795: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:07:05.795: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  1 23:07:05.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 patch pod redis-master-78tmp --namespace=e2e-tests-kubectl-qmsbg -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  1 23:07:05.874: INFO: stderr: ""
Feb  1 23:07:05.874: INFO: stdout: "pod/redis-master-78tmp patched\n"
STEP: checking annotations
Feb  1 23:07:05.877: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:07:05.877: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:07:05.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qmsbg" for this suite.
Feb  1 23:07:27.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:07:27.927: INFO: namespace: e2e-tests-kubectl-qmsbg, resource: bindings, ignored listing per whitelist
Feb  1 23:07:27.927: INFO: namespace e2e-tests-kubectl-qmsbg deletion completed in 22.0809796s

â€¢ [SLOW TEST:25.375 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:07:27.927: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  1 23:07:27.977: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  1 23:07:27.982: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  1 23:07:32.989: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  1 23:07:32.989: INFO: Creating deployment "test-rolling-update-deployment"
Feb  1 23:07:32.996: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  1 23:07:33.005: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  1 23:07:35.014: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  1 23:07:35.020: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  1 23:07:35.028: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-vdrkb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vdrkb/deployments/test-rolling-update-deployment,UID:27f5b610-2676-11e9-b4dc-025000000001,ResourceVersion:12144,Generation:1,CreationTimestamp:2019-02-01 23:07:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-01 23:07:33 +0000 UTC 2019-02-01 23:07:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-01 23:07:34 +0000 UTC 2019-02-01 23:07:33 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  1 23:07:35.031: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-vdrkb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vdrkb/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:27f867ea-2676-11e9-b4dc-025000000001,ResourceVersion:12135,Generation:1,CreationTimestamp:2019-02-01 23:07:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 27f5b610-2676-11e9-b4dc-025000000001 0xc001dba597 0xc001dba598}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  1 23:07:35.031: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  1 23:07:35.031: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-vdrkb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vdrkb/replicasets/test-rolling-update-controller,UID:24f8ab2b-2676-11e9-b4dc-025000000001,ResourceVersion:12143,Generation:2,CreationTimestamp:2019-02-01 23:07:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 27f5b610-2676-11e9-b4dc-025000000001 0xc001dba4d7 0xc001dba4d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  1 23:07:35.034: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-9mxfl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-9mxfl,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-vdrkb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vdrkb/pods/test-rolling-update-deployment-68b55d7bc6-9mxfl,UID:27f91e5f-2676-11e9-b4dc-025000000001,ResourceVersion:12134,Generation:0,CreationTimestamp:2019-02-01 23:07:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 27f867ea-2676-11e9-b4dc-025000000001 0xc001dbae57 0xc001dbae58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gtcjl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gtcjl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gtcjl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001dbaed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001dbaef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:07:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:07:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:07:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-01 23:07:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.36,StartTime:2019-02-01 23:07:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-01 23:07:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4c03d293a12716a0c8811072ec4c5bbaa3249f6390ff434822bbd69799f260d3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:07:35.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vdrkb" for this suite.
Feb  1 23:07:41.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:07:41.042: INFO: namespace: e2e-tests-deployment-vdrkb, resource: bindings, ignored listing per whitelist
Feb  1 23:07:41.074: INFO: namespace e2e-tests-deployment-vdrkb deletion completed in 6.071793s

â€¢ [SLOW TEST:13.181 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:07:41.075: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  1 23:07:41.133: INFO: Waiting up to 5m0s for pod "pod-2ccf1054-2676-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-rjrd6" to be "success or failure"
Feb  1 23:07:41.135: INFO: Pod "pod-2ccf1054-2676-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.307ms
Feb  1 23:07:43.142: INFO: Pod "pod-2ccf1054-2676-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0093476s
Feb  1 23:07:45.146: INFO: Pod "pod-2ccf1054-2676-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0133297s
STEP: Saw pod success
Feb  1 23:07:45.147: INFO: Pod "pod-2ccf1054-2676-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:07:45.149: INFO: Trying to get logs from node docker-desktop pod pod-2ccf1054-2676-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  1 23:07:45.167: INFO: Waiting for pod pod-2ccf1054-2676-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:07:45.170: INFO: Pod pod-2ccf1054-2676-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:07:45.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rjrd6" for this suite.
Feb  1 23:07:51.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:07:51.207: INFO: namespace: e2e-tests-emptydir-rjrd6, resource: bindings, ignored listing per whitelist
Feb  1 23:07:51.267: INFO: namespace e2e-tests-emptydir-rjrd6 deletion completed in 6.092525s

â€¢ [SLOW TEST:10.193 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:07:51.269: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  1 23:07:51.326: INFO: Waiting up to 5m0s for pod "pod-32e242fe-2676-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-5vvmp" to be "success or failure"
Feb  1 23:07:51.333: INFO: Pod "pod-32e242fe-2676-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 6.8333ms
Feb  1 23:07:53.337: INFO: Pod "pod-32e242fe-2676-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0099085s
STEP: Saw pod success
Feb  1 23:07:53.337: INFO: Pod "pod-32e242fe-2676-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:07:53.338: INFO: Trying to get logs from node docker-desktop pod pod-32e242fe-2676-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  1 23:07:53.354: INFO: Waiting for pod pod-32e242fe-2676-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:07:53.357: INFO: Pod pod-32e242fe-2676-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:07:53.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5vvmp" for this suite.
Feb  1 23:07:59.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:07:59.396: INFO: namespace: e2e-tests-emptydir-5vvmp, resource: bindings, ignored listing per whitelist
Feb  1 23:07:59.428: INFO: namespace e2e-tests-emptydir-5vvmp deletion completed in 6.0665788s

â€¢ [SLOW TEST:8.159 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:07:59.430: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  1 23:07:59.507: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"37c01029-2676-11e9-b4dc-025000000001", Controller:(*bool)(0xc00187020e), BlockOwnerDeletion:(*bool)(0xc00187020f)}}
Feb  1 23:07:59.531: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"37bea433-2676-11e9-b4dc-025000000001", Controller:(*bool)(0xc001a43142), BlockOwnerDeletion:(*bool)(0xc001a43143)}}
Feb  1 23:07:59.540: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"37bf26eb-2676-11e9-b4dc-025000000001", Controller:(*bool)(0xc001870476), BlockOwnerDeletion:(*bool)(0xc001870477)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:08:04.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gm2lz" for this suite.
Feb  1 23:08:10.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:08:10.581: INFO: namespace: e2e-tests-gc-gm2lz, resource: bindings, ignored listing per whitelist
Feb  1 23:08:10.595: INFO: namespace e2e-tests-gc-gm2lz deletion completed in 6.0769307s

â€¢ [SLOW TEST:11.205 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:08:10.595: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3e669778-2676-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  1 23:08:10.653: INFO: Waiting up to 5m0s for pod "pod-secrets-3e6779b8-2676-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-6wsqm" to be "success or failure"
Feb  1 23:08:10.657: INFO: Pod "pod-secrets-3e6779b8-2676-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.069ms
Feb  1 23:08:12.661: INFO: Pod "pod-secrets-3e6779b8-2676-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0075688s
STEP: Saw pod success
Feb  1 23:08:12.661: INFO: Pod "pod-secrets-3e6779b8-2676-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:08:12.664: INFO: Trying to get logs from node docker-desktop pod pod-secrets-3e6779b8-2676-11e9-a68a-f677bb5aadde container secret-env-test: <nil>
STEP: delete the pod
Feb  1 23:08:12.683: INFO: Waiting for pod pod-secrets-3e6779b8-2676-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:08:12.689: INFO: Pod pod-secrets-3e6779b8-2676-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:08:12.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6wsqm" for this suite.
Feb  1 23:08:18.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:08:18.741: INFO: namespace: e2e-tests-secrets-6wsqm, resource: bindings, ignored listing per whitelist
Feb  1 23:08:18.774: INFO: namespace e2e-tests-secrets-6wsqm deletion completed in 6.0824312s

â€¢ [SLOW TEST:8.179 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:08:18.777: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qdfwf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  1 23:08:18.824: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  1 23:45:40.292: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.0.41:8080/dial?request=hostName&protocol=http&host=10.1.0.40&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-qdfwf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  1 23:45:40.292: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  1 23:45:40.864: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:45:40.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qdfwf" for this suite.
Feb  1 23:46:04.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:46:05.322: INFO: namespace: e2e-tests-pod-network-test-qdfwf, resource: bindings, ignored listing per whitelist
Feb  1 23:46:05.342: INFO: namespace e2e-tests-pod-network-test-qdfwf deletion completed in 24.4600232s

â€¢ [SLOW TEST:45.283 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:46:05.343: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:46:13.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-mv8jp" for this suite.
Feb  1 23:46:19.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:46:20.168: INFO: namespace: e2e-tests-emptydir-wrapper-mv8jp, resource: bindings, ignored listing per whitelist
Feb  1 23:46:20.372: INFO: namespace e2e-tests-emptydir-wrapper-mv8jp deletion completed in 6.5229647s

â€¢ [SLOW TEST:15.045 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:46:20.374: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-936950cb-267b-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  1 23:46:20.788: INFO: Waiting up to 5m0s for pod "pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-c5v56" to be "success or failure"
Feb  1 23:46:20.800: INFO: Pod "pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 8.2722ms
Feb  1 23:46:22.817: INFO: Pod "pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0248963s
Feb  1 23:46:24.826: INFO: Pod "pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0347202s
Feb  1 23:46:26.840: INFO: Pod "pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0484358s
STEP: Saw pod success
Feb  1 23:46:26.840: INFO: Pod "pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:46:26.849: INFO: Trying to get logs from node docker-desktop pod pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  1 23:46:26.970: INFO: Waiting for pod pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:46:26.992: INFO: Pod pod-secrets-936b80e5-267b-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:46:26.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-c5v56" for this suite.
Feb  1 23:46:33.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:46:33.347: INFO: namespace: e2e-tests-secrets-c5v56, resource: bindings, ignored listing per whitelist
Feb  1 23:46:33.452: INFO: namespace e2e-tests-secrets-c5v56 deletion completed in 6.4443702s

â€¢ [SLOW TEST:13.079 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:46:33.453: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  1 23:46:33.849: INFO: Waiting up to 5m0s for pod "pod-9b34226c-267b-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-sj9s9" to be "success or failure"
Feb  1 23:46:33.873: INFO: Pod "pod-9b34226c-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 23.7354ms
Feb  1 23:46:35.912: INFO: Pod "pod-9b34226c-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0619867s
Feb  1 23:46:37.897: INFO: Pod "pod-9b34226c-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0787049s
Feb  1 23:46:39.912: INFO: Pod "pod-9b34226c-267b-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0936331s
STEP: Saw pod success
Feb  1 23:46:39.912: INFO: Pod "pod-9b34226c-267b-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:46:39.922: INFO: Trying to get logs from node docker-desktop pod pod-9b34226c-267b-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  1 23:46:40.035: INFO: Waiting for pod pod-9b34226c-267b-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:46:40.063: INFO: Pod pod-9b34226c-267b-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:46:40.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sj9s9" for this suite.
Feb  1 23:46:46.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:46:46.340: INFO: namespace: e2e-tests-emptydir-sj9s9, resource: bindings, ignored listing per whitelist
Feb  1 23:46:46.555: INFO: namespace e2e-tests-emptydir-sj9s9 deletion completed in 6.4731325s

â€¢ [SLOW TEST:13.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:46:46.560: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  1 23:46:47.111: INFO: Number of nodes with available pods: 0
Feb  1 23:46:47.111: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:48.142: INFO: Number of nodes with available pods: 0
Feb  1 23:46:48.142: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:49.138: INFO: Number of nodes with available pods: 0
Feb  1 23:46:49.138: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:50.131: INFO: Number of nodes with available pods: 0
Feb  1 23:46:50.132: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:51.164: INFO: Number of nodes with available pods: 0
Feb  1 23:46:51.164: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:52.133: INFO: Number of nodes with available pods: 1
Feb  1 23:46:52.133: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  1 23:46:52.254: INFO: Number of nodes with available pods: 0
Feb  1 23:46:52.255: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:53.284: INFO: Number of nodes with available pods: 0
Feb  1 23:46:53.284: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:54.272: INFO: Number of nodes with available pods: 0
Feb  1 23:46:54.272: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:55.277: INFO: Number of nodes with available pods: 0
Feb  1 23:46:55.277: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:56.271: INFO: Number of nodes with available pods: 0
Feb  1 23:46:56.271: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:57.277: INFO: Number of nodes with available pods: 0
Feb  1 23:46:57.278: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:58.271: INFO: Number of nodes with available pods: 0
Feb  1 23:46:58.272: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:46:59.278: INFO: Number of nodes with available pods: 0
Feb  1 23:46:59.279: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:00.274: INFO: Number of nodes with available pods: 0
Feb  1 23:47:00.275: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:01.273: INFO: Number of nodes with available pods: 0
Feb  1 23:47:01.274: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:02.275: INFO: Number of nodes with available pods: 0
Feb  1 23:47:02.275: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:03.272: INFO: Number of nodes with available pods: 0
Feb  1 23:47:03.272: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:04.279: INFO: Number of nodes with available pods: 0
Feb  1 23:47:04.279: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:05.276: INFO: Number of nodes with available pods: 0
Feb  1 23:47:05.277: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:06.273: INFO: Number of nodes with available pods: 0
Feb  1 23:47:06.275: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:07.275: INFO: Number of nodes with available pods: 0
Feb  1 23:47:07.275: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:08.247: INFO: Number of nodes with available pods: 0
Feb  1 23:47:08.247: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:09.243: INFO: Number of nodes with available pods: 0
Feb  1 23:47:09.243: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:10.252: INFO: Number of nodes with available pods: 0
Feb  1 23:47:10.253: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:11.238: INFO: Number of nodes with available pods: 0
Feb  1 23:47:11.239: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:12.250: INFO: Number of nodes with available pods: 0
Feb  1 23:47:12.250: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:13.237: INFO: Number of nodes with available pods: 0
Feb  1 23:47:13.237: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:14.236: INFO: Number of nodes with available pods: 0
Feb  1 23:47:14.236: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:15.235: INFO: Number of nodes with available pods: 0
Feb  1 23:47:15.235: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:16.233: INFO: Number of nodes with available pods: 0
Feb  1 23:47:16.233: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:17.239: INFO: Number of nodes with available pods: 0
Feb  1 23:47:17.239: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:18.235: INFO: Number of nodes with available pods: 0
Feb  1 23:47:18.235: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:19.233: INFO: Number of nodes with available pods: 0
Feb  1 23:47:19.234: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:20.234: INFO: Number of nodes with available pods: 0
Feb  1 23:47:20.234: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:21.232: INFO: Number of nodes with available pods: 0
Feb  1 23:47:21.232: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:22.243: INFO: Number of nodes with available pods: 0
Feb  1 23:47:22.243: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:23.232: INFO: Number of nodes with available pods: 0
Feb  1 23:47:23.232: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:24.233: INFO: Number of nodes with available pods: 0
Feb  1 23:47:24.233: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:25.233: INFO: Number of nodes with available pods: 0
Feb  1 23:47:25.234: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:26.231: INFO: Number of nodes with available pods: 0
Feb  1 23:47:26.231: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:27.230: INFO: Number of nodes with available pods: 0
Feb  1 23:47:27.230: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:28.230: INFO: Number of nodes with available pods: 0
Feb  1 23:47:28.230: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:29.231: INFO: Number of nodes with available pods: 0
Feb  1 23:47:29.231: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:30.231: INFO: Number of nodes with available pods: 0
Feb  1 23:47:30.231: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:31.230: INFO: Number of nodes with available pods: 0
Feb  1 23:47:31.230: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:32.233: INFO: Number of nodes with available pods: 0
Feb  1 23:47:32.233: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:33.231: INFO: Number of nodes with available pods: 0
Feb  1 23:47:33.231: INFO: Node docker-desktop is running more than one daemon pod
Feb  1 23:47:34.229: INFO: Number of nodes with available pods: 1
Feb  1 23:47:34.229: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-4m2qr, will wait for the garbage collector to delete the pods
Feb  1 23:47:34.299: INFO: Deleting DaemonSet.extensions daemon-set took: 11.8042ms
Feb  1 23:47:34.402: INFO: Terminating DaemonSet.extensions daemon-set pods took: 102.3254ms
Feb  1 23:48:11.540: INFO: Number of nodes with available pods: 0
Feb  1 23:48:11.540: INFO: Number of running nodes: 0, number of available pods: 0
Feb  1 23:48:11.544: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4m2qr/daemonsets","resourceVersion":"12707"},"items":null}

Feb  1 23:48:11.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4m2qr/pods","resourceVersion":"12707"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:48:11.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4m2qr" for this suite.
Feb  1 23:48:17.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:48:17.626: INFO: namespace: e2e-tests-daemonsets-4m2qr, resource: bindings, ignored listing per whitelist
Feb  1 23:48:17.640: INFO: namespace e2e-tests-daemonsets-4m2qr deletion completed in 6.0856417s

â€¢ [SLOW TEST:91.187 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:48:17.642: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0201 23:48:23.731546      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  1 23:48:23.731: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:48:23.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lcbwh" for this suite.
Feb  1 23:48:29.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:48:29.812: INFO: namespace: e2e-tests-gc-lcbwh, resource: bindings, ignored listing per whitelist
Feb  1 23:48:29.839: INFO: namespace e2e-tests-gc-lcbwh deletion completed in 6.095128s

â€¢ [SLOW TEST:12.198 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:48:29.839: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  1 23:48:29.914: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb  1 23:48:29.920: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-76bh6/daemonsets","resourceVersion":"12944"},"items":null}

Feb  1 23:48:29.922: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-76bh6/pods","resourceVersion":"12944"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:48:29.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-76bh6" for this suite.
Feb  1 23:48:35.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:48:35.950: INFO: namespace: e2e-tests-daemonsets-76bh6, resource: bindings, ignored listing per whitelist
Feb  1 23:48:36.013: INFO: namespace e2e-tests-daemonsets-76bh6 deletion completed in 6.0849283s

S [SKIPPING] [6.174 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb  1 23:48:29.914: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:48:36.014: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e4124afa-267b-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  1 23:48:36.086: INFO: Waiting up to 5m0s for pod "pod-configmaps-e4130e5e-267b-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-tsd9q" to be "success or failure"
Feb  1 23:48:36.100: INFO: Pod "pod-configmaps-e4130e5e-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 13.6766ms
Feb  1 23:48:38.069: INFO: Pod "pod-configmaps-e4130e5e-267b-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0171781s
STEP: Saw pod success
Feb  1 23:48:38.069: INFO: Pod "pod-configmaps-e4130e5e-267b-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:48:38.073: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-e4130e5e-267b-11e9-a68a-f677bb5aadde container configmap-volume-test: <nil>
STEP: delete the pod
Feb  1 23:48:38.105: INFO: Waiting for pod pod-configmaps-e4130e5e-267b-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:48:38.108: INFO: Pod pod-configmaps-e4130e5e-267b-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:48:38.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tsd9q" for this suite.
Feb  1 23:48:44.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:48:44.183: INFO: namespace: e2e-tests-configmap-tsd9q, resource: bindings, ignored listing per whitelist
Feb  1 23:48:44.211: INFO: namespace e2e-tests-configmap-tsd9q deletion completed in 6.0968303s

â€¢ [SLOW TEST:8.232 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:48:44.211: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  1 23:48:44.281: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8f57e54-267b-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-7fjs5" to be "success or failure"
Feb  1 23:48:44.290: INFO: Pod "downwardapi-volume-e8f57e54-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 9.1607ms
Feb  1 23:48:46.294: INFO: Pod "downwardapi-volume-e8f57e54-267b-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0125732s
STEP: Saw pod success
Feb  1 23:48:46.294: INFO: Pod "downwardapi-volume-e8f57e54-267b-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:48:46.297: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-e8f57e54-267b-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  1 23:48:46.334: INFO: Waiting for pod downwardapi-volume-e8f57e54-267b-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:48:46.337: INFO: Pod downwardapi-volume-e8f57e54-267b-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:48:46.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7fjs5" for this suite.
Feb  1 23:48:52.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:48:52.386: INFO: namespace: e2e-tests-projected-7fjs5, resource: bindings, ignored listing per whitelist
Feb  1 23:48:52.430: INFO: namespace e2e-tests-projected-7fjs5 deletion completed in 6.0882371s

â€¢ [SLOW TEST:8.219 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:48:52.430: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  1 23:48:52.496: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eddb00af-267b-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-w22hw" to be "success or failure"
Feb  1 23:48:52.498: INFO: Pod "downwardapi-volume-eddb00af-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.2041ms
Feb  1 23:48:54.501: INFO: Pod "downwardapi-volume-eddb00af-267b-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0051414s
STEP: Saw pod success
Feb  1 23:48:54.501: INFO: Pod "downwardapi-volume-eddb00af-267b-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:48:54.503: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-eddb00af-267b-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  1 23:48:54.533: INFO: Waiting for pod downwardapi-volume-eddb00af-267b-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:48:54.538: INFO: Pod downwardapi-volume-eddb00af-267b-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:48:54.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w22hw" for this suite.
Feb  1 23:49:00.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:49:00.594: INFO: namespace: e2e-tests-downward-api-w22hw, resource: bindings, ignored listing per whitelist
Feb  1 23:49:00.633: INFO: namespace e2e-tests-downward-api-w22hw deletion completed in 6.0915663s

â€¢ [SLOW TEST:8.202 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:49:00.633: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  1 23:49:00.688: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  1 23:49:00.693: INFO: Waiting for terminating namespaces to be deleted...
Feb  1 23:49:00.696: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Feb  1 23:49:00.701: INFO: coredns-86c58d9df4-492hj from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  1 23:49:00.701: INFO: 	Container coredns ready: true, restart count 0
Feb  1 23:49:00.701: INFO: kube-proxy-hzvvt from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  1 23:49:00.701: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  1 23:49:00.701: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  1 23:49:00.701: INFO: sonobuoy-systemd-logs-daemon-set-2081b0686f0449ba-4wdch from heptio-sonobuoy started at 2019-02-01 22:53:40 +0000 UTC (2 container statuses recorded)
Feb  1 23:49:00.701: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 8
Feb  1 23:49:00.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  1 23:49:00.701: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  1 23:49:00.701: INFO: coredns-86c58d9df4-zxg7j from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  1 23:49:00.701: INFO: 	Container coredns ready: true, restart count 0
Feb  1 23:49:00.701: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-01 22:53:35 +0000 UTC (1 container statuses recorded)
Feb  1 23:49:00.701: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  1 23:49:00.701: INFO: sonobuoy-e2e-job-bb494af789db4143 from heptio-sonobuoy started at 2019-02-01 22:53:40 +0000 UTC (2 container statuses recorded)
Feb  1 23:49:00.702: INFO: 	Container e2e ready: true, restart count 0
Feb  1 23:49:00.702: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  1 23:49:00.702: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  1 23:49:00.702: INFO: compose-api-5fb5fd58d-fjvcj from docker started at 2019-02-01 15:57:21 +0000 UTC (1 container statuses recorded)
Feb  1 23:49:00.702: INFO: 	Container compose ready: true, restart count 0
Feb  1 23:49:00.702: INFO: compose-56897cc96b-gnrcd from docker started at 2019-02-01 15:57:21 +0000 UTC (1 container statuses recorded)
Feb  1 23:49:00.702: INFO: 	Container compose ready: true, restart count 0
Feb  1 23:49:00.702: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node docker-desktop
Feb  1 23:49:00.716: INFO: Pod compose-56897cc96b-gnrcd requesting resource cpu=0m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod compose-api-5fb5fd58d-fjvcj requesting resource cpu=0m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod sonobuoy requesting resource cpu=0m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod sonobuoy-e2e-job-bb494af789db4143 requesting resource cpu=0m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod sonobuoy-systemd-logs-daemon-set-2081b0686f0449ba-4wdch requesting resource cpu=0m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod coredns-86c58d9df4-492hj requesting resource cpu=100m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod coredns-86c58d9df4-zxg7j requesting resource cpu=100m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod etcd-docker-desktop requesting resource cpu=0m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod kube-apiserver-docker-desktop requesting resource cpu=250m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod kube-controller-manager-docker-desktop requesting resource cpu=200m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod kube-proxy-hzvvt requesting resource cpu=0m on Node docker-desktop
Feb  1 23:49:00.716: INFO: Pod kube-scheduler-docker-desktop requesting resource cpu=100m on Node docker-desktop
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2c254bb-267b-11e9-a68a-f677bb5aadde.157f625b35ed0490], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-wwr7q/filler-pod-f2c254bb-267b-11e9-a68a-f677bb5aadde to docker-desktop]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2c254bb-267b-11e9-a68a-f677bb5aadde.157f625b7832c434], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2c254bb-267b-11e9-a68a-f677bb5aadde.157f625b82f104a8], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2c254bb-267b-11e9-a68a-f677bb5aadde.157f625b98b9ada8], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157f625bae664f44], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node docker-desktop
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:49:03.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wwr7q" for this suite.
Feb  1 23:49:09.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:49:09.789: INFO: namespace: e2e-tests-sched-pred-wwr7q, resource: bindings, ignored listing per whitelist
Feb  1 23:49:09.823: INFO: namespace e2e-tests-sched-pred-wwr7q deletion completed in 6.0959048s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:9.225 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:49:09.824: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f83759f1-267b-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  1 23:49:09.880: INFO: Waiting up to 5m0s for pod "pod-secrets-f837caf1-267b-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-t58wv" to be "success or failure"
Feb  1 23:49:09.883: INFO: Pod "pod-secrets-f837caf1-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1061ms
Feb  1 23:49:11.887: INFO: Pod "pod-secrets-f837caf1-267b-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0062629s
STEP: Saw pod success
Feb  1 23:49:11.887: INFO: Pod "pod-secrets-f837caf1-267b-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:49:11.889: INFO: Trying to get logs from node docker-desktop pod pod-secrets-f837caf1-267b-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  1 23:49:11.906: INFO: Waiting for pod pod-secrets-f837caf1-267b-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:49:11.908: INFO: Pod pod-secrets-f837caf1-267b-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:49:11.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t58wv" for this suite.
Feb  1 23:49:17.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:49:17.982: INFO: namespace: e2e-tests-secrets-t58wv, resource: bindings, ignored listing per whitelist
Feb  1 23:49:17.995: INFO: namespace e2e-tests-secrets-t58wv deletion completed in 6.0835014s

â€¢ [SLOW TEST:8.172 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:49:18.000: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-fd17d5c6-267b-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  1 23:49:18.062: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fd1851d9-267b-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-8kjlj" to be "success or failure"
Feb  1 23:49:18.065: INFO: Pod "pod-projected-secrets-fd1851d9-267b-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.7014ms
Feb  1 23:49:20.072: INFO: Pod "pod-projected-secrets-fd1851d9-267b-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0093058s
STEP: Saw pod success
Feb  1 23:49:20.072: INFO: Pod "pod-projected-secrets-fd1851d9-267b-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:49:20.076: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-fd1851d9-267b-11e9-a68a-f677bb5aadde container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  1 23:49:20.091: INFO: Waiting for pod pod-projected-secrets-fd1851d9-267b-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:49:20.096: INFO: Pod pod-projected-secrets-fd1851d9-267b-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:49:20.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8kjlj" for this suite.
Feb  1 23:49:26.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:49:26.131: INFO: namespace: e2e-tests-projected-8kjlj, resource: bindings, ignored listing per whitelist
Feb  1 23:49:26.178: INFO: namespace e2e-tests-projected-8kjlj deletion completed in 6.0764972s

â€¢ [SLOW TEST:8.178 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:49:26.182: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  1 23:49:26.234: INFO: Waiting up to 5m0s for pod "downward-api-01f74820-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-bfcwv" to be "success or failure"
Feb  1 23:49:26.247: INFO: Pod "downward-api-01f74820-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 11.9803ms
Feb  1 23:49:28.251: INFO: Pod "downward-api-01f74820-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0159992s
STEP: Saw pod success
Feb  1 23:49:28.251: INFO: Pod "downward-api-01f74820-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:49:28.252: INFO: Trying to get logs from node docker-desktop pod downward-api-01f74820-267c-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  1 23:49:28.268: INFO: Waiting for pod downward-api-01f74820-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:49:28.271: INFO: Pod downward-api-01f74820-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:49:28.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bfcwv" for this suite.
Feb  1 23:49:34.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:49:34.318: INFO: namespace: e2e-tests-downward-api-bfcwv, resource: bindings, ignored listing per whitelist
Feb  1 23:49:34.366: INFO: namespace e2e-tests-downward-api-bfcwv deletion completed in 6.0930585s

â€¢ [SLOW TEST:8.184 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:49:34.366: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb  1 23:49:34.421: INFO: Waiting up to 5m0s for pod "client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-containers-j29pv" to be "success or failure"
Feb  1 23:49:34.423: INFO: Pod "client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.9542ms
Feb  1 23:49:36.432: INFO: Pod "client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0108813s
Feb  1 23:49:38.400: INFO: Pod "client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014057s
STEP: Saw pod success
Feb  1 23:49:38.400: INFO: Pod "client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:49:38.403: INFO: Trying to get logs from node docker-desktop pod client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  1 23:49:38.417: INFO: Waiting for pod client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:49:38.419: INFO: Pod client-containers-06d893ac-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:49:38.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-j29pv" for this suite.
Feb  1 23:49:44.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:49:44.492: INFO: namespace: e2e-tests-containers-j29pv, resource: bindings, ignored listing per whitelist
Feb  1 23:49:44.513: INFO: namespace e2e-tests-containers-j29pv deletion completed in 6.091913s

â€¢ [SLOW TEST:10.182 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:49:44.517: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb  1 23:49:44.591: INFO: Waiting up to 5m0s for pod "client-containers-0ce80f1c-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-containers-2qnqw" to be "success or failure"
Feb  1 23:49:44.594: INFO: Pod "client-containers-0ce80f1c-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.3778ms
Feb  1 23:49:46.600: INFO: Pod "client-containers-0ce80f1c-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0092865s
STEP: Saw pod success
Feb  1 23:49:46.600: INFO: Pod "client-containers-0ce80f1c-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:49:46.603: INFO: Trying to get logs from node docker-desktop pod client-containers-0ce80f1c-267c-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  1 23:49:46.620: INFO: Waiting for pod client-containers-0ce80f1c-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:49:46.623: INFO: Pod client-containers-0ce80f1c-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:49:46.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2qnqw" for this suite.
Feb  1 23:49:52.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:49:52.728: INFO: namespace: e2e-tests-containers-2qnqw, resource: bindings, ignored listing per whitelist
Feb  1 23:49:52.739: INFO: namespace e2e-tests-containers-2qnqw deletion completed in 6.1118441s

â€¢ [SLOW TEST:8.223 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:49:52.739: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-11cf4438-267c-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  1 23:49:52.822: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11cfef1e-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-5bs2q" to be "success or failure"
Feb  1 23:49:52.830: INFO: Pod "pod-projected-configmaps-11cfef1e-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 6.5115ms
Feb  1 23:49:54.834: INFO: Pod "pod-projected-configmaps-11cfef1e-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0107641s
STEP: Saw pod success
Feb  1 23:49:54.834: INFO: Pod "pod-projected-configmaps-11cfef1e-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:49:54.837: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-11cfef1e-267c-11e9-a68a-f677bb5aadde container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  1 23:49:54.861: INFO: Waiting for pod pod-projected-configmaps-11cfef1e-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:49:54.867: INFO: Pod pod-projected-configmaps-11cfef1e-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:49:54.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5bs2q" for this suite.
Feb  1 23:50:00.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:50:00.951: INFO: namespace: e2e-tests-projected-5bs2q, resource: bindings, ignored listing per whitelist
Feb  1 23:50:00.979: INFO: namespace e2e-tests-projected-5bs2q deletion completed in 6.1072446s

â€¢ [SLOW TEST:8.239 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:50:00.979: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  1 23:50:01.053: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:50:05.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fknbt" for this suite.
Feb  1 23:50:27.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:50:27.384: INFO: namespace: e2e-tests-init-container-fknbt, resource: bindings, ignored listing per whitelist
Feb  1 23:50:27.401: INFO: namespace e2e-tests-init-container-fknbt deletion completed in 22.1018705s

â€¢ [SLOW TEST:26.457 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:50:27.402: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0201 23:50:37.478995      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  1 23:50:37.479: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:50:37.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bvrs7" for this suite.
Feb  1 23:50:43.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:50:43.487: INFO: namespace: e2e-tests-gc-bvrs7, resource: bindings, ignored listing per whitelist
Feb  1 23:50:43.539: INFO: namespace e2e-tests-gc-bvrs7 deletion completed in 6.0919603s

â€¢ [SLOW TEST:16.172 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:50:43.539: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3013891d-267c-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  1 23:50:43.597: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3013fecf-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-d6c9p" to be "success or failure"
Feb  1 23:50:43.608: INFO: Pod "pod-projected-configmaps-3013fecf-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 10.79ms
Feb  1 23:50:45.612: INFO: Pod "pod-projected-configmaps-3013fecf-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0144947s
STEP: Saw pod success
Feb  1 23:50:45.612: INFO: Pod "pod-projected-configmaps-3013fecf-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:50:45.614: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-3013fecf-267c-11e9-a68a-f677bb5aadde container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  1 23:50:45.636: INFO: Waiting for pod pod-projected-configmaps-3013fecf-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:50:45.640: INFO: Pod pod-projected-configmaps-3013fecf-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:50:45.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d6c9p" for this suite.
Feb  1 23:50:51.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:50:51.699: INFO: namespace: e2e-tests-projected-d6c9p, resource: bindings, ignored listing per whitelist
Feb  1 23:50:51.723: INFO: namespace e2e-tests-projected-d6c9p deletion completed in 6.0779365s

â€¢ [SLOW TEST:8.184 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:50:51.723: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  1 23:50:51.788: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n7jpc,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7jpc/configmaps/e2e-watch-test-resource-version,UID:34f3e905-267c-11e9-b4dc-025000000001,ResourceVersion:13496,Generation:0,CreationTimestamp:2019-02-01 23:50:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  1 23:50:51.789: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n7jpc,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7jpc/configmaps/e2e-watch-test-resource-version,UID:34f3e905-267c-11e9-b4dc-025000000001,ResourceVersion:13497,Generation:0,CreationTimestamp:2019-02-01 23:50:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:50:51.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-n7jpc" for this suite.
Feb  1 23:50:57.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:50:57.858: INFO: namespace: e2e-tests-watch-n7jpc, resource: bindings, ignored listing per whitelist
Feb  1 23:50:57.860: INFO: namespace e2e-tests-watch-n7jpc deletion completed in 6.0687158s

â€¢ [SLOW TEST:6.137 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:50:57.860: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  1 23:50:57.910: INFO: namespace e2e-tests-kubectl-k6lrw
Feb  1 23:50:57.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-k6lrw'
Feb  1 23:50:58.132: INFO: stderr: ""
Feb  1 23:50:58.132: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  1 23:50:59.138: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:50:59.138: INFO: Found 0 / 1
Feb  1 23:51:00.139: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:51:00.139: INFO: Found 1 / 1
Feb  1 23:51:00.139: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  1 23:51:00.142: INFO: Selector matched 1 pods for map[app:redis]
Feb  1 23:51:00.142: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  1 23:51:00.142: INFO: wait on redis-master startup in e2e-tests-kubectl-k6lrw 
Feb  1 23:51:00.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 logs redis-master-ktfqm redis-master --namespace=e2e-tests-kubectl-k6lrw'
Feb  1 23:51:00.217: INFO: stderr: ""
Feb  1 23:51:00.217: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Feb 23:50:59.450 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Feb 23:50:59.450 # Server started, Redis version 3.2.12\n1:M 01 Feb 23:50:59.450 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Feb 23:50:59.450 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb  1 23:51:00.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-k6lrw'
Feb  1 23:51:00.299: INFO: stderr: ""
Feb  1 23:51:00.299: INFO: stdout: "service/rm2 exposed\n"
Feb  1 23:51:00.301: INFO: Service rm2 in namespace e2e-tests-kubectl-k6lrw found.
STEP: exposing service
Feb  1 23:51:02.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-k6lrw'
Feb  1 23:51:02.392: INFO: stderr: ""
Feb  1 23:51:02.392: INFO: stdout: "service/rm3 exposed\n"
Feb  1 23:51:02.396: INFO: Service rm3 in namespace e2e-tests-kubectl-k6lrw found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:51:04.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k6lrw" for this suite.
Feb  1 23:51:26.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:51:26.397: INFO: namespace: e2e-tests-kubectl-k6lrw, resource: bindings, ignored listing per whitelist
Feb  1 23:51:26.449: INFO: namespace e2e-tests-kubectl-k6lrw deletion completed in 22.0758329s

â€¢ [SLOW TEST:28.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:51:26.449: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  1 23:51:30.543: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  1 23:51:30.545: INFO: Pod pod-with-poststart-http-hook still exists
Feb  1 23:51:32.546: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  1 23:51:32.550: INFO: Pod pod-with-poststart-http-hook still exists
Feb  1 23:51:34.546: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  1 23:51:34.549: INFO: Pod pod-with-poststart-http-hook still exists
Feb  1 23:51:36.546: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  1 23:51:36.550: INFO: Pod pod-with-poststart-http-hook still exists
Feb  1 23:51:38.511: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  1 23:51:38.515: INFO: Pod pod-with-poststart-http-hook still exists
Feb  1 23:51:40.511: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  1 23:51:40.515: INFO: Pod pod-with-poststart-http-hook still exists
Feb  1 23:51:42.512: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  1 23:51:42.514: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:51:42.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mg9rd" for this suite.
Feb  1 23:52:04.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:52:04.594: INFO: namespace: e2e-tests-container-lifecycle-hook-mg9rd, resource: bindings, ignored listing per whitelist
Feb  1 23:52:04.597: INFO: namespace e2e-tests-container-lifecycle-hook-mg9rd deletion completed in 22.0798678s

â€¢ [SLOW TEST:38.183 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:52:04.600: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kcjfw
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-kcjfw
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-kcjfw
Feb  1 23:52:04.690: INFO: Found 0 stateful pods, waiting for 1
Feb  1 23:52:14.661: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  1 23:52:14.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  1 23:52:14.821: INFO: stderr: ""
Feb  1 23:52:14.821: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  1 23:52:14.821: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  1 23:52:14.824: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  1 23:52:24.828: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  1 23:52:24.828: INFO: Waiting for statefulset status.replicas updated to 0
Feb  1 23:52:24.843: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999985s
Feb  1 23:52:25.849: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.9943701s
Feb  1 23:52:26.854: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.9893372s
Feb  1 23:52:27.860: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.9844721s
Feb  1 23:52:28.865: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.9787976s
Feb  1 23:52:29.869: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.973405s
Feb  1 23:52:30.874: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.969244s
Feb  1 23:52:31.880: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.9640404s
Feb  1 23:52:32.885: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.957507s
Feb  1 23:52:33.890: INFO: Verifying statefulset ss doesn't scale past 1 for another 952.909ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-kcjfw
Feb  1 23:52:34.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  1 23:52:35.059: INFO: stderr: ""
Feb  1 23:52:35.059: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  1 23:52:35.059: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  1 23:52:35.063: INFO: Found 1 stateful pods, waiting for 3
Feb  1 23:52:45.037: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  1 23:52:45.037: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  1 23:52:45.037: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  1 23:52:45.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  1 23:52:45.204: INFO: stderr: ""
Feb  1 23:52:45.204: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  1 23:52:45.204: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  1 23:52:45.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  1 23:52:45.383: INFO: stderr: ""
Feb  1 23:52:45.383: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  1 23:52:45.383: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  1 23:52:45.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  1 23:52:45.543: INFO: stderr: ""
Feb  1 23:52:45.543: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  1 23:52:45.543: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  1 23:52:45.544: INFO: Waiting for statefulset status.replicas updated to 0
Feb  1 23:52:45.546: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  1 23:52:55.553: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  1 23:52:55.553: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  1 23:52:55.553: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  1 23:52:55.564: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9998715s
Feb  1 23:52:56.568: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.9944019s
Feb  1 23:52:57.574: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.9896387s
Feb  1 23:52:58.579: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.9839771s
Feb  1 23:52:59.585: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.9779038s
Feb  1 23:53:00.589: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.9737079s
Feb  1 23:53:01.592: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9698288s
Feb  1 23:53:02.596: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9665777s
Feb  1 23:53:03.602: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.9618093s
Feb  1 23:53:04.610: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.0121ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-kcjfw
Feb  1 23:53:05.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  1 23:53:05.773: INFO: stderr: ""
Feb  1 23:53:05.773: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  1 23:53:05.773: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  1 23:53:05.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  1 23:53:05.931: INFO: stderr: ""
Feb  1 23:53:05.931: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  1 23:53:05.931: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  1 23:53:05.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-kcjfw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  1 23:53:06.082: INFO: stderr: ""
Feb  1 23:53:06.084: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  1 23:53:06.084: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  1 23:53:06.084: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  1 23:53:16.068: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kcjfw
Feb  1 23:53:16.071: INFO: Scaling statefulset ss to 0
Feb  1 23:53:16.080: INFO: Waiting for statefulset status.replicas updated to 0
Feb  1 23:53:16.085: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:53:16.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kcjfw" for this suite.
Feb  1 23:53:22.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:53:22.148: INFO: namespace: e2e-tests-statefulset-kcjfw, resource: bindings, ignored listing per whitelist
Feb  1 23:53:22.183: INFO: namespace e2e-tests-statefulset-kcjfw deletion completed in 6.0854282s

â€¢ [SLOW TEST:77.687 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:53:22.183: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0201 23:54:02.225775      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  1 23:54:02.225: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:54:02.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7t4qk" for this suite.
Feb  1 23:54:08.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:54:08.260: INFO: namespace: e2e-tests-gc-7t4qk, resource: bindings, ignored listing per whitelist
Feb  1 23:54:08.303: INFO: namespace e2e-tests-gc-7t4qk deletion completed in 6.1090451s

â€¢ [SLOW TEST:46.191 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:54:08.305: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:54:10.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-hz5vl" for this suite.
Feb  1 23:54:48.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:54:48.532: INFO: namespace: e2e-tests-kubelet-test-hz5vl, resource: bindings, ignored listing per whitelist
Feb  1 23:54:48.545: INFO: namespace e2e-tests-kubelet-test-hz5vl deletion completed in 38.0800332s

â€¢ [SLOW TEST:40.275 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:54:48.546: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb  1 23:54:48.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 api-versions'
Feb  1 23:54:48.652: INFO: stderr: ""
Feb  1 23:54:48.652: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncompose.docker.com/v1beta1\ncompose.docker.com/v1beta2\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:54:48.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jhkqx" for this suite.
Feb  1 23:54:54.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:54:54.679: INFO: namespace: e2e-tests-kubectl-jhkqx, resource: bindings, ignored listing per whitelist
Feb  1 23:54:54.732: INFO: namespace e2e-tests-kubectl-jhkqx deletion completed in 6.0761771s

â€¢ [SLOW TEST:6.186 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:54:54.732: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c5cb3aed-267c-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  1 23:54:54.782: INFO: Waiting up to 5m0s for pod "pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-sc96n" to be "success or failure"
Feb  1 23:54:54.784: INFO: Pod "pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.391ms
Feb  1 23:54:56.790: INFO: Pod "pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007982s
Feb  1 23:54:58.794: INFO: Pod "pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0126792s
STEP: Saw pod success
Feb  1 23:54:58.794: INFO: Pod "pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:54:58.797: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde container configmap-volume-test: <nil>
STEP: delete the pod
Feb  1 23:54:58.819: INFO: Waiting for pod pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:54:58.824: INFO: Pod pod-configmaps-c5cba83c-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:54:58.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sc96n" for this suite.
Feb  1 23:55:04.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:55:04.847: INFO: namespace: e2e-tests-configmap-sc96n, resource: bindings, ignored listing per whitelist
Feb  1 23:55:04.897: INFO: namespace e2e-tests-configmap-sc96n deletion completed in 6.0703198s

â€¢ [SLOW TEST:10.165 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:55:04.898: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  1 23:55:26.931: INFO: Container started at 2019-02-01 23:55:06 +0000 UTC, pod became ready at 2019-02-01 23:55:26 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:55:26.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qksql" for this suite.
Feb  1 23:55:48.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:55:48.924: INFO: namespace: e2e-tests-container-probe-qksql, resource: bindings, ignored listing per whitelist
Feb  1 23:55:48.989: INFO: namespace e2e-tests-container-probe-qksql deletion completed in 22.089256s

â€¢ [SLOW TEST:44.161 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:55:48.989: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0201 23:55:49.621765      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  1 23:55:49.621: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:55:49.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4nfk5" for this suite.
Feb  1 23:55:55.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:55:55.688: INFO: namespace: e2e-tests-gc-4nfk5, resource: bindings, ignored listing per whitelist
Feb  1 23:55:55.700: INFO: namespace e2e-tests-gc-4nfk5 deletion completed in 6.0754122s

â€¢ [SLOW TEST:6.710 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:55:55.700: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ea228b4a-267c-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  1 23:55:55.752: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ea22ff9d-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-96sjv" to be "success or failure"
Feb  1 23:55:55.754: INFO: Pod "pod-projected-configmaps-ea22ff9d-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.5473ms
Feb  1 23:55:57.758: INFO: Pod "pod-projected-configmaps-ea22ff9d-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0064152s
STEP: Saw pod success
Feb  1 23:55:57.758: INFO: Pod "pod-projected-configmaps-ea22ff9d-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:55:57.761: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-ea22ff9d-267c-11e9-a68a-f677bb5aadde container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  1 23:55:57.777: INFO: Waiting for pod pod-projected-configmaps-ea22ff9d-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:55:57.783: INFO: Pod pod-projected-configmaps-ea22ff9d-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:55:57.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-96sjv" for this suite.
Feb  1 23:56:03.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:56:03.870: INFO: namespace: e2e-tests-projected-96sjv, resource: bindings, ignored listing per whitelist
Feb  1 23:56:03.876: INFO: namespace e2e-tests-projected-96sjv deletion completed in 6.0895976s

â€¢ [SLOW TEST:8.177 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:56:03.877: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-lrmpg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-lrmpg to expose endpoints map[]
Feb  1 23:56:03.930: INFO: Get endpoints failed (2.8802ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb  1 23:56:04.935: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-lrmpg exposes endpoints map[] (1.0079754s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-lrmpg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-lrmpg to expose endpoints map[pod1:[80]]
Feb  1 23:56:06.976: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-lrmpg exposes endpoints map[pod1:[80]] (2.021496s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-lrmpg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-lrmpg to expose endpoints map[pod1:[80] pod2:[80]]
Feb  1 23:56:08.976: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-lrmpg exposes endpoints map[pod1:[80] pod2:[80]] (2.0299194s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-lrmpg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-lrmpg to expose endpoints map[pod2:[80]]
Feb  1 23:56:09.995: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-lrmpg exposes endpoints map[pod2:[80]] (1.0149758s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-lrmpg
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-lrmpg to expose endpoints map[]
Feb  1 23:56:10.004: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-lrmpg exposes endpoints map[] (2.8277ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:56:10.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-lrmpg" for this suite.
Feb  1 23:56:32.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:56:32.066: INFO: namespace: e2e-tests-services-lrmpg, resource: bindings, ignored listing per whitelist
Feb  1 23:56:32.097: INFO: namespace e2e-tests-services-lrmpg deletion completed in 22.0758837s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:28.255 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:56:32.097: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb  1 23:56:32.159: INFO: Waiting up to 5m0s for pod "var-expansion-ffd6588a-267c-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-var-expansion-mgz2s" to be "success or failure"
Feb  1 23:56:32.164: INFO: Pod "var-expansion-ffd6588a-267c-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.9097ms
Feb  1 23:56:34.173: INFO: Pod "var-expansion-ffd6588a-267c-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0138842s
STEP: Saw pod success
Feb  1 23:56:34.173: INFO: Pod "var-expansion-ffd6588a-267c-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:56:34.175: INFO: Trying to get logs from node docker-desktop pod var-expansion-ffd6588a-267c-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  1 23:56:34.194: INFO: Waiting for pod var-expansion-ffd6588a-267c-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:56:34.197: INFO: Pod var-expansion-ffd6588a-267c-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:56:34.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mgz2s" for this suite.
Feb  1 23:56:40.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:56:40.241: INFO: namespace: e2e-tests-var-expansion-mgz2s, resource: bindings, ignored listing per whitelist
Feb  1 23:56:40.258: INFO: namespace e2e-tests-var-expansion-mgz2s deletion completed in 6.0860885s

â€¢ [SLOW TEST:8.196 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:56:40.261: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  1 23:56:40.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04b234cb-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-qfmrc" to be "success or failure"
Feb  1 23:56:40.316: INFO: Pod "downwardapi-volume-04b234cb-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 5.2803ms
Feb  1 23:56:42.320: INFO: Pod "downwardapi-volume-04b234cb-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008966s
STEP: Saw pod success
Feb  1 23:56:42.320: INFO: Pod "downwardapi-volume-04b234cb-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:56:42.323: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-04b234cb-267d-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  1 23:56:42.348: INFO: Waiting for pod downwardapi-volume-04b234cb-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:56:42.350: INFO: Pod downwardapi-volume-04b234cb-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:56:42.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qfmrc" for this suite.
Feb  1 23:56:48.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:56:48.384: INFO: namespace: e2e-tests-downward-api-qfmrc, resource: bindings, ignored listing per whitelist
Feb  1 23:56:48.440: INFO: namespace e2e-tests-downward-api-qfmrc deletion completed in 6.0861141s

â€¢ [SLOW TEST:8.179 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:56:48.441: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  1 23:56:48.496: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09930d57-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-qfx2t" to be "success or failure"
Feb  1 23:56:48.498: INFO: Pod "downwardapi-volume-09930d57-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.9879ms
Feb  1 23:56:50.501: INFO: Pod "downwardapi-volume-09930d57-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0046944s
STEP: Saw pod success
Feb  1 23:56:50.501: INFO: Pod "downwardapi-volume-09930d57-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:56:50.503: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-09930d57-267d-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  1 23:56:50.517: INFO: Waiting for pod downwardapi-volume-09930d57-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:56:50.519: INFO: Pod downwardapi-volume-09930d57-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:56:50.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qfx2t" for this suite.
Feb  1 23:56:56.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:56:56.581: INFO: namespace: e2e-tests-projected-qfx2t, resource: bindings, ignored listing per whitelist
Feb  1 23:56:56.611: INFO: namespace e2e-tests-projected-qfx2t deletion completed in 6.0885008s

â€¢ [SLOW TEST:8.171 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:56:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dqxvj
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-dqxvj
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-dqxvj
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-dqxvj
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-dqxvj
Feb  1 23:57:00.703: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-dqxvj, name: ss-0, uid: 10bbeedc-267d-11e9-b4dc-025000000001, status phase: Pending. Waiting for statefulset controller to delete.
Feb  1 23:57:01.089: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-dqxvj, name: ss-0, uid: 10bbeedc-267d-11e9-b4dc-025000000001, status phase: Failed. Waiting for statefulset controller to delete.
Feb  1 23:57:01.094: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-dqxvj, name: ss-0, uid: 10bbeedc-267d-11e9-b4dc-025000000001, status phase: Failed. Waiting for statefulset controller to delete.
Feb  1 23:57:01.098: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-dqxvj
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-dqxvj
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-dqxvj and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  1 23:57:05.127: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dqxvj
Feb  1 23:57:05.131: INFO: Scaling statefulset ss to 0
Feb  1 23:57:15.110: INFO: Waiting for statefulset status.replicas updated to 0
Feb  1 23:57:15.113: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:57:15.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dqxvj" for this suite.
Feb  1 23:57:21.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:57:21.199: INFO: namespace: e2e-tests-statefulset-dqxvj, resource: bindings, ignored listing per whitelist
Feb  1 23:57:21.208: INFO: namespace e2e-tests-statefulset-dqxvj deletion completed in 6.0821284s

â€¢ [SLOW TEST:24.631 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:57:21.211: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1d1c491c-267d-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  1 23:57:21.275: INFO: Waiting up to 5m0s for pod "pod-configmaps-1d1cb85c-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-k2tfn" to be "success or failure"
Feb  1 23:57:21.288: INFO: Pod "pod-configmaps-1d1cb85c-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 12.3299ms
Feb  1 23:57:23.290: INFO: Pod "pod-configmaps-1d1cb85c-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0149076s
STEP: Saw pod success
Feb  1 23:57:23.290: INFO: Pod "pod-configmaps-1d1cb85c-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:57:23.292: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-1d1cb85c-267d-11e9-a68a-f677bb5aadde container configmap-volume-test: <nil>
STEP: delete the pod
Feb  1 23:57:23.310: INFO: Waiting for pod pod-configmaps-1d1cb85c-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:57:23.319: INFO: Pod pod-configmaps-1d1cb85c-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:57:23.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k2tfn" for this suite.
Feb  1 23:57:29.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:57:29.401: INFO: namespace: e2e-tests-configmap-k2tfn, resource: bindings, ignored listing per whitelist
Feb  1 23:57:29.410: INFO: namespace e2e-tests-configmap-k2tfn deletion completed in 6.0844318s

â€¢ [SLOW TEST:8.199 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:57:29.410: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-21fdabf8-267d-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  1 23:57:29.463: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-21fe1666-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-pnjng" to be "success or failure"
Feb  1 23:57:29.466: INFO: Pod "pod-projected-secrets-21fe1666-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.6456ms
Feb  1 23:57:31.470: INFO: Pod "pod-projected-secrets-21fe1666-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007675s
STEP: Saw pod success
Feb  1 23:57:31.470: INFO: Pod "pod-projected-secrets-21fe1666-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:57:31.472: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-21fe1666-267d-11e9-a68a-f677bb5aadde container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  1 23:57:31.488: INFO: Waiting for pod pod-projected-secrets-21fe1666-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:57:31.490: INFO: Pod pod-projected-secrets-21fe1666-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:57:31.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pnjng" for this suite.
Feb  1 23:57:37.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:57:37.511: INFO: namespace: e2e-tests-projected-pnjng, resource: bindings, ignored listing per whitelist
Feb  1 23:57:37.540: INFO: namespace e2e-tests-projected-pnjng deletion completed in 6.0767242s

â€¢ [SLOW TEST:8.165 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:57:37.540: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-qqf94
I0201 23:57:37.592165      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-qqf94, replica count: 1
I0201 23:57:38.643412      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0201 23:57:39.643865      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  1 23:57:39.756: INFO: Created: latency-svc-bktlw
Feb  1 23:57:39.764: INFO: Got endpoints: latency-svc-bktlw [19.7984ms]
Feb  1 23:57:39.776: INFO: Created: latency-svc-nf6qf
Feb  1 23:57:39.804: INFO: Created: latency-svc-w7jfb
Feb  1 23:57:39.804: INFO: Got endpoints: latency-svc-nf6qf [39.261ms]
Feb  1 23:57:39.809: INFO: Got endpoints: latency-svc-w7jfb [43.6113ms]
Feb  1 23:57:39.814: INFO: Created: latency-svc-hhn2t
Feb  1 23:57:39.819: INFO: Got endpoints: latency-svc-hhn2t [53.6718ms]
Feb  1 23:57:39.826: INFO: Created: latency-svc-tzbrl
Feb  1 23:57:39.831: INFO: Got endpoints: latency-svc-tzbrl [66.4123ms]
Feb  1 23:57:39.842: INFO: Created: latency-svc-lqltb
Feb  1 23:57:39.845: INFO: Got endpoints: latency-svc-lqltb [80.0065ms]
Feb  1 23:57:39.852: INFO: Created: latency-svc-qrxkf
Feb  1 23:57:39.860: INFO: Got endpoints: latency-svc-qrxkf [95.0715ms]
Feb  1 23:57:39.866: INFO: Created: latency-svc-wwfl2
Feb  1 23:57:39.869: INFO: Got endpoints: latency-svc-wwfl2 [103.7685ms]
Feb  1 23:57:39.877: INFO: Created: latency-svc-wzsr2
Feb  1 23:57:39.882: INFO: Got endpoints: latency-svc-wzsr2 [116.7879ms]
Feb  1 23:57:39.890: INFO: Created: latency-svc-9f5bh
Feb  1 23:57:39.895: INFO: Got endpoints: latency-svc-9f5bh [129.8627ms]
Feb  1 23:57:39.909: INFO: Created: latency-svc-6snqv
Feb  1 23:57:39.916: INFO: Got endpoints: latency-svc-6snqv [150.914ms]
Feb  1 23:57:39.922: INFO: Created: latency-svc-p7l9x
Feb  1 23:57:39.925: INFO: Created: latency-svc-nfgp4
Feb  1 23:57:39.925: INFO: Got endpoints: latency-svc-p7l9x [160.0204ms]
Feb  1 23:57:39.929: INFO: Got endpoints: latency-svc-nfgp4 [164.4264ms]
Feb  1 23:57:39.936: INFO: Created: latency-svc-kl48b
Feb  1 23:57:39.941: INFO: Got endpoints: latency-svc-kl48b [176.0167ms]
Feb  1 23:57:39.945: INFO: Created: latency-svc-qsvmd
Feb  1 23:57:39.953: INFO: Created: latency-svc-bnf7x
Feb  1 23:57:39.953: INFO: Got endpoints: latency-svc-qsvmd [186.957ms]
Feb  1 23:57:39.957: INFO: Got endpoints: latency-svc-bnf7x [191.9469ms]
Feb  1 23:57:39.964: INFO: Created: latency-svc-w4xnh
Feb  1 23:57:39.970: INFO: Created: latency-svc-mkqxf
Feb  1 23:57:39.970: INFO: Got endpoints: latency-svc-w4xnh [166.1558ms]
Feb  1 23:57:39.976: INFO: Got endpoints: latency-svc-mkqxf [167.0046ms]
Feb  1 23:57:39.978: INFO: Created: latency-svc-sk4fh
Feb  1 23:57:39.983: INFO: Got endpoints: latency-svc-sk4fh [161.1352ms]
Feb  1 23:57:39.984: INFO: Created: latency-svc-9448j
Feb  1 23:57:39.989: INFO: Got endpoints: latency-svc-9448j [158.4838ms]
Feb  1 23:57:39.999: INFO: Created: latency-svc-gjmm9
Feb  1 23:57:40.008: INFO: Got endpoints: latency-svc-gjmm9 [163.5342ms]
Feb  1 23:57:40.009: INFO: Created: latency-svc-55dfw
Feb  1 23:57:40.016: INFO: Got endpoints: latency-svc-55dfw [155.6581ms]
Feb  1 23:57:40.025: INFO: Created: latency-svc-6pjlv
Feb  1 23:57:40.035: INFO: Created: latency-svc-kwbgm
Feb  1 23:57:40.036: INFO: Got endpoints: latency-svc-kwbgm [153.5556ms]
Feb  1 23:57:40.037: INFO: Got endpoints: latency-svc-6pjlv [167.9195ms]
Feb  1 23:57:40.048: INFO: Created: latency-svc-c2qxw
Feb  1 23:57:40.050: INFO: Got endpoints: latency-svc-c2qxw [154.5771ms]
Feb  1 23:57:40.061: INFO: Created: latency-svc-jblr4
Feb  1 23:57:40.064: INFO: Got endpoints: latency-svc-jblr4 [147.8998ms]
Feb  1 23:57:40.069: INFO: Created: latency-svc-9wj9w
Feb  1 23:57:40.072: INFO: Got endpoints: latency-svc-9wj9w [147.1448ms]
Feb  1 23:57:40.074: INFO: Created: latency-svc-9m7nv
Feb  1 23:57:40.076: INFO: Got endpoints: latency-svc-9m7nv [146.1582ms]
Feb  1 23:57:40.083: INFO: Created: latency-svc-5kskq
Feb  1 23:57:40.089: INFO: Got endpoints: latency-svc-5kskq [146.6175ms]
Feb  1 23:57:40.093: INFO: Created: latency-svc-r4qnj
Feb  1 23:57:40.097: INFO: Got endpoints: latency-svc-r4qnj [139.7122ms]
Feb  1 23:57:40.099: INFO: Created: latency-svc-tssz9
Feb  1 23:57:40.103: INFO: Got endpoints: latency-svc-tssz9 [146.0637ms]
Feb  1 23:57:40.106: INFO: Created: latency-svc-5jsvg
Feb  1 23:57:40.111: INFO: Got endpoints: latency-svc-5jsvg [140.9368ms]
Feb  1 23:57:40.117: INFO: Created: latency-svc-p5d2b
Feb  1 23:57:40.123: INFO: Got endpoints: latency-svc-p5d2b [146.7938ms]
Feb  1 23:57:40.126: INFO: Created: latency-svc-8j7bn
Feb  1 23:57:40.132: INFO: Got endpoints: latency-svc-8j7bn [148.5125ms]
Feb  1 23:57:40.134: INFO: Created: latency-svc-kbgsw
Feb  1 23:57:40.141: INFO: Got endpoints: latency-svc-kbgsw [151.1476ms]
Feb  1 23:57:40.145: INFO: Created: latency-svc-nsjfl
Feb  1 23:57:40.158: INFO: Created: latency-svc-pv6hk
Feb  1 23:57:40.158: INFO: Got endpoints: latency-svc-pv6hk [141.0283ms]
Feb  1 23:57:40.159: INFO: Created: latency-svc-mdtvd
Feb  1 23:57:40.162: INFO: Got endpoints: latency-svc-mdtvd [125.2843ms]
Feb  1 23:57:40.162: INFO: Got endpoints: latency-svc-nsjfl [153.8175ms]
Feb  1 23:57:40.169: INFO: Created: latency-svc-bdpkt
Feb  1 23:57:40.174: INFO: Created: latency-svc-hd9km
Feb  1 23:57:40.180: INFO: Created: latency-svc-vnjf2
Feb  1 23:57:40.192: INFO: Created: latency-svc-t2vmr
Feb  1 23:57:40.203: INFO: Created: latency-svc-wkjlw
Feb  1 23:57:40.210: INFO: Got endpoints: latency-svc-bdpkt [174.6124ms]
Feb  1 23:57:40.211: INFO: Created: latency-svc-svjmj
Feb  1 23:57:40.218: INFO: Created: latency-svc-bf8gn
Feb  1 23:57:40.226: INFO: Created: latency-svc-tccxn
Feb  1 23:57:40.240: INFO: Created: latency-svc-86m7w
Feb  1 23:57:40.243: INFO: Created: latency-svc-ll4x2
Feb  1 23:57:40.249: INFO: Created: latency-svc-k7glw
Feb  1 23:57:40.256: INFO: Created: latency-svc-jr958
Feb  1 23:57:40.262: INFO: Got endpoints: latency-svc-hd9km [210.873ms]
Feb  1 23:57:40.262: INFO: Created: latency-svc-lpxvv
Feb  1 23:57:40.271: INFO: Created: latency-svc-lmw8t
Feb  1 23:57:40.278: INFO: Created: latency-svc-jzgmb
Feb  1 23:57:40.286: INFO: Created: latency-svc-qj9mz
Feb  1 23:57:40.294: INFO: Created: latency-svc-m74pj
Feb  1 23:57:40.309: INFO: Got endpoints: latency-svc-vnjf2 [244.4686ms]
Feb  1 23:57:40.318: INFO: Created: latency-svc-vsn5q
Feb  1 23:57:40.359: INFO: Got endpoints: latency-svc-t2vmr [285.5622ms]
Feb  1 23:57:40.367: INFO: Created: latency-svc-c4hs4
Feb  1 23:57:40.408: INFO: Got endpoints: latency-svc-wkjlw [332.3594ms]
Feb  1 23:57:40.419: INFO: Created: latency-svc-pw5x2
Feb  1 23:57:40.459: INFO: Got endpoints: latency-svc-svjmj [370.5683ms]
Feb  1 23:57:40.466: INFO: Created: latency-svc-m65sj
Feb  1 23:57:40.513: INFO: Got endpoints: latency-svc-bf8gn [416.4976ms]
Feb  1 23:57:40.524: INFO: Created: latency-svc-kkhsw
Feb  1 23:57:40.559: INFO: Got endpoints: latency-svc-tccxn [455.7074ms]
Feb  1 23:57:40.569: INFO: Created: latency-svc-hhgzz
Feb  1 23:57:40.608: INFO: Got endpoints: latency-svc-86m7w [496.6114ms]
Feb  1 23:57:40.616: INFO: Created: latency-svc-v4xbb
Feb  1 23:57:40.661: INFO: Got endpoints: latency-svc-ll4x2 [537.2958ms]
Feb  1 23:57:40.671: INFO: Created: latency-svc-f7x85
Feb  1 23:57:40.709: INFO: Got endpoints: latency-svc-k7glw [576.8259ms]
Feb  1 23:57:40.717: INFO: Created: latency-svc-6q5nn
Feb  1 23:57:40.762: INFO: Got endpoints: latency-svc-jr958 [620.813ms]
Feb  1 23:57:40.771: INFO: Created: latency-svc-l8bhn
Feb  1 23:57:40.808: INFO: Got endpoints: latency-svc-lpxvv [650.596ms]
Feb  1 23:57:40.817: INFO: Created: latency-svc-tdnqk
Feb  1 23:57:40.859: INFO: Got endpoints: latency-svc-lmw8t [697.0666ms]
Feb  1 23:57:40.868: INFO: Created: latency-svc-hs8xn
Feb  1 23:57:40.910: INFO: Got endpoints: latency-svc-jzgmb [747.1898ms]
Feb  1 23:57:40.918: INFO: Created: latency-svc-zxf2t
Feb  1 23:57:40.958: INFO: Got endpoints: latency-svc-qj9mz [747.1341ms]
Feb  1 23:57:40.966: INFO: Created: latency-svc-67wgh
Feb  1 23:57:41.011: INFO: Got endpoints: latency-svc-m74pj [748.5567ms]
Feb  1 23:57:41.022: INFO: Created: latency-svc-9fbfm
Feb  1 23:57:41.061: INFO: Got endpoints: latency-svc-vsn5q [751.7634ms]
Feb  1 23:57:41.068: INFO: Created: latency-svc-vnlsg
Feb  1 23:57:41.110: INFO: Got endpoints: latency-svc-c4hs4 [751.5643ms]
Feb  1 23:57:41.120: INFO: Created: latency-svc-zvqhc
Feb  1 23:57:41.159: INFO: Got endpoints: latency-svc-pw5x2 [750.2306ms]
Feb  1 23:57:41.178: INFO: Created: latency-svc-v2rrb
Feb  1 23:57:41.209: INFO: Got endpoints: latency-svc-m65sj [749.1732ms]
Feb  1 23:57:41.220: INFO: Created: latency-svc-wxlv7
Feb  1 23:57:41.260: INFO: Got endpoints: latency-svc-kkhsw [746.4926ms]
Feb  1 23:57:41.269: INFO: Created: latency-svc-k4mxf
Feb  1 23:57:41.309: INFO: Got endpoints: latency-svc-hhgzz [749.9823ms]
Feb  1 23:57:41.317: INFO: Created: latency-svc-str5r
Feb  1 23:57:41.359: INFO: Got endpoints: latency-svc-v4xbb [751.1328ms]
Feb  1 23:57:41.370: INFO: Created: latency-svc-8fzcb
Feb  1 23:57:41.408: INFO: Got endpoints: latency-svc-f7x85 [747.3997ms]
Feb  1 23:57:41.421: INFO: Created: latency-svc-dhkq6
Feb  1 23:57:41.461: INFO: Got endpoints: latency-svc-6q5nn [752.0242ms]
Feb  1 23:57:41.472: INFO: Created: latency-svc-8krvs
Feb  1 23:57:41.509: INFO: Got endpoints: latency-svc-l8bhn [747.703ms]
Feb  1 23:57:41.528: INFO: Created: latency-svc-j5q8g
Feb  1 23:57:41.558: INFO: Got endpoints: latency-svc-tdnqk [749.4474ms]
Feb  1 23:57:41.566: INFO: Created: latency-svc-mkwss
Feb  1 23:57:41.608: INFO: Got endpoints: latency-svc-hs8xn [748.6911ms]
Feb  1 23:57:41.616: INFO: Created: latency-svc-w8rtq
Feb  1 23:57:41.659: INFO: Got endpoints: latency-svc-zxf2t [749.5336ms]
Feb  1 23:57:41.668: INFO: Created: latency-svc-zqndd
Feb  1 23:57:41.708: INFO: Got endpoints: latency-svc-67wgh [750.6162ms]
Feb  1 23:57:41.718: INFO: Created: latency-svc-77d9p
Feb  1 23:57:41.761: INFO: Got endpoints: latency-svc-9fbfm [749.6517ms]
Feb  1 23:57:41.772: INFO: Created: latency-svc-728tf
Feb  1 23:57:41.808: INFO: Got endpoints: latency-svc-vnlsg [746.9875ms]
Feb  1 23:57:41.817: INFO: Created: latency-svc-v5qfw
Feb  1 23:57:41.859: INFO: Got endpoints: latency-svc-zvqhc [748.6336ms]
Feb  1 23:57:41.867: INFO: Created: latency-svc-8jb58
Feb  1 23:57:41.909: INFO: Got endpoints: latency-svc-v2rrb [749.9014ms]
Feb  1 23:57:41.918: INFO: Created: latency-svc-t7zht
Feb  1 23:57:41.960: INFO: Got endpoints: latency-svc-wxlv7 [750.8628ms]
Feb  1 23:57:41.969: INFO: Created: latency-svc-4ps4t
Feb  1 23:57:42.010: INFO: Got endpoints: latency-svc-k4mxf [750.6475ms]
Feb  1 23:57:42.019: INFO: Created: latency-svc-sknd9
Feb  1 23:57:42.060: INFO: Got endpoints: latency-svc-str5r [750.8795ms]
Feb  1 23:57:42.069: INFO: Created: latency-svc-sd5qd
Feb  1 23:57:42.109: INFO: Got endpoints: latency-svc-8fzcb [749.2211ms]
Feb  1 23:57:42.119: INFO: Created: latency-svc-shkxx
Feb  1 23:57:42.160: INFO: Got endpoints: latency-svc-dhkq6 [751.7969ms]
Feb  1 23:57:42.175: INFO: Created: latency-svc-wgtzr
Feb  1 23:57:42.209: INFO: Got endpoints: latency-svc-8krvs [748.0818ms]
Feb  1 23:57:42.219: INFO: Created: latency-svc-fxrp5
Feb  1 23:57:42.258: INFO: Got endpoints: latency-svc-j5q8g [748.7468ms]
Feb  1 23:57:42.269: INFO: Created: latency-svc-fh7rj
Feb  1 23:57:42.309: INFO: Got endpoints: latency-svc-mkwss [751.2535ms]
Feb  1 23:57:42.320: INFO: Created: latency-svc-x8b5t
Feb  1 23:57:42.359: INFO: Got endpoints: latency-svc-w8rtq [750.7595ms]
Feb  1 23:57:42.367: INFO: Created: latency-svc-2cphl
Feb  1 23:57:42.409: INFO: Got endpoints: latency-svc-zqndd [749.3158ms]
Feb  1 23:57:42.422: INFO: Created: latency-svc-j48ld
Feb  1 23:57:42.459: INFO: Got endpoints: latency-svc-77d9p [750.6328ms]
Feb  1 23:57:42.467: INFO: Created: latency-svc-hxzrk
Feb  1 23:57:42.510: INFO: Got endpoints: latency-svc-728tf [749.1489ms]
Feb  1 23:57:42.539: INFO: Created: latency-svc-dgfhg
Feb  1 23:57:42.560: INFO: Got endpoints: latency-svc-v5qfw [751.2048ms]
Feb  1 23:57:42.571: INFO: Created: latency-svc-wbt2b
Feb  1 23:57:42.609: INFO: Got endpoints: latency-svc-8jb58 [750.4368ms]
Feb  1 23:57:42.623: INFO: Created: latency-svc-qzmd4
Feb  1 23:57:42.661: INFO: Got endpoints: latency-svc-t7zht [751.4799ms]
Feb  1 23:57:42.670: INFO: Created: latency-svc-spfgm
Feb  1 23:57:42.710: INFO: Got endpoints: latency-svc-4ps4t [749.688ms]
Feb  1 23:57:42.721: INFO: Created: latency-svc-p4vxz
Feb  1 23:57:42.759: INFO: Got endpoints: latency-svc-sknd9 [748.511ms]
Feb  1 23:57:42.772: INFO: Created: latency-svc-pvfwb
Feb  1 23:57:42.812: INFO: Got endpoints: latency-svc-sd5qd [751.6439ms]
Feb  1 23:57:42.824: INFO: Created: latency-svc-9jnqs
Feb  1 23:57:42.859: INFO: Got endpoints: latency-svc-shkxx [749.8303ms]
Feb  1 23:57:42.869: INFO: Created: latency-svc-xcrlr
Feb  1 23:57:42.909: INFO: Got endpoints: latency-svc-wgtzr [748.7313ms]
Feb  1 23:57:42.919: INFO: Created: latency-svc-j6q7p
Feb  1 23:57:42.960: INFO: Got endpoints: latency-svc-fxrp5 [750.971ms]
Feb  1 23:57:42.970: INFO: Created: latency-svc-rp95l
Feb  1 23:57:43.009: INFO: Got endpoints: latency-svc-fh7rj [751.0509ms]
Feb  1 23:57:43.024: INFO: Created: latency-svc-2gkwh
Feb  1 23:57:43.060: INFO: Got endpoints: latency-svc-x8b5t [750.5634ms]
Feb  1 23:57:43.070: INFO: Created: latency-svc-59hsr
Feb  1 23:57:43.111: INFO: Got endpoints: latency-svc-2cphl [752.1456ms]
Feb  1 23:57:43.126: INFO: Created: latency-svc-cbngw
Feb  1 23:57:43.159: INFO: Got endpoints: latency-svc-j48ld [750.3122ms]
Feb  1 23:57:43.169: INFO: Created: latency-svc-24s5d
Feb  1 23:57:43.210: INFO: Got endpoints: latency-svc-hxzrk [750.8463ms]
Feb  1 23:57:43.219: INFO: Created: latency-svc-rkpbf
Feb  1 23:57:43.262: INFO: Got endpoints: latency-svc-dgfhg [751.105ms]
Feb  1 23:57:43.272: INFO: Created: latency-svc-ncftp
Feb  1 23:57:43.309: INFO: Got endpoints: latency-svc-wbt2b [749.1412ms]
Feb  1 23:57:43.322: INFO: Created: latency-svc-rzsk5
Feb  1 23:57:43.361: INFO: Got endpoints: latency-svc-qzmd4 [750.944ms]
Feb  1 23:57:43.373: INFO: Created: latency-svc-tnjjt
Feb  1 23:57:43.410: INFO: Got endpoints: latency-svc-spfgm [748.7767ms]
Feb  1 23:57:43.423: INFO: Created: latency-svc-btbsr
Feb  1 23:57:43.460: INFO: Got endpoints: latency-svc-p4vxz [750.1582ms]
Feb  1 23:57:43.471: INFO: Created: latency-svc-pskrc
Feb  1 23:57:43.510: INFO: Got endpoints: latency-svc-pvfwb [750.51ms]
Feb  1 23:57:43.523: INFO: Created: latency-svc-lnnnk
Feb  1 23:57:43.561: INFO: Got endpoints: latency-svc-9jnqs [749.0817ms]
Feb  1 23:57:43.576: INFO: Created: latency-svc-8s6t5
Feb  1 23:57:43.611: INFO: Got endpoints: latency-svc-xcrlr [752.3074ms]
Feb  1 23:57:43.632: INFO: Created: latency-svc-lpdq6
Feb  1 23:57:43.660: INFO: Got endpoints: latency-svc-j6q7p [750.4953ms]
Feb  1 23:57:43.671: INFO: Created: latency-svc-qjxtj
Feb  1 23:57:43.710: INFO: Got endpoints: latency-svc-rp95l [750.351ms]
Feb  1 23:57:43.723: INFO: Created: latency-svc-x28c4
Feb  1 23:57:43.760: INFO: Got endpoints: latency-svc-2gkwh [750.3174ms]
Feb  1 23:57:43.770: INFO: Created: latency-svc-w2x8s
Feb  1 23:57:43.810: INFO: Got endpoints: latency-svc-59hsr [749.7161ms]
Feb  1 23:57:43.823: INFO: Created: latency-svc-p4jn8
Feb  1 23:57:43.861: INFO: Got endpoints: latency-svc-cbngw [750.3995ms]
Feb  1 23:57:43.871: INFO: Created: latency-svc-vpqk8
Feb  1 23:57:43.910: INFO: Got endpoints: latency-svc-24s5d [750.4026ms]
Feb  1 23:57:43.920: INFO: Created: latency-svc-jknq2
Feb  1 23:57:43.961: INFO: Got endpoints: latency-svc-rkpbf [750.8925ms]
Feb  1 23:57:43.973: INFO: Created: latency-svc-llm4m
Feb  1 23:57:44.010: INFO: Got endpoints: latency-svc-ncftp [748.5932ms]
Feb  1 23:57:44.026: INFO: Created: latency-svc-fszxz
Feb  1 23:57:44.059: INFO: Got endpoints: latency-svc-rzsk5 [749.9695ms]
Feb  1 23:57:44.074: INFO: Created: latency-svc-99wtm
Feb  1 23:57:44.111: INFO: Got endpoints: latency-svc-tnjjt [750.4107ms]
Feb  1 23:57:44.125: INFO: Created: latency-svc-9w6sk
Feb  1 23:57:44.160: INFO: Got endpoints: latency-svc-btbsr [750.4221ms]
Feb  1 23:57:44.177: INFO: Created: latency-svc-b44nc
Feb  1 23:57:44.210: INFO: Got endpoints: latency-svc-pskrc [749.899ms]
Feb  1 23:57:44.223: INFO: Created: latency-svc-p9rb6
Feb  1 23:57:44.261: INFO: Got endpoints: latency-svc-lnnnk [750.2731ms]
Feb  1 23:57:44.276: INFO: Created: latency-svc-mmndx
Feb  1 23:57:44.311: INFO: Got endpoints: latency-svc-8s6t5 [749.5483ms]
Feb  1 23:57:44.325: INFO: Created: latency-svc-mm6cw
Feb  1 23:57:44.360: INFO: Got endpoints: latency-svc-lpdq6 [748.7957ms]
Feb  1 23:57:44.369: INFO: Created: latency-svc-qq59f
Feb  1 23:57:44.416: INFO: Got endpoints: latency-svc-qjxtj [756.3128ms]
Feb  1 23:57:44.427: INFO: Created: latency-svc-jnbzv
Feb  1 23:57:44.460: INFO: Got endpoints: latency-svc-x28c4 [749.3987ms]
Feb  1 23:57:44.472: INFO: Created: latency-svc-69dvv
Feb  1 23:57:44.510: INFO: Got endpoints: latency-svc-w2x8s [750.2007ms]
Feb  1 23:57:44.522: INFO: Created: latency-svc-wdhps
Feb  1 23:57:44.562: INFO: Got endpoints: latency-svc-p4jn8 [751.6284ms]
Feb  1 23:57:44.606: INFO: Created: latency-svc-lxbph
Feb  1 23:57:44.610: INFO: Got endpoints: latency-svc-vpqk8 [748.132ms]
Feb  1 23:57:44.628: INFO: Created: latency-svc-9thl8
Feb  1 23:57:44.668: INFO: Got endpoints: latency-svc-jknq2 [758.3751ms]
Feb  1 23:57:44.681: INFO: Created: latency-svc-cc7dj
Feb  1 23:57:44.711: INFO: Got endpoints: latency-svc-llm4m [749.5412ms]
Feb  1 23:57:44.729: INFO: Created: latency-svc-jdv4k
Feb  1 23:57:44.760: INFO: Got endpoints: latency-svc-fszxz [749.1228ms]
Feb  1 23:57:44.771: INFO: Created: latency-svc-w5hpn
Feb  1 23:57:44.815: INFO: Got endpoints: latency-svc-99wtm [755.5402ms]
Feb  1 23:57:44.832: INFO: Created: latency-svc-q6gsf
Feb  1 23:57:44.862: INFO: Got endpoints: latency-svc-9w6sk [750.2685ms]
Feb  1 23:57:44.872: INFO: Created: latency-svc-bzwm2
Feb  1 23:57:44.911: INFO: Got endpoints: latency-svc-b44nc [750.4164ms]
Feb  1 23:57:44.932: INFO: Created: latency-svc-wscs9
Feb  1 23:57:44.962: INFO: Got endpoints: latency-svc-p9rb6 [751.8647ms]
Feb  1 23:57:44.975: INFO: Created: latency-svc-l7tjg
Feb  1 23:57:45.014: INFO: Got endpoints: latency-svc-mmndx [753.0894ms]
Feb  1 23:57:45.027: INFO: Created: latency-svc-l8sm7
Feb  1 23:57:45.061: INFO: Got endpoints: latency-svc-mm6cw [749.9371ms]
Feb  1 23:57:45.072: INFO: Created: latency-svc-qppzg
Feb  1 23:57:45.110: INFO: Got endpoints: latency-svc-qq59f [750.0456ms]
Feb  1 23:57:45.126: INFO: Created: latency-svc-8s98d
Feb  1 23:57:45.161: INFO: Got endpoints: latency-svc-jnbzv [745.0319ms]
Feb  1 23:57:45.172: INFO: Created: latency-svc-lzr7m
Feb  1 23:57:45.210: INFO: Got endpoints: latency-svc-69dvv [750.1082ms]
Feb  1 23:57:45.221: INFO: Created: latency-svc-5rx7j
Feb  1 23:57:45.264: INFO: Got endpoints: latency-svc-wdhps [754.0931ms]
Feb  1 23:57:45.279: INFO: Created: latency-svc-n7ccx
Feb  1 23:57:45.310: INFO: Got endpoints: latency-svc-lxbph [745.3578ms]
Feb  1 23:57:45.330: INFO: Created: latency-svc-vcts6
Feb  1 23:57:45.361: INFO: Got endpoints: latency-svc-9thl8 [751.2765ms]
Feb  1 23:57:45.373: INFO: Created: latency-svc-kchc8
Feb  1 23:57:45.411: INFO: Got endpoints: latency-svc-cc7dj [742.4661ms]
Feb  1 23:57:45.424: INFO: Created: latency-svc-2z5sx
Feb  1 23:57:45.462: INFO: Got endpoints: latency-svc-jdv4k [750.6562ms]
Feb  1 23:57:45.473: INFO: Created: latency-svc-k4b9c
Feb  1 23:57:45.510: INFO: Got endpoints: latency-svc-w5hpn [750.5292ms]
Feb  1 23:57:45.522: INFO: Created: latency-svc-jgjpz
Feb  1 23:57:45.561: INFO: Got endpoints: latency-svc-q6gsf [745.9121ms]
Feb  1 23:57:45.584: INFO: Created: latency-svc-xj6jn
Feb  1 23:57:45.611: INFO: Got endpoints: latency-svc-bzwm2 [749.3428ms]
Feb  1 23:57:45.625: INFO: Created: latency-svc-nkvt4
Feb  1 23:57:45.661: INFO: Got endpoints: latency-svc-wscs9 [750.1339ms]
Feb  1 23:57:45.675: INFO: Created: latency-svc-wqf8v
Feb  1 23:57:45.713: INFO: Got endpoints: latency-svc-l7tjg [749.4783ms]
Feb  1 23:57:45.737: INFO: Created: latency-svc-f9bxr
Feb  1 23:57:45.763: INFO: Got endpoints: latency-svc-l8sm7 [749.4123ms]
Feb  1 23:57:45.780: INFO: Created: latency-svc-8d5s6
Feb  1 23:57:45.811: INFO: Got endpoints: latency-svc-qppzg [749.9462ms]
Feb  1 23:57:45.826: INFO: Created: latency-svc-9kbms
Feb  1 23:57:45.863: INFO: Got endpoints: latency-svc-8s98d [752.6209ms]
Feb  1 23:57:45.888: INFO: Created: latency-svc-gqmb8
Feb  1 23:57:45.916: INFO: Got endpoints: latency-svc-lzr7m [754.2441ms]
Feb  1 23:57:45.940: INFO: Created: latency-svc-8b69h
Feb  1 23:57:45.964: INFO: Got endpoints: latency-svc-5rx7j [754.0481ms]
Feb  1 23:57:45.978: INFO: Created: latency-svc-jqpf8
Feb  1 23:57:46.011: INFO: Got endpoints: latency-svc-n7ccx [746.5473ms]
Feb  1 23:57:46.023: INFO: Created: latency-svc-ccf2n
Feb  1 23:57:46.061: INFO: Got endpoints: latency-svc-vcts6 [750.4067ms]
Feb  1 23:57:46.079: INFO: Created: latency-svc-ckt5j
Feb  1 23:57:46.110: INFO: Got endpoints: latency-svc-kchc8 [748.6861ms]
Feb  1 23:57:46.125: INFO: Created: latency-svc-l8wfd
Feb  1 23:57:46.161: INFO: Got endpoints: latency-svc-2z5sx [749.7955ms]
Feb  1 23:57:46.176: INFO: Created: latency-svc-7tlhn
Feb  1 23:57:46.217: INFO: Got endpoints: latency-svc-k4b9c [754.9604ms]
Feb  1 23:57:46.234: INFO: Created: latency-svc-56m7g
Feb  1 23:57:46.261: INFO: Got endpoints: latency-svc-jgjpz [750.7176ms]
Feb  1 23:57:46.272: INFO: Created: latency-svc-x6lxh
Feb  1 23:57:46.311: INFO: Got endpoints: latency-svc-xj6jn [749.8018ms]
Feb  1 23:57:46.323: INFO: Created: latency-svc-d9xr5
Feb  1 23:57:46.362: INFO: Got endpoints: latency-svc-nkvt4 [751.2389ms]
Feb  1 23:57:46.376: INFO: Created: latency-svc-f2lsz
Feb  1 23:57:46.411: INFO: Got endpoints: latency-svc-wqf8v [750.0235ms]
Feb  1 23:57:46.422: INFO: Created: latency-svc-tjhdx
Feb  1 23:57:46.460: INFO: Got endpoints: latency-svc-f9bxr [743.7288ms]
Feb  1 23:57:46.475: INFO: Created: latency-svc-jvsd8
Feb  1 23:57:46.510: INFO: Got endpoints: latency-svc-8d5s6 [746.8185ms]
Feb  1 23:57:46.526: INFO: Created: latency-svc-jlp9t
Feb  1 23:57:46.561: INFO: Got endpoints: latency-svc-9kbms [749.8611ms]
Feb  1 23:57:46.573: INFO: Created: latency-svc-cr28s
Feb  1 23:57:46.610: INFO: Got endpoints: latency-svc-gqmb8 [746.2626ms]
Feb  1 23:57:46.625: INFO: Created: latency-svc-5wqq8
Feb  1 23:57:46.662: INFO: Got endpoints: latency-svc-8b69h [745.9204ms]
Feb  1 23:57:46.684: INFO: Created: latency-svc-vs6jz
Feb  1 23:57:46.711: INFO: Got endpoints: latency-svc-jqpf8 [746.1264ms]
Feb  1 23:57:46.725: INFO: Created: latency-svc-8x2b2
Feb  1 23:57:46.762: INFO: Got endpoints: latency-svc-ccf2n [750.4774ms]
Feb  1 23:57:46.776: INFO: Created: latency-svc-4f9qs
Feb  1 23:57:46.812: INFO: Got endpoints: latency-svc-ckt5j [749.239ms]
Feb  1 23:57:46.833: INFO: Created: latency-svc-8vzhs
Feb  1 23:57:46.860: INFO: Got endpoints: latency-svc-l8wfd [748.9933ms]
Feb  1 23:57:46.878: INFO: Created: latency-svc-nv8m4
Feb  1 23:57:46.911: INFO: Got endpoints: latency-svc-7tlhn [750.1939ms]
Feb  1 23:57:46.933: INFO: Created: latency-svc-qpvtd
Feb  1 23:57:46.960: INFO: Got endpoints: latency-svc-56m7g [742.6623ms]
Feb  1 23:57:46.974: INFO: Created: latency-svc-lrg4j
Feb  1 23:57:47.011: INFO: Got endpoints: latency-svc-x6lxh [749.8041ms]
Feb  1 23:57:47.024: INFO: Created: latency-svc-thjvh
Feb  1 23:57:47.061: INFO: Got endpoints: latency-svc-d9xr5 [750.383ms]
Feb  1 23:57:47.075: INFO: Created: latency-svc-5ppvv
Feb  1 23:57:47.110: INFO: Got endpoints: latency-svc-f2lsz [747.066ms]
Feb  1 23:57:47.127: INFO: Created: latency-svc-w9ldp
Feb  1 23:57:47.162: INFO: Got endpoints: latency-svc-tjhdx [750.8729ms]
Feb  1 23:57:47.177: INFO: Created: latency-svc-2scxq
Feb  1 23:57:47.211: INFO: Got endpoints: latency-svc-jvsd8 [751.0199ms]
Feb  1 23:57:47.229: INFO: Created: latency-svc-lj49d
Feb  1 23:57:47.261: INFO: Got endpoints: latency-svc-jlp9t [749.8477ms]
Feb  1 23:57:47.277: INFO: Created: latency-svc-4wdzp
Feb  1 23:57:47.311: INFO: Got endpoints: latency-svc-cr28s [749.4088ms]
Feb  1 23:57:47.324: INFO: Created: latency-svc-66l4s
Feb  1 23:57:47.361: INFO: Got endpoints: latency-svc-5wqq8 [750.6637ms]
Feb  1 23:57:47.374: INFO: Created: latency-svc-6v478
Feb  1 23:57:47.411: INFO: Got endpoints: latency-svc-vs6jz [749.0141ms]
Feb  1 23:57:47.428: INFO: Created: latency-svc-mshtw
Feb  1 23:57:47.462: INFO: Got endpoints: latency-svc-8x2b2 [751.6159ms]
Feb  1 23:57:47.476: INFO: Created: latency-svc-7khvh
Feb  1 23:57:47.510: INFO: Got endpoints: latency-svc-4f9qs [748.4517ms]
Feb  1 23:57:47.525: INFO: Created: latency-svc-xvgpw
Feb  1 23:57:47.562: INFO: Got endpoints: latency-svc-8vzhs [749.843ms]
Feb  1 23:57:47.580: INFO: Created: latency-svc-jxjl5
Feb  1 23:57:47.615: INFO: Got endpoints: latency-svc-nv8m4 [755.3125ms]
Feb  1 23:57:47.661: INFO: Got endpoints: latency-svc-qpvtd [749.3877ms]
Feb  1 23:57:47.711: INFO: Got endpoints: latency-svc-lrg4j [750.6249ms]
Feb  1 23:57:47.760: INFO: Got endpoints: latency-svc-thjvh [748.2519ms]
Feb  1 23:57:47.811: INFO: Got endpoints: latency-svc-5ppvv [749.2966ms]
Feb  1 23:57:47.861: INFO: Got endpoints: latency-svc-w9ldp [750.4869ms]
Feb  1 23:57:47.912: INFO: Got endpoints: latency-svc-2scxq [749.3797ms]
Feb  1 23:57:47.962: INFO: Got endpoints: latency-svc-lj49d [747.7598ms]
Feb  1 23:57:48.013: INFO: Got endpoints: latency-svc-4wdzp [752.0918ms]
Feb  1 23:57:48.062: INFO: Got endpoints: latency-svc-66l4s [751.1431ms]
Feb  1 23:57:48.112: INFO: Got endpoints: latency-svc-6v478 [750.523ms]
Feb  1 23:57:48.161: INFO: Got endpoints: latency-svc-mshtw [749.4879ms]
Feb  1 23:57:48.210: INFO: Got endpoints: latency-svc-7khvh [747.8328ms]
Feb  1 23:57:48.262: INFO: Got endpoints: latency-svc-xvgpw [750.7438ms]
Feb  1 23:57:48.313: INFO: Got endpoints: latency-svc-jxjl5 [750.6408ms]
Feb  1 23:57:48.313: INFO: Latencies: [39.261ms 43.6113ms 53.6718ms 66.4123ms 80.0065ms 95.0715ms 103.7685ms 116.7879ms 125.2843ms 129.8627ms 139.7122ms 140.9368ms 141.0283ms 146.0637ms 146.1582ms 146.6175ms 146.7938ms 147.1448ms 147.8998ms 148.5125ms 150.914ms 151.1476ms 153.5556ms 153.8175ms 154.5771ms 155.6581ms 158.4838ms 160.0204ms 161.1352ms 163.5342ms 164.4264ms 166.1558ms 167.0046ms 167.9195ms 174.6124ms 176.0167ms 186.957ms 191.9469ms 210.873ms 244.4686ms 285.5622ms 332.3594ms 370.5683ms 416.4976ms 455.7074ms 496.6114ms 537.2958ms 576.8259ms 620.813ms 650.596ms 697.0666ms 742.4661ms 742.6623ms 743.7288ms 745.0319ms 745.3578ms 745.9121ms 745.9204ms 746.1264ms 746.2626ms 746.4926ms 746.5473ms 746.8185ms 746.9875ms 747.066ms 747.1341ms 747.1898ms 747.3997ms 747.703ms 747.7598ms 747.8328ms 748.0818ms 748.132ms 748.2519ms 748.4517ms 748.511ms 748.5567ms 748.5932ms 748.6336ms 748.6861ms 748.6911ms 748.7313ms 748.7468ms 748.7767ms 748.7957ms 748.9933ms 749.0141ms 749.0817ms 749.1228ms 749.1412ms 749.1489ms 749.1732ms 749.2211ms 749.239ms 749.2966ms 749.3158ms 749.3428ms 749.3797ms 749.3877ms 749.3987ms 749.4088ms 749.4123ms 749.4474ms 749.4783ms 749.4879ms 749.5336ms 749.5412ms 749.5483ms 749.6517ms 749.688ms 749.7161ms 749.7955ms 749.8018ms 749.8041ms 749.8303ms 749.843ms 749.8477ms 749.8611ms 749.899ms 749.9014ms 749.9371ms 749.9462ms 749.9695ms 749.9823ms 750.0235ms 750.0456ms 750.1082ms 750.1339ms 750.1582ms 750.1939ms 750.2007ms 750.2306ms 750.2685ms 750.2731ms 750.3122ms 750.3174ms 750.351ms 750.383ms 750.3995ms 750.4026ms 750.4067ms 750.4107ms 750.4164ms 750.4221ms 750.4368ms 750.4774ms 750.4869ms 750.4953ms 750.51ms 750.523ms 750.5292ms 750.5634ms 750.6162ms 750.6249ms 750.6328ms 750.6408ms 750.6475ms 750.6562ms 750.6637ms 750.7176ms 750.7438ms 750.7595ms 750.8463ms 750.8628ms 750.8729ms 750.8795ms 750.8925ms 750.944ms 750.971ms 751.0199ms 751.0509ms 751.105ms 751.1328ms 751.1431ms 751.2048ms 751.2389ms 751.2535ms 751.2765ms 751.4799ms 751.5643ms 751.6159ms 751.6284ms 751.6439ms 751.7634ms 751.7969ms 751.8647ms 752.0242ms 752.0918ms 752.1456ms 752.3074ms 752.6209ms 753.0894ms 754.0481ms 754.0931ms 754.2441ms 754.9604ms 755.3125ms 755.5402ms 756.3128ms 758.3751ms]
Feb  1 23:57:48.313: INFO: 50 %ile: 749.4088ms
Feb  1 23:57:48.313: INFO: 90 %ile: 751.6159ms
Feb  1 23:57:48.313: INFO: 99 %ile: 756.3128ms
Feb  1 23:57:48.313: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:57:48.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-qqf94" for this suite.
Feb  1 23:58:02.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:58:02.472: INFO: namespace: e2e-tests-svc-latency-qqf94, resource: bindings, ignored listing per whitelist
Feb  1 23:58:02.522: INFO: namespace e2e-tests-svc-latency-qqf94 deletion completed in 14.193336s

â€¢ [SLOW TEST:24.983 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:58:02.523: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb  1 23:58:02.645: INFO: Waiting up to 5m0s for pod "client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-containers-hqtp9" to be "success or failure"
Feb  1 23:58:02.669: INFO: Pod "client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 23.7448ms
Feb  1 23:58:04.674: INFO: Pod "client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0285872s
Feb  1 23:58:06.680: INFO: Pod "client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0348499s
STEP: Saw pod success
Feb  1 23:58:06.680: INFO: Pod "client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:58:06.683: INFO: Trying to get logs from node docker-desktop pod client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  1 23:58:06.715: INFO: Waiting for pod client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:58:06.719: INFO: Pod client-containers-35c487b9-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:58:06.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hqtp9" for this suite.
Feb  1 23:58:12.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:58:12.785: INFO: namespace: e2e-tests-containers-hqtp9, resource: bindings, ignored listing per whitelist
Feb  1 23:58:12.794: INFO: namespace e2e-tests-containers-hqtp9 deletion completed in 6.1055268s

â€¢ [SLOW TEST:10.305 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:58:12.794: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:58:16.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-plwmn" for this suite.
Feb  1 23:58:22.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:58:22.971: INFO: namespace: e2e-tests-kubelet-test-plwmn, resource: bindings, ignored listing per whitelist
Feb  1 23:58:22.986: INFO: namespace e2e-tests-kubelet-test-plwmn deletion completed in 6.0920241s

â€¢ [SLOW TEST:10.192 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:58:22.986: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb  1 23:58:23.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:23.206: INFO: stderr: ""
Feb  1 23:58:23.206: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  1 23:58:23.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:23.297: INFO: stderr: ""
Feb  1 23:58:23.297: INFO: stdout: "update-demo-nautilus-dxsjc update-demo-nautilus-zwxts "
Feb  1 23:58:23.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-dxsjc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:23.364: INFO: stderr: ""
Feb  1 23:58:23.364: INFO: stdout: ""
Feb  1 23:58:23.364: INFO: update-demo-nautilus-dxsjc is created but not running
Feb  1 23:58:28.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:28.441: INFO: stderr: ""
Feb  1 23:58:28.441: INFO: stdout: "update-demo-nautilus-dxsjc update-demo-nautilus-zwxts "
Feb  1 23:58:28.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-dxsjc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:28.510: INFO: stderr: ""
Feb  1 23:58:28.510: INFO: stdout: "true"
Feb  1 23:58:28.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-dxsjc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:28.580: INFO: stderr: ""
Feb  1 23:58:28.580: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  1 23:58:28.580: INFO: validating pod update-demo-nautilus-dxsjc
Feb  1 23:58:28.588: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  1 23:58:28.588: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  1 23:58:28.588: INFO: update-demo-nautilus-dxsjc is verified up and running
Feb  1 23:58:28.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-zwxts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:28.654: INFO: stderr: ""
Feb  1 23:58:28.654: INFO: stdout: "true"
Feb  1 23:58:28.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-zwxts -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:28.729: INFO: stderr: ""
Feb  1 23:58:28.729: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  1 23:58:28.729: INFO: validating pod update-demo-nautilus-zwxts
Feb  1 23:58:28.733: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  1 23:58:28.733: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  1 23:58:28.733: INFO: update-demo-nautilus-zwxts is verified up and running
STEP: rolling-update to new replication controller
Feb  1 23:58:28.734: INFO: scanned /root for discovery docs: <nil>
Feb  1 23:58:28.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:51.107: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  1 23:58:51.107: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  1 23:58:51.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:51.180: INFO: stderr: ""
Feb  1 23:58:51.180: INFO: stdout: "update-demo-kitten-fgk54 update-demo-kitten-slt62 "
Feb  1 23:58:51.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-kitten-fgk54 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:51.242: INFO: stderr: ""
Feb  1 23:58:51.242: INFO: stdout: "true"
Feb  1 23:58:51.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-kitten-fgk54 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:51.307: INFO: stderr: ""
Feb  1 23:58:51.307: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  1 23:58:51.307: INFO: validating pod update-demo-kitten-fgk54
Feb  1 23:58:51.311: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  1 23:58:51.311: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  1 23:58:51.311: INFO: update-demo-kitten-fgk54 is verified up and running
Feb  1 23:58:51.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-kitten-slt62 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:51.375: INFO: stderr: ""
Feb  1 23:58:51.375: INFO: stdout: "true"
Feb  1 23:58:51.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-kitten-slt62 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qnjjw'
Feb  1 23:58:51.438: INFO: stderr: ""
Feb  1 23:58:51.438: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  1 23:58:51.438: INFO: validating pod update-demo-kitten-slt62
Feb  1 23:58:51.441: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  1 23:58:51.441: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  1 23:58:51.441: INFO: update-demo-kitten-slt62 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:58:51.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qnjjw" for this suite.
Feb  1 23:59:13.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:59:13.461: INFO: namespace: e2e-tests-kubectl-qnjjw, resource: bindings, ignored listing per whitelist
Feb  1 23:59:13.489: INFO: namespace e2e-tests-kubectl-qnjjw deletion completed in 22.0798257s

â€¢ [SLOW TEST:50.572 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:59:13.489: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  1 23:59:13.550: INFO: Waiting up to 5m0s for pod "downward-api-6008b340-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-tf2mj" to be "success or failure"
Feb  1 23:59:13.554: INFO: Pod "downward-api-6008b340-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.1176ms
Feb  1 23:59:15.557: INFO: Pod "downward-api-6008b340-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006585s
STEP: Saw pod success
Feb  1 23:59:15.557: INFO: Pod "downward-api-6008b340-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:59:15.560: INFO: Trying to get logs from node docker-desktop pod downward-api-6008b340-267d-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  1 23:59:15.577: INFO: Waiting for pod downward-api-6008b340-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:59:15.580: INFO: Pod downward-api-6008b340-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:59:15.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tf2mj" for this suite.
Feb  1 23:59:21.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:59:21.639: INFO: namespace: e2e-tests-downward-api-tf2mj, resource: bindings, ignored listing per whitelist
Feb  1 23:59:21.668: INFO: namespace e2e-tests-downward-api-tf2mj deletion completed in 6.0841604s

â€¢ [SLOW TEST:8.180 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:59:21.670: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-d8pqj.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d8pqj.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d8pqj.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-d8pqj.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d8pqj.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d8pqj.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  1 23:59:35.849: INFO: DNS probes using e2e-tests-dns-d8pqj/dns-test-64e7a51d-267d-11e9-a68a-f677bb5aadde succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:59:35.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-d8pqj" for this suite.
Feb  1 23:59:41.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:59:41.943: INFO: namespace: e2e-tests-dns-d8pqj, resource: bindings, ignored listing per whitelist
Feb  1 23:59:42.014: INFO: namespace e2e-tests-dns-d8pqj deletion completed in 6.1454829s

â€¢ [SLOW TEST:20.379 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:59:42.014: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  1 23:59:42.106: INFO: Waiting up to 5m0s for pod "downwardapi-volume-710d7544-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-btkqh" to be "success or failure"
Feb  1 23:59:42.109: INFO: Pod "downwardapi-volume-710d7544-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.7708ms
Feb  1 23:59:44.113: INFO: Pod "downwardapi-volume-710d7544-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0077324s
STEP: Saw pod success
Feb  1 23:59:44.113: INFO: Pod "downwardapi-volume-710d7544-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:59:44.116: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-710d7544-267d-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  1 23:59:44.143: INFO: Waiting for pod downwardapi-volume-710d7544-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:59:44.148: INFO: Pod downwardapi-volume-710d7544-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:59:44.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-btkqh" for this suite.
Feb  1 23:59:50.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:59:50.179: INFO: namespace: e2e-tests-downward-api-btkqh, resource: bindings, ignored listing per whitelist
Feb  1 23:59:50.233: INFO: namespace e2e-tests-downward-api-btkqh deletion completed in 6.0822695s

â€¢ [SLOW TEST:8.219 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:59:50.233: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  1 23:59:50.290: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75ee8f6a-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-szkc9" to be "success or failure"
Feb  1 23:59:50.304: INFO: Pod "downwardapi-volume-75ee8f6a-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 12.9986ms
Feb  1 23:59:52.311: INFO: Pod "downwardapi-volume-75ee8f6a-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0199619s
STEP: Saw pod success
Feb  1 23:59:52.311: INFO: Pod "downwardapi-volume-75ee8f6a-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  1 23:59:52.322: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-75ee8f6a-267d-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  1 23:59:52.351: INFO: Waiting for pod downwardapi-volume-75ee8f6a-267d-11e9-a68a-f677bb5aadde to disappear
Feb  1 23:59:52.355: INFO: Pod downwardapi-volume-75ee8f6a-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  1 23:59:52.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-szkc9" for this suite.
Feb  1 23:59:58.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  1 23:59:58.395: INFO: namespace: e2e-tests-projected-szkc9, resource: bindings, ignored listing per whitelist
Feb  1 23:59:58.444: INFO: namespace e2e-tests-projected-szkc9 deletion completed in 6.0854147s

â€¢ [SLOW TEST:8.211 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  1 23:59:58.446: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-v2shf/configmap-test-7ad386bb-267d-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  1 23:59:58.503: INFO: Waiting up to 5m0s for pod "pod-configmaps-7ad40001-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-v2shf" to be "success or failure"
Feb  1 23:59:58.506: INFO: Pod "pod-configmaps-7ad40001-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.8788ms
Feb  2 00:00:00.520: INFO: Pod "pod-configmaps-7ad40001-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0165038s
STEP: Saw pod success
Feb  2 00:00:00.520: INFO: Pod "pod-configmaps-7ad40001-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:00:00.523: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-7ad40001-267d-11e9-a68a-f677bb5aadde container env-test: <nil>
STEP: delete the pod
Feb  2 00:00:00.540: INFO: Waiting for pod pod-configmaps-7ad40001-267d-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:00:00.542: INFO: Pod pod-configmaps-7ad40001-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:00:00.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v2shf" for this suite.
Feb  2 00:00:06.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:00:06.590: INFO: namespace: e2e-tests-configmap-v2shf, resource: bindings, ignored listing per whitelist
Feb  2 00:00:06.619: INFO: namespace e2e-tests-configmap-v2shf deletion completed in 6.0742589s

â€¢ [SLOW TEST:8.174 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:00:06.622: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-hdpq2 in namespace e2e-tests-proxy-9lkj9
I0202 00:00:06.684393      17 runners.go:184] Created replication controller with name: proxy-service-hdpq2, namespace: e2e-tests-proxy-9lkj9, replica count: 1
I0202 00:00:07.701422      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0202 00:00:08.702094      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0202 00:00:09.705452      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0202 00:00:10.706342      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:11.707018      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:12.707614      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:13.709470      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:14.713304      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:15.714092      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:16.714472      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:17.715595      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:18.716522      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0202 00:00:19.717398      17 runners.go:184] proxy-service-hdpq2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  2 00:00:19.721: INFO: setup took 13.0838188s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  2 00:00:19.728: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.0136ms)
Feb  2 00:00:19.729: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.336ms)
Feb  2 00:00:19.733: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 10.5465ms)
Feb  2 00:00:19.736: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 12.6557ms)
Feb  2 00:00:19.737: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 14.0749ms)
Feb  2 00:00:19.736: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 13.6655ms)
Feb  2 00:00:19.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 15.9205ms)
Feb  2 00:00:19.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 15.8877ms)
Feb  2 00:00:19.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 15.873ms)
Feb  2 00:00:19.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 16.1094ms)
Feb  2 00:00:19.740: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 16.4431ms)
Feb  2 00:00:19.741: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 19.8097ms)
Feb  2 00:00:19.741: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 19.3626ms)
Feb  2 00:00:19.743: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 20.1795ms)
Feb  2 00:00:19.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 21.2643ms)
Feb  2 00:00:19.745: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 22.4568ms)
Feb  2 00:00:19.752: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 5.043ms)
Feb  2 00:00:19.752: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 6.6108ms)
Feb  2 00:00:19.753: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 7.065ms)
Feb  2 00:00:19.753: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 6.5581ms)
Feb  2 00:00:19.754: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 6.6229ms)
Feb  2 00:00:19.754: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 6.1388ms)
Feb  2 00:00:19.755: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.3732ms)
Feb  2 00:00:19.755: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 7.9716ms)
Feb  2 00:00:19.755: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 8.7998ms)
Feb  2 00:00:19.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 8.1299ms)
Feb  2 00:00:19.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 8.8064ms)
Feb  2 00:00:19.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 9.9918ms)
Feb  2 00:00:19.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 9.58ms)
Feb  2 00:00:19.757: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 10.2388ms)
Feb  2 00:00:19.757: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 10.8158ms)
Feb  2 00:00:19.757: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 9.4917ms)
Feb  2 00:00:19.760: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 3.2455ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 4.8749ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.2028ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 5.4743ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 5.9836ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 6.1503ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 5.7479ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.4083ms)
Feb  2 00:00:19.764: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 5.6682ms)
Feb  2 00:00:19.766: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 6.5822ms)
Feb  2 00:00:19.767: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 9.2391ms)
Feb  2 00:00:19.767: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 8.3988ms)
Feb  2 00:00:19.767: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 9.7694ms)
Feb  2 00:00:19.768: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 10.2502ms)
Feb  2 00:00:19.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 9.8102ms)
Feb  2 00:00:19.769: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 11.0837ms)
Feb  2 00:00:19.776: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 6.5384ms)
Feb  2 00:00:19.780: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 9.7718ms)
Feb  2 00:00:19.780: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 10.3086ms)
Feb  2 00:00:19.780: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 10.0255ms)
Feb  2 00:00:19.780: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 9.9899ms)
Feb  2 00:00:19.780: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 10.8558ms)
Feb  2 00:00:19.780: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 10.4206ms)
Feb  2 00:00:19.781: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 10.4747ms)
Feb  2 00:00:19.781: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 10.6543ms)
Feb  2 00:00:19.781: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 10.7679ms)
Feb  2 00:00:19.782: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 11.6542ms)
Feb  2 00:00:19.782: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 11.3847ms)
Feb  2 00:00:19.783: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 12.4559ms)
Feb  2 00:00:19.783: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 12.6686ms)
Feb  2 00:00:19.783: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 12.6295ms)
Feb  2 00:00:19.783: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 13.4782ms)
Feb  2 00:00:19.789: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 5.3033ms)
Feb  2 00:00:19.789: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 4.7477ms)
Feb  2 00:00:19.790: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 5.5848ms)
Feb  2 00:00:19.790: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 5.0319ms)
Feb  2 00:00:19.791: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.0416ms)
Feb  2 00:00:19.792: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 6.8383ms)
Feb  2 00:00:19.793: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 6.6014ms)
Feb  2 00:00:19.793: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 7.4731ms)
Feb  2 00:00:19.793: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 7.786ms)
Feb  2 00:00:19.794: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 7.992ms)
Feb  2 00:00:19.794: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 7.7445ms)
Feb  2 00:00:19.794: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.682ms)
Feb  2 00:00:19.794: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 8.2163ms)
Feb  2 00:00:19.796: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 9.9225ms)
Feb  2 00:00:19.796: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 10.4988ms)
Feb  2 00:00:19.796: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 10.3756ms)
Feb  2 00:00:19.798: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 1.8002ms)
Feb  2 00:00:19.803: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 3.9344ms)
Feb  2 00:00:19.803: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 6.6261ms)
Feb  2 00:00:19.803: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 5.2829ms)
Feb  2 00:00:19.803: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 6.88ms)
Feb  2 00:00:19.803: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 4.6785ms)
Feb  2 00:00:19.806: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 7.4101ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 7.1967ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 8.1763ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 7.5735ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 7.7224ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.1762ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 8.3278ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 8.154ms)
Feb  2 00:00:19.807: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 8.5136ms)
Feb  2 00:00:19.808: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 8.6019ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 5.5296ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 5.1308ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 5.721ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 5.1452ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 5.9461ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 5.4853ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 5.4335ms)
Feb  2 00:00:19.814: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 5.7559ms)
Feb  2 00:00:19.815: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 6.2746ms)
Feb  2 00:00:19.815: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 6.7924ms)
Feb  2 00:00:19.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 6.8578ms)
Feb  2 00:00:19.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 7.3079ms)
Feb  2 00:00:19.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 7.449ms)
Feb  2 00:00:19.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 7.9296ms)
Feb  2 00:00:19.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 8.1374ms)
Feb  2 00:00:19.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 9.5036ms)
Feb  2 00:00:19.822: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 3.8402ms)
Feb  2 00:00:19.825: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 6.7318ms)
Feb  2 00:00:19.825: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 6.8273ms)
Feb  2 00:00:19.825: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 7.0087ms)
Feb  2 00:00:19.826: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 7.3943ms)
Feb  2 00:00:19.826: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 7.5242ms)
Feb  2 00:00:19.826: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 7.6942ms)
Feb  2 00:00:19.827: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 8.9318ms)
Feb  2 00:00:19.828: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 9.2898ms)
Feb  2 00:00:19.828: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 9.735ms)
Feb  2 00:00:19.828: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 9.7247ms)
Feb  2 00:00:19.828: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 10.2283ms)
Feb  2 00:00:19.828: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 9.7095ms)
Feb  2 00:00:19.829: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 10.1629ms)
Feb  2 00:00:19.829: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 10.4188ms)
Feb  2 00:00:19.829: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 10.3181ms)
Feb  2 00:00:19.833: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 3.5671ms)
Feb  2 00:00:19.833: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 4.3035ms)
Feb  2 00:00:19.834: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 4.2941ms)
Feb  2 00:00:19.834: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 4.3327ms)
Feb  2 00:00:19.831: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 2.4756ms)
Feb  2 00:00:19.834: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 5.073ms)
Feb  2 00:00:19.837: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 7.7651ms)
Feb  2 00:00:19.837: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 7.7895ms)
Feb  2 00:00:19.837: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 7.6259ms)
Feb  2 00:00:19.837: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 7.7197ms)
Feb  2 00:00:19.837: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 7.8582ms)
Feb  2 00:00:19.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.1729ms)
Feb  2 00:00:19.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.1683ms)
Feb  2 00:00:19.837: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 8.0478ms)
Feb  2 00:00:19.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 8.4338ms)
Feb  2 00:00:19.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 8.5236ms)
Feb  2 00:00:19.843: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 4.6559ms)
Feb  2 00:00:19.845: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 6.3965ms)
Feb  2 00:00:19.845: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 6.55ms)
Feb  2 00:00:19.845: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 7.0775ms)
Feb  2 00:00:19.845: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.7636ms)
Feb  2 00:00:19.845: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 6.9208ms)
Feb  2 00:00:19.845: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 6.7706ms)
Feb  2 00:00:19.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 6.0959ms)
Feb  2 00:00:19.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 6.3561ms)
Feb  2 00:00:19.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 6.3582ms)
Feb  2 00:00:19.845: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 5.6984ms)
Feb  2 00:00:19.847: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 7.4934ms)
Feb  2 00:00:19.847: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 7.2841ms)
Feb  2 00:00:19.847: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 7.8687ms)
Feb  2 00:00:19.847: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 7.8253ms)
Feb  2 00:00:19.847: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 9.0246ms)
Feb  2 00:00:19.851: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 3.4736ms)
Feb  2 00:00:19.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 3.6081ms)
Feb  2 00:00:19.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 4.4671ms)
Feb  2 00:00:19.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 5.8354ms)
Feb  2 00:00:19.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 6.0794ms)
Feb  2 00:00:19.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 6.3992ms)
Feb  2 00:00:19.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 6.0546ms)
Feb  2 00:00:19.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 6.2866ms)
Feb  2 00:00:19.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 6.2792ms)
Feb  2 00:00:19.855: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.7771ms)
Feb  2 00:00:19.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 8.2891ms)
Feb  2 00:00:19.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 8.0973ms)
Feb  2 00:00:19.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 8.2637ms)
Feb  2 00:00:19.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 8.2726ms)
Feb  2 00:00:19.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 8.3952ms)
Feb  2 00:00:19.856: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 8.3992ms)
Feb  2 00:00:19.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 2.5654ms)
Feb  2 00:00:19.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 2.5326ms)
Feb  2 00:00:19.860: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 3.8212ms)
Feb  2 00:00:19.861: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 3.975ms)
Feb  2 00:00:19.861: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 4.2972ms)
Feb  2 00:00:19.861: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 3.6473ms)
Feb  2 00:00:19.861: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 3.9992ms)
Feb  2 00:00:19.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 4.4748ms)
Feb  2 00:00:19.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 4.898ms)
Feb  2 00:00:19.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 4.6679ms)
Feb  2 00:00:19.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 5.2708ms)
Feb  2 00:00:19.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 5.318ms)
Feb  2 00:00:19.862: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 5.2776ms)
Feb  2 00:00:19.863: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 5.652ms)
Feb  2 00:00:19.863: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 5.5256ms)
Feb  2 00:00:19.863: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 5.7635ms)
Feb  2 00:00:19.869: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 5.5247ms)
Feb  2 00:00:19.870: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 6.2784ms)
Feb  2 00:00:19.870: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 6.818ms)
Feb  2 00:00:19.870: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.6742ms)
Feb  2 00:00:19.870: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 6.8025ms)
Feb  2 00:00:19.870: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 6.4291ms)
Feb  2 00:00:19.870: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 6.8983ms)
Feb  2 00:00:19.871: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 6.6077ms)
Feb  2 00:00:19.871: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 6.7338ms)
Feb  2 00:00:19.871: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 6.8497ms)
Feb  2 00:00:19.871: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 7.248ms)
Feb  2 00:00:19.871: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 7.3147ms)
Feb  2 00:00:19.871: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 7.5744ms)
Feb  2 00:00:19.872: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 8.2368ms)
Feb  2 00:00:19.874: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 10.7266ms)
Feb  2 00:00:19.874: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 11.0971ms)
Feb  2 00:00:19.881: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 6.4152ms)
Feb  2 00:00:19.881: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 7.0511ms)
Feb  2 00:00:19.883: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 8.6548ms)
Feb  2 00:00:19.883: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 9.1379ms)
Feb  2 00:00:19.884: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.9281ms)
Feb  2 00:00:19.883: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.8196ms)
Feb  2 00:00:19.884: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 8.757ms)
Feb  2 00:00:19.884: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 8.837ms)
Feb  2 00:00:19.884: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 9.3536ms)
Feb  2 00:00:19.884: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 9.0904ms)
Feb  2 00:00:19.886: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 11.509ms)
Feb  2 00:00:19.886: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 11.9224ms)
Feb  2 00:00:19.886: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 11.4986ms)
Feb  2 00:00:19.887: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 11.7766ms)
Feb  2 00:00:19.887: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 11.9888ms)
Feb  2 00:00:19.887: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 11.8012ms)
Feb  2 00:00:19.889: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 2.5413ms)
Feb  2 00:00:19.897: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 8.8699ms)
Feb  2 00:00:19.897: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 9.0387ms)
Feb  2 00:00:19.897: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 10.0398ms)
Feb  2 00:00:19.897: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 9.3328ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 9.3741ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 10.4267ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 10.569ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 9.7107ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 10.5243ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 9.3916ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 11.0485ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 10.5309ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 10.9904ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 10.4954ms)
Feb  2 00:00:19.898: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 10.7746ms)
Feb  2 00:00:19.902: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 3.6694ms)
Feb  2 00:00:19.902: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 3.6177ms)
Feb  2 00:00:19.904: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 4.9365ms)
Feb  2 00:00:19.904: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 4.4821ms)
Feb  2 00:00:19.905: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 4.9702ms)
Feb  2 00:00:19.905: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 5.1412ms)
Feb  2 00:00:19.905: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 5.8206ms)
Feb  2 00:00:19.905: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 5.0655ms)
Feb  2 00:00:19.905: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 5.8276ms)
Feb  2 00:00:19.906: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 7.2144ms)
Feb  2 00:00:19.907: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 7.1678ms)
Feb  2 00:00:19.907: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 6.9379ms)
Feb  2 00:00:19.907: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 7.5645ms)
Feb  2 00:00:19.908: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 8.3714ms)
Feb  2 00:00:19.908: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 9.3196ms)
Feb  2 00:00:19.907: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 7.9467ms)
Feb  2 00:00:19.912: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 4.0564ms)
Feb  2 00:00:19.913: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 4.9342ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 8.7601ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 8.2912ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 9.0691ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 8.5616ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 8.9175ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 8.7392ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 8.3282ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 8.7366ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 8.7122ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 8.5483ms)
Feb  2 00:00:19.917: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 9.1977ms)
Feb  2 00:00:19.918: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 8.7994ms)
Feb  2 00:00:19.918: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 9.3943ms)
Feb  2 00:00:19.918: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 9.3654ms)
Feb  2 00:00:19.923: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 4.5171ms)
Feb  2 00:00:19.923: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 4.6694ms)
Feb  2 00:00:19.923: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 4.9072ms)
Feb  2 00:00:19.925: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 6.4127ms)
Feb  2 00:00:19.925: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 6.7964ms)
Feb  2 00:00:19.925: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 7.0348ms)
Feb  2 00:00:19.925: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.7517ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 7.0327ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 7.6521ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 7.8626ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 7.4003ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 7.1508ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 7.7513ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 7.2389ms)
Feb  2 00:00:19.926: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 7.1223ms)
Feb  2 00:00:19.925: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 6.8699ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 7.2681ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 7.0745ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 8.2112ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 7.3329ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 8.6878ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 7.9797ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 8.2213ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 4.6672ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 4.5875ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 8.4609ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 4.1784ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 4.8334ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 7.1684ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 8.2846ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 7.6032ms)
Feb  2 00:00:19.935: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 7.8504ms)
Feb  2 00:00:19.943: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:1080/proxy/... (200; 5.6979ms)
Feb  2 00:00:19.943: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:443/proxy/... (200; 5.4513ms)
Feb  2 00:00:19.943: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 3.247ms)
Feb  2 00:00:19.943: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:462/proxy/: tls qux (200; 5.383ms)
Feb  2 00:00:19.943: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r/proxy/rewriteme"... (200; 5.3511ms)
Feb  2 00:00:19.943: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 5.813ms)
Feb  2 00:00:19.944: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname1/proxy/: tls baz (200; 6.5891ms)
Feb  2 00:00:19.944: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname1/proxy/: foo (200; 7.0158ms)
Feb  2 00:00:19.944: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/https:proxy-service-hdpq2-sr88r:460/proxy/: tls baz (200; 6.7235ms)
Feb  2 00:00:19.944: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:162/proxy/: bar (200; 6.8689ms)
Feb  2 00:00:19.944: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname1/proxy/: foo (200; 6.6563ms)
Feb  2 00:00:19.945: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/proxy-service-hdpq2-sr88r:1080/proxy/rewri... (200; 6.7598ms)
Feb  2 00:00:19.945: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/https:proxy-service-hdpq2:tlsportname2/proxy/: tls qux (200; 7.2031ms)
Feb  2 00:00:19.945: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/pods/http:proxy-service-hdpq2-sr88r:160/proxy/: foo (200; 6.946ms)
Feb  2 00:00:19.945: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/http:proxy-service-hdpq2:portname2/proxy/: bar (200; 6.9424ms)
Feb  2 00:00:19.944: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9lkj9/services/proxy-service-hdpq2:portname2/proxy/: bar (200; 6.9612ms)
STEP: deleting ReplicationController proxy-service-hdpq2 in namespace e2e-tests-proxy-9lkj9, will wait for the garbage collector to delete the pods
Feb  2 00:00:20.007: INFO: Deleting ReplicationController proxy-service-hdpq2 took: 7.1392ms
Feb  2 00:00:20.107: INFO: Terminating ReplicationController proxy-service-hdpq2 pods took: 100.4608ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:00:30.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9lkj9" for this suite.
Feb  2 00:00:36.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:00:36.783: INFO: namespace: e2e-tests-proxy-9lkj9, resource: bindings, ignored listing per whitelist
Feb  2 00:00:36.786: INFO: namespace e2e-tests-proxy-9lkj9 deletion completed in 6.0742937s

â€¢ [SLOW TEST:30.198 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:00:36.786: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  2 00:00:36.832: INFO: PodSpec: initContainers in spec.initContainers
Feb  2 00:01:17.620: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-91ad2f3a-267d-11e9-a68a-f677bb5aadde", GenerateName:"", Namespace:"e2e-tests-init-container-rrtxc", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-rrtxc/pods/pod-init-91ad2f3a-267d-11e9-a68a-f677bb5aadde", UID:"91ad9446-267d-11e9-b4dc-025000000001", ResourceVersion:"16817", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63684662436, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"832454800"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6fg9j", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001f2c600), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6fg9j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6fg9j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6fg9j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001f71978), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"docker-desktop", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001e2f5c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f71a90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f71ab0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001f71ab8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001f71abc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684662436, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684662436, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684662436, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684662436, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.65.3", PodIP:"10.1.0.113", StartTime:(*v1.Time)(0xc0022fe6e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001a5f1f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001a5f260)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4ed1a7c74b360359a9e161f73bc0778a08e29d1c67ae1b1f9fc373372a0236b9"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0022fe720), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0022fe700), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:01:17.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rrtxc" for this suite.
Feb  2 00:01:31.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:01:31.666: INFO: namespace: e2e-tests-init-container-rrtxc, resource: bindings, ignored listing per whitelist
Feb  2 00:01:31.711: INFO: namespace e2e-tests-init-container-rrtxc deletion completed in 14.0846083s

â€¢ [SLOW TEST:54.994 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:01:31.712: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:01:31.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-6bz4w" for this suite.
Feb  2 00:01:37.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:01:37.806: INFO: namespace: e2e-tests-kubelet-test-6bz4w, resource: bindings, ignored listing per whitelist
Feb  2 00:01:37.851: INFO: namespace e2e-tests-kubelet-test-6bz4w deletion completed in 6.1071348s

â€¢ [SLOW TEST:6.174 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:01:37.852: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb  2 00:01:37.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 cluster-info'
Feb  2 00:01:38.069: INFO: stderr: ""
Feb  2 00:01:38.070: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:01:38.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vbwwf" for this suite.
Feb  2 00:01:44.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:01:44.130: INFO: namespace: e2e-tests-kubectl-vbwwf, resource: bindings, ignored listing per whitelist
Feb  2 00:01:44.150: INFO: namespace e2e-tests-kubectl-vbwwf deletion completed in 6.0777438s

â€¢ [SLOW TEST:6.298 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:01:44.150: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b9d456f8-267d-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:01:44.204: INFO: Waiting up to 5m0s for pod "pod-secrets-b9d4ba11-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-hpv22" to be "success or failure"
Feb  2 00:01:44.207: INFO: Pod "pod-secrets-b9d4ba11-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.8012ms
Feb  2 00:01:46.210: INFO: Pod "pod-secrets-b9d4ba11-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0051256s
STEP: Saw pod success
Feb  2 00:01:46.210: INFO: Pod "pod-secrets-b9d4ba11-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:01:46.211: INFO: Trying to get logs from node docker-desktop pod pod-secrets-b9d4ba11-267d-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  2 00:01:46.226: INFO: Waiting for pod pod-secrets-b9d4ba11-267d-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:01:46.228: INFO: Pod pod-secrets-b9d4ba11-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:01:46.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hpv22" for this suite.
Feb  2 00:01:52.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:01:52.266: INFO: namespace: e2e-tests-secrets-hpv22, resource: bindings, ignored listing per whitelist
Feb  2 00:01:52.307: INFO: namespace e2e-tests-secrets-hpv22 deletion completed in 6.0762406s

â€¢ [SLOW TEST:8.157 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:01:52.308: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:01:57.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-swj8q" for this suite.
Feb  2 00:02:19.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:02:19.390: INFO: namespace: e2e-tests-replication-controller-swj8q, resource: bindings, ignored listing per whitelist
Feb  2 00:02:19.434: INFO: namespace e2e-tests-replication-controller-swj8q deletion completed in 22.0831639s

â€¢ [SLOW TEST:27.161 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:02:19.435: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-2kgt
STEP: Creating a pod to test atomic-volume-subpath
Feb  2 00:02:19.493: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2kgt" in namespace "e2e-tests-subpath-ldvxm" to be "success or failure"
Feb  2 00:02:19.496: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.9722ms
Feb  2 00:02:21.505: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0113543s
Feb  2 00:02:23.509: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 4.0155862s
Feb  2 00:02:25.512: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 6.0188938s
Feb  2 00:02:27.517: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 8.0239985s
Feb  2 00:02:29.523: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 10.029762s
Feb  2 00:02:31.529: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 12.0356606s
Feb  2 00:02:33.533: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 14.039819s
Feb  2 00:02:35.541: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 16.0482256s
Feb  2 00:02:37.513: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 18.0539662s
Feb  2 00:02:39.517: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 20.0587488s
Feb  2 00:02:41.523: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Running", Reason="", readiness=false. Elapsed: 22.0645451s
Feb  2 00:02:43.528: INFO: Pod "pod-subpath-test-configmap-2kgt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0692602s
STEP: Saw pod success
Feb  2 00:02:43.528: INFO: Pod "pod-subpath-test-configmap-2kgt" satisfied condition "success or failure"
Feb  2 00:02:43.531: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-2kgt container test-container-subpath-configmap-2kgt: <nil>
STEP: delete the pod
Feb  2 00:02:43.551: INFO: Waiting for pod pod-subpath-test-configmap-2kgt to disappear
Feb  2 00:02:43.556: INFO: Pod pod-subpath-test-configmap-2kgt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2kgt
Feb  2 00:02:43.556: INFO: Deleting pod "pod-subpath-test-configmap-2kgt" in namespace "e2e-tests-subpath-ldvxm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:02:43.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ldvxm" for this suite.
Feb  2 00:02:49.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:02:49.624: INFO: namespace: e2e-tests-subpath-ldvxm, resource: bindings, ignored listing per whitelist
Feb  2 00:02:49.634: INFO: namespace e2e-tests-subpath-ldvxm deletion completed in 6.0730297s

â€¢ [SLOW TEST:30.234 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:02:49.634: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  2 00:02:49.687: INFO: Waiting up to 5m0s for pod "pod-e0dc985f-267d-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-xxmf2" to be "success or failure"
Feb  2 00:02:49.689: INFO: Pod "pod-e0dc985f-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.7582ms
Feb  2 00:02:51.694: INFO: Pod "pod-e0dc985f-267d-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0069331s
Feb  2 00:02:53.700: INFO: Pod "pod-e0dc985f-267d-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0122309s
STEP: Saw pod success
Feb  2 00:02:53.700: INFO: Pod "pod-e0dc985f-267d-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:02:53.702: INFO: Trying to get logs from node docker-desktop pod pod-e0dc985f-267d-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:02:53.721: INFO: Waiting for pod pod-e0dc985f-267d-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:02:53.723: INFO: Pod pod-e0dc985f-267d-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:02:53.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xxmf2" for this suite.
Feb  2 00:02:59.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:02:59.748: INFO: namespace: e2e-tests-emptydir-xxmf2, resource: bindings, ignored listing per whitelist
Feb  2 00:02:59.804: INFO: namespace e2e-tests-emptydir-xxmf2 deletion completed in 6.0775377s

â€¢ [SLOW TEST:10.170 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:02:59.804: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:02:59.851: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:03:01.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vkphp" for this suite.
Feb  2 00:03:39.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:03:39.895: INFO: namespace: e2e-tests-pods-vkphp, resource: bindings, ignored listing per whitelist
Feb  2 00:03:39.906: INFO: namespace e2e-tests-pods-vkphp deletion completed in 38.0804741s

â€¢ [SLOW TEST:40.171 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:03:39.908: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-mn7x5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-mn7x5 to expose endpoints map[]
Feb  2 00:03:39.966: INFO: Get endpoints failed (2.1914ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb  2 00:03:40.971: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-mn7x5 exposes endpoints map[] (1.0068356s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-mn7x5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-mn7x5 to expose endpoints map[pod1:[100]]
Feb  2 00:03:42.996: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-mn7x5 exposes endpoints map[pod1:[100]] (2.0179687s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-mn7x5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-mn7x5 to expose endpoints map[pod1:[100] pod2:[101]]
Feb  2 00:03:45.042: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-mn7x5 exposes endpoints map[pod1:[100] pod2:[101]] (2.041779s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-mn7x5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-mn7x5 to expose endpoints map[pod2:[101]]
Feb  2 00:03:45.062: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-mn7x5 exposes endpoints map[pod2:[101]] (9.0901ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-mn7x5
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-mn7x5 to expose endpoints map[]
Feb  2 00:03:45.072: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-mn7x5 exposes endpoints map[] (4.5852ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:03:45.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-mn7x5" for this suite.
Feb  2 00:03:51.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:03:51.133: INFO: namespace: e2e-tests-services-mn7x5, resource: bindings, ignored listing per whitelist
Feb  2 00:03:51.172: INFO: namespace e2e-tests-services-mn7x5 deletion completed in 6.0810538s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:11.264 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:03:51.172: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-k98bd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  2 00:03:51.221: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  2 00:04:15.239: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.0.122:8080/dial?request=hostName&protocol=udp&host=10.1.0.121&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-k98bd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:04:15.239: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:04:15.368: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:04:15.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-k98bd" for this suite.
Feb  2 00:04:37.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:04:37.378: INFO: namespace: e2e-tests-pod-network-test-k98bd, resource: bindings, ignored listing per whitelist
Feb  2 00:04:37.422: INFO: namespace e2e-tests-pod-network-test-k98bd deletion completed in 22.080815s

â€¢ [SLOW TEST:46.319 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:04:37.422: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-9g575
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  2 00:04:37.471: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  2 00:04:59.524: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.1.0.123 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9g575 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:04:59.524: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:05:00.624: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:05:00.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-9g575" for this suite.
Feb  2 00:05:22.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:05:22.615: INFO: namespace: e2e-tests-pod-network-test-9g575, resource: bindings, ignored listing per whitelist
Feb  2 00:05:22.667: INFO: namespace e2e-tests-pod-network-test-9g575 deletion completed in 22.0752089s

â€¢ [SLOW TEST:45.280 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:05:22.667: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  2 00:05:22.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:22.856: INFO: stderr: ""
Feb  2 00:05:22.856: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  2 00:05:22.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:22.961: INFO: stderr: ""
Feb  2 00:05:22.961: INFO: stdout: "update-demo-nautilus-pw5vm update-demo-nautilus-tgfq5 "
Feb  2 00:05:22.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-pw5vm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:23.030: INFO: stderr: ""
Feb  2 00:05:23.030: INFO: stdout: ""
Feb  2 00:05:23.030: INFO: update-demo-nautilus-pw5vm is created but not running
Feb  2 00:05:28.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:28.108: INFO: stderr: ""
Feb  2 00:05:28.108: INFO: stdout: "update-demo-nautilus-pw5vm update-demo-nautilus-tgfq5 "
Feb  2 00:05:28.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-pw5vm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:28.174: INFO: stderr: ""
Feb  2 00:05:28.174: INFO: stdout: "true"
Feb  2 00:05:28.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-pw5vm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:28.243: INFO: stderr: ""
Feb  2 00:05:28.243: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  2 00:05:28.243: INFO: validating pod update-demo-nautilus-pw5vm
Feb  2 00:05:28.249: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  2 00:05:28.249: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  2 00:05:28.249: INFO: update-demo-nautilus-pw5vm is verified up and running
Feb  2 00:05:28.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-tgfq5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:28.327: INFO: stderr: ""
Feb  2 00:05:28.328: INFO: stdout: "true"
Feb  2 00:05:28.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-tgfq5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:28.388: INFO: stderr: ""
Feb  2 00:05:28.389: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  2 00:05:28.389: INFO: validating pod update-demo-nautilus-tgfq5
Feb  2 00:05:28.392: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  2 00:05:28.392: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  2 00:05:28.392: INFO: update-demo-nautilus-tgfq5 is verified up and running
STEP: scaling down the replication controller
Feb  2 00:05:28.393: INFO: scanned /root for discovery docs: <nil>
Feb  2 00:05:28.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:29.480: INFO: stderr: ""
Feb  2 00:05:29.480: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  2 00:05:29.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:29.549: INFO: stderr: ""
Feb  2 00:05:29.549: INFO: stdout: "update-demo-nautilus-pw5vm update-demo-nautilus-tgfq5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  2 00:05:34.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:34.627: INFO: stderr: ""
Feb  2 00:05:34.627: INFO: stdout: "update-demo-nautilus-pw5vm update-demo-nautilus-tgfq5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  2 00:05:39.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:39.669: INFO: stderr: ""
Feb  2 00:05:39.669: INFO: stdout: "update-demo-nautilus-pw5vm update-demo-nautilus-tgfq5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  2 00:05:44.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:44.742: INFO: stderr: ""
Feb  2 00:05:44.742: INFO: stdout: "update-demo-nautilus-pw5vm "
Feb  2 00:05:44.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-pw5vm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:44.805: INFO: stderr: ""
Feb  2 00:05:44.805: INFO: stdout: "true"
Feb  2 00:05:44.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-pw5vm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:44.865: INFO: stderr: ""
Feb  2 00:05:44.865: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  2 00:05:44.865: INFO: validating pod update-demo-nautilus-pw5vm
Feb  2 00:05:44.868: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  2 00:05:44.868: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  2 00:05:44.868: INFO: update-demo-nautilus-pw5vm is verified up and running
STEP: scaling up the replication controller
Feb  2 00:05:44.869: INFO: scanned /root for discovery docs: <nil>
Feb  2 00:05:44.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:45.957: INFO: stderr: ""
Feb  2 00:05:45.958: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  2 00:05:45.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:46.035: INFO: stderr: ""
Feb  2 00:05:46.035: INFO: stdout: "update-demo-nautilus-c7ss2 update-demo-nautilus-pw5vm "
Feb  2 00:05:46.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-c7ss2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:46.132: INFO: stderr: ""
Feb  2 00:05:46.132: INFO: stdout: ""
Feb  2 00:05:46.132: INFO: update-demo-nautilus-c7ss2 is created but not running
Feb  2 00:05:51.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:51.212: INFO: stderr: ""
Feb  2 00:05:51.212: INFO: stdout: "update-demo-nautilus-c7ss2 update-demo-nautilus-pw5vm "
Feb  2 00:05:51.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-c7ss2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:51.277: INFO: stderr: ""
Feb  2 00:05:51.277: INFO: stdout: "true"
Feb  2 00:05:51.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-c7ss2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:51.337: INFO: stderr: ""
Feb  2 00:05:51.337: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  2 00:05:51.337: INFO: validating pod update-demo-nautilus-c7ss2
Feb  2 00:05:51.341: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  2 00:05:51.341: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  2 00:05:51.341: INFO: update-demo-nautilus-c7ss2 is verified up and running
Feb  2 00:05:51.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-pw5vm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:51.407: INFO: stderr: ""
Feb  2 00:05:51.407: INFO: stdout: "true"
Feb  2 00:05:51.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods update-demo-nautilus-pw5vm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:51.474: INFO: stderr: ""
Feb  2 00:05:51.475: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  2 00:05:51.475: INFO: validating pod update-demo-nautilus-pw5vm
Feb  2 00:05:51.477: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  2 00:05:51.477: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  2 00:05:51.477: INFO: update-demo-nautilus-pw5vm is verified up and running
STEP: using delete to clean up resources
Feb  2 00:05:51.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:51.545: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 00:05:51.545: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  2 00:05:51.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7dnpm'
Feb  2 00:05:51.663: INFO: stderr: "No resources found.\n"
Feb  2 00:05:51.663: INFO: stdout: ""
Feb  2 00:05:51.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -l name=update-demo --namespace=e2e-tests-kubectl-7dnpm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  2 00:05:51.755: INFO: stderr: ""
Feb  2 00:05:51.755: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:05:51.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7dnpm" for this suite.
Feb  2 00:06:13.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:06:13.786: INFO: namespace: e2e-tests-kubectl-7dnpm, resource: bindings, ignored listing per whitelist
Feb  2 00:06:13.806: INFO: namespace e2e-tests-kubectl-7dnpm deletion completed in 22.082238s

â€¢ [SLOW TEST:51.208 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:06:13.806: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-62p87/secret-test-5a8f954e-267e-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:06:13.867: INFO: Waiting up to 5m0s for pod "pod-configmaps-5a900e85-267e-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-62p87" to be "success or failure"
Feb  2 00:06:13.871: INFO: Pod "pod-configmaps-5a900e85-267e-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.9919ms
Feb  2 00:06:15.873: INFO: Pod "pod-configmaps-5a900e85-267e-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0056519s
STEP: Saw pod success
Feb  2 00:06:15.873: INFO: Pod "pod-configmaps-5a900e85-267e-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:06:15.875: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-5a900e85-267e-11e9-a68a-f677bb5aadde container env-test: <nil>
STEP: delete the pod
Feb  2 00:06:15.897: INFO: Waiting for pod pod-configmaps-5a900e85-267e-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:06:15.901: INFO: Pod pod-configmaps-5a900e85-267e-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:06:15.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-62p87" for this suite.
Feb  2 00:06:21.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:06:21.928: INFO: namespace: e2e-tests-secrets-62p87, resource: bindings, ignored listing per whitelist
Feb  2 00:06:21.978: INFO: namespace e2e-tests-secrets-62p87 deletion completed in 6.069931s

â€¢ [SLOW TEST:8.172 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:06:21.978: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-28ctp
Feb  2 00:06:26.037: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-28ctp
STEP: checking the pod's current state and verifying that restartCount is present
Feb  2 00:06:26.039: INFO: Initial restart count of pod liveness-http is 0
Feb  2 00:06:40.046: INFO: Restart count of pod e2e-tests-container-probe-28ctp/liveness-http is now 1 (14.0415762s elapsed)
Feb  2 00:07:00.103: INFO: Restart count of pod e2e-tests-container-probe-28ctp/liveness-http is now 2 (34.0985672s elapsed)
Feb  2 00:07:18.113: INFO: Restart count of pod e2e-tests-container-probe-28ctp/liveness-http is now 3 (52.1431154s elapsed)
Feb  2 00:07:38.123: INFO: Restart count of pod e2e-tests-container-probe-28ctp/liveness-http is now 4 (1m12.1875288s elapsed)
Feb  2 00:08:40.213: INFO: Restart count of pod e2e-tests-container-probe-28ctp/liveness-http is now 5 (2m14.3464441s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:08:40.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-28ctp" for this suite.
Feb  2 00:08:46.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:08:46.290: INFO: namespace: e2e-tests-container-probe-28ctp, resource: bindings, ignored listing per whitelist
Feb  2 00:08:46.316: INFO: namespace e2e-tests-container-probe-28ctp deletion completed in 6.0840937s

â€¢ [SLOW TEST:144.511 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:08:46.316: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:08:46.365: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:08:55.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-v28z4" for this suite.
Feb  2 00:09:01.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:09:01.528: INFO: namespace: e2e-tests-custom-resource-definition-v28z4, resource: bindings, ignored listing per whitelist
Feb  2 00:09:01.583: INFO: namespace e2e-tests-custom-resource-definition-v28z4 deletion completed in 6.089822s

â€¢ [SLOW TEST:15.267 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:09:01.587: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  2 00:09:01.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6lz4k'
Feb  2 00:09:01.720: INFO: stderr: ""
Feb  2 00:09:01.721: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb  2 00:09:01.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6lz4k'
Feb  2 00:09:10.031: INFO: stderr: ""
Feb  2 00:09:10.031: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:09:10.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6lz4k" for this suite.
Feb  2 00:09:16.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:09:16.087: INFO: namespace: e2e-tests-kubectl-6lz4k, resource: bindings, ignored listing per whitelist
Feb  2 00:09:16.108: INFO: namespace e2e-tests-kubectl-6lz4k deletion completed in 6.0738581s

â€¢ [SLOW TEST:14.556 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:09:16.108: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb  2 00:09:16.160: INFO: Pod name pod-release: Found 0 pods out of 1
Feb  2 00:09:21.163: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:09:22.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2c8sn" for this suite.
Feb  2 00:09:28.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:09:28.219: INFO: namespace: e2e-tests-replication-controller-2c8sn, resource: bindings, ignored listing per whitelist
Feb  2 00:09:28.259: INFO: namespace e2e-tests-replication-controller-2c8sn deletion completed in 6.0780439s

â€¢ [SLOW TEST:12.151 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:09:28.260: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  2 00:09:28.321: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tqhcl,SelfLink:/api/v1/namespaces/e2e-tests-watch-tqhcl/configmaps/e2e-watch-test-label-changed,UID:ce7662e2-267e-11e9-b4dc-025000000001,ResourceVersion:17991,Generation:0,CreationTimestamp:2019-02-02 00:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  2 00:09:28.321: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tqhcl,SelfLink:/api/v1/namespaces/e2e-tests-watch-tqhcl/configmaps/e2e-watch-test-label-changed,UID:ce7662e2-267e-11e9-b4dc-025000000001,ResourceVersion:17992,Generation:0,CreationTimestamp:2019-02-02 00:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  2 00:09:28.321: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tqhcl,SelfLink:/api/v1/namespaces/e2e-tests-watch-tqhcl/configmaps/e2e-watch-test-label-changed,UID:ce7662e2-267e-11e9-b4dc-025000000001,ResourceVersion:17993,Generation:0,CreationTimestamp:2019-02-02 00:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  2 00:09:38.308: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tqhcl,SelfLink:/api/v1/namespaces/e2e-tests-watch-tqhcl/configmaps/e2e-watch-test-label-changed,UID:ce7662e2-267e-11e9-b4dc-025000000001,ResourceVersion:18006,Generation:0,CreationTimestamp:2019-02-02 00:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  2 00:09:38.308: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tqhcl,SelfLink:/api/v1/namespaces/e2e-tests-watch-tqhcl/configmaps/e2e-watch-test-label-changed,UID:ce7662e2-267e-11e9-b4dc-025000000001,ResourceVersion:18007,Generation:0,CreationTimestamp:2019-02-02 00:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  2 00:09:38.308: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tqhcl,SelfLink:/api/v1/namespaces/e2e-tests-watch-tqhcl/configmaps/e2e-watch-test-label-changed,UID:ce7662e2-267e-11e9-b4dc-025000000001,ResourceVersion:18008,Generation:0,CreationTimestamp:2019-02-02 00:09:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:09:38.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tqhcl" for this suite.
Feb  2 00:09:44.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:09:44.348: INFO: namespace: e2e-tests-watch-tqhcl, resource: bindings, ignored listing per whitelist
Feb  2 00:09:44.383: INFO: namespace e2e-tests-watch-tqhcl deletion completed in 6.0729085s

â€¢ [SLOW TEST:16.158 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:09:44.386: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:09:44.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 version'
Feb  2 00:09:44.497: INFO: stderr: ""
Feb  2 00:09:44.497: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T20:56:12Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:09:44.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ndt7s" for this suite.
Feb  2 00:09:50.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:09:50.570: INFO: namespace: e2e-tests-kubectl-ndt7s, resource: bindings, ignored listing per whitelist
Feb  2 00:09:50.573: INFO: namespace e2e-tests-kubectl-ndt7s deletion completed in 6.0715749s

â€¢ [SLOW TEST:6.188 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:09:50.573: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:09:50.621: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dbc2197a-267e-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-shlmq" to be "success or failure"
Feb  2 00:09:50.623: INFO: Pod "downwardapi-volume-dbc2197a-267e-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.7957ms
Feb  2 00:09:52.628: INFO: Pod "downwardapi-volume-dbc2197a-267e-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0064548s
STEP: Saw pod success
Feb  2 00:09:52.628: INFO: Pod "downwardapi-volume-dbc2197a-267e-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:09:52.631: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-dbc2197a-267e-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:09:52.647: INFO: Waiting for pod downwardapi-volume-dbc2197a-267e-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:09:52.652: INFO: Pod downwardapi-volume-dbc2197a-267e-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:09:52.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-shlmq" for this suite.
Feb  2 00:09:58.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:09:58.728: INFO: namespace: e2e-tests-projected-shlmq, resource: bindings, ignored listing per whitelist
Feb  2 00:09:58.736: INFO: namespace e2e-tests-projected-shlmq deletion completed in 6.0810998s

â€¢ [SLOW TEST:8.163 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:09:58.736: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb  2 00:10:00.826: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-e0a0ce16-267e-11e9-a68a-f677bb5aadde", GenerateName:"", Namespace:"e2e-tests-pods-5zkd4", SelfLink:"/api/v1/namespaces/e2e-tests-pods-5zkd4/pods/pod-submit-remove-e0a0ce16-267e-11e9-a68a-f677bb5aadde", UID:"e0a17aa1-267e-11e9-b4dc-025000000001", ResourceVersion:"18082", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63684662998, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"788059400"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-q265j", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000888900), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q265j", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001386328), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"docker-desktop", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000a7de60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001386370)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001386c30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001386c38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001386c3c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684662998, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684663000, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684663000, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684662998, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.65.3", PodIP:"10.1.0.133", StartTime:(*v1.Time)(0xc001414300), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001414320), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://fd019c075391707a23a3fed7ab34098e4013a5b4f8a08b7d60947d8d368230ba"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb  2 00:10:05.846: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:10:05.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5zkd4" for this suite.
Feb  2 00:10:11.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:10:11.894: INFO: namespace: e2e-tests-pods-5zkd4, resource: bindings, ignored listing per whitelist
Feb  2 00:10:11.898: INFO: namespace e2e-tests-pods-5zkd4 deletion completed in 6.0806957s

â€¢ [SLOW TEST:13.197 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:10:11.899: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb  2 00:10:12.485: INFO: created pod pod-service-account-defaultsa
Feb  2 00:10:12.485: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  2 00:10:12.491: INFO: created pod pod-service-account-mountsa
Feb  2 00:10:12.491: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  2 00:10:12.508: INFO: created pod pod-service-account-nomountsa
Feb  2 00:10:12.508: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  2 00:10:12.518: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  2 00:10:12.518: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  2 00:10:12.532: INFO: created pod pod-service-account-mountsa-mountspec
Feb  2 00:10:12.532: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  2 00:10:12.548: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  2 00:10:12.548: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  2 00:10:12.562: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  2 00:10:12.562: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  2 00:10:12.571: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  2 00:10:12.571: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  2 00:10:12.595: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  2 00:10:12.595: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:10:12.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-t5nd2" for this suite.
Feb  2 00:10:34.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:10:34.683: INFO: namespace: e2e-tests-svcaccounts-t5nd2, resource: bindings, ignored listing per whitelist
Feb  2 00:10:34.686: INFO: namespace e2e-tests-svcaccounts-t5nd2 deletion completed in 22.082172s

â€¢ [SLOW TEST:22.786 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:10:34.686: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f60d85e5-267e-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:10:34.739: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f60df555-267e-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-k7bw8" to be "success or failure"
Feb  2 00:10:34.741: INFO: Pod "pod-projected-secrets-f60df555-267e-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.7686ms
Feb  2 00:10:36.711: INFO: Pod "pod-projected-secrets-f60df555-267e-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0065413s
STEP: Saw pod success
Feb  2 00:10:36.711: INFO: Pod "pod-projected-secrets-f60df555-267e-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:10:36.715: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-f60df555-267e-11e9-a68a-f677bb5aadde container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  2 00:10:36.730: INFO: Waiting for pod pod-projected-secrets-f60df555-267e-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:10:36.734: INFO: Pod pod-projected-secrets-f60df555-267e-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:10:36.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k7bw8" for this suite.
Feb  2 00:10:42.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:10:42.759: INFO: namespace: e2e-tests-projected-k7bw8, resource: bindings, ignored listing per whitelist
Feb  2 00:10:42.811: INFO: namespace e2e-tests-projected-k7bw8 deletion completed in 6.0747593s

â€¢ [SLOW TEST:8.160 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:10:42.811: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  2 00:10:42.870: INFO: Waiting up to 5m0s for pod "pod-fae63df3-267e-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-7b2s8" to be "success or failure"
Feb  2 00:10:42.883: INFO: Pod "pod-fae63df3-267e-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 13.1965ms
Feb  2 00:10:44.887: INFO: Pod "pod-fae63df3-267e-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0167633s
Feb  2 00:10:46.892: INFO: Pod "pod-fae63df3-267e-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0221901s
STEP: Saw pod success
Feb  2 00:10:46.892: INFO: Pod "pod-fae63df3-267e-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:10:46.896: INFO: Trying to get logs from node docker-desktop pod pod-fae63df3-267e-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:10:46.915: INFO: Waiting for pod pod-fae63df3-267e-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:10:46.918: INFO: Pod pod-fae63df3-267e-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:10:46.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7b2s8" for this suite.
Feb  2 00:10:52.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:10:52.991: INFO: namespace: e2e-tests-emptydir-7b2s8, resource: bindings, ignored listing per whitelist
Feb  2 00:10:52.997: INFO: namespace e2e-tests-emptydir-7b2s8 deletion completed in 6.0764518s

â€¢ [SLOW TEST:10.186 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:10:52.997: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  2 00:10:55.585: INFO: Successfully updated pod "annotationupdate00f8eb66-267f-11e9-a68a-f677bb5aadde"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:10:57.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6kmpk" for this suite.
Feb  2 00:11:19.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:11:19.629: INFO: namespace: e2e-tests-downward-api-6kmpk, resource: bindings, ignored listing per whitelist
Feb  2 00:11:19.648: INFO: namespace e2e-tests-downward-api-6kmpk deletion completed in 22.0744432s

â€¢ [SLOW TEST:26.686 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:11:19.648: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  2 00:11:19.700: INFO: Waiting up to 5m0s for pod "downward-api-10da3fc8-267f-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-jf5kd" to be "success or failure"
Feb  2 00:11:19.702: INFO: Pod "downward-api-10da3fc8-267f-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0473ms
Feb  2 00:11:21.705: INFO: Pod "downward-api-10da3fc8-267f-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00498s
STEP: Saw pod success
Feb  2 00:11:21.705: INFO: Pod "downward-api-10da3fc8-267f-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:11:21.707: INFO: Trying to get logs from node docker-desktop pod downward-api-10da3fc8-267f-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  2 00:11:21.730: INFO: Waiting for pod downward-api-10da3fc8-267f-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:11:21.736: INFO: Pod downward-api-10da3fc8-267f-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:11:21.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jf5kd" for this suite.
Feb  2 00:11:27.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:11:27.826: INFO: namespace: e2e-tests-downward-api-jf5kd, resource: bindings, ignored listing per whitelist
Feb  2 00:11:27.827: INFO: namespace e2e-tests-downward-api-jf5kd deletion completed in 6.0855877s

â€¢ [SLOW TEST:8.179 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:11:27.828: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:11:27.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15bb1759-267f-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-8h6kd" to be "success or failure"
Feb  2 00:11:27.887: INFO: Pod "downwardapi-volume-15bb1759-267f-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.6117ms
Feb  2 00:11:29.897: INFO: Pod "downwardapi-volume-15bb1759-267f-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0126672s
STEP: Saw pod success
Feb  2 00:11:29.897: INFO: Pod "downwardapi-volume-15bb1759-267f-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:11:29.899: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-15bb1759-267f-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:11:29.917: INFO: Waiting for pod downwardapi-volume-15bb1759-267f-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:11:29.920: INFO: Pod downwardapi-volume-15bb1759-267f-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:11:29.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8h6kd" for this suite.
Feb  2 00:11:35.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:11:35.974: INFO: namespace: e2e-tests-downward-api-8h6kd, resource: bindings, ignored listing per whitelist
Feb  2 00:11:36.002: INFO: namespace e2e-tests-downward-api-8h6kd deletion completed in 6.079193s

â€¢ [SLOW TEST:8.175 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:11:36.008: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  2 00:11:36.057: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  2 00:11:36.061: INFO: Waiting for terminating namespaces to be deleted...
Feb  2 00:11:36.064: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Feb  2 00:11:36.068: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-01 22:53:35 +0000 UTC (1 container statuses recorded)
Feb  2 00:11:36.068: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  2 00:11:36.069: INFO: sonobuoy-e2e-job-bb494af789db4143 from heptio-sonobuoy started at 2019-02-01 22:53:40 +0000 UTC (2 container statuses recorded)
Feb  2 00:11:36.069: INFO: 	Container e2e ready: true, restart count 0
Feb  2 00:11:36.069: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  2 00:11:36.070: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:11:36.070: INFO: coredns-86c58d9df4-zxg7j from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  2 00:11:36.070: INFO: 	Container coredns ready: true, restart count 0
Feb  2 00:11:36.070: INFO: compose-56897cc96b-gnrcd from docker started at 2019-02-01 15:57:21 +0000 UTC (1 container statuses recorded)
Feb  2 00:11:36.071: INFO: 	Container compose ready: true, restart count 0
Feb  2 00:11:36.071: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:11:36.071: INFO: compose-api-5fb5fd58d-fjvcj from docker started at 2019-02-01 15:57:21 +0000 UTC (1 container statuses recorded)
Feb  2 00:11:36.071: INFO: 	Container compose ready: true, restart count 0
Feb  2 00:11:36.071: INFO: kube-proxy-hzvvt from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  2 00:11:36.072: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  2 00:11:36.072: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:11:36.072: INFO: coredns-86c58d9df4-492hj from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  2 00:11:36.072: INFO: 	Container coredns ready: true, restart count 0
Feb  2 00:11:36.072: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:11:36.072: INFO: sonobuoy-systemd-logs-daemon-set-2081b0686f0449ba-4wdch from heptio-sonobuoy started at 2019-02-01 22:53:40 +0000 UTC (2 container statuses recorded)
Feb  2 00:11:36.073: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 13
Feb  2 00:11:36.073: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157f6396c79a63ec], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:11:37.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9zgcq" for this suite.
Feb  2 00:11:43.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:11:43.099: INFO: namespace: e2e-tests-sched-pred-9zgcq, resource: bindings, ignored listing per whitelist
Feb  2 00:11:43.145: INFO: namespace e2e-tests-sched-pred-9zgcq deletion completed in 6.0890112s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:7.173 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:11:43.145: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  2 00:11:43.212: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b7l74,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7l74/configmaps/e2e-watch-test-watch-closed,UID:1edd35fb-267f-11e9-b4dc-025000000001,ResourceVersion:18455,Generation:0,CreationTimestamp:2019-02-02 00:11:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  2 00:11:43.212: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b7l74,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7l74/configmaps/e2e-watch-test-watch-closed,UID:1edd35fb-267f-11e9-b4dc-025000000001,ResourceVersion:18456,Generation:0,CreationTimestamp:2019-02-02 00:11:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  2 00:11:43.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b7l74,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7l74/configmaps/e2e-watch-test-watch-closed,UID:1edd35fb-267f-11e9-b4dc-025000000001,ResourceVersion:18457,Generation:0,CreationTimestamp:2019-02-02 00:11:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  2 00:11:43.223: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-b7l74,SelfLink:/api/v1/namespaces/e2e-tests-watch-b7l74/configmaps/e2e-watch-test-watch-closed,UID:1edd35fb-267f-11e9-b4dc-025000000001,ResourceVersion:18458,Generation:0,CreationTimestamp:2019-02-02 00:11:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:11:43.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-b7l74" for this suite.
Feb  2 00:11:49.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:11:49.279: INFO: namespace: e2e-tests-watch-b7l74, resource: bindings, ignored listing per whitelist
Feb  2 00:11:49.304: INFO: namespace e2e-tests-watch-b7l74 deletion completed in 6.0791398s

â€¢ [SLOW TEST:6.159 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:11:49.304: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2288397c-267f-11e9-a68a-f677bb5aadde
STEP: Creating configMap with name cm-test-opt-upd-22883a53-267f-11e9-a68a-f677bb5aadde
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2288397c-267f-11e9-a68a-f677bb5aadde
STEP: Updating configmap cm-test-opt-upd-22883a53-267f-11e9-a68a-f677bb5aadde
STEP: Creating configMap with name cm-test-opt-create-22883ac8-267f-11e9-a68a-f677bb5aadde
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:11:55.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6wpbj" for this suite.
Feb  2 00:12:17.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:12:17.485: INFO: namespace: e2e-tests-configmap-6wpbj, resource: bindings, ignored listing per whitelist
Feb  2 00:12:17.490: INFO: namespace e2e-tests-configmap-6wpbj deletion completed in 22.0760651s

â€¢ [SLOW TEST:28.220 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:12:17.490: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb  2 00:12:17.746: INFO: Pod name wrapped-volume-race-3369a2b1-267f-11e9-a68a-f677bb5aadde: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3369a2b1-267f-11e9-a68a-f677bb5aadde in namespace e2e-tests-emptydir-wrapper-vfkbl, will wait for the garbage collector to delete the pods
Feb  2 00:12:33.876: INFO: Deleting ReplicationController wrapped-volume-race-3369a2b1-267f-11e9-a68a-f677bb5aadde took: 10.4971ms
Feb  2 00:12:33.979: INFO: Terminating ReplicationController wrapped-volume-race-3369a2b1-267f-11e9-a68a-f677bb5aadde pods took: 102.0557ms
STEP: Creating RC which spawns configmap-volume pods
Feb  2 00:13:10.528: INFO: Pod name wrapped-volume-race-52e7d1e5-267f-11e9-a68a-f677bb5aadde: Found 0 pods out of 5
Feb  2 00:13:15.533: INFO: Pod name wrapped-volume-race-52e7d1e5-267f-11e9-a68a-f677bb5aadde: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-52e7d1e5-267f-11e9-a68a-f677bb5aadde in namespace e2e-tests-emptydir-wrapper-vfkbl, will wait for the garbage collector to delete the pods
Feb  2 00:13:25.628: INFO: Deleting ReplicationController wrapped-volume-race-52e7d1e5-267f-11e9-a68a-f677bb5aadde took: 7.0066ms
Feb  2 00:13:25.729: INFO: Terminating ReplicationController wrapped-volume-race-52e7d1e5-267f-11e9-a68a-f677bb5aadde pods took: 100.5463ms
STEP: Creating RC which spawns configmap-volume pods
Feb  2 00:14:09.781: INFO: Pod name wrapped-volume-race-7638606b-267f-11e9-a68a-f677bb5aadde: Found 0 pods out of 5
Feb  2 00:14:14.785: INFO: Pod name wrapped-volume-race-7638606b-267f-11e9-a68a-f677bb5aadde: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-7638606b-267f-11e9-a68a-f677bb5aadde in namespace e2e-tests-emptydir-wrapper-vfkbl, will wait for the garbage collector to delete the pods
Feb  2 00:14:24.869: INFO: Deleting ReplicationController wrapped-volume-race-7638606b-267f-11e9-a68a-f677bb5aadde took: 7.9126ms
Feb  2 00:14:24.972: INFO: Terminating ReplicationController wrapped-volume-race-7638606b-267f-11e9-a68a-f677bb5aadde pods took: 102.2693ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:15:02.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-vfkbl" for this suite.
Feb  2 00:15:08.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:15:08.608: INFO: namespace: e2e-tests-emptydir-wrapper-vfkbl, resource: bindings, ignored listing per whitelist
Feb  2 00:15:08.655: INFO: namespace e2e-tests-emptydir-wrapper-vfkbl deletion completed in 6.0834256s

â€¢ [SLOW TEST:171.373 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:15:08.656: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  2 00:15:16.739: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:16.739: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:16.824: INFO: Exec stderr: ""
Feb  2 00:15:16.824: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:16.824: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:16.934: INFO: Exec stderr: ""
Feb  2 00:15:16.934: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:16.934: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:17.018: INFO: Exec stderr: ""
Feb  2 00:15:17.018: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:17.018: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:17.107: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  2 00:15:17.107: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:17.107: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:17.206: INFO: Exec stderr: ""
Feb  2 00:15:17.206: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:17.206: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:17.301: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  2 00:15:17.301: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:17.301: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:17.389: INFO: Exec stderr: ""
Feb  2 00:15:17.389: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:17.389: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:17.479: INFO: Exec stderr: ""
Feb  2 00:15:17.479: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:17.479: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:17.559: INFO: Exec stderr: ""
Feb  2 00:15:17.559: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-chws7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:15:17.559: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:15:18.189: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:15:18.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-chws7" for this suite.
Feb  2 00:15:56.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:15:56.206: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-chws7, resource: bindings, ignored listing per whitelist
Feb  2 00:15:56.235: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-chws7 deletion completed in 38.0784135s

â€¢ [SLOW TEST:47.614 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:15:56.235: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-44hxr
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb  2 00:15:56.298: INFO: Found 0 stateful pods, waiting for 3
Feb  2 00:16:06.269: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  2 00:16:06.269: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  2 00:16:06.269: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  2 00:16:06.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-44hxr ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  2 00:16:06.427: INFO: stderr: ""
Feb  2 00:16:06.427: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  2 00:16:06.427: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  2 00:16:16.463: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  2 00:16:26.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-44hxr ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  2 00:16:26.635: INFO: stderr: ""
Feb  2 00:16:26.635: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  2 00:16:26.635: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  2 00:16:36.621: INFO: Waiting for StatefulSet e2e-tests-statefulset-44hxr/ss2 to complete update
Feb  2 00:16:36.621: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  2 00:16:36.621: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  2 00:16:36.621: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  2 00:16:46.629: INFO: Waiting for StatefulSet e2e-tests-statefulset-44hxr/ss2 to complete update
Feb  2 00:16:46.629: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  2 00:16:56.630: INFO: Waiting for StatefulSet e2e-tests-statefulset-44hxr/ss2 to complete update
Feb  2 00:16:56.630: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb  2 00:17:06.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-44hxr ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  2 00:17:06.782: INFO: stderr: ""
Feb  2 00:17:06.783: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  2 00:17:06.783: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  2 00:17:16.825: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  2 00:17:26.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-44hxr ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  2 00:17:27.006: INFO: stderr: ""
Feb  2 00:17:27.006: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  2 00:17:27.006: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  2 00:17:36.991: INFO: Waiting for StatefulSet e2e-tests-statefulset-44hxr/ss2 to complete update
Feb  2 00:17:36.991: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  2 00:17:36.991: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  2 00:17:36.991: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  2 00:17:47.000: INFO: Waiting for StatefulSet e2e-tests-statefulset-44hxr/ss2 to complete update
Feb  2 00:17:47.000: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  2 00:17:47.000: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Feb  2 00:17:57.004: INFO: Waiting for StatefulSet e2e-tests-statefulset-44hxr/ss2 to complete update
Feb  2 00:17:57.004: INFO: Waiting for Pod e2e-tests-statefulset-44hxr/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  2 00:18:06.965: INFO: Deleting all statefulset in ns e2e-tests-statefulset-44hxr
Feb  2 00:18:06.968: INFO: Scaling statefulset ss2 to 0
Feb  2 00:18:26.986: INFO: Waiting for statefulset status.replicas updated to 0
Feb  2 00:18:26.988: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:18:27.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-44hxr" for this suite.
Feb  2 00:18:33.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:18:33.057: INFO: namespace: e2e-tests-statefulset-44hxr, resource: bindings, ignored listing per whitelist
Feb  2 00:18:33.087: INFO: namespace e2e-tests-statefulset-44hxr deletion completed in 6.0802987s

â€¢ [SLOW TEST:157.025 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:18:33.089: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb  2 00:18:35.155: INFO: Pod pod-hostip-13345397-2680-11e9-a68a-f677bb5aadde has hostIP: 192.168.65.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:18:35.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kxkz5" for this suite.
Feb  2 00:18:57.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:18:57.169: INFO: namespace: e2e-tests-pods-kxkz5, resource: bindings, ignored listing per whitelist
Feb  2 00:18:57.208: INFO: namespace e2e-tests-pods-kxkz5 deletion completed in 22.0848843s

â€¢ [SLOW TEST:24.154 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:18:57.208: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  2 00:18:57.261: INFO: Waiting up to 5m0s for pod "pod-2194b953-2680-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-djcqq" to be "success or failure"
Feb  2 00:18:57.264: INFO: Pod "pod-2194b953-2680-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.5862ms
Feb  2 00:18:59.267: INFO: Pod "pod-2194b953-2680-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0055708s
STEP: Saw pod success
Feb  2 00:18:59.267: INFO: Pod "pod-2194b953-2680-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:18:59.269: INFO: Trying to get logs from node docker-desktop pod pod-2194b953-2680-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:18:59.291: INFO: Waiting for pod pod-2194b953-2680-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:18:59.301: INFO: Pod pod-2194b953-2680-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:18:59.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-djcqq" for this suite.
Feb  2 00:19:05.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:19:05.389: INFO: namespace: e2e-tests-emptydir-djcqq, resource: bindings, ignored listing per whitelist
Feb  2 00:19:05.398: INFO: namespace e2e-tests-emptydir-djcqq deletion completed in 6.0861116s

â€¢ [SLOW TEST:8.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:19:05.398: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:19:05.449: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  2 00:19:05.457: INFO: Number of nodes with available pods: 0
Feb  2 00:19:05.457: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:19:06.430: INFO: Number of nodes with available pods: 0
Feb  2 00:19:06.430: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:19:07.435: INFO: Number of nodes with available pods: 1
Feb  2 00:19:07.435: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  2 00:19:07.454: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:08.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:09.464: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:10.465: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:11.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:12.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:13.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:14.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:15.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:16.461: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:17.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:18.462: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:19.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:20.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:21.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:22.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:23.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:24.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:25.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:26.464: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:27.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:28.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:29.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:30.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:31.462: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:32.462: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:33.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:34.463: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:35.462: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:36.426: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:37.428: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:38.428: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:39.426: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:40.428: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:41.430: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:41.430: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:42.431: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:42.431: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:43.428: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:43.428: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:44.429: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:44.430: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:45.429: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:45.430: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:46.429: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:46.429: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:47.428: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:47.428: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:48.429: INFO: Wrong image for pod: daemon-set-fxjmc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  2 00:19:48.430: INFO: Pod daemon-set-fxjmc is not available
Feb  2 00:19:49.428: INFO: Pod daemon-set-hwj2g is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  2 00:19:49.435: INFO: Number of nodes with available pods: 0
Feb  2 00:19:49.435: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:19:50.445: INFO: Number of nodes with available pods: 0
Feb  2 00:19:50.445: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:19:51.444: INFO: Number of nodes with available pods: 1
Feb  2 00:19:51.445: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-lw6sq, will wait for the garbage collector to delete the pods
Feb  2 00:19:51.516: INFO: Deleting DaemonSet.extensions daemon-set took: 7.5973ms
Feb  2 00:19:51.617: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.8653ms
Feb  2 00:19:59.320: INFO: Number of nodes with available pods: 0
Feb  2 00:19:59.320: INFO: Number of running nodes: 0, number of available pods: 0
Feb  2 00:19:59.322: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lw6sq/daemonsets","resourceVersion":"20436"},"items":null}

Feb  2 00:19:59.324: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lw6sq/pods","resourceVersion":"20436"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:19:59.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lw6sq" for this suite.
Feb  2 00:20:05.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:20:05.405: INFO: namespace: e2e-tests-daemonsets-lw6sq, resource: bindings, ignored listing per whitelist
Feb  2 00:20:05.412: INFO: namespace e2e-tests-daemonsets-lw6sq deletion completed in 6.080686s

â€¢ [SLOW TEST:60.083 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:20:05.414: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-4a3d9e54-2680-11e9-a68a-f677bb5aadde
STEP: Creating secret with name secret-projected-all-test-volume-4a3d9dca-2680-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  2 00:20:05.483: INFO: Waiting up to 5m0s for pod "projected-volume-4a3d9d52-2680-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-pm2gn" to be "success or failure"
Feb  2 00:20:05.491: INFO: Pod "projected-volume-4a3d9d52-2680-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 7.8428ms
Feb  2 00:20:07.461: INFO: Pod "projected-volume-4a3d9d52-2680-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0123085s
STEP: Saw pod success
Feb  2 00:20:07.461: INFO: Pod "projected-volume-4a3d9d52-2680-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:20:07.464: INFO: Trying to get logs from node docker-desktop pod projected-volume-4a3d9d52-2680-11e9-a68a-f677bb5aadde container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  2 00:20:07.484: INFO: Waiting for pod projected-volume-4a3d9d52-2680-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:20:07.489: INFO: Pod projected-volume-4a3d9d52-2680-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:20:07.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pm2gn" for this suite.
Feb  2 00:20:13.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:20:13.564: INFO: namespace: e2e-tests-projected-pm2gn, resource: bindings, ignored listing per whitelist
Feb  2 00:20:13.578: INFO: namespace e2e-tests-projected-pm2gn deletion completed in 6.0822845s

â€¢ [SLOW TEST:8.200 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:20:13.578: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  2 00:20:16.156: INFO: Successfully updated pod "annotationupdate4f1917e6-2680-11e9-a68a-f677bb5aadde"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:20:18.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z299w" for this suite.
Feb  2 00:20:40.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:20:40.176: INFO: namespace: e2e-tests-projected-z299w, resource: bindings, ignored listing per whitelist
Feb  2 00:20:40.219: INFO: namespace e2e-tests-projected-z299w deletion completed in 22.0776142s

â€¢ [SLOW TEST:26.675 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:20:40.219: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  2 00:20:40.266: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  2 00:20:40.270: INFO: Waiting for terminating namespaces to be deleted...
Feb  2 00:20:40.273: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Feb  2 00:20:40.277: INFO: compose-56897cc96b-gnrcd from docker started at 2019-02-01 15:57:21 +0000 UTC (1 container statuses recorded)
Feb  2 00:20:40.278: INFO: 	Container compose ready: true, restart count 0
Feb  2 00:20:40.278: INFO: kube-scheduler-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:20:40.278: INFO: compose-api-5fb5fd58d-fjvcj from docker started at 2019-02-01 15:57:21 +0000 UTC (1 container statuses recorded)
Feb  2 00:20:40.278: INFO: 	Container compose ready: true, restart count 0
Feb  2 00:20:40.278: INFO: kube-proxy-hzvvt from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  2 00:20:40.278: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  2 00:20:40.278: INFO: etcd-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:20:40.278: INFO: coredns-86c58d9df4-492hj from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  2 00:20:40.278: INFO: 	Container coredns ready: true, restart count 0
Feb  2 00:20:40.279: INFO: kube-apiserver-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:20:40.279: INFO: sonobuoy-systemd-logs-daemon-set-2081b0686f0449ba-4wdch from heptio-sonobuoy started at 2019-02-01 22:53:40 +0000 UTC (2 container statuses recorded)
Feb  2 00:20:40.279: INFO: 	Container sonobuoy-systemd-logs-config ready: false, restart count 14
Feb  2 00:20:40.279: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  2 00:20:40.279: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-01 22:53:35 +0000 UTC (1 container statuses recorded)
Feb  2 00:20:40.279: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  2 00:20:40.279: INFO: sonobuoy-e2e-job-bb494af789db4143 from heptio-sonobuoy started at 2019-02-01 22:53:40 +0000 UTC (2 container statuses recorded)
Feb  2 00:20:40.279: INFO: 	Container e2e ready: true, restart count 0
Feb  2 00:20:40.280: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  2 00:20:40.280: INFO: kube-controller-manager-docker-desktop from kube-system started at <nil> (0 container statuses recorded)
Feb  2 00:20:40.280: INFO: coredns-86c58d9df4-zxg7j from kube-system started at 2019-02-01 15:56:16 +0000 UTC (1 container statuses recorded)
Feb  2 00:20:40.280: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-60323dae-2680-11e9-a68a-f677bb5aadde 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-60323dae-2680-11e9-a68a-f677bb5aadde off the node docker-desktop
STEP: verifying the node doesn't have the label kubernetes.io/e2e-60323dae-2680-11e9-a68a-f677bb5aadde
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:20:44.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gn6lv" for this suite.
Feb  2 00:20:52.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:20:52.424: INFO: namespace: e2e-tests-sched-pred-gn6lv, resource: bindings, ignored listing per whitelist
Feb  2 00:20:52.428: INFO: namespace e2e-tests-sched-pred-gn6lv deletion completed in 8.0720697s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:12.209 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:20:52.428: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:20:52.484: INFO: Waiting up to 5m0s for pod "downwardapi-volume-664244d5-2680-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-p2q5q" to be "success or failure"
Feb  2 00:20:52.486: INFO: Pod "downwardapi-volume-664244d5-2680-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.8061ms
Feb  2 00:20:54.489: INFO: Pod "downwardapi-volume-664244d5-2680-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0048269s
STEP: Saw pod success
Feb  2 00:20:54.489: INFO: Pod "downwardapi-volume-664244d5-2680-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:20:54.493: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-664244d5-2680-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:20:54.508: INFO: Waiting for pod downwardapi-volume-664244d5-2680-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:20:54.517: INFO: Pod downwardapi-volume-664244d5-2680-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:20:54.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p2q5q" for this suite.
Feb  2 00:21:00.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:21:00.576: INFO: namespace: e2e-tests-downward-api-p2q5q, resource: bindings, ignored listing per whitelist
Feb  2 00:21:00.608: INFO: namespace e2e-tests-downward-api-p2q5q deletion completed in 6.0890388s

â€¢ [SLOW TEST:8.181 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:21:00.615: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:21:00.668: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6b23078d-2680-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-vb96x" to be "success or failure"
Feb  2 00:21:00.673: INFO: Pod "downwardapi-volume-6b23078d-2680-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.7786ms
Feb  2 00:21:02.677: INFO: Pod "downwardapi-volume-6b23078d-2680-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0085469s
STEP: Saw pod success
Feb  2 00:21:02.677: INFO: Pod "downwardapi-volume-6b23078d-2680-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:21:02.679: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-6b23078d-2680-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:21:02.694: INFO: Waiting for pod downwardapi-volume-6b23078d-2680-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:21:02.697: INFO: Pod downwardapi-volume-6b23078d-2680-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:21:02.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vb96x" for this suite.
Feb  2 00:21:08.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:21:08.743: INFO: namespace: e2e-tests-projected-vb96x, resource: bindings, ignored listing per whitelist
Feb  2 00:21:08.745: INFO: namespace e2e-tests-projected-vb96x deletion completed in 6.080122s

â€¢ [SLOW TEST:8.165 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:21:08.745: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-f6gq5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  2 00:21:08.814: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  2 00:21:30.871: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.0.185:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-f6gq5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  2 00:21:30.871: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
Feb  2 00:21:30.974: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:21:30.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-f6gq5" for this suite.
Feb  2 00:21:52.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:21:52.998: INFO: namespace: e2e-tests-pod-network-test-f6gq5, resource: bindings, ignored listing per whitelist
Feb  2 00:21:53.025: INFO: namespace e2e-tests-pod-network-test-f6gq5 deletion completed in 22.0819946s

â€¢ [SLOW TEST:44.315 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:21:53.025: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:21:53.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a602aaf-2680-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-j6lxk" to be "success or failure"
Feb  2 00:21:53.091: INFO: Pod "downwardapi-volume-8a602aaf-2680-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 9.2875ms
Feb  2 00:21:55.094: INFO: Pod "downwardapi-volume-8a602aaf-2680-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0127045s
STEP: Saw pod success
Feb  2 00:21:55.094: INFO: Pod "downwardapi-volume-8a602aaf-2680-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:21:55.097: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-8a602aaf-2680-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:21:55.119: INFO: Waiting for pod downwardapi-volume-8a602aaf-2680-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:21:55.124: INFO: Pod downwardapi-volume-8a602aaf-2680-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:21:55.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j6lxk" for this suite.
Feb  2 00:22:01.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:22:01.202: INFO: namespace: e2e-tests-downward-api-j6lxk, resource: bindings, ignored listing per whitelist
Feb  2 00:22:01.215: INFO: namespace e2e-tests-downward-api-j6lxk deletion completed in 6.0875222s

â€¢ [SLOW TEST:8.189 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:22:01.216: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-r72x2
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-r72x2
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-r72x2
Feb  2 00:22:01.276: INFO: Found 0 stateful pods, waiting for 1
Feb  2 00:22:11.245: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  2 00:22:11.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-r72x2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  2 00:22:11.399: INFO: stderr: ""
Feb  2 00:22:11.399: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  2 00:22:11.399: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  2 00:22:11.402: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  2 00:22:21.407: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  2 00:22:21.407: INFO: Waiting for statefulset status.replicas updated to 0
Feb  2 00:22:21.427: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:21.427: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:21.427: INFO: ss-1                  Pending         []
Feb  2 00:22:21.428: INFO: 
Feb  2 00:22:21.428: INFO: StatefulSet ss has not reached scale 3, at 2
Feb  2 00:22:22.434: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.9869738s
Feb  2 00:22:23.438: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.9814283s
Feb  2 00:22:24.443: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.9769317s
Feb  2 00:22:25.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972593s
Feb  2 00:22:26.452: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.9678592s
Feb  2 00:22:27.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9632926s
Feb  2 00:22:28.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9587259s
Feb  2 00:22:29.467: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.9530019s
Feb  2 00:22:30.472: INFO: Verifying statefulset ss doesn't scale past 3 for another 947.9984ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-r72x2
Feb  2 00:22:31.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-r72x2 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  2 00:22:31.643: INFO: stderr: ""
Feb  2 00:22:31.643: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  2 00:22:31.643: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  2 00:22:31.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-r72x2 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  2 00:22:31.813: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  2 00:22:31.814: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  2 00:22:31.814: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  2 00:22:31.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-r72x2 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  2 00:22:31.974: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  2 00:22:31.974: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  2 00:22:31.974: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  2 00:22:31.978: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  2 00:22:31.978: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  2 00:22:31.978: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  2 00:22:31.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-r72x2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  2 00:22:32.134: INFO: stderr: ""
Feb  2 00:22:32.135: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  2 00:22:32.135: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  2 00:22:32.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-r72x2 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  2 00:22:32.297: INFO: stderr: ""
Feb  2 00:22:32.297: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  2 00:22:32.297: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  2 00:22:32.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 exec --namespace=e2e-tests-statefulset-r72x2 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  2 00:22:32.462: INFO: stderr: ""
Feb  2 00:22:32.462: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  2 00:22:32.462: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  2 00:22:32.462: INFO: Waiting for statefulset status.replicas updated to 0
Feb  2 00:22:32.465: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb  2 00:22:42.438: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  2 00:22:42.438: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  2 00:22:42.438: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  2 00:22:42.450: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:42.450: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:42.450: INFO: ss-1  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:42.450: INFO: ss-2  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:42.450: INFO: 
Feb  2 00:22:42.450: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  2 00:22:43.455: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:43.455: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:43.455: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:43.455: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:43.455: INFO: 
Feb  2 00:22:43.455: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  2 00:22:44.462: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:44.462: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:44.462: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:44.462: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:44.462: INFO: 
Feb  2 00:22:44.462: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  2 00:22:45.468: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:45.468: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:45.468: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:45.468: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:45.468: INFO: 
Feb  2 00:22:45.468: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  2 00:22:46.473: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:46.473: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:46.473: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:46.473: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:46.473: INFO: 
Feb  2 00:22:46.473: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  2 00:22:47.478: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:47.478: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:47.478: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:47.478: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:47.478: INFO: 
Feb  2 00:22:47.478: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  2 00:22:48.485: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  2 00:22:48.485: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:01 +0000 UTC  }]
Feb  2 00:22:48.485: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:48.485: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:22:21 +0000 UTC  }]
Feb  2 00:22:48.485: INFO: 
Feb  2 00:22:48.485: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  2 00:22:49.490: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.9588951s
Feb  2 00:22:50.495: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.9541971s
Feb  2 00:22:51.499: INFO: Verifying statefulset ss doesn't scale past 0 for another 949.6213ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-r72x2
Feb  2 00:22:52.504: INFO: Scaling statefulset ss to 0
Feb  2 00:22:52.512: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  2 00:22:52.514: INFO: Deleting all statefulset in ns e2e-tests-statefulset-r72x2
Feb  2 00:22:52.517: INFO: Scaling statefulset ss to 0
Feb  2 00:22:52.523: INFO: Waiting for statefulset status.replicas updated to 0
Feb  2 00:22:52.525: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:22:52.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-r72x2" for this suite.
Feb  2 00:22:58.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:22:58.594: INFO: namespace: e2e-tests-statefulset-r72x2, resource: bindings, ignored listing per whitelist
Feb  2 00:22:58.620: INFO: namespace e2e-tests-statefulset-r72x2 deletion completed in 6.0839554s

â€¢ [SLOW TEST:57.473 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:22:58.620: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  2 00:23:03.208: INFO: Successfully updated pod "labelsupdateb179f176-2680-11e9-a68a-f677bb5aadde"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:23:05.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bvpwd" for this suite.
Feb  2 00:23:27.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:23:27.232: INFO: namespace: e2e-tests-downward-api-bvpwd, resource: bindings, ignored listing per whitelist
Feb  2 00:23:27.279: INFO: namespace e2e-tests-downward-api-bvpwd deletion completed in 22.0822215s

â€¢ [SLOW TEST:28.693 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:23:27.282: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:23:27.337: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-qqcf2" to be "success or failure"
Feb  2 00:23:27.344: INFO: Pod "downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 7.4369ms
Feb  2 00:23:29.351: INFO: Pod "downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01402s
Feb  2 00:23:31.355: INFO: Pod "downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0178805s
STEP: Saw pod success
Feb  2 00:23:31.355: INFO: Pod "downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:23:31.357: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:23:31.376: INFO: Waiting for pod downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:23:31.380: INFO: Pod downwardapi-volume-c28eb83d-2680-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:23:31.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qqcf2" for this suite.
Feb  2 00:23:37.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:23:37.382: INFO: namespace: e2e-tests-downward-api-qqcf2, resource: bindings, ignored listing per whitelist
Feb  2 00:23:37.423: INFO: namespace e2e-tests-downward-api-qqcf2 deletion completed in 6.0752284s

â€¢ [SLOW TEST:10.176 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:23:37.424: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c89a0a17-2680-11e9-a68a-f677bb5aadde
STEP: Creating configMap with name cm-test-opt-upd-c89a0abf-2680-11e9-a68a-f677bb5aadde
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c89a0a17-2680-11e9-a68a-f677bb5aadde
STEP: Updating configmap cm-test-opt-upd-c89a0abf-2680-11e9-a68a-f677bb5aadde
STEP: Creating configMap with name cm-test-opt-create-c89a0b4c-2680-11e9-a68a-f677bb5aadde
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:25:11.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rftzm" for this suite.
Feb  2 00:25:34.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:25:34.054: INFO: namespace: e2e-tests-projected-rftzm, resource: bindings, ignored listing per whitelist
Feb  2 00:25:34.078: INFO: namespace e2e-tests-projected-rftzm deletion completed in 22.0844913s

â€¢ [SLOW TEST:116.759 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:25:34.079: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:25:34.128: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:25:38.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tgg62" for this suite.
Feb  2 00:26:20.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:26:20.256: INFO: namespace: e2e-tests-pods-tgg62, resource: bindings, ignored listing per whitelist
Feb  2 00:26:20.266: INFO: namespace e2e-tests-pods-tgg62 deletion completed in 42.0958683s

â€¢ [SLOW TEST:46.257 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:26:20.268: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-29abb5a0-2681-11e9-a68a-f677bb5aadde
STEP: Creating secret with name s-test-opt-upd-29abb735-2681-11e9-a68a-f677bb5aadde
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-29abb5a0-2681-11e9-a68a-f677bb5aadde
STEP: Updating secret s-test-opt-upd-29abb735-2681-11e9-a68a-f677bb5aadde
STEP: Creating secret with name s-test-opt-create-29abb7e2-2681-11e9-a68a-f677bb5aadde
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:27:36.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t7zlh" for this suite.
Feb  2 00:27:58.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:27:58.810: INFO: namespace: e2e-tests-secrets-t7zlh, resource: bindings, ignored listing per whitelist
Feb  2 00:27:58.812: INFO: namespace e2e-tests-secrets-t7zlh deletion completed in 22.0749491s

â€¢ [SLOW TEST:98.649 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:27:58.813: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  2 00:27:58.862: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:28:01.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hs6d6" for this suite.
Feb  2 00:28:07.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:28:07.825: INFO: namespace: e2e-tests-init-container-hs6d6, resource: bindings, ignored listing per whitelist
Feb  2 00:28:07.829: INFO: namespace e2e-tests-init-container-hs6d6 deletion completed in 6.084418s

â€¢ [SLOW TEST:9.052 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:28:07.829: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:28:07.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-8x8rd" for this suite.
Feb  2 00:28:13.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:28:13.949: INFO: namespace: e2e-tests-services-8x8rd, resource: bindings, ignored listing per whitelist
Feb  2 00:28:13.954: INFO: namespace e2e-tests-services-8x8rd deletion completed in 6.079606s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:6.125 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:28:13.955: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  2 00:28:14.010: INFO: Waiting up to 5m0s for pod "downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-7mskm" to be "success or failure"
Feb  2 00:28:14.013: INFO: Pod "downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.93ms
Feb  2 00:28:16.017: INFO: Pod "downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0065216s
Feb  2 00:28:18.025: INFO: Pod "downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014992s
STEP: Saw pod success
Feb  2 00:28:18.026: INFO: Pod "downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:28:18.028: INFO: Trying to get logs from node docker-desktop pod downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  2 00:28:18.050: INFO: Waiting for pod downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:28:18.055: INFO: Pod downward-api-6d6dbd67-2681-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:28:18.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7mskm" for this suite.
Feb  2 00:28:24.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:28:24.098: INFO: namespace: e2e-tests-downward-api-7mskm, resource: bindings, ignored listing per whitelist
Feb  2 00:28:24.133: INFO: namespace e2e-tests-downward-api-7mskm deletion completed in 6.0753352s

â€¢ [SLOW TEST:10.178 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:28:24.133: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-krjg
STEP: Creating a pod to test atomic-volume-subpath
Feb  2 00:28:24.191: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-krjg" in namespace "e2e-tests-subpath-wc2lj" to be "success or failure"
Feb  2 00:28:24.197: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0143ms
Feb  2 00:28:26.203: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0118825s
Feb  2 00:28:28.207: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 4.0158831s
Feb  2 00:28:30.211: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 6.0194887s
Feb  2 00:28:32.216: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 8.0246551s
Feb  2 00:28:34.222: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 10.0301763s
Feb  2 00:28:36.193: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 12.0364095s
Feb  2 00:28:38.198: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 14.0411524s
Feb  2 00:28:40.202: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 16.0451625s
Feb  2 00:28:42.208: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 18.0515082s
Feb  2 00:28:44.212: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 20.0557177s
Feb  2 00:28:46.220: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Running", Reason="", readiness=false. Elapsed: 22.0630173s
Feb  2 00:28:48.224: INFO: Pod "pod-subpath-test-secret-krjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0671204s
STEP: Saw pod success
Feb  2 00:28:48.224: INFO: Pod "pod-subpath-test-secret-krjg" satisfied condition "success or failure"
Feb  2 00:28:48.226: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-secret-krjg container test-container-subpath-secret-krjg: <nil>
STEP: delete the pod
Feb  2 00:28:48.245: INFO: Waiting for pod pod-subpath-test-secret-krjg to disappear
Feb  2 00:28:48.250: INFO: Pod pod-subpath-test-secret-krjg no longer exists
STEP: Deleting pod pod-subpath-test-secret-krjg
Feb  2 00:28:48.250: INFO: Deleting pod "pod-subpath-test-secret-krjg" in namespace "e2e-tests-subpath-wc2lj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:28:48.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wc2lj" for this suite.
Feb  2 00:28:54.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:28:54.302: INFO: namespace: e2e-tests-subpath-wc2lj, resource: bindings, ignored listing per whitelist
Feb  2 00:28:54.340: INFO: namespace e2e-tests-subpath-wc2lj deletion completed in 6.0799071s

â€¢ [SLOW TEST:30.242 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:28:54.341: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  2 00:28:54.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ckpbh'
Feb  2 00:28:54.568: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  2 00:28:54.568: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb  2 00:28:56.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-ckpbh'
Feb  2 00:28:56.670: INFO: stderr: ""
Feb  2 00:28:56.670: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:28:56.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ckpbh" for this suite.
Feb  2 00:29:18.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:29:18.703: INFO: namespace: e2e-tests-kubectl-ckpbh, resource: bindings, ignored listing per whitelist
Feb  2 00:29:18.719: INFO: namespace e2e-tests-kubectl-ckpbh deletion completed in 22.0811732s

â€¢ [SLOW TEST:24.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:29:18.725: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:29:18.791: INFO: Waiting up to 5m0s for pod "downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-v6d54" to be "success or failure"
Feb  2 00:29:18.793: INFO: Pod "downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.9921ms
Feb  2 00:29:20.800: INFO: Pod "downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0089544s
Feb  2 00:29:22.806: INFO: Pod "downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0151123s
STEP: Saw pod success
Feb  2 00:29:22.807: INFO: Pod "downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:29:22.810: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:29:22.834: INFO: Waiting for pod downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:29:22.836: INFO: Pod downwardapi-volume-940a8314-2681-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:29:22.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-v6d54" for this suite.
Feb  2 00:29:28.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:29:28.910: INFO: namespace: e2e-tests-downward-api-v6d54, resource: bindings, ignored listing per whitelist
Feb  2 00:29:28.921: INFO: namespace e2e-tests-downward-api-v6d54 deletion completed in 6.0826557s

â€¢ [SLOW TEST:10.197 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:29:28.922: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb  2 00:29:28.976: INFO: Waiting up to 5m0s for pod "var-expansion-9a1cac67-2681-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-var-expansion-lf7rb" to be "success or failure"
Feb  2 00:29:28.980: INFO: Pod "var-expansion-9a1cac67-2681-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.9039ms
Feb  2 00:29:30.983: INFO: Pod "var-expansion-9a1cac67-2681-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0064419s
STEP: Saw pod success
Feb  2 00:29:30.983: INFO: Pod "var-expansion-9a1cac67-2681-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:29:30.986: INFO: Trying to get logs from node docker-desktop pod var-expansion-9a1cac67-2681-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  2 00:29:31.010: INFO: Waiting for pod var-expansion-9a1cac67-2681-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:29:31.013: INFO: Pod var-expansion-9a1cac67-2681-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:29:31.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-lf7rb" for this suite.
Feb  2 00:29:36.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:29:37.041: INFO: namespace: e2e-tests-var-expansion-lf7rb, resource: bindings, ignored listing per whitelist
Feb  2 00:29:37.058: INFO: namespace e2e-tests-var-expansion-lf7rb deletion completed in 6.0765362s

â€¢ [SLOW TEST:8.171 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:29:37.060: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:29:37.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7k55h" for this suite.
Feb  2 00:29:59.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:29:59.175: INFO: namespace: e2e-tests-pods-7k55h, resource: bindings, ignored listing per whitelist
Feb  2 00:29:59.208: INFO: namespace e2e-tests-pods-7k55h deletion completed in 22.0804647s

â€¢ [SLOW TEST:22.148 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:29:59.208: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-x79sv/configmap-test-ac299f3c-2681-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:29:59.264: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-x79sv" to be "success or failure"
Feb  2 00:29:59.266: INFO: Pod "pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1652ms
Feb  2 00:30:01.272: INFO: Pod "pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007838s
Feb  2 00:30:03.277: INFO: Pod "pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0136903s
STEP: Saw pod success
Feb  2 00:30:03.277: INFO: Pod "pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:30:03.280: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde container env-test: <nil>
STEP: delete the pod
Feb  2 00:30:03.301: INFO: Waiting for pod pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:30:03.304: INFO: Pod pod-configmaps-ac2a283d-2681-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:30:03.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x79sv" for this suite.
Feb  2 00:30:09.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:30:09.321: INFO: namespace: e2e-tests-configmap-x79sv, resource: bindings, ignored listing per whitelist
Feb  2 00:30:09.358: INFO: namespace e2e-tests-configmap-x79sv deletion completed in 6.0862243s

â€¢ [SLOW TEST:10.185 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:30:09.358: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-6g2g
STEP: Creating a pod to test atomic-volume-subpath
Feb  2 00:30:09.418: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6g2g" in namespace "e2e-tests-subpath-vhm2p" to be "success or failure"
Feb  2 00:30:09.420: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1382ms
Feb  2 00:30:11.425: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007202s
Feb  2 00:30:13.429: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 4.0117509s
Feb  2 00:30:15.435: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 6.0170598s
Feb  2 00:30:17.440: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 8.022452s
Feb  2 00:30:19.445: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 10.0267933s
Feb  2 00:30:21.449: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 12.0309765s
Feb  2 00:30:23.454: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 14.0363157s
Feb  2 00:30:25.459: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 16.0417746s
Feb  2 00:30:27.465: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 18.0472137s
Feb  2 00:30:29.469: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 20.0515248s
Feb  2 00:30:31.477: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Running", Reason="", readiness=false. Elapsed: 22.0589387s
Feb  2 00:30:33.480: INFO: Pod "pod-subpath-test-projected-6g2g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0625659s
STEP: Saw pod success
Feb  2 00:30:33.480: INFO: Pod "pod-subpath-test-projected-6g2g" satisfied condition "success or failure"
Feb  2 00:30:33.482: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-projected-6g2g container test-container-subpath-projected-6g2g: <nil>
STEP: delete the pod
Feb  2 00:30:33.500: INFO: Waiting for pod pod-subpath-test-projected-6g2g to disappear
Feb  2 00:30:33.511: INFO: Pod pod-subpath-test-projected-6g2g no longer exists
STEP: Deleting pod pod-subpath-test-projected-6g2g
Feb  2 00:30:33.511: INFO: Deleting pod "pod-subpath-test-projected-6g2g" in namespace "e2e-tests-subpath-vhm2p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:30:33.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vhm2p" for this suite.
Feb  2 00:30:39.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:30:39.556: INFO: namespace: e2e-tests-subpath-vhm2p, resource: bindings, ignored listing per whitelist
Feb  2 00:30:39.567: INFO: namespace e2e-tests-subpath-vhm2p deletion completed in 6.0811157s

â€¢ [SLOW TEST:30.243 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:30:39.572: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:31:39.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c6vrw" for this suite.
Feb  2 00:32:01.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:32:01.650: INFO: namespace: e2e-tests-container-probe-c6vrw, resource: bindings, ignored listing per whitelist
Feb  2 00:32:01.651: INFO: namespace e2e-tests-container-probe-c6vrw deletion completed in 22.0801913s

â€¢ [SLOW TEST:82.149 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:32:01.655: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:32:01.702: INFO: Creating deployment "nginx-deployment"
Feb  2 00:32:01.706: INFO: Waiting for observed generation 1
Feb  2 00:32:03.710: INFO: Waiting for all required pods to come up
Feb  2 00:32:03.726: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  2 00:32:09.707: INFO: Waiting for deployment "nginx-deployment" to complete
Feb  2 00:32:09.712: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb  2 00:32:09.718: INFO: Updating deployment nginx-deployment
Feb  2 00:32:09.719: INFO: Waiting for observed generation 2
Feb  2 00:32:11.728: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  2 00:32:11.731: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  2 00:32:11.733: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  2 00:32:11.742: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  2 00:32:11.742: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  2 00:32:11.745: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  2 00:32:11.750: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb  2 00:32:11.751: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb  2 00:32:11.759: INFO: Updating deployment nginx-deployment
Feb  2 00:32:11.759: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb  2 00:32:11.769: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  2 00:32:11.790: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  2 00:32:11.828: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-4sgst,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4sgst/deployments/nginx-deployment,UID:f525bd4c-2681-11e9-b4dc-025000000001,ResourceVersion:22371,Generation:3,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-02-02 00:32:09 +0000 UTC 2019-02-02 00:32:01 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-02-02 00:32:11 +0000 UTC 2019-02-02 00:32:11 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb  2 00:32:11.871: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-4sgst,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4sgst/replicasets/nginx-deployment-65bbdb5f8,UID:f9ecdbca-2681-11e9-b4dc-025000000001,ResourceVersion:22367,Generation:3,CreationTimestamp:2019-02-02 00:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f525bd4c-2681-11e9-b4dc-025000000001 0xc001d08067 0xc001d08068}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  2 00:32:11.871: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb  2 00:32:11.871: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-4sgst,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4sgst/replicasets/nginx-deployment-555b55d965,UID:f5269bfc-2681-11e9-b4dc-025000000001,ResourceVersion:22365,Generation:3,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f525bd4c-2681-11e9-b4dc-025000000001 0xc0019d3f97 0xc0019d3f98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb  2 00:32:11.882: INFO: Pod "nginx-deployment-555b55d965-2ddlx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2ddlx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-2ddlx,UID:f52b45bc-2681-11e9-b4dc-025000000001,ResourceVersion:22287,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a96447 0xc001a96448}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a964c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a964e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.210,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://d9566b3601f1e9424a58a420c4e14ad8db30ad258c7c987a8236c371c6ab6159}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.890: INFO: Pod "nginx-deployment-555b55d965-2gvjd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2gvjd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-2gvjd,UID:f5290781-2681-11e9-b4dc-025000000001,ResourceVersion:22300,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a965a0 0xc001a965a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a96610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a96630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.208,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://9cf55f0175d67882a6fc25f251806f34658c34af37d9295459a54287b64d382f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.891: INFO: Pod "nginx-deployment-555b55d965-2vlxb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2vlxb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-2vlxb,UID:fb28299b-2681-11e9-b4dc-025000000001,ResourceVersion:22395,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a96760 0xc001a96761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a967d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a967f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-02-02 00:32:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.891: INFO: Pod "nginx-deployment-555b55d965-5bzgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5bzgl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-5bzgl,UID:fb2cbc4c-2681-11e9-b4dc-025000000001,ResourceVersion:22410,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a96917 0xc001a96918}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a96c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a96c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.892: INFO: Pod "nginx-deployment-555b55d965-6dvxg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6dvxg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-6dvxg,UID:f52f2d70-2681-11e9-b4dc-025000000001,ResourceVersion:22270,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a96ca0 0xc001a96ca1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a96dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a96df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.215,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://7cb21200268617f192f982bbe7b50559fb5e55d0485441bdafa4c1b8d24e2075}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.892: INFO: Pod "nginx-deployment-555b55d965-88hjk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-88hjk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-88hjk,UID:f52edef1-2681-11e9-b4dc-025000000001,ResourceVersion:22292,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a96eb0 0xc001a96eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a97060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a97080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.211,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://9d8ec87c830c83aa87fcc37e6bf6ae3d54e0b9d435344940851f3daadfc18c2b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.892: INFO: Pod "nginx-deployment-555b55d965-b57fl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-b57fl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-b57fl,UID:f52b524d-2681-11e9-b4dc-025000000001,ResourceVersion:22276,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a97150 0xc001a97151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a97210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a97230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.214,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://7c94b976464c2d2d6dd57c3bf9e53993eb90fdfb92d862ceea5041138e1a3cfa}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.893: INFO: Pod "nginx-deployment-555b55d965-dggkb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dggkb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-dggkb,UID:fb31f010-2681-11e9-b4dc-025000000001,ResourceVersion:22403,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a973c0 0xc001a973c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a97420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a97440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.895: INFO: Pod "nginx-deployment-555b55d965-dmhpq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dmhpq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-dmhpq,UID:fb2a0d81-2681-11e9-b4dc-025000000001,ResourceVersion:22383,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a974a7 0xc001a974a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a97520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a97540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.895: INFO: Pod "nginx-deployment-555b55d965-dzqm4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dzqm4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-dzqm4,UID:fb31a1b1-2681-11e9-b4dc-025000000001,ResourceVersion:22398,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a975b0 0xc001a975b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a97610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a97630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.922: INFO: Pod "nginx-deployment-555b55d965-j4vtb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j4vtb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-j4vtb,UID:f528f956-2681-11e9-b4dc-025000000001,ResourceVersion:22282,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a97687 0xc001a97688}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a97700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a97720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.207,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://7524a190fe824c2fb7d1276fd1757f460b5b86c2a47bea4719c4442b37772bd2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.923: INFO: Pod "nginx-deployment-555b55d965-lmp22" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lmp22,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-lmp22,UID:f52adcd7-2681-11e9-b4dc-025000000001,ResourceVersion:22260,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a977e0 0xc001a977e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a97860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a97880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.209,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8b0612b9a923b5fca3ebcfea681015e0dabe67aa9dfd27d051371cc6b7aa6a57}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.923: INFO: Pod "nginx-deployment-555b55d965-q9k7f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q9k7f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-q9k7f,UID:f52b65d3-2681-11e9-b4dc-025000000001,ResourceVersion:22296,Generation:0,CreationTimestamp:2019-02-02 00:32:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc001a97940 0xc001a97941}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a979b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e64000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:01 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.213,StartTime:2019-02-02 00:32:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:32:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1495853f05066bc8047f1a9d2a461fc9c0965843f7475e05d7874f6df7d433f7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.923: INFO: Pod "nginx-deployment-555b55d965-r2hsb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r2hsb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-r2hsb,UID:fb30db71-2681-11e9-b4dc-025000000001,ResourceVersion:22394,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc000e641f0 0xc000e641f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e64250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e64270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.925: INFO: Pod "nginx-deployment-555b55d965-r7fdg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r7fdg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-r7fdg,UID:fb2d4367-2681-11e9-b4dc-025000000001,ResourceVersion:22401,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc000e642c7 0xc000e642c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e64500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e64520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.925: INFO: Pod "nginx-deployment-555b55d965-rl78h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rl78h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-rl78h,UID:fb2a1de4-2681-11e9-b4dc-025000000001,ResourceVersion:22382,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc000e64590 0xc000e64591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e646e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e64700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.925: INFO: Pod "nginx-deployment-555b55d965-sgvp7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sgvp7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-sgvp7,UID:fb333360-2681-11e9-b4dc-025000000001,ResourceVersion:22407,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc000e64770 0xc000e64771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e64810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e64970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.925: INFO: Pod "nginx-deployment-555b55d965-vtwgq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vtwgq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-vtwgq,UID:fb32c4e9-2681-11e9-b4dc-025000000001,ResourceVersion:22409,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc000e64a37 0xc000e64a38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e64da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e64dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.925: INFO: Pod "nginx-deployment-555b55d965-xg6lj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xg6lj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-xg6lj,UID:fb2d0eaa-2681-11e9-b4dc-025000000001,ResourceVersion:22411,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc000e64e17 0xc000e64e18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e64f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e64fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.926: INFO: Pod "nginx-deployment-555b55d965-zwfzh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zwfzh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-555b55d965-zwfzh,UID:fb2c1690-2681-11e9-b4dc-025000000001,ResourceVersion:22405,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 f5269bfc-2681-11e9-b4dc-025000000001 0xc000e65040 0xc000e65041}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e650b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e650d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.926: INFO: Pod "nginx-deployment-65bbdb5f8-54v8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-54v8g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-54v8g,UID:fb2a2a1e-2681-11e9-b4dc-025000000001,ResourceVersion:22397,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e65210 0xc000e65211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e65320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e65340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.926: INFO: Pod "nginx-deployment-65bbdb5f8-6ftv7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6ftv7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-6ftv7,UID:fb28fa60-2681-11e9-b4dc-025000000001,ResourceVersion:22375,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e653b0 0xc000e653b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e65470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e65490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.926: INFO: Pod "nginx-deployment-65bbdb5f8-87t7r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-87t7r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-87t7r,UID:f9ed8378-2681-11e9-b4dc-025000000001,ResourceVersion:22320,Generation:0,CreationTimestamp:2019-02-02 00:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e65500 0xc000e65501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e656d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e65760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-02-02 00:32:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.926: INFO: Pod "nginx-deployment-65bbdb5f8-8h5rz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8h5rz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-8h5rz,UID:fb2ca876-2681-11e9-b4dc-025000000001,ResourceVersion:22404,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e65820 0xc000e65821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e658a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e658c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.927: INFO: Pod "nginx-deployment-65bbdb5f8-hzc8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hzc8g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-hzc8g,UID:fb2a1f47-2681-11e9-b4dc-025000000001,ResourceVersion:22393,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e65930 0xc000e65931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e65b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e65b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.927: INFO: Pod "nginx-deployment-65bbdb5f8-k5czh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-k5czh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-k5czh,UID:f9f7befb-2681-11e9-b4dc-025000000001,ResourceVersion:22352,Generation:0,CreationTimestamp:2019-02-02 00:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e65c00 0xc000e65c01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e65c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e65ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-02-02 00:32:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.928: INFO: Pod "nginx-deployment-65bbdb5f8-ld5wr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ld5wr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-ld5wr,UID:fb2c321b-2681-11e9-b4dc-025000000001,ResourceVersion:22408,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e65da0 0xc000e65da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e65ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e65ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.928: INFO: Pod "nginx-deployment-65bbdb5f8-ntpr8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ntpr8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-ntpr8,UID:f9fae60c-2681-11e9-b4dc-025000000001,ResourceVersion:22358,Generation:0,CreationTimestamp:2019-02-02 00:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc000e65f90 0xc000e65f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00108a050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00108a070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-02-02 00:32:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.942: INFO: Pod "nginx-deployment-65bbdb5f8-pgmf5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pgmf5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-pgmf5,UID:fb316236-2681-11e9-b4dc-025000000001,ResourceVersion:22399,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc00108a510 0xc00108a511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00108a580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00108a5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.942: INFO: Pod "nginx-deployment-65bbdb5f8-tdzs6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tdzs6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-tdzs6,UID:f9ee3479-2681-11e9-b4dc-025000000001,ResourceVersion:22337,Generation:0,CreationTimestamp:2019-02-02 00:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc00108a627 0xc00108a628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00108a720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00108a740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-02-02 00:32:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.942: INFO: Pod "nginx-deployment-65bbdb5f8-vqw67" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vqw67,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-vqw67,UID:f9ee4896-2681-11e9-b4dc-025000000001,ResourceVersion:22333,Generation:0,CreationTimestamp:2019-02-02 00:32:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc00108a9a0 0xc00108a9a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00108aa20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00108aa40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:09 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2019-02-02 00:32:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.942: INFO: Pod "nginx-deployment-65bbdb5f8-wsbvl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wsbvl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-wsbvl,UID:fb2e74d1-2681-11e9-b4dc-025000000001,ResourceVersion:22400,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc00108ad10 0xc00108ad11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00108ae70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00108ae90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  2 00:32:11.943: INFO: Pod "nginx-deployment-65bbdb5f8-zw8qh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zw8qh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-4sgst,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4sgst/pods/nginx-deployment-65bbdb5f8-zw8qh,UID:fb2c0433-2681-11e9-b4dc-025000000001,ResourceVersion:22406,Generation:0,CreationTimestamp:2019-02-02 00:32:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f9ecdbca-2681-11e9-b4dc-025000000001 0xc00108af00 0xc00108af01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-64hn5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-64hn5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-64hn5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00108aff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00108b0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:32:11 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:32:11.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4sgst" for this suite.
Feb  2 00:32:20.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:32:20.185: INFO: namespace: e2e-tests-deployment-4sgst, resource: bindings, ignored listing per whitelist
Feb  2 00:32:20.230: INFO: namespace e2e-tests-deployment-4sgst deletion completed in 8.2662193s

â€¢ [SLOW TEST:18.611 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:32:20.234: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:32:40.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-pnqtx" for this suite.
Feb  2 00:33:30.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:33:30.486: INFO: namespace: e2e-tests-kubelet-test-pnqtx, resource: bindings, ignored listing per whitelist
Feb  2 00:33:30.528: INFO: namespace e2e-tests-kubelet-test-pnqtx deletion completed in 50.0978302s

â€¢ [SLOW TEST:70.364 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:33:30.529: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2a205213-2682-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:33:30.595: INFO: Waiting up to 5m0s for pod "pod-secrets-2a20ca31-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-556xn" to be "success or failure"
Feb  2 00:33:30.597: INFO: Pod "pod-secrets-2a20ca31-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.2155ms
Feb  2 00:33:32.600: INFO: Pod "pod-secrets-2a20ca31-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0049438s
STEP: Saw pod success
Feb  2 00:33:32.600: INFO: Pod "pod-secrets-2a20ca31-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:33:32.602: INFO: Trying to get logs from node docker-desktop pod pod-secrets-2a20ca31-2682-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  2 00:33:32.623: INFO: Waiting for pod pod-secrets-2a20ca31-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:33:32.625: INFO: Pod pod-secrets-2a20ca31-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:33:32.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-556xn" for this suite.
Feb  2 00:33:38.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:33:38.635: INFO: namespace: e2e-tests-secrets-556xn, resource: bindings, ignored listing per whitelist
Feb  2 00:33:38.675: INFO: namespace e2e-tests-secrets-556xn deletion completed in 6.0771723s

â€¢ [SLOW TEST:8.180 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:33:38.675: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  2 00:33:41.255: INFO: Successfully updated pod "pod-update-2ef96abb-2682-11e9-a68a-f677bb5aadde"
STEP: verifying the updated pod is in kubernetes
Feb  2 00:33:41.262: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:33:41.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f78bh" for this suite.
Feb  2 00:34:03.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:34:03.290: INFO: namespace: e2e-tests-pods-f78bh, resource: bindings, ignored listing per whitelist
Feb  2 00:34:03.362: INFO: namespace e2e-tests-pods-f78bh deletion completed in 22.0975325s

â€¢ [SLOW TEST:24.687 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:34:03.363: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3db08c36-2682-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:34:03.417: INFO: Waiting up to 5m0s for pod "pod-configmaps-3db0fa57-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-rcf62" to be "success or failure"
Feb  2 00:34:03.419: INFO: Pod "pod-configmaps-3db0fa57-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1053ms
Feb  2 00:34:05.391: INFO: Pod "pod-configmaps-3db0fa57-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0092058s
STEP: Saw pod success
Feb  2 00:34:05.391: INFO: Pod "pod-configmaps-3db0fa57-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:34:05.394: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-3db0fa57-2682-11e9-a68a-f677bb5aadde container configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:34:05.418: INFO: Waiting for pod pod-configmaps-3db0fa57-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:34:05.426: INFO: Pod pod-configmaps-3db0fa57-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:34:05.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rcf62" for this suite.
Feb  2 00:34:11.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:34:11.466: INFO: namespace: e2e-tests-configmap-rcf62, resource: bindings, ignored listing per whitelist
Feb  2 00:34:11.505: INFO: namespace e2e-tests-configmap-rcf62 deletion completed in 6.0757273s

â€¢ [SLOW TEST:8.177 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:34:11.505: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-428aa338-2682-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:34:11.556: INFO: Waiting up to 5m0s for pod "pod-secrets-428b11bc-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-5rlfv" to be "success or failure"
Feb  2 00:34:11.573: INFO: Pod "pod-secrets-428b11bc-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 16.0384ms
Feb  2 00:34:13.575: INFO: Pod "pod-secrets-428b11bc-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0184996s
STEP: Saw pod success
Feb  2 00:34:13.575: INFO: Pod "pod-secrets-428b11bc-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:34:13.578: INFO: Trying to get logs from node docker-desktop pod pod-secrets-428b11bc-2682-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  2 00:34:13.597: INFO: Waiting for pod pod-secrets-428b11bc-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:34:13.600: INFO: Pod pod-secrets-428b11bc-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:34:13.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5rlfv" for this suite.
Feb  2 00:34:19.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:34:19.670: INFO: namespace: e2e-tests-secrets-5rlfv, resource: bindings, ignored listing per whitelist
Feb  2 00:34:19.686: INFO: namespace e2e-tests-secrets-5rlfv deletion completed in 6.0836367s

â€¢ [SLOW TEST:8.181 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:34:19.686: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  2 00:34:19.747: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22930,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  2 00:34:19.747: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22930,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  2 00:34:29.754: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22943,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  2 00:34:29.754: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22943,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  2 00:34:39.726: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22955,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  2 00:34:39.726: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22955,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  2 00:34:49.734: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22968,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  2 00:34:49.734: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-a,UID:476d0ed6-2682-11e9-b4dc-025000000001,ResourceVersion:22968,Generation:0,CreationTimestamp:2019-02-02 00:34:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  2 00:34:59.743: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-b,UID:5f438f00-2682-11e9-b4dc-025000000001,ResourceVersion:22980,Generation:0,CreationTimestamp:2019-02-02 00:34:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  2 00:34:59.743: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-b,UID:5f438f00-2682-11e9-b4dc-025000000001,ResourceVersion:22980,Generation:0,CreationTimestamp:2019-02-02 00:34:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  2 00:35:09.716: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-b,UID:5f438f00-2682-11e9-b4dc-025000000001,ResourceVersion:22993,Generation:0,CreationTimestamp:2019-02-02 00:34:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  2 00:35:09.717: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gq6zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gq6zp/configmaps/e2e-watch-test-configmap-b,UID:5f438f00-2682-11e9-b4dc-025000000001,ResourceVersion:22993,Generation:0,CreationTimestamp:2019-02-02 00:34:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:35:19.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gq6zp" for this suite.
Feb  2 00:35:25.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:35:25.743: INFO: namespace: e2e-tests-watch-gq6zp, resource: bindings, ignored listing per whitelist
Feb  2 00:35:25.793: INFO: namespace e2e-tests-watch-gq6zp deletion completed in 6.0706558s

â€¢ [SLOW TEST:66.176 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:35:25.793: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  2 00:35:27.870: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-6ed30c07-2682-11e9-a68a-f677bb5aadde,GenerateName:,Namespace:e2e-tests-events-zvhdk,SelfLink:/api/v1/namespaces/e2e-tests-events-zvhdk/pods/send-events-6ed30c07-2682-11e9-a68a-f677bb5aadde,UID:6ed38017-2682-11e9-b4dc-025000000001,ResourceVersion:23029,Generation:0,CreationTimestamp:2019-02-02 00:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 843981800,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gcfpd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gcfpd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-gcfpd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014ad110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014ad130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:35:25 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:35:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:35:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:35:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.246,StartTime:2019-02-02 00:35:25 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-02 00:35:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://976e7cc012cee748daea76bf5d2424155bab65f86ea6c4be32cee51f9e851e49}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb  2 00:35:29.874: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  2 00:35:31.880: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:35:31.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-zvhdk" for this suite.
Feb  2 00:36:09.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:36:09.875: INFO: namespace: e2e-tests-events-zvhdk, resource: bindings, ignored listing per whitelist
Feb  2 00:36:09.911: INFO: namespace e2e-tests-events-zvhdk deletion completed in 38.0902375s

â€¢ [SLOW TEST:44.187 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:36:09.911: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:36:09.974: INFO: Waiting up to 5m0s for pod "downwardapi-volume-891fd825-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-7vld8" to be "success or failure"
Feb  2 00:36:09.979: INFO: Pod "downwardapi-volume-891fd825-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5119ms
Feb  2 00:36:11.982: INFO: Pod "downwardapi-volume-891fd825-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0077245s
STEP: Saw pod success
Feb  2 00:36:11.982: INFO: Pod "downwardapi-volume-891fd825-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:36:11.986: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-891fd825-2682-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:36:12.005: INFO: Waiting for pod downwardapi-volume-891fd825-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:36:12.007: INFO: Pod downwardapi-volume-891fd825-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:36:12.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7vld8" for this suite.
Feb  2 00:36:18.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:36:18.072: INFO: namespace: e2e-tests-downward-api-7vld8, resource: bindings, ignored listing per whitelist
Feb  2 00:36:18.096: INFO: namespace e2e-tests-downward-api-7vld8 deletion completed in 6.0874348s

â€¢ [SLOW TEST:8.185 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:36:18.097: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb  2 00:36:18.161: INFO: Waiting up to 5m0s for pod "client-containers-8e015013-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-containers-dqxhf" to be "success or failure"
Feb  2 00:36:18.179: INFO: Pod "client-containers-8e015013-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 16.9572ms
Feb  2 00:36:20.184: INFO: Pod "client-containers-8e015013-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0222237s
STEP: Saw pod success
Feb  2 00:36:20.184: INFO: Pod "client-containers-8e015013-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:36:20.187: INFO: Trying to get logs from node docker-desktop pod client-containers-8e015013-2682-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:36:20.206: INFO: Waiting for pod client-containers-8e015013-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:36:20.209: INFO: Pod client-containers-8e015013-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:36:20.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dqxhf" for this suite.
Feb  2 00:36:26.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:36:26.256: INFO: namespace: e2e-tests-containers-dqxhf, resource: bindings, ignored listing per whitelist
Feb  2 00:36:26.301: INFO: namespace e2e-tests-containers-dqxhf deletion completed in 6.0886521s

â€¢ [SLOW TEST:8.204 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:36:26.301: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-92e33dff-2682-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:36:26.355: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-92e3abf6-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-2rt4b" to be "success or failure"
Feb  2 00:36:26.358: INFO: Pod "pod-projected-secrets-92e3abf6-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.7858ms
Feb  2 00:36:28.361: INFO: Pod "pod-projected-secrets-92e3abf6-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0064288s
STEP: Saw pod success
Feb  2 00:36:28.361: INFO: Pod "pod-projected-secrets-92e3abf6-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:36:28.364: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-92e3abf6-2682-11e9-a68a-f677bb5aadde container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  2 00:36:28.382: INFO: Waiting for pod pod-projected-secrets-92e3abf6-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:36:28.386: INFO: Pod pod-projected-secrets-92e3abf6-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:36:28.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2rt4b" for this suite.
Feb  2 00:36:34.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:36:34.440: INFO: namespace: e2e-tests-projected-2rt4b, resource: bindings, ignored listing per whitelist
Feb  2 00:36:34.468: INFO: namespace e2e-tests-projected-2rt4b deletion completed in 6.0770807s

â€¢ [SLOW TEST:8.167 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:36:34.470: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:36:34.524: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  2 00:36:34.532: INFO: Number of nodes with available pods: 0
Feb  2 00:36:34.532: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  2 00:36:34.546: INFO: Number of nodes with available pods: 0
Feb  2 00:36:34.546: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:35.513: INFO: Number of nodes with available pods: 0
Feb  2 00:36:35.514: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:36.519: INFO: Number of nodes with available pods: 1
Feb  2 00:36:36.519: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  2 00:36:36.533: INFO: Number of nodes with available pods: 1
Feb  2 00:36:36.533: INFO: Number of running nodes: 0, number of available pods: 1
Feb  2 00:36:37.539: INFO: Number of nodes with available pods: 0
Feb  2 00:36:37.539: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  2 00:36:37.545: INFO: Number of nodes with available pods: 0
Feb  2 00:36:37.546: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:38.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:38.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:39.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:39.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:40.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:40.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:41.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:41.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:42.552: INFO: Number of nodes with available pods: 0
Feb  2 00:36:42.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:43.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:43.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:44.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:44.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:45.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:45.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:46.552: INFO: Number of nodes with available pods: 0
Feb  2 00:36:46.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:47.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:47.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:48.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:48.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:49.552: INFO: Number of nodes with available pods: 0
Feb  2 00:36:49.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:50.549: INFO: Number of nodes with available pods: 0
Feb  2 00:36:50.549: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:51.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:51.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:52.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:52.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:53.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:53.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:54.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:54.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:55.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:55.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:56.553: INFO: Number of nodes with available pods: 0
Feb  2 00:36:56.553: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:57.550: INFO: Number of nodes with available pods: 0
Feb  2 00:36:57.550: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:58.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:58.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:36:59.551: INFO: Number of nodes with available pods: 0
Feb  2 00:36:59.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:00.552: INFO: Number of nodes with available pods: 0
Feb  2 00:37:00.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:01.552: INFO: Number of nodes with available pods: 0
Feb  2 00:37:01.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:02.552: INFO: Number of nodes with available pods: 0
Feb  2 00:37:02.552: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:03.551: INFO: Number of nodes with available pods: 0
Feb  2 00:37:03.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:04.551: INFO: Number of nodes with available pods: 0
Feb  2 00:37:04.551: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:05.515: INFO: Number of nodes with available pods: 0
Feb  2 00:37:05.515: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:06.515: INFO: Number of nodes with available pods: 0
Feb  2 00:37:06.515: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:07.516: INFO: Number of nodes with available pods: 0
Feb  2 00:37:07.516: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:08.515: INFO: Number of nodes with available pods: 0
Feb  2 00:37:08.515: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:09.518: INFO: Number of nodes with available pods: 0
Feb  2 00:37:09.518: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:10.516: INFO: Number of nodes with available pods: 0
Feb  2 00:37:10.516: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:11.516: INFO: Number of nodes with available pods: 0
Feb  2 00:37:11.516: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:12.518: INFO: Number of nodes with available pods: 0
Feb  2 00:37:12.518: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:37:13.518: INFO: Number of nodes with available pods: 1
Feb  2 00:37:13.518: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-4xc82, will wait for the garbage collector to delete the pods
Feb  2 00:37:13.584: INFO: Deleting DaemonSet.extensions daemon-set took: 7.9114ms
Feb  2 00:37:13.686: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.8835ms
Feb  2 00:37:58.054: INFO: Number of nodes with available pods: 0
Feb  2 00:37:58.054: INFO: Number of running nodes: 0, number of available pods: 0
Feb  2 00:37:58.056: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4xc82/daemonsets","resourceVersion":"23346"},"items":null}

Feb  2 00:37:58.058: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4xc82/pods","resourceVersion":"23346"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:37:58.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4xc82" for this suite.
Feb  2 00:38:04.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:38:04.103: INFO: namespace: e2e-tests-daemonsets-4xc82, resource: bindings, ignored listing per whitelist
Feb  2 00:38:04.146: INFO: namespace e2e-tests-daemonsets-4xc82 deletion completed in 6.0791577s

â€¢ [SLOW TEST:89.780 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:38:04.146: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  2 00:38:04.199: INFO: Waiting up to 5m0s for pod "pod-cd359177-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-ktx6x" to be "success or failure"
Feb  2 00:38:04.201: INFO: Pod "pod-cd359177-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.8172ms
Feb  2 00:38:06.172: INFO: Pod "pod-cd359177-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0071794s
STEP: Saw pod success
Feb  2 00:38:06.172: INFO: Pod "pod-cd359177-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:38:06.174: INFO: Trying to get logs from node docker-desktop pod pod-cd359177-2682-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:38:06.196: INFO: Waiting for pod pod-cd359177-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:38:06.201: INFO: Pod pod-cd359177-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:38:06.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ktx6x" for this suite.
Feb  2 00:38:12.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:38:12.226: INFO: namespace: e2e-tests-emptydir-ktx6x, resource: bindings, ignored listing per whitelist
Feb  2 00:38:12.280: INFO: namespace e2e-tests-emptydir-ktx6x deletion completed in 6.0768584s

â€¢ [SLOW TEST:8.169 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:38:12.281: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:38:12.336: INFO: (0) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 8.3111ms)
Feb  2 00:38:12.338: INFO: (1) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2396ms)
Feb  2 00:38:12.341: INFO: (2) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2387ms)
Feb  2 00:38:12.343: INFO: (3) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.363ms)
Feb  2 00:38:12.345: INFO: (4) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.0141ms)
Feb  2 00:38:12.347: INFO: (5) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.1994ms)
Feb  2 00:38:12.350: INFO: (6) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.1679ms)
Feb  2 00:38:12.352: INFO: (7) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2015ms)
Feb  2 00:38:12.354: INFO: (8) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.0353ms)
Feb  2 00:38:12.356: INFO: (9) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.012ms)
Feb  2 00:38:12.358: INFO: (10) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 1.9359ms)
Feb  2 00:38:12.360: INFO: (11) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.06ms)
Feb  2 00:38:12.362: INFO: (12) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2065ms)
Feb  2 00:38:12.365: INFO: (13) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.3331ms)
Feb  2 00:38:12.368: INFO: (14) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 3.2963ms)
Feb  2 00:38:12.370: INFO: (15) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.1864ms)
Feb  2 00:38:12.372: INFO: (16) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.1532ms)
Feb  2 00:38:12.375: INFO: (17) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.0121ms)
Feb  2 00:38:12.377: INFO: (18) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.3853ms)
Feb  2 00:38:12.379: INFO: (19) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2264ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:38:12.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-h8l9n" for this suite.
Feb  2 00:38:18.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:38:18.419: INFO: namespace: e2e-tests-proxy-h8l9n, resource: bindings, ignored listing per whitelist
Feb  2 00:38:18.455: INFO: namespace e2e-tests-proxy-h8l9n deletion completed in 6.0739096s

â€¢ [SLOW TEST:6.174 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:38:18.457: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb  2 00:38:18.506: INFO: Waiting up to 5m0s for pod "var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-var-expansion-kscjb" to be "success or failure"
Feb  2 00:38:18.508: INFO: Pod "var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1ms
Feb  2 00:38:20.512: INFO: Pod "var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0064051s
Feb  2 00:38:22.516: INFO: Pod "var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010203s
STEP: Saw pod success
Feb  2 00:38:22.516: INFO: Pod "var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:38:22.519: INFO: Trying to get logs from node docker-desktop pod var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  2 00:38:22.537: INFO: Waiting for pod var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:38:22.539: INFO: Pod var-expansion-d5bca57d-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:38:22.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kscjb" for this suite.
Feb  2 00:38:28.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:38:28.580: INFO: namespace: e2e-tests-var-expansion-kscjb, resource: bindings, ignored listing per whitelist
Feb  2 00:38:28.623: INFO: namespace e2e-tests-var-expansion-kscjb deletion completed in 6.0813472s

â€¢ [SLOW TEST:10.167 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:38:28.623: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0202 00:38:38.713607      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  2 00:38:38.713: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:38:38.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9zsxk" for this suite.
Feb  2 00:38:44.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:38:44.791: INFO: namespace: e2e-tests-gc-9zsxk, resource: bindings, ignored listing per whitelist
Feb  2 00:38:44.846: INFO: namespace e2e-tests-gc-9zsxk deletion completed in 6.1296519s

â€¢ [SLOW TEST:16.257 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:38:44.846: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:38:46.969: INFO: Waiting up to 5m0s for pod "client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-pods-t4xbv" to be "success or failure"
Feb  2 00:38:46.980: INFO: Pod "client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 11.8411ms
Feb  2 00:38:48.985: INFO: Pod "client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0160932s
Feb  2 00:38:50.989: INFO: Pod "client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0203672s
STEP: Saw pod success
Feb  2 00:38:50.989: INFO: Pod "client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:38:50.992: INFO: Trying to get logs from node docker-desktop pod client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde container env3cont: <nil>
STEP: delete the pod
Feb  2 00:38:51.011: INFO: Waiting for pod client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:38:51.018: INFO: Pod client-envvars-e6b32572-2682-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:38:51.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-t4xbv" for this suite.
Feb  2 00:39:40.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:39:41.000: INFO: namespace: e2e-tests-pods-t4xbv, resource: bindings, ignored listing per whitelist
Feb  2 00:39:41.036: INFO: namespace e2e-tests-pods-t4xbv deletion completed in 50.0835953s

â€¢ [SLOW TEST:56.259 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:39:41.039: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  2 00:39:43.635: INFO: Successfully updated pod "labelsupdate06f5d3fe-2683-11e9-a68a-f677bb5aadde"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:39:45.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-spc6h" for this suite.
Feb  2 00:40:07.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:40:07.670: INFO: namespace: e2e-tests-projected-spc6h, resource: bindings, ignored listing per whitelist
Feb  2 00:40:07.708: INFO: namespace e2e-tests-projected-spc6h deletion completed in 22.0840695s

â€¢ [SLOW TEST:26.705 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:40:07.716: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-z8hbf
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-z8hbf
STEP: Deleting pre-stop pod
Feb  2 00:40:18.826: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:40:18.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-z8hbf" for this suite.
Feb  2 00:40:58.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:40:58.872: INFO: namespace: e2e-tests-prestop-z8hbf, resource: bindings, ignored listing per whitelist
Feb  2 00:40:58.885: INFO: namespace e2e-tests-prestop-z8hbf deletion completed in 40.0805232s

â€¢ [SLOW TEST:51.203 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:40:58.885: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:40:58.936: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  2 00:41:03.940: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  2 00:41:03.941: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  2 00:41:03.958: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-lvtpq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lvtpq/deployments/test-cleanup-deployment,UID:38594ea1-2683-11e9-b4dc-025000000001,ResourceVersion:23989,Generation:1,CreationTimestamp:2019-02-02 00:41:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb  2 00:41:03.963: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Feb  2 00:41:03.964: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb  2 00:41:03.964: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-lvtpq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lvtpq/replicasets/test-cleanup-controller,UID:355c5840-2683-11e9-b4dc-025000000001,ResourceVersion:23990,Generation:1,CreationTimestamp:2019-02-02 00:40:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 38594ea1-2683-11e9-b4dc-025000000001 0xc001d4ce87 0xc001d4ce88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  2 00:41:03.968: INFO: Pod "test-cleanup-controller-8wfmw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-8wfmw,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-lvtpq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lvtpq/pods/test-cleanup-controller-8wfmw,UID:355d9769-2683-11e9-b4dc-025000000001,ResourceVersion:23985,Generation:0,CreationTimestamp:2019-02-02 00:40:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 355c5840-2683-11e9-b4dc-025000000001 0xc001b01527 0xc001b01528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-r7cnz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-r7cnz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-r7cnz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b015c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b01960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:40:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:41:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:41:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:40:58 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.1.13,StartTime:2019-02-02 00:40:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-02 00:41:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://29eb91c89c946db24dced6daef4f04db56ec84ced2ee887804be483c7c04c78a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:41:03.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lvtpq" for this suite.
Feb  2 00:41:09.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:41:10.000: INFO: namespace: e2e-tests-deployment-lvtpq, resource: bindings, ignored listing per whitelist
Feb  2 00:41:10.054: INFO: namespace e2e-tests-deployment-lvtpq deletion completed in 6.1089451s

â€¢ [SLOW TEST:11.204 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:41:10.054: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb  2 00:41:10.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 --namespace=e2e-tests-kubectl-wtl68 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  2 00:41:12.907: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  2 00:41:12.907: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:41:14.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wtl68" for this suite.
Feb  2 00:41:20.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:41:20.985: INFO: namespace: e2e-tests-kubectl-wtl68, resource: bindings, ignored listing per whitelist
Feb  2 00:41:21.011: INFO: namespace e2e-tests-kubectl-wtl68 deletion completed in 6.0921896s

â€¢ [SLOW TEST:10.957 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:41:21.014: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-428e474f-2683-11e9-a68a-f677bb5aadde
STEP: Creating secret with name s-test-opt-upd-428e47df-2683-11e9-a68a-f677bb5aadde
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-428e474f-2683-11e9-a68a-f677bb5aadde
STEP: Updating secret s-test-opt-upd-428e47df-2683-11e9-a68a-f677bb5aadde
STEP: Creating secret with name s-test-opt-create-428e4885-2683-11e9-a68a-f677bb5aadde
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:42:41.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wmqml" for this suite.
Feb  2 00:43:03.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:43:03.585: INFO: namespace: e2e-tests-projected-wmqml, resource: bindings, ignored listing per whitelist
Feb  2 00:43:03.596: INFO: namespace e2e-tests-projected-wmqml deletion completed in 22.0839874s

â€¢ [SLOW TEST:102.686 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:43:03.596: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb  2 00:43:03.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-q4j9g'
Feb  2 00:43:03.829: INFO: stderr: ""
Feb  2 00:43:03.829: INFO: stdout: "pod/pause created\n"
Feb  2 00:43:03.829: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  2 00:43:03.829: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-q4j9g" to be "running and ready"
Feb  2 00:43:03.834: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5205ms
Feb  2 00:43:05.806: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010367s
Feb  2 00:43:05.806: INFO: Pod "pause" satisfied condition "running and ready"
Feb  2 00:43:05.806: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  2 00:43:05.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-q4j9g'
Feb  2 00:43:05.881: INFO: stderr: ""
Feb  2 00:43:05.881: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  2 00:43:05.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q4j9g'
Feb  2 00:43:05.957: INFO: stderr: ""
Feb  2 00:43:05.957: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  2 00:43:05.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 label pods pause testing-label- --namespace=e2e-tests-kubectl-q4j9g'
Feb  2 00:43:06.031: INFO: stderr: ""
Feb  2 00:43:06.031: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  2 00:43:06.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q4j9g'
Feb  2 00:43:06.098: INFO: stderr: ""
Feb  2 00:43:06.098: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb  2 00:43:06.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-q4j9g'
Feb  2 00:43:06.174: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 00:43:06.175: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  2 00:43:06.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-q4j9g'
Feb  2 00:43:06.266: INFO: stderr: "No resources found.\n"
Feb  2 00:43:06.266: INFO: stdout: ""
Feb  2 00:43:06.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pods -l name=pause --namespace=e2e-tests-kubectl-q4j9g -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  2 00:43:06.347: INFO: stderr: ""
Feb  2 00:43:06.347: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:43:06.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q4j9g" for this suite.
Feb  2 00:43:12.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:43:12.403: INFO: namespace: e2e-tests-kubectl-q4j9g, resource: bindings, ignored listing per whitelist
Feb  2 00:43:12.433: INFO: namespace e2e-tests-kubectl-q4j9g deletion completed in 6.0820714s

â€¢ [SLOW TEST:8.872 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:43:12.433: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  2 00:43:12.481: INFO: Waiting up to 5m0s for pod "pod-84f585e5-2683-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-2c8hf" to be "success or failure"
Feb  2 00:43:12.483: INFO: Pod "pod-84f585e5-2683-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.3005ms
Feb  2 00:43:14.488: INFO: Pod "pod-84f585e5-2683-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0071071s
STEP: Saw pod success
Feb  2 00:43:14.488: INFO: Pod "pod-84f585e5-2683-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:43:14.491: INFO: Trying to get logs from node docker-desktop pod pod-84f585e5-2683-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:43:14.511: INFO: Waiting for pod pod-84f585e5-2683-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:43:14.516: INFO: Pod pod-84f585e5-2683-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:43:14.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2c8hf" for this suite.
Feb  2 00:43:20.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:43:20.567: INFO: namespace: e2e-tests-emptydir-2c8hf, resource: bindings, ignored listing per whitelist
Feb  2 00:43:20.609: INFO: namespace e2e-tests-emptydir-2c8hf deletion completed in 6.0881757s

â€¢ [SLOW TEST:8.176 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:43:20.610: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  2 00:43:20.663: INFO: Waiting up to 5m0s for pod "downward-api-89d61167-2683-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-downward-api-fmgwr" to be "success or failure"
Feb  2 00:43:20.666: INFO: Pod "downward-api-89d61167-2683-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.5314ms
Feb  2 00:43:22.670: INFO: Pod "downward-api-89d61167-2683-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0062342s
STEP: Saw pod success
Feb  2 00:43:22.670: INFO: Pod "downward-api-89d61167-2683-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:43:22.675: INFO: Trying to get logs from node docker-desktop pod downward-api-89d61167-2683-11e9-a68a-f677bb5aadde container dapi-container: <nil>
STEP: delete the pod
Feb  2 00:43:22.693: INFO: Waiting for pod downward-api-89d61167-2683-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:43:22.697: INFO: Pod downward-api-89d61167-2683-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:43:22.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fmgwr" for this suite.
Feb  2 00:43:28.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:43:28.729: INFO: namespace: e2e-tests-downward-api-fmgwr, resource: bindings, ignored listing per whitelist
Feb  2 00:43:28.780: INFO: namespace e2e-tests-downward-api-fmgwr deletion completed in 6.0781627s

â€¢ [SLOW TEST:8.171 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:43:28.781: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  2 00:43:28.826: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:43:32.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wxtqk" for this suite.
Feb  2 00:43:38.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:43:38.707: INFO: namespace: e2e-tests-init-container-wxtqk, resource: bindings, ignored listing per whitelist
Feb  2 00:43:38.744: INFO: namespace e2e-tests-init-container-wxtqk deletion completed in 6.1029803s

â€¢ [SLOW TEST:9.998 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:43:38.744: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb  2 00:43:39.313: INFO: Waiting up to 5m0s for pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj" in namespace "e2e-tests-svcaccounts-l4nt2" to be "success or failure"
Feb  2 00:43:39.317: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj": Phase="Pending", Reason="", readiness=false. Elapsed: 3.4829ms
Feb  2 00:43:41.322: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0089895s
Feb  2 00:43:43.327: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0138434s
STEP: Saw pod success
Feb  2 00:43:43.327: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj" satisfied condition "success or failure"
Feb  2 00:43:43.329: INFO: Trying to get logs from node docker-desktop pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj container token-test: <nil>
STEP: delete the pod
Feb  2 00:43:43.354: INFO: Waiting for pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj to disappear
Feb  2 00:43:43.360: INFO: Pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-4jbgj no longer exists
STEP: Creating a pod to test consume service account root CA
Feb  2 00:43:43.365: INFO: Waiting up to 5m0s for pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f" in namespace "e2e-tests-svcaccounts-l4nt2" to be "success or failure"
Feb  2 00:43:43.370: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.9312ms
Feb  2 00:43:45.376: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0115254s
Feb  2 00:43:47.383: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0185585s
STEP: Saw pod success
Feb  2 00:43:47.384: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f" satisfied condition "success or failure"
Feb  2 00:43:47.386: INFO: Trying to get logs from node docker-desktop pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f container root-ca-test: <nil>
STEP: delete the pod
Feb  2 00:43:47.407: INFO: Waiting for pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f to disappear
Feb  2 00:43:47.410: INFO: Pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-zvr7f no longer exists
STEP: Creating a pod to test consume service account namespace
Feb  2 00:43:47.423: INFO: Waiting up to 5m0s for pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78" in namespace "e2e-tests-svcaccounts-l4nt2" to be "success or failure"
Feb  2 00:43:47.436: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78": Phase="Pending", Reason="", readiness=false. Elapsed: 11.907ms
Feb  2 00:43:49.440: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0163357s
Feb  2 00:43:51.446: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0216388s
STEP: Saw pod success
Feb  2 00:43:51.446: INFO: Pod "pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78" satisfied condition "success or failure"
Feb  2 00:43:51.448: INFO: Trying to get logs from node docker-desktop pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78 container namespace-test: <nil>
STEP: delete the pod
Feb  2 00:43:51.465: INFO: Waiting for pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78 to disappear
Feb  2 00:43:51.469: INFO: Pod pod-service-account-94f3a1d4-2683-11e9-a68a-f677bb5aadde-64g78 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:43:51.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-l4nt2" for this suite.
Feb  2 00:43:57.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:43:57.558: INFO: namespace: e2e-tests-svcaccounts-l4nt2, resource: bindings, ignored listing per whitelist
Feb  2 00:43:57.574: INFO: namespace e2e-tests-svcaccounts-l4nt2 deletion completed in 6.0993549s

â€¢ [SLOW TEST:18.830 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:43:57.574: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9fe1224d-2683-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:43:57.649: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9fe1be6e-2683-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-8kcmr" to be "success or failure"
Feb  2 00:43:57.651: INFO: Pod "pod-projected-configmaps-9fe1be6e-2683-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.7737ms
Feb  2 00:43:59.657: INFO: Pod "pod-projected-configmaps-9fe1be6e-2683-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0080292s
STEP: Saw pod success
Feb  2 00:43:59.658: INFO: Pod "pod-projected-configmaps-9fe1be6e-2683-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:43:59.661: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-9fe1be6e-2683-11e9-a68a-f677bb5aadde container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:43:59.685: INFO: Waiting for pod pod-projected-configmaps-9fe1be6e-2683-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:43:59.687: INFO: Pod pod-projected-configmaps-9fe1be6e-2683-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:43:59.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8kcmr" for this suite.
Feb  2 00:44:05.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:44:05.728: INFO: namespace: e2e-tests-projected-8kcmr, resource: bindings, ignored listing per whitelist
Feb  2 00:44:05.739: INFO: namespace e2e-tests-projected-8kcmr deletion completed in 6.0842043s

â€¢ [SLOW TEST:8.200 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:44:05.740: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-b6ld
STEP: Creating a pod to test atomic-volume-subpath
Feb  2 00:44:05.796: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-b6ld" in namespace "e2e-tests-subpath-tqgzf" to be "success or failure"
Feb  2 00:44:05.800: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Pending", Reason="", readiness=false. Elapsed: 3.8189ms
Feb  2 00:44:07.803: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0068589s
Feb  2 00:44:09.806: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 4.0101222s
Feb  2 00:44:11.810: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 6.0139739s
Feb  2 00:44:13.815: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 8.0189263s
Feb  2 00:44:15.819: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 10.0229832s
Feb  2 00:44:17.823: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 12.0262372s
Feb  2 00:44:19.827: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 14.030398s
Feb  2 00:44:21.831: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 16.0346796s
Feb  2 00:44:23.838: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 18.0415155s
Feb  2 00:44:25.844: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 20.0480661s
Feb  2 00:44:27.851: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Running", Reason="", readiness=false. Elapsed: 22.0548298s
Feb  2 00:44:29.858: INFO: Pod "pod-subpath-test-configmap-b6ld": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0616377s
STEP: Saw pod success
Feb  2 00:44:29.858: INFO: Pod "pod-subpath-test-configmap-b6ld" satisfied condition "success or failure"
Feb  2 00:44:29.861: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-b6ld container test-container-subpath-configmap-b6ld: <nil>
STEP: delete the pod
Feb  2 00:44:29.883: INFO: Waiting for pod pod-subpath-test-configmap-b6ld to disappear
Feb  2 00:44:29.887: INFO: Pod pod-subpath-test-configmap-b6ld no longer exists
STEP: Deleting pod pod-subpath-test-configmap-b6ld
Feb  2 00:44:29.887: INFO: Deleting pod "pod-subpath-test-configmap-b6ld" in namespace "e2e-tests-subpath-tqgzf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:44:29.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tqgzf" for this suite.
Feb  2 00:44:35.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:44:35.893: INFO: namespace: e2e-tests-subpath-tqgzf, resource: bindings, ignored listing per whitelist
Feb  2 00:44:35.932: INFO: namespace e2e-tests-subpath-tqgzf deletion completed in 6.0751664s

â€¢ [SLOW TEST:30.227 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:44:35.932: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde
Feb  2 00:44:35.989: INFO: Pod name my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde: Found 0 pods out of 1
Feb  2 00:44:40.994: INFO: Pod name my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde: Found 1 pods out of 1
Feb  2 00:44:40.994: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde" are running
Feb  2 00:44:40.996: INFO: Pod "my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde-7v2tb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-02 00:44:35 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-02 00:44:38 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-02 00:44:38 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-02 00:44:35 +0000 UTC Reason: Message:}])
Feb  2 00:44:40.996: INFO: Trying to dial the pod
Feb  2 00:44:46.009: INFO: Controller my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde: Got expected result from replica 1 [my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde-7v2tb]: "my-hostname-basic-b6bb72ac-2683-11e9-a68a-f677bb5aadde-7v2tb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:44:46.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-s92lf" for this suite.
Feb  2 00:44:52.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:44:52.084: INFO: namespace: e2e-tests-replication-controller-s92lf, resource: bindings, ignored listing per whitelist
Feb  2 00:44:52.094: INFO: namespace e2e-tests-replication-controller-s92lf deletion completed in 6.0821625s

â€¢ [SLOW TEST:16.162 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:44:52.094: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  2 00:44:52.155: INFO: Number of nodes with available pods: 0
Feb  2 00:44:52.155: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:44:53.162: INFO: Number of nodes with available pods: 0
Feb  2 00:44:53.162: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:44:54.167: INFO: Number of nodes with available pods: 0
Feb  2 00:44:54.167: INFO: Node docker-desktop is running more than one daemon pod
Feb  2 00:44:55.166: INFO: Number of nodes with available pods: 1
Feb  2 00:44:55.166: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  2 00:44:55.181: INFO: Number of nodes with available pods: 1
Feb  2 00:44:55.181: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-h57g9, will wait for the garbage collector to delete the pods
Feb  2 00:44:56.256: INFO: Deleting DaemonSet.extensions daemon-set took: 5.7937ms
Feb  2 00:44:56.357: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.507ms
Feb  2 00:45:37.493: INFO: Number of nodes with available pods: 0
Feb  2 00:45:37.493: INFO: Number of running nodes: 0, number of available pods: 0
Feb  2 00:45:37.499: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h57g9/daemonsets","resourceVersion":"24766"},"items":null}

Feb  2 00:45:37.501: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h57g9/pods","resourceVersion":"24766"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:45:37.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h57g9" for this suite.
Feb  2 00:45:43.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:45:43.575: INFO: namespace: e2e-tests-daemonsets-h57g9, resource: bindings, ignored listing per whitelist
Feb  2 00:45:43.586: INFO: namespace e2e-tests-daemonsets-h57g9 deletion completed in 6.0774718s

â€¢ [SLOW TEST:51.561 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:45:43.586: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:45:43.647: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df0f8320-2683-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-gc98s" to be "success or failure"
Feb  2 00:45:43.650: INFO: Pod "downwardapi-volume-df0f8320-2683-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.8054ms
Feb  2 00:45:45.655: INFO: Pod "downwardapi-volume-df0f8320-2683-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0084188s
STEP: Saw pod success
Feb  2 00:45:45.655: INFO: Pod "downwardapi-volume-df0f8320-2683-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:45:45.659: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-df0f8320-2683-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:45:45.677: INFO: Waiting for pod downwardapi-volume-df0f8320-2683-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:45:45.685: INFO: Pod downwardapi-volume-df0f8320-2683-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:45:45.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gc98s" for this suite.
Feb  2 00:45:51.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:45:51.760: INFO: namespace: e2e-tests-projected-gc98s, resource: bindings, ignored listing per whitelist
Feb  2 00:45:51.772: INFO: namespace e2e-tests-projected-gc98s deletion completed in 6.0805584s

â€¢ [SLOW TEST:8.186 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:45:51.773: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:46:16.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-46psw" for this suite.
Feb  2 00:46:22.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:46:22.107: INFO: namespace: e2e-tests-container-runtime-46psw, resource: bindings, ignored listing per whitelist
Feb  2 00:46:22.113: INFO: namespace e2e-tests-container-runtime-46psw deletion completed in 6.0797775s

â€¢ [SLOW TEST:30.375 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:46:22.113: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-8bn7
STEP: Creating a pod to test atomic-volume-subpath
Feb  2 00:46:22.177: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-8bn7" in namespace "e2e-tests-subpath-dzpkx" to be "success or failure"
Feb  2 00:46:22.180: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.854ms
Feb  2 00:46:24.184: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0071021s
Feb  2 00:46:26.188: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 4.0113554s
Feb  2 00:46:28.193: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 6.0161028s
Feb  2 00:46:30.197: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 8.0204544s
Feb  2 00:46:32.202: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 10.0249838s
Feb  2 00:46:34.171: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 12.0288633s
Feb  2 00:46:36.178: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 14.0358708s
Feb  2 00:46:38.184: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 16.0418555s
Feb  2 00:46:40.189: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 18.0467284s
Feb  2 00:46:42.196: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 20.0533918s
Feb  2 00:46:44.201: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Running", Reason="", readiness=false. Elapsed: 22.0591115s
Feb  2 00:46:46.205: INFO: Pod "pod-subpath-test-downwardapi-8bn7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0632729s
STEP: Saw pod success
Feb  2 00:46:46.206: INFO: Pod "pod-subpath-test-downwardapi-8bn7" satisfied condition "success or failure"
Feb  2 00:46:46.208: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-downwardapi-8bn7 container test-container-subpath-downwardapi-8bn7: <nil>
STEP: delete the pod
Feb  2 00:46:46.227: INFO: Waiting for pod pod-subpath-test-downwardapi-8bn7 to disappear
Feb  2 00:46:46.231: INFO: Pod pod-subpath-test-downwardapi-8bn7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-8bn7
Feb  2 00:46:46.231: INFO: Deleting pod "pod-subpath-test-downwardapi-8bn7" in namespace "e2e-tests-subpath-dzpkx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:46:46.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dzpkx" for this suite.
Feb  2 00:46:52.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:46:52.306: INFO: namespace: e2e-tests-subpath-dzpkx, resource: bindings, ignored listing per whitelist
Feb  2 00:46:52.322: INFO: namespace e2e-tests-subpath-dzpkx deletion completed in 6.0851889s

â€¢ [SLOW TEST:30.244 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:46:52.328: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-080a668d-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:46:52.403: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-7vfcl" to be "success or failure"
Feb  2 00:46:52.405: INFO: Pod "pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.9766ms
Feb  2 00:46:54.410: INFO: Pod "pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00684s
Feb  2 00:46:56.416: INFO: Pod "pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0131737s
STEP: Saw pod success
Feb  2 00:46:56.417: INFO: Pod "pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:46:56.419: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:46:56.440: INFO: Waiting for pod pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:46:56.443: INFO: Pod pod-projected-configmaps-080ae297-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:46:56.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7vfcl" for this suite.
Feb  2 00:47:02.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:47:02.506: INFO: namespace: e2e-tests-projected-7vfcl, resource: bindings, ignored listing per whitelist
Feb  2 00:47:02.520: INFO: namespace e2e-tests-projected-7vfcl deletion completed in 6.0740624s

â€¢ [SLOW TEST:10.193 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:47:02.520: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  2 00:47:02.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nlmzd'
Feb  2 00:47:02.657: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  2 00:47:02.657: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb  2 00:47:02.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-nlmzd'
Feb  2 00:47:02.748: INFO: stderr: ""
Feb  2 00:47:02.748: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:47:02.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nlmzd" for this suite.
Feb  2 00:47:08.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:47:08.746: INFO: namespace: e2e-tests-kubectl-nlmzd, resource: bindings, ignored listing per whitelist
Feb  2 00:47:08.807: INFO: namespace e2e-tests-kubectl-nlmzd deletion completed in 6.0874141s

â€¢ [SLOW TEST:6.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:47:08.807: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  2 00:47:08.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-8zhwf'
Feb  2 00:47:08.926: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  2 00:47:08.926: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb  2 00:47:12.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-8zhwf'
Feb  2 00:47:13.030: INFO: stderr: ""
Feb  2 00:47:13.030: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:47:13.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8zhwf" for this suite.
Feb  2 00:47:19.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:47:19.119: INFO: namespace: e2e-tests-kubectl-8zhwf, resource: bindings, ignored listing per whitelist
Feb  2 00:47:19.125: INFO: namespace e2e-tests-kubectl-8zhwf deletion completed in 6.091022s

â€¢ [SLOW TEST:10.319 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:47:19.129: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Feb  2 00:47:30.282: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:47:47.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-2c8sl" for this suite.
Feb  2 00:47:53.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:47:53.251: INFO: namespace: e2e-tests-namespaces-2c8sl, resource: bindings, ignored listing per whitelist
Feb  2 00:47:53.304: INFO: namespace e2e-tests-namespaces-2c8sl deletion completed in 6.0808098s
STEP: Destroying namespace "e2e-tests-nsdeletetest-cgc8r" for this suite.
Feb  2 00:47:53.306: INFO: Namespace e2e-tests-nsdeletetest-cgc8r was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-fvcp5" for this suite.
Feb  2 00:47:59.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:47:59.374: INFO: namespace: e2e-tests-nsdeletetest-fvcp5, resource: bindings, ignored listing per whitelist
Feb  2 00:47:59.393: INFO: namespace e2e-tests-nsdeletetest-fvcp5 deletion completed in 6.0872511s

â€¢ [SLOW TEST:40.299 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:47:59.398: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  2 00:47:59.452: INFO: Waiting up to 5m0s for pod "pod-3001e3de-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-247mq" to be "success or failure"
Feb  2 00:47:59.455: INFO: Pod "pod-3001e3de-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.2287ms
Feb  2 00:48:01.458: INFO: Pod "pod-3001e3de-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0059711s
STEP: Saw pod success
Feb  2 00:48:01.458: INFO: Pod "pod-3001e3de-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:48:01.461: INFO: Trying to get logs from node docker-desktop pod pod-3001e3de-2684-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:48:01.475: INFO: Waiting for pod pod-3001e3de-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:48:01.480: INFO: Pod pod-3001e3de-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:48:01.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-247mq" for this suite.
Feb  2 00:48:07.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:48:07.506: INFO: namespace: e2e-tests-emptydir-247mq, resource: bindings, ignored listing per whitelist
Feb  2 00:48:07.537: INFO: namespace e2e-tests-emptydir-247mq deletion completed in 6.0880881s

â€¢ [SLOW TEST:8.174 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:48:07.538: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-34db9752-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:48:07.593: INFO: Waiting up to 5m0s for pod "pod-configmaps-34dc159f-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-64p6f" to be "success or failure"
Feb  2 00:48:07.596: INFO: Pod "pod-configmaps-34dc159f-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.1321ms
Feb  2 00:48:09.599: INFO: Pod "pod-configmaps-34dc159f-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0056785s
STEP: Saw pod success
Feb  2 00:48:09.599: INFO: Pod "pod-configmaps-34dc159f-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:48:09.601: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-34dc159f-2684-11e9-a68a-f677bb5aadde container configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:48:09.621: INFO: Waiting for pod pod-configmaps-34dc159f-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:48:09.624: INFO: Pod pod-configmaps-34dc159f-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:48:09.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-64p6f" for this suite.
Feb  2 00:48:15.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:48:15.703: INFO: namespace: e2e-tests-configmap-64p6f, resource: bindings, ignored listing per whitelist
Feb  2 00:48:15.715: INFO: namespace e2e-tests-configmap-64p6f deletion completed in 6.086246s

â€¢ [SLOW TEST:8.178 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:48:15.716: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  2 00:48:15.771: INFO: Waiting up to 5m0s for pod "pod-39bbfad3-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-q7j59" to be "success or failure"
Feb  2 00:48:15.774: INFO: Pod "pod-39bbfad3-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1983ms
Feb  2 00:48:17.777: INFO: Pod "pod-39bbfad3-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0058762s
STEP: Saw pod success
Feb  2 00:48:17.777: INFO: Pod "pod-39bbfad3-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:48:17.779: INFO: Trying to get logs from node docker-desktop pod pod-39bbfad3-2684-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:48:17.794: INFO: Waiting for pod pod-39bbfad3-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:48:17.803: INFO: Pod pod-39bbfad3-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:48:17.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q7j59" for this suite.
Feb  2 00:48:23.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:48:23.848: INFO: namespace: e2e-tests-emptydir-q7j59, resource: bindings, ignored listing per whitelist
Feb  2 00:48:23.887: INFO: namespace e2e-tests-emptydir-q7j59 deletion completed in 6.0785865s

â€¢ [SLOW TEST:8.172 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:48:23.888: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3e99d893-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:48:23.939: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3e9a5423-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-svr2t" to be "success or failure"
Feb  2 00:48:23.943: INFO: Pod "pod-projected-configmaps-3e9a5423-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.7986ms
Feb  2 00:48:25.948: INFO: Pod "pod-projected-configmaps-3e9a5423-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0081062s
STEP: Saw pod success
Feb  2 00:48:25.948: INFO: Pod "pod-projected-configmaps-3e9a5423-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:48:25.950: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-3e9a5423-2684-11e9-a68a-f677bb5aadde container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:48:25.971: INFO: Waiting for pod pod-projected-configmaps-3e9a5423-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:48:25.982: INFO: Pod pod-projected-configmaps-3e9a5423-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:48:25.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-svr2t" for this suite.
Feb  2 00:48:32.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:48:32.020: INFO: namespace: e2e-tests-projected-svr2t, resource: bindings, ignored listing per whitelist
Feb  2 00:48:32.067: INFO: namespace e2e-tests-projected-svr2t deletion completed in 6.0790319s

â€¢ [SLOW TEST:8.180 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:48:32.067: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-437a2e1b-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:48:32.120: INFO: Waiting up to 5m0s for pod "pod-configmaps-437a99cd-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-mxn55" to be "success or failure"
Feb  2 00:48:32.124: INFO: Pod "pod-configmaps-437a99cd-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.4411ms
Feb  2 00:48:34.093: INFO: Pod "pod-configmaps-437a99cd-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0070384s
STEP: Saw pod success
Feb  2 00:48:34.093: INFO: Pod "pod-configmaps-437a99cd-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:48:34.096: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-437a99cd-2684-11e9-a68a-f677bb5aadde container configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:48:34.115: INFO: Waiting for pod pod-configmaps-437a99cd-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:48:34.119: INFO: Pod pod-configmaps-437a99cd-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:48:34.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mxn55" for this suite.
Feb  2 00:48:40.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:48:40.157: INFO: namespace: e2e-tests-configmap-mxn55, resource: bindings, ignored listing per whitelist
Feb  2 00:48:40.202: INFO: namespace e2e-tests-configmap-mxn55 deletion completed in 6.0803891s

â€¢ [SLOW TEST:8.169 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:48:40.203: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  2 00:48:40.257: INFO: Waiting up to 5m0s for pod "pod-4853b9f1-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-x284t" to be "success or failure"
Feb  2 00:48:40.268: INFO: Pod "pod-4853b9f1-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 10.7381ms
Feb  2 00:48:42.272: INFO: Pod "pod-4853b9f1-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0144214s
STEP: Saw pod success
Feb  2 00:48:42.272: INFO: Pod "pod-4853b9f1-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:48:42.274: INFO: Trying to get logs from node docker-desktop pod pod-4853b9f1-2684-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:48:42.302: INFO: Waiting for pod pod-4853b9f1-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:48:42.313: INFO: Pod pod-4853b9f1-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:48:42.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x284t" for this suite.
Feb  2 00:48:48.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:48:48.389: INFO: namespace: e2e-tests-emptydir-x284t, resource: bindings, ignored listing per whitelist
Feb  2 00:48:48.410: INFO: namespace e2e-tests-emptydir-x284t deletion completed in 6.0900978s

â€¢ [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:48:48.410: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tjfnm
Feb  2 00:48:50.479: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tjfnm
STEP: checking the pod's current state and verifying that restartCount is present
Feb  2 00:48:50.482: INFO: Initial restart count of pod liveness-exec is 0
Feb  2 00:49:38.529: INFO: Restart count of pod e2e-tests-container-probe-tjfnm/liveness-exec is now 1 (48.1168486s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:49:38.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tjfnm" for this suite.
Feb  2 00:49:44.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:49:44.625: INFO: namespace: e2e-tests-container-probe-tjfnm, resource: bindings, ignored listing per whitelist
Feb  2 00:49:44.639: INFO: namespace e2e-tests-container-probe-tjfnm deletion completed in 6.0943329s

â€¢ [SLOW TEST:56.298 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:49:44.639: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-6ebf24d8-2684-11e9-a68a-f677bb5aadde
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:49:48.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2wptm" for this suite.
Feb  2 00:50:10.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:50:10.764: INFO: namespace: e2e-tests-configmap-2wptm, resource: bindings, ignored listing per whitelist
Feb  2 00:50:10.789: INFO: namespace e2e-tests-configmap-2wptm deletion completed in 22.0754321s

â€¢ [SLOW TEST:26.185 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:50:10.790: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  2 00:50:14.886: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:14.889: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:16.891: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:16.894: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:18.891: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:18.895: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:20.892: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:20.896: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:22.891: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:22.895: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:24.889: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:24.894: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:26.890: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:26.894: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:28.890: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:28.895: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:30.889: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:30.894: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:32.891: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:32.895: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:34.856: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:34.861: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:36.855: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:36.859: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  2 00:50:38.855: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  2 00:50:38.860: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:50:38.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rjl2n" for this suite.
Feb  2 00:51:00.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:51:00.889: INFO: namespace: e2e-tests-container-lifecycle-hook-rjl2n, resource: bindings, ignored listing per whitelist
Feb  2 00:51:00.948: INFO: namespace e2e-tests-container-lifecycle-hook-rjl2n deletion completed in 22.0846101s

â€¢ [SLOW TEST:50.193 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:51:00.953: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:51:01.007: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c38dd98-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-7h5w7" to be "success or failure"
Feb  2 00:51:01.008: INFO: Pod "downwardapi-volume-9c38dd98-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.4797ms
Feb  2 00:51:03.013: INFO: Pod "downwardapi-volume-9c38dd98-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0058712s
STEP: Saw pod success
Feb  2 00:51:03.013: INFO: Pod "downwardapi-volume-9c38dd98-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:51:03.015: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-9c38dd98-2684-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:51:03.042: INFO: Waiting for pod downwardapi-volume-9c38dd98-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:51:03.047: INFO: Pod downwardapi-volume-9c38dd98-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:51:03.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7h5w7" for this suite.
Feb  2 00:51:09.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:51:09.040: INFO: namespace: e2e-tests-projected-7h5w7, resource: bindings, ignored listing per whitelist
Feb  2 00:51:09.115: INFO: namespace e2e-tests-projected-7h5w7 deletion completed in 6.0984409s

â€¢ [SLOW TEST:8.197 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:51:09.115: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  2 00:51:09.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a117b85c-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-49vrx" to be "success or failure"
Feb  2 00:51:09.183: INFO: Pod "downwardapi-volume-a117b85c-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.3371ms
Feb  2 00:51:11.189: INFO: Pod "downwardapi-volume-a117b85c-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0102543s
STEP: Saw pod success
Feb  2 00:51:11.190: INFO: Pod "downwardapi-volume-a117b85c-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:51:11.194: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-a117b85c-2684-11e9-a68a-f677bb5aadde container client-container: <nil>
STEP: delete the pod
Feb  2 00:51:11.219: INFO: Waiting for pod downwardapi-volume-a117b85c-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:51:11.224: INFO: Pod downwardapi-volume-a117b85c-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:51:11.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-49vrx" for this suite.
Feb  2 00:51:17.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:51:17.294: INFO: namespace: e2e-tests-projected-49vrx, resource: bindings, ignored listing per whitelist
Feb  2 00:51:17.311: INFO: namespace e2e-tests-projected-49vrx deletion completed in 6.0832454s

â€¢ [SLOW TEST:8.196 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:51:17.312: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a5f9ea9b-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:51:17.375: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a5fa63f0-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-mtngb" to be "success or failure"
Feb  2 00:51:17.377: INFO: Pod "pod-projected-configmaps-a5fa63f0-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.6744ms
Feb  2 00:51:19.382: INFO: Pod "pod-projected-configmaps-a5fa63f0-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0075833s
STEP: Saw pod success
Feb  2 00:51:19.382: INFO: Pod "pod-projected-configmaps-a5fa63f0-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:51:19.387: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-a5fa63f0-2684-11e9-a68a-f677bb5aadde container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:51:19.416: INFO: Waiting for pod pod-projected-configmaps-a5fa63f0-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:51:19.421: INFO: Pod pod-projected-configmaps-a5fa63f0-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:51:19.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mtngb" for this suite.
Feb  2 00:51:25.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:51:25.506: INFO: namespace: e2e-tests-projected-mtngb, resource: bindings, ignored listing per whitelist
Feb  2 00:51:25.508: INFO: namespace e2e-tests-projected-mtngb deletion completed in 6.0845048s

â€¢ [SLOW TEST:8.197 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:51:25.508: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  2 00:51:25.560: INFO: Waiting up to 5m0s for pod "pod-aadb74dc-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-fdmss" to be "success or failure"
Feb  2 00:51:25.567: INFO: Pod "pod-aadb74dc-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 6.7512ms
Feb  2 00:51:27.569: INFO: Pod "pod-aadb74dc-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0094047s
STEP: Saw pod success
Feb  2 00:51:27.569: INFO: Pod "pod-aadb74dc-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:51:27.571: INFO: Trying to get logs from node docker-desktop pod pod-aadb74dc-2684-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:51:27.587: INFO: Waiting for pod pod-aadb74dc-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:51:27.589: INFO: Pod pod-aadb74dc-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:51:27.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fdmss" for this suite.
Feb  2 00:51:33.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:51:33.671: INFO: namespace: e2e-tests-emptydir-fdmss, resource: bindings, ignored listing per whitelist
Feb  2 00:51:33.677: INFO: namespace e2e-tests-emptydir-fdmss deletion completed in 6.0849676s

â€¢ [SLOW TEST:8.169 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:51:33.678: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:51:33.732: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  2 00:51:38.703: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  2 00:51:38.703: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  2 00:51:40.707: INFO: Creating deployment "test-rollover-deployment"
Feb  2 00:51:40.713: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  2 00:51:42.721: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  2 00:51:42.726: INFO: Ensure that both replica sets have 1 created replica
Feb  2 00:51:42.730: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  2 00:51:42.737: INFO: Updating deployment test-rollover-deployment
Feb  2 00:51:42.737: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  2 00:51:44.745: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  2 00:51:44.751: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  2 00:51:44.756: INFO: all replica sets need to contain the pod-template-hash label
Feb  2 00:51:44.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665502, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  2 00:51:46.763: INFO: all replica sets need to contain the pod-template-hash label
Feb  2 00:51:46.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  2 00:51:48.764: INFO: all replica sets need to contain the pod-template-hash label
Feb  2 00:51:48.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  2 00:51:50.763: INFO: all replica sets need to contain the pod-template-hash label
Feb  2 00:51:50.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  2 00:51:52.764: INFO: all replica sets need to contain the pod-template-hash label
Feb  2 00:51:52.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  2 00:51:54.764: INFO: all replica sets need to contain the pod-template-hash label
Feb  2 00:51:54.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684665500, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  2 00:51:56.765: INFO: 
Feb  2 00:51:56.765: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  2 00:51:56.771: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-2qppf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2qppf/deployments/test-rollover-deployment,UID:b3e3b128-2684-11e9-b4dc-025000000001,ResourceVersion:25932,Generation:2,CreationTimestamp:2019-02-02 00:51:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-02 00:51:40 +0000 UTC 2019-02-02 00:51:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-02 00:51:55 +0000 UTC 2019-02-02 00:51:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  2 00:51:56.775: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-2qppf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2qppf/replicasets/test-rollover-deployment-6b7f9d6597,UID:b5193a45-2684-11e9-b4dc-025000000001,ResourceVersion:25922,Generation:2,CreationTimestamp:2019-02-02 00:51:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b3e3b128-2684-11e9-b4dc-025000000001 0xc001f869f7 0xc001f869f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  2 00:51:56.775: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  2 00:51:56.775: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-2qppf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2qppf/replicasets/test-rollover-controller,UID:afba8458-2684-11e9-b4dc-025000000001,ResourceVersion:25931,Generation:2,CreationTimestamp:2019-02-02 00:51:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b3e3b128-2684-11e9-b4dc-025000000001 0xc001f86807 0xc001f86808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  2 00:51:56.775: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-2qppf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2qppf/replicasets/test-rollover-deployment-6586df867b,UID:b3e5f7d3-2684-11e9-b4dc-025000000001,ResourceVersion:25895,Generation:2,CreationTimestamp:2019-02-02 00:51:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b3e3b128-2684-11e9-b4dc-025000000001 0xc001f868c7 0xc001f868c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  2 00:51:56.778: INFO: Pod "test-rollover-deployment-6b7f9d6597-g82dw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-g82dw,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-2qppf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2qppf/pods/test-rollover-deployment-6b7f9d6597-g82dw,UID:b51c74ed-2684-11e9-b4dc-025000000001,ResourceVersion:25909,Generation:0,CreationTimestamp:2019-02-02 00:51:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 b5193a45-2684-11e9-b4dc-025000000001 0xc001f87fc7 0xc001f87fc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rt5lk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rt5lk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rt5lk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c52430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c52450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:51:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:51:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:51:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-02 00:51:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.1.55,StartTime:2019-02-02 00:51:42 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-02 00:51:44 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://aff4306e192e7644b5cdc8d248159f04440060eb22063222cb6d4bba9a44d582}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:51:56.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2qppf" for this suite.
Feb  2 00:52:02.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:52:02.878: INFO: namespace: e2e-tests-deployment-2qppf, resource: bindings, ignored listing per whitelist
Feb  2 00:52:02.897: INFO: namespace e2e-tests-deployment-2qppf deletion completed in 6.1166249s

â€¢ [SLOW TEST:29.254 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:52:02.900: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  2 00:52:05.463: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c12646b5-2684-11e9-a68a-f677bb5aadde"
Feb  2 00:52:05.463: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c12646b5-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-pods-nrcmd" to be "terminated due to deadline exceeded"
Feb  2 00:52:05.466: INFO: Pod "pod-update-activedeadlineseconds-c12646b5-2684-11e9-a68a-f677bb5aadde": Phase="Running", Reason="", readiness=true. Elapsed: 3.4518ms
Feb  2 00:52:07.471: INFO: Pod "pod-update-activedeadlineseconds-c12646b5-2684-11e9-a68a-f677bb5aadde": Phase="Running", Reason="", readiness=true. Elapsed: 2.0079222s
Feb  2 00:52:09.476: INFO: Pod "pod-update-activedeadlineseconds-c12646b5-2684-11e9-a68a-f677bb5aadde": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.0132418s
Feb  2 00:52:09.476: INFO: Pod "pod-update-activedeadlineseconds-c12646b5-2684-11e9-a68a-f677bb5aadde" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:52:09.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nrcmd" for this suite.
Feb  2 00:52:15.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:52:15.558: INFO: namespace: e2e-tests-pods-nrcmd, resource: bindings, ignored listing per whitelist
Feb  2 00:52:15.565: INFO: namespace e2e-tests-pods-nrcmd deletion completed in 6.0857837s

â€¢ [SLOW TEST:12.700 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:52:15.566: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c8b1c57d-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:52:15.622: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c8b23134-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-projected-4l9br" to be "success or failure"
Feb  2 00:52:15.624: INFO: Pod "pod-projected-secrets-c8b23134-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.9816ms
Feb  2 00:52:17.627: INFO: Pod "pod-projected-secrets-c8b23134-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0050639s
STEP: Saw pod success
Feb  2 00:52:17.628: INFO: Pod "pod-projected-secrets-c8b23134-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:52:17.630: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-c8b23134-2684-11e9-a68a-f677bb5aadde container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  2 00:52:17.655: INFO: Waiting for pod pod-projected-secrets-c8b23134-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:52:17.659: INFO: Pod pod-projected-secrets-c8b23134-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:52:17.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4l9br" for this suite.
Feb  2 00:52:23.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:52:23.708: INFO: namespace: e2e-tests-projected-4l9br, resource: bindings, ignored listing per whitelist
Feb  2 00:52:23.750: INFO: namespace e2e-tests-projected-4l9br deletion completed in 6.0877212s

â€¢ [SLOW TEST:8.184 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:52:23.750: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  2 00:52:23.805: INFO: (0) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 4.2467ms)
Feb  2 00:52:23.807: INFO: (1) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.1387ms)
Feb  2 00:52:23.810: INFO: (2) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2336ms)
Feb  2 00:52:23.812: INFO: (3) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.0011ms)
Feb  2 00:52:23.814: INFO: (4) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.3708ms)
Feb  2 00:52:23.817: INFO: (5) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.5276ms)
Feb  2 00:52:23.819: INFO: (6) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.7786ms)
Feb  2 00:52:23.822: INFO: (7) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.832ms)
Feb  2 00:52:23.825: INFO: (8) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.4232ms)
Feb  2 00:52:23.827: INFO: (9) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2245ms)
Feb  2 00:52:23.830: INFO: (10) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.4677ms)
Feb  2 00:52:23.833: INFO: (11) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.9895ms)
Feb  2 00:52:23.835: INFO: (12) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.5002ms)
Feb  2 00:52:23.837: INFO: (13) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2723ms)
Feb  2 00:52:23.840: INFO: (14) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.7768ms)
Feb  2 00:52:23.843: INFO: (15) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2004ms)
Feb  2 00:52:23.845: INFO: (16) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.2977ms)
Feb  2 00:52:23.847: INFO: (17) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 2.1935ms)
Feb  2 00:52:23.852: INFO: (18) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 4.56ms)
Feb  2 00:52:23.861: INFO: (19) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="diagnose.log">diagnose.log</a>
<a href="dock... (200; 9.1519ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:52:23.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-d8pfw" for this suite.
Feb  2 00:52:29.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:52:29.935: INFO: namespace: e2e-tests-proxy-d8pfw, resource: bindings, ignored listing per whitelist
Feb  2 00:52:29.945: INFO: namespace e2e-tests-proxy-d8pfw deletion completed in 6.0814652s

â€¢ [SLOW TEST:6.195 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:52:29.945: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0202 00:53:00.494957      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  2 00:53:00.495: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:53:00.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-2s6tq" for this suite.
Feb  2 00:53:06.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:53:06.504: INFO: namespace: e2e-tests-gc-2s6tq, resource: bindings, ignored listing per whitelist
Feb  2 00:53:06.539: INFO: namespace e2e-tests-gc-2s6tq deletion completed in 6.0759496s

â€¢ [SLOW TEST:36.663 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:53:06.539: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e71385b6-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume configMaps
Feb  2 00:53:06.595: INFO: Waiting up to 5m0s for pod "pod-configmaps-e7141521-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-configmap-27kdx" to be "success or failure"
Feb  2 00:53:06.609: INFO: Pod "pod-configmaps-e7141521-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 14.2127ms
Feb  2 00:53:08.614: INFO: Pod "pod-configmaps-e7141521-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0196369s
STEP: Saw pod success
Feb  2 00:53:08.614: INFO: Pod "pod-configmaps-e7141521-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:53:08.617: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-e7141521-2684-11e9-a68a-f677bb5aadde container configmap-volume-test: <nil>
STEP: delete the pod
Feb  2 00:53:08.636: INFO: Waiting for pod pod-configmaps-e7141521-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:53:08.641: INFO: Pod pod-configmaps-e7141521-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:53:08.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-27kdx" for this suite.
Feb  2 00:53:14.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:53:14.689: INFO: namespace: e2e-tests-configmap-27kdx, resource: bindings, ignored listing per whitelist
Feb  2 00:53:14.729: INFO: namespace e2e-tests-configmap-27kdx deletion completed in 6.0816537s

â€¢ [SLOW TEST:8.190 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:53:14.729: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  2 00:53:14.778: INFO: Waiting up to 5m0s for pod "pod-ebf4eae9-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-8jr2j" to be "success or failure"
Feb  2 00:53:14.784: INFO: Pod "pod-ebf4eae9-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 5.72ms
Feb  2 00:53:16.789: INFO: Pod "pod-ebf4eae9-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0103s
STEP: Saw pod success
Feb  2 00:53:16.789: INFO: Pod "pod-ebf4eae9-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:53:16.791: INFO: Trying to get logs from node docker-desktop pod pod-ebf4eae9-2684-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:53:16.815: INFO: Waiting for pod pod-ebf4eae9-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:53:16.818: INFO: Pod pod-ebf4eae9-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:53:16.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8jr2j" for this suite.
Feb  2 00:53:22.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:53:22.856: INFO: namespace: e2e-tests-emptydir-8jr2j, resource: bindings, ignored listing per whitelist
Feb  2 00:53:22.906: INFO: namespace e2e-tests-emptydir-8jr2j deletion completed in 6.084956s

â€¢ [SLOW TEST:8.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:53:22.906: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb  2 00:53:22.971: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-g9kvn" to be "success or failure"
Feb  2 00:53:22.975: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.2843ms
Feb  2 00:53:24.981: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0103349s
STEP: Saw pod success
Feb  2 00:53:24.981: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  2 00:53:24.985: INFO: Trying to get logs from node docker-desktop pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  2 00:53:25.012: INFO: Waiting for pod pod-host-path-test to disappear
Feb  2 00:53:25.020: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:53:25.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-g9kvn" for this suite.
Feb  2 00:53:31.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:53:31.104: INFO: namespace: e2e-tests-hostpath-g9kvn, resource: bindings, ignored listing per whitelist
Feb  2 00:53:31.115: INFO: namespace e2e-tests-hostpath-g9kvn deletion completed in 6.0917418s

â€¢ [SLOW TEST:8.209 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:53:31.116: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  2 00:53:31.171: INFO: Waiting up to 5m0s for pod "pod-f5ba3c8f-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-emptydir-cdl7x" to be "success or failure"
Feb  2 00:53:31.174: INFO: Pod "pod-f5ba3c8f-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.519ms
Feb  2 00:53:33.177: INFO: Pod "pod-f5ba3c8f-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0061259s
STEP: Saw pod success
Feb  2 00:53:33.177: INFO: Pod "pod-f5ba3c8f-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:53:33.180: INFO: Trying to get logs from node docker-desktop pod pod-f5ba3c8f-2684-11e9-a68a-f677bb5aadde container test-container: <nil>
STEP: delete the pod
Feb  2 00:53:33.210: INFO: Waiting for pod pod-f5ba3c8f-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:53:33.220: INFO: Pod pod-f5ba3c8f-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:53:33.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cdl7x" for this suite.
Feb  2 00:53:39.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:53:39.246: INFO: namespace: e2e-tests-emptydir-cdl7x, resource: bindings, ignored listing per whitelist
Feb  2 00:53:39.279: INFO: namespace e2e-tests-emptydir-cdl7x deletion completed in 6.0841852s

â€¢ [SLOW TEST:8.198 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:53:39.279: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fa97b7b5-2684-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 00:53:39.357: INFO: Waiting up to 5m0s for pod "pod-secrets-fa9b4608-2684-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-m22s8" to be "success or failure"
Feb  2 00:53:39.368: INFO: Pod "pod-secrets-fa9b4608-2684-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 11.1422ms
Feb  2 00:53:41.372: INFO: Pod "pod-secrets-fa9b4608-2684-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0152133s
STEP: Saw pod success
Feb  2 00:53:41.372: INFO: Pod "pod-secrets-fa9b4608-2684-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 00:53:41.375: INFO: Trying to get logs from node docker-desktop pod pod-secrets-fa9b4608-2684-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  2 00:53:41.396: INFO: Waiting for pod pod-secrets-fa9b4608-2684-11e9-a68a-f677bb5aadde to disappear
Feb  2 00:53:41.399: INFO: Pod pod-secrets-fa9b4608-2684-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:53:41.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-m22s8" for this suite.
Feb  2 00:53:47.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:53:47.478: INFO: namespace: e2e-tests-secrets-m22s8, resource: bindings, ignored listing per whitelist
Feb  2 00:53:47.490: INFO: namespace e2e-tests-secrets-m22s8 deletion completed in 6.0813905s
STEP: Destroying namespace "e2e-tests-secret-namespace-xzlkp" for this suite.
Feb  2 00:53:53.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:53:53.536: INFO: namespace: e2e-tests-secret-namespace-xzlkp, resource: bindings, ignored listing per whitelist
Feb  2 00:53:53.565: INFO: namespace e2e-tests-secret-namespace-xzlkp deletion completed in 6.0750801s

â€¢ [SLOW TEST:14.286 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:53:53.566: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-031bc005-2685-11e9-a68a-f677bb5aadde
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-031bc005-2685-11e9-a68a-f677bb5aadde
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:53:57.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lsxjt" for this suite.
Feb  2 00:54:19.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:54:19.685: INFO: namespace: e2e-tests-configmap-lsxjt, resource: bindings, ignored listing per whitelist
Feb  2 00:54:19.716: INFO: namespace e2e-tests-configmap-lsxjt deletion completed in 22.0749304s

â€¢ [SLOW TEST:26.185 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:54:19.716: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  2 00:54:25.806: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  2 00:54:25.812: INFO: Pod pod-with-prestop-http-hook still exists
Feb  2 00:54:27.813: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  2 00:54:27.818: INFO: Pod pod-with-prestop-http-hook still exists
Feb  2 00:54:29.813: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  2 00:54:29.818: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:54:29.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6mrgh" for this suite.
Feb  2 00:54:51.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:54:51.859: INFO: namespace: e2e-tests-container-lifecycle-hook-6mrgh, resource: bindings, ignored listing per whitelist
Feb  2 00:54:51.904: INFO: namespace e2e-tests-container-lifecycle-hook-6mrgh deletion completed in 22.1083472s

â€¢ [SLOW TEST:32.222 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:54:51.904: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-x9jmw;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x9jmw.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.145.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.145.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.145.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.145.202_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-x9jmw;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-x9jmw.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-x9jmw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x9jmw.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.145.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.145.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.145.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.145.202_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  2 00:54:56.001: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.011: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.025: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.027: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.029: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.031: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.034: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.037: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.039: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.041: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:54:56.061: INFO: Lookups using e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-x9jmw jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc]

Feb  2 00:55:01.072: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.082: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.097: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.098: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.100: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.102: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.104: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.106: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.108: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.110: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:01.121: INFO: Lookups using e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-x9jmw jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc]

Feb  2 00:55:06.041: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.052: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.072: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.074: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.076: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.080: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.083: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.085: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.087: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.091: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:06.106: INFO: Lookups using e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-x9jmw jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc]

Feb  2 00:55:11.049: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.060: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.074: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.076: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.079: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.081: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.083: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.086: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.088: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.090: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:11.104: INFO: Lookups using e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-x9jmw jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc]

Feb  2 00:55:16.043: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.052: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.066: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.069: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.071: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.073: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.078: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.081: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.083: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.086: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:16.118: INFO: Lookups using e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-x9jmw jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc]

Feb  2 00:55:21.044: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.054: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.071: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.073: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.075: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.077: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.080: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.082: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.083: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.085: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc from pod e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde: the server could not find the requested resource (get pods dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde)
Feb  2 00:55:21.096: INFO: Lookups using e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-x9jmw wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-x9jmw jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw jessie_udp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@dns-test-service.e2e-tests-dns-x9jmw.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-x9jmw.svc]

Feb  2 00:55:26.098: INFO: DNS probes using e2e-tests-dns-x9jmw/dns-test-25e3922c-2685-11e9-a68a-f677bb5aadde succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:55:26.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-x9jmw" for this suite.
Feb  2 00:55:32.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:55:32.230: INFO: namespace: e2e-tests-dns-x9jmw, resource: bindings, ignored listing per whitelist
Feb  2 00:55:32.269: INFO: namespace e2e-tests-dns-x9jmw deletion completed in 6.0924782s

â€¢ [SLOW TEST:40.399 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:55:32.269: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-sj9nl
Feb  2 00:55:36.293: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-sj9nl
STEP: checking the pod's current state and verifying that restartCount is present
Feb  2 00:55:36.296: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 00:59:36.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sj9nl" for this suite.
Feb  2 00:59:42.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 00:59:42.731: INFO: namespace: e2e-tests-container-probe-sj9nl, resource: bindings, ignored listing per whitelist
Feb  2 00:59:42.735: INFO: namespace e2e-tests-container-probe-sj9nl deletion completed in 6.0786629s

â€¢ [SLOW TEST:250.778 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 00:59:42.735: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-czvhs
Feb  2 00:59:44.796: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-czvhs
STEP: checking the pod's current state and verifying that restartCount is present
Feb  2 00:59:44.798: INFO: Initial restart count of pod liveness-http is 0
Feb  2 01:00:06.812: INFO: Restart count of pod e2e-tests-container-probe-czvhs/liveness-http is now 1 (22.0479593s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 01:00:06.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-czvhs" for this suite.
Feb  2 01:00:12.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 01:00:12.894: INFO: namespace: e2e-tests-container-probe-czvhs, resource: bindings, ignored listing per whitelist
Feb  2 01:00:12.913: INFO: namespace e2e-tests-container-probe-czvhs deletion completed in 6.0835788s

â€¢ [SLOW TEST:30.212 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 01:00:12.913: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-e5377178-2685-11e9-a68a-f677bb5aadde
STEP: Creating a pod to test consume secrets
Feb  2 01:00:12.974: INFO: Waiting up to 5m0s for pod "pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde" in namespace "e2e-tests-secrets-4cwjk" to be "success or failure"
Feb  2 01:00:12.982: INFO: Pod "pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 8.1585ms
Feb  2 01:00:14.990: INFO: Pod "pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016034s
Feb  2 01:00:16.994: INFO: Pod "pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0201307s
STEP: Saw pod success
Feb  2 01:00:16.994: INFO: Pod "pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde" satisfied condition "success or failure"
Feb  2 01:00:16.998: INFO: Trying to get logs from node docker-desktop pod pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde container secret-volume-test: <nil>
STEP: delete the pod
Feb  2 01:00:17.020: INFO: Waiting for pod pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde to disappear
Feb  2 01:00:17.023: INFO: Pod pod-secrets-e538047f-2685-11e9-a68a-f677bb5aadde no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 01:00:17.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4cwjk" for this suite.
Feb  2 01:00:23.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 01:00:23.052: INFO: namespace: e2e-tests-secrets-4cwjk, resource: bindings, ignored listing per whitelist
Feb  2 01:00:23.112: INFO: namespace e2e-tests-secrets-4cwjk deletion completed in 6.0857576s

â€¢ [SLOW TEST:10.199 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 01:00:23.112: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  2 01:00:23.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8ddnd'
Feb  2 01:00:23.370: INFO: stderr: ""
Feb  2 01:00:23.370: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb  2 01:00:28.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8ddnd -o json'
Feb  2 01:00:28.496: INFO: stderr: ""
Feb  2 01:00:28.496: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-02T01:00:23Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-8ddnd\",\n        \"resourceVersion\": \"27045\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-8ddnd/pods/e2e-test-nginx-pod\",\n        \"uid\": \"eb677239-2685-11e9-b4dc-025000000001\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-d8f7j\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"docker-desktop\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-d8f7j\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-d8f7j\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-02T01:00:23Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-02T01:00:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-02T01:00:25Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-02T01:00:23Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://ee08b3f93257ad6a6fdbcdcd886386034c8aeecfacc21c4a0e4303b6ee3aa980\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-02T01:00:24Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.65.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.1.72\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-02T01:00:23Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  2 01:00:28.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 replace -f - --namespace=e2e-tests-kubectl-8ddnd'
Feb  2 01:00:28.622: INFO: stderr: ""
Feb  2 01:00:28.622: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb  2 01:00:28.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8ddnd'
Feb  2 01:00:30.512: INFO: stderr: ""
Feb  2 01:00:30.512: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 01:00:30.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8ddnd" for this suite.
Feb  2 01:00:36.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 01:00:36.543: INFO: namespace: e2e-tests-kubectl-8ddnd, resource: bindings, ignored listing per whitelist
Feb  2 01:00:36.568: INFO: namespace e2e-tests-kubectl-8ddnd deletion completed in 6.0867552s

â€¢ [SLOW TEST:13.491 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 01:00:36.568: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb  2 01:00:36.617: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  2 01:00:36.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:00:36.745: INFO: stderr: ""
Feb  2 01:00:36.745: INFO: stdout: "service/redis-slave created\n"
Feb  2 01:00:36.745: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  2 01:00:36.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:00:36.884: INFO: stderr: ""
Feb  2 01:00:36.884: INFO: stdout: "service/redis-master created\n"
Feb  2 01:00:36.884: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  2 01:00:36.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:00:37.012: INFO: stderr: ""
Feb  2 01:00:37.012: INFO: stdout: "service/frontend created\n"
Feb  2 01:00:37.013: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  2 01:00:37.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:00:37.143: INFO: stderr: ""
Feb  2 01:00:37.143: INFO: stdout: "deployment.extensions/frontend created\n"
Feb  2 01:00:37.144: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  2 01:00:37.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:00:37.329: INFO: stderr: ""
Feb  2 01:00:37.329: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb  2 01:00:37.329: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  2 01:00:37.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 create -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:00:37.472: INFO: stderr: ""
Feb  2 01:00:37.472: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb  2 01:00:37.473: INFO: Waiting for all frontend pods to be Running.
Feb  2 01:01:02.528: INFO: Waiting for frontend to serve content.
Feb  2 01:01:07.537: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb  2 01:01:12.559: INFO: Trying to add a new entry to the guestbook.
Feb  2 01:01:12.579: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb  2 01:01:12.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:01:12.769: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 01:01:12.769: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  2 01:01:12.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:01:12.931: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 01:01:12.931: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  2 01:01:12.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:01:13.092: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 01:01:13.092: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  2 01:01:13.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:01:13.242: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 01:01:13.242: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  2 01:01:13.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:01:13.512: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 01:01:13.512: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  2 01:01:13.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-249251776 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-llp8t'
Feb  2 01:01:13.899: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  2 01:01:13.899: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 01:01:13.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-llp8t" for this suite.
Feb  2 01:02:05.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 01:02:05.911: INFO: namespace: e2e-tests-kubectl-llp8t, resource: bindings, ignored listing per whitelist
Feb  2 01:02:05.969: INFO: namespace e2e-tests-kubectl-llp8t deletion completed in 52.1063878s

â€¢ [SLOW TEST:89.505 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  2 01:02:05.969: INFO: >>> kubeConfig: /tmp/kubeconfig-249251776
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb  2 01:02:06.019: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-249251776 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  2 01:02:06.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bjbx9" for this suite.
Feb  2 01:02:12.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  2 01:02:12.169: INFO: namespace: e2e-tests-kubectl-bjbx9, resource: bindings, ignored listing per whitelist
Feb  2 01:02:12.178: INFO: namespace e2e-tests-kubectl-bjbx9 deletion completed in 6.0793239s

â€¢ [SLOW TEST:6.209 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSFeb  2 01:02:12.178: INFO: Running AfterSuite actions on all nodes
Feb  2 01:02:12.179: INFO: Running AfterSuite actions on node 1
Feb  2 01:02:12.179: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5474.702 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h31m15.4386722s
Test Suite Passed
