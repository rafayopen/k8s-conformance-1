Conformance test: not doing test setup.
I0301 07:37:58.974614   31738 e2e.go:224] Starting e2e run "ef40428f-3bf4-11e9-9193-2e670c8e304c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551425878 - Will randomize all specs
Will run 201 of 2161 specs

Mar  1 07:37:59.211: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 07:37:59.213: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  1 07:37:59.393: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  1 07:37:59.589: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  1 07:37:59.589: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Mar  1 07:37:59.589: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  1 07:37:59.630: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Mar  1 07:37:59.630: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar  1 07:37:59.630: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Mar  1 07:37:59.630: INFO: e2e test version: v1.13.3
Mar  1 07:37:59.664: INFO: kube-apiserver version: v1.13.3
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:37:59.664: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
Mar  1 07:38:01.021: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Mar  1 07:38:01.140: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-d2zdt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar  1 07:38:01.418: INFO: Waiting up to 5m0s for pod "client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c" in namespace "e2e-tests-containers-d2zdt" to be "success or failure"
Mar  1 07:38:01.464: INFO: Pod "client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 46.419422ms
Mar  1 07:38:03.500: INFO: Pod "client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082413545s
Mar  1 07:38:05.537: INFO: Pod "client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11954678s
Mar  1 07:38:07.573: INFO: Pod "client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.155293705s
STEP: Saw pod success
Mar  1 07:38:07.573: INFO: Pod "client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:38:07.607: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 07:38:07.821: INFO: Waiting for pod client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c to disappear
Mar  1 07:38:07.855: INFO: Pod client-containers-f10e0641-3bf4-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:38:07.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-d2zdt" for this suite.
Mar  1 07:38:13.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:38:14.643: INFO: namespace: e2e-tests-containers-d2zdt, resource: bindings, ignored listing per whitelist
Mar  1 07:38:15.489: INFO: namespace e2e-tests-containers-d2zdt deletion completed in 7.597888628s

• [SLOW TEST:15.825 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:38:15.489: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-lgsfc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lgsfc
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar  1 07:38:17.198: INFO: Found 1 stateful pods, waiting for 3
Mar  1 07:38:27.234: INFO: Found 2 stateful pods, waiting for 3
Mar  1 07:38:37.235: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:38:37.235: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:38:37.235: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 07:38:37.425: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  1 07:38:37.576: INFO: Updating stateful set ss2
Mar  1 07:38:37.646: INFO: Waiting for Pod e2e-tests-statefulset-lgsfc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar  1 07:38:47.844: INFO: Found 2 stateful pods, waiting for 3
Mar  1 07:38:57.880: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:38:57.883: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:38:57.883: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  1 07:38:58.040: INFO: Updating stateful set ss2
Mar  1 07:38:58.117: INFO: Waiting for Pod e2e-tests-statefulset-lgsfc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 07:39:08.272: INFO: Updating stateful set ss2
Mar  1 07:39:08.344: INFO: Waiting for StatefulSet e2e-tests-statefulset-lgsfc/ss2 to complete update
Mar  1 07:39:08.345: INFO: Waiting for Pod e2e-tests-statefulset-lgsfc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 07:39:18.417: INFO: Waiting for StatefulSet e2e-tests-statefulset-lgsfc/ss2 to complete update
Mar  1 07:39:18.417: INFO: Waiting for Pod e2e-tests-statefulset-lgsfc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 07:39:28.415: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lgsfc
Mar  1 07:39:28.450: INFO: Scaling statefulset ss2 to 0
Mar  1 07:39:58.599: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:39:58.637: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:39:58.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lgsfc" for this suite.
Mar  1 07:40:06.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:40:07.048: INFO: namespace: e2e-tests-statefulset-lgsfc, resource: bindings, ignored listing per whitelist
Mar  1 07:40:08.317: INFO: namespace e2e-tests-statefulset-lgsfc deletion completed in 9.508687007s

• [SLOW TEST:112.828 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:40:08.317: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-94bsv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 07:40:09.798: INFO: Waiting up to 5m0s for pod "pod-3d936374-3bf5-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-94bsv" to be "success or failure"
Mar  1 07:40:09.836: INFO: Pod "pod-3d936374-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 38.084476ms
Mar  1 07:40:11.873: INFO: Pod "pod-3d936374-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074594123s
Mar  1 07:40:13.908: INFO: Pod "pod-3d936374-3bf5-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110002721s
STEP: Saw pod success
Mar  1 07:40:13.908: INFO: Pod "pod-3d936374-3bf5-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:40:13.943: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-3d936374-3bf5-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 07:40:14.032: INFO: Waiting for pod pod-3d936374-3bf5-11e9-9193-2e670c8e304c to disappear
Mar  1 07:40:14.067: INFO: Pod pod-3d936374-3bf5-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:40:14.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-94bsv" for this suite.
Mar  1 07:40:20.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:40:20.627: INFO: namespace: e2e-tests-emptydir-94bsv, resource: bindings, ignored listing per whitelist
Mar  1 07:40:21.533: INFO: namespace e2e-tests-emptydir-94bsv deletion completed in 7.428396032s

• [SLOW TEST:13.216 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:40:21.533: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-ns6cs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 07:40:23.074: INFO: Creating ReplicaSet my-hostname-basic-4582dd6b-3bf5-11e9-9193-2e670c8e304c
Mar  1 07:40:23.146: INFO: Pod name my-hostname-basic-4582dd6b-3bf5-11e9-9193-2e670c8e304c: Found 1 pods out of 1
Mar  1 07:40:23.146: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4582dd6b-3bf5-11e9-9193-2e670c8e304c" is running
Mar  1 07:40:29.229: INFO: Pod "my-hostname-basic-4582dd6b-3bf5-11e9-9193-2e670c8e304c-4h8gx" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 07:40:23 +0000 UTC Reason: Message:}])
Mar  1 07:40:29.229: INFO: Trying to dial the pod
Mar  1 07:40:34.425: INFO: Controller my-hostname-basic-4582dd6b-3bf5-11e9-9193-2e670c8e304c: Got expected result from replica 1 [my-hostname-basic-4582dd6b-3bf5-11e9-9193-2e670c8e304c-4h8gx]: "my-hostname-basic-4582dd6b-3bf5-11e9-9193-2e670c8e304c-4h8gx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:40:34.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-ns6cs" for this suite.
Mar  1 07:40:42.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:40:42.740: INFO: namespace: e2e-tests-replicaset-ns6cs, resource: bindings, ignored listing per whitelist
Mar  1 07:40:43.974: INFO: namespace e2e-tests-replicaset-ns6cs deletion completed in 9.513258932s

• [SLOW TEST:22.441 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:40:43.974: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-vmxpt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-52dbf14b-3bf5-11e9-9193-2e670c8e304c
Mar  1 07:40:45.573: INFO: Pod name my-hostname-basic-52dbf14b-3bf5-11e9-9193-2e670c8e304c: Found 1 pods out of 1
Mar  1 07:40:45.573: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-52dbf14b-3bf5-11e9-9193-2e670c8e304c" are running
Mar  1 07:40:49.687: INFO: Pod "my-hostname-basic-52dbf14b-3bf5-11e9-9193-2e670c8e304c-9fv5d" is running (conditions: [])
Mar  1 07:40:49.687: INFO: Trying to dial the pod
Mar  1 07:40:54.884: INFO: Controller my-hostname-basic-52dbf14b-3bf5-11e9-9193-2e670c8e304c: Got expected result from replica 1 [my-hostname-basic-52dbf14b-3bf5-11e9-9193-2e670c8e304c-9fv5d]: "my-hostname-basic-52dbf14b-3bf5-11e9-9193-2e670c8e304c-9fv5d", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:40:54.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-vmxpt" for this suite.
Mar  1 07:41:01.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:41:01.439: INFO: namespace: e2e-tests-replication-controller-vmxpt, resource: bindings, ignored listing per whitelist
Mar  1 07:41:02.380: INFO: namespace e2e-tests-replication-controller-vmxpt deletion completed in 7.460661088s

• [SLOW TEST:18.406 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:41:02.380: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-zbzhl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 07:41:03.848: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:41:10.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zbzhl" for this suite.
Mar  1 07:41:16.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:41:17.681: INFO: namespace: e2e-tests-init-container-zbzhl, resource: bindings, ignored listing per whitelist
Mar  1 07:41:17.947: INFO: namespace e2e-tests-init-container-zbzhl deletion completed in 7.531535582s

• [SLOW TEST:15.567 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:41:17.947: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qn5g2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 07:41:19.533: INFO: Waiting up to 5m0s for pod "downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-qn5g2" to be "success or failure"
Mar  1 07:41:19.568: INFO: Pod "downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.894789ms
Mar  1 07:41:21.605: INFO: Pod "downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071974351s
Mar  1 07:41:23.640: INFO: Pod "downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107321232s
STEP: Saw pod success
Mar  1 07:41:23.640: INFO: Pod "downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:41:23.675: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:41:23.757: INFO: Waiting for pod downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c to disappear
Mar  1 07:41:23.792: INFO: Pod downward-api-6723efe9-3bf5-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:41:23.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qn5g2" for this suite.
Mar  1 07:41:29.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:41:30.290: INFO: namespace: e2e-tests-downward-api-qn5g2, resource: bindings, ignored listing per whitelist
Mar  1 07:41:31.301: INFO: namespace e2e-tests-downward-api-qn5g2 deletion completed in 7.472705319s

• [SLOW TEST:13.354 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:41:31.302: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-nl9rx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-npxn
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 07:41:32.959: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-npxn" in namespace "e2e-tests-subpath-nl9rx" to be "success or failure"
Mar  1 07:41:33.001: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Pending", Reason="", readiness=false. Elapsed: 42.280249ms
Mar  1 07:41:35.037: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077906653s
Mar  1 07:41:37.072: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113514129s
Mar  1 07:41:39.108: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 6.148959568s
Mar  1 07:41:41.143: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 8.184361615s
Mar  1 07:41:43.178: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 10.219702053s
Mar  1 07:41:45.225: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 12.266208678s
Mar  1 07:41:47.261: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 14.302090276s
Mar  1 07:41:49.298: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 16.339410329s
Mar  1 07:41:51.334: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 18.375704061s
Mar  1 07:41:53.370: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 20.410793686s
Mar  1 07:41:55.405: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Running", Reason="", readiness=false. Elapsed: 22.446271964s
Mar  1 07:41:57.448: INFO: Pod "pod-subpath-test-configmap-npxn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.488918344s
STEP: Saw pod success
Mar  1 07:41:57.448: INFO: Pod "pod-subpath-test-configmap-npxn" satisfied condition "success or failure"
Mar  1 07:41:57.483: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-subpath-test-configmap-npxn container test-container-subpath-configmap-npxn: <nil>
STEP: delete the pod
Mar  1 07:41:57.574: INFO: Waiting for pod pod-subpath-test-configmap-npxn to disappear
Mar  1 07:41:57.608: INFO: Pod pod-subpath-test-configmap-npxn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-npxn
Mar  1 07:41:57.608: INFO: Deleting pod "pod-subpath-test-configmap-npxn" in namespace "e2e-tests-subpath-nl9rx"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:41:57.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nl9rx" for this suite.
Mar  1 07:42:03.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:42:04.326: INFO: namespace: e2e-tests-subpath-nl9rx, resource: bindings, ignored listing per whitelist
Mar  1 07:42:05.203: INFO: namespace e2e-tests-subpath-nl9rx deletion completed in 7.525198848s

• [SLOW TEST:33.901 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:42:05.203: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n22cl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:42:06.695: INFO: Waiting up to 5m0s for pod "downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-n22cl" to be "success or failure"
Mar  1 07:42:06.729: INFO: Pod "downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.243011ms
Mar  1 07:42:08.765: INFO: Pod "downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06962358s
Mar  1 07:42:10.818: INFO: Pod "downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123514364s
STEP: Saw pod success
Mar  1 07:42:10.820: INFO: Pod "downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:42:10.879: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 07:42:10.971: INFO: Waiting for pod downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c to disappear
Mar  1 07:42:11.012: INFO: Pod downwardapi-volume-834067b7-3bf5-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:42:11.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n22cl" for this suite.
Mar  1 07:42:17.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:42:17.745: INFO: namespace: e2e-tests-projected-n22cl, resource: bindings, ignored listing per whitelist
Mar  1 07:42:18.554: INFO: namespace e2e-tests-projected-n22cl deletion completed in 7.493671494s

• [SLOW TEST:13.351 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:42:18.555: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-m7m28
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m7m28
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 07:42:20.087: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 07:42:50.745: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.17:8080/dial?request=hostName&protocol=udp&host=100.96.1.16&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-m7m28 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:42:50.745: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 07:42:51.373: INFO: Waiting for endpoints: map[]
Mar  1 07:42:51.408: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.17:8080/dial?request=hostName&protocol=udp&host=100.96.0.12&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-m7m28 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 07:42:51.408: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 07:42:52.002: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:42:52.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m7m28" for this suite.
Mar  1 07:43:14.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:43:15.206: INFO: namespace: e2e-tests-pod-network-test-m7m28, resource: bindings, ignored listing per whitelist
Mar  1 07:43:15.521: INFO: namespace e2e-tests-pod-network-test-m7m28 deletion completed in 23.483228352s

• [SLOW TEST:56.967 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:43:15.522: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-lcdfp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 07:43:25.596: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 07:43:25.636: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 07:43:27.637: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 07:43:27.673: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 07:43:29.636: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 07:43:29.672: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 07:43:31.637: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 07:43:31.672: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 07:43:33.636: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 07:43:33.671: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 07:43:35.636: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 07:43:35.671: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:43:35.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-lcdfp" for this suite.
Mar  1 07:43:57.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:43:58.178: INFO: namespace: e2e-tests-container-lifecycle-hook-lcdfp, resource: bindings, ignored listing per whitelist
Mar  1 07:43:59.259: INFO: namespace e2e-tests-container-lifecycle-hook-lcdfp deletion completed in 23.508274891s

• [SLOW TEST:43.738 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:43:59.259: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pm7tn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:44:00.797: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-pm7tn" to be "success or failure"
Mar  1 07:44:00.831: INFO: Pod "downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.021729ms
Mar  1 07:44:02.867: INFO: Pod "downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069766933s
Mar  1 07:44:04.903: INFO: Pod "downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105938145s
STEP: Saw pod success
Mar  1 07:44:04.903: INFO: Pod "downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:44:04.939: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 07:44:05.051: INFO: Waiting for pod downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c to disappear
Mar  1 07:44:05.085: INFO: Pod downwardapi-volume-c7430001-3bf5-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:44:05.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pm7tn" for this suite.
Mar  1 07:44:11.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:11.519: INFO: namespace: e2e-tests-projected-pm7tn, resource: bindings, ignored listing per whitelist
Mar  1 07:44:12.585: INFO: namespace e2e-tests-projected-pm7tn deletion completed in 7.463953891s

• [SLOW TEST:13.326 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:44:12.586: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-jhpbz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  1 07:44:14.201: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhpbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhpbz/configmaps/e2e-watch-test-watch-closed,UID:cf38e916-3bf5-11e9-a289-2aff89a14c6e,ResourceVersion:3699,Generation:0,CreationTimestamp:2019-03-01 07:44:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 07:44:14.201: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhpbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhpbz/configmaps/e2e-watch-test-watch-closed,UID:cf38e916-3bf5-11e9-a289-2aff89a14c6e,ResourceVersion:3700,Generation:0,CreationTimestamp:2019-03-01 07:44:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  1 07:44:14.342: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhpbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhpbz/configmaps/e2e-watch-test-watch-closed,UID:cf38e916-3bf5-11e9-a289-2aff89a14c6e,ResourceVersion:3702,Generation:0,CreationTimestamp:2019-03-01 07:44:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 07:44:14.343: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhpbz,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhpbz/configmaps/e2e-watch-test-watch-closed,UID:cf38e916-3bf5-11e9-a289-2aff89a14c6e,ResourceVersion:3703,Generation:0,CreationTimestamp:2019-03-01 07:44:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:44:14.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-jhpbz" for this suite.
Mar  1 07:44:20.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:21.759: INFO: namespace: e2e-tests-watch-jhpbz, resource: bindings, ignored listing per whitelist
Mar  1 07:44:21.864: INFO: namespace e2e-tests-watch-jhpbz deletion completed in 7.484120635s

• [SLOW TEST:9.278 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:44:21.864: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nvvjs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 07:44:23.360: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nvvjs'
Mar  1 07:44:23.785: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 07:44:23.785: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Mar  1 07:44:23.825: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-nvvjs'
Mar  1 07:44:24.396: INFO: stderr: ""
Mar  1 07:44:24.396: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:44:24.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nvvjs" for this suite.
Mar  1 07:44:30.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:44:30.841: INFO: namespace: e2e-tests-kubectl-nvvjs, resource: bindings, ignored listing per whitelist
Mar  1 07:44:31.900: INFO: namespace e2e-tests-kubectl-nvvjs deletion completed in 7.455016222s

• [SLOW TEST:10.036 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:44:31.900: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-9mp2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 07:44:33.464: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:44:37.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-9mp2p" for this suite.
Mar  1 07:44:59.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:45:00.739: INFO: namespace: e2e-tests-init-container-9mp2p, resource: bindings, ignored listing per whitelist
Mar  1 07:45:01.316: INFO: namespace e2e-tests-init-container-9mp2p deletion completed in 23.497387628s

• [SLOW TEST:29.415 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:45:01.316: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-nwjpl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 07:45:02.940: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Mar  1 07:45:03.013: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nwjpl/daemonsets","resourceVersion":"3851"},"items":null}

Mar  1 07:45:03.048: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nwjpl/pods","resourceVersion":"3851"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:45:03.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nwjpl" for this suite.
Mar  1 07:45:09.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:45:10.099: INFO: namespace: e2e-tests-daemonsets-nwjpl, resource: bindings, ignored listing per whitelist
Mar  1 07:45:10.710: INFO: namespace e2e-tests-daemonsets-nwjpl deletion completed in 7.518423345s

S [SKIPPING] [9.394 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar  1 07:45:02.940: Requires at least 2 nodes (not -1)

  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:45:10.710: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-n42sf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f1d1a224-3bf5-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 07:45:12.233: INFO: Waiting up to 5m0s for pod "pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-n42sf" to be "success or failure"
Mar  1 07:45:12.270: INFO: Pod "pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 36.760362ms
Mar  1 07:45:14.309: INFO: Pod "pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075660149s
Mar  1 07:45:16.346: INFO: Pod "pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.112428768s
STEP: Saw pod success
Mar  1 07:45:16.346: INFO: Pod "pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:45:16.381: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:45:16.469: INFO: Waiting for pod pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c to disappear
Mar  1 07:45:16.505: INFO: Pod pod-secrets-f1d71f86-3bf5-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:45:16.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n42sf" for this suite.
Mar  1 07:45:22.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:45:23.253: INFO: namespace: e2e-tests-secrets-n42sf, resource: bindings, ignored listing per whitelist
Mar  1 07:45:24.043: INFO: namespace e2e-tests-secrets-n42sf deletion completed in 7.50235548s

• [SLOW TEST:13.332 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:45:24.043: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-m7btf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 07:45:25.721: INFO: (0) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 126.975526ms)
Mar  1 07:45:25.757: INFO: (1) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.917725ms)
Mar  1 07:45:25.793: INFO: (2) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.841189ms)
Mar  1 07:45:25.829: INFO: (3) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.155595ms)
Mar  1 07:45:25.865: INFO: (4) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.646286ms)
Mar  1 07:45:25.902: INFO: (5) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.888838ms)
Mar  1 07:45:25.938: INFO: (6) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.073231ms)
Mar  1 07:45:25.974: INFO: (7) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.106894ms)
Mar  1 07:45:26.010: INFO: (8) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.153524ms)
Mar  1 07:45:26.047: INFO: (9) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.440612ms)
Mar  1 07:45:26.083: INFO: (10) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.912336ms)
Mar  1 07:45:26.165: INFO: (11) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 82.597625ms)
Mar  1 07:45:26.201: INFO: (12) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.642286ms)
Mar  1 07:45:26.237: INFO: (13) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.977525ms)
Mar  1 07:45:26.274: INFO: (14) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.765989ms)
Mar  1 07:45:26.310: INFO: (15) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.943415ms)
Mar  1 07:45:26.347: INFO: (16) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.542339ms)
Mar  1 07:45:26.383: INFO: (17) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.779789ms)
Mar  1 07:45:26.418: INFO: (18) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 35.826854ms)
Mar  1 07:45:26.455: INFO: (19) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.17802ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:45:26.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-m7btf" for this suite.
Mar  1 07:45:32.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:45:33.364: INFO: namespace: e2e-tests-proxy-m7btf, resource: bindings, ignored listing per whitelist
Mar  1 07:45:33.973: INFO: namespace e2e-tests-proxy-m7btf deletion completed in 7.482665025s

• [SLOW TEST:9.930 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:45:33.973: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nwzv4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-nwzv4/secret-test-ffb39d49-3bf5-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 07:45:35.522: INFO: Waiting up to 5m0s for pod "pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-nwzv4" to be "success or failure"
Mar  1 07:45:35.569: INFO: Pod "pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 46.932221ms
Mar  1 07:45:37.605: INFO: Pod "pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083169721s
Mar  1 07:45:39.641: INFO: Pod "pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.119281625s
STEP: Saw pod success
Mar  1 07:45:39.641: INFO: Pod "pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:45:39.676: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c container env-test: <nil>
STEP: delete the pod
Mar  1 07:45:39.759: INFO: Waiting for pod pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c to disappear
Mar  1 07:45:39.831: INFO: Pod pod-configmaps-ffb8f2f2-3bf5-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:45:39.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nwzv4" for this suite.
Mar  1 07:45:45.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:45:46.085: INFO: namespace: e2e-tests-secrets-nwzv4, resource: bindings, ignored listing per whitelist
Mar  1 07:45:47.357: INFO: namespace e2e-tests-secrets-nwzv4 deletion completed in 7.491316137s

• [SLOW TEST:13.384 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:45:47.357: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-h926h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-r76rv
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-26jpj
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:45:55.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-h926h" for this suite.
Mar  1 07:46:01.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:46:02.964: INFO: namespace: e2e-tests-namespaces-h926h, resource: bindings, ignored listing per whitelist
Mar  1 07:46:03.278: INFO: namespace e2e-tests-namespaces-h926h deletion completed in 7.481610472s
STEP: Destroying namespace "e2e-tests-nsdeletetest-r76rv" for this suite.
Mar  1 07:46:03.313: INFO: Namespace e2e-tests-nsdeletetest-r76rv was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-26jpj" for this suite.
Mar  1 07:46:09.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:46:09.882: INFO: namespace: e2e-tests-nsdeletetest-26jpj, resource: bindings, ignored listing per whitelist
Mar  1 07:46:10.762: INFO: namespace e2e-tests-nsdeletetest-26jpj deletion completed in 7.44921137s

• [SLOW TEST:23.405 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:46:10.762: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-w5svg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 07:46:12.349: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-w5svg'
Mar  1 07:46:12.988: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 07:46:12.988: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Mar  1 07:46:13.039: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-w5svg'
Mar  1 07:46:13.370: INFO: stderr: ""
Mar  1 07:46:13.370: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:46:13.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w5svg" for this suite.
Mar  1 07:46:19.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:46:20.258: INFO: namespace: e2e-tests-kubectl-w5svg, resource: bindings, ignored listing per whitelist
Mar  1 07:46:20.845: INFO: namespace e2e-tests-kubectl-w5svg deletion completed in 7.440643651s

• [SLOW TEST:10.083 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:46:20.846: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-g8ttm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar  1 07:46:22.454: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 07:46:22.524: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 07:46:22.560: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v before test
Mar  1 07:46:22.603: INFO: vpn-shoot-6f8cffc7cf-dss8s from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container vpn-shoot ready: true, restart count 0
Mar  1 07:46:22.603: INFO: coredns-67df79bbdd-vvpqk from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container coredns ready: true, restart count 0
Mar  1 07:46:22.603: INFO: addons-kube-lego-69bbdc96b6-kq9t6 from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container kube-lego ready: true, restart count 0
Mar  1 07:46:22.603: INFO: metrics-server-5887bb7679-cp4bx from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 07:46:22.603: INFO: blackbox-exporter-86f6cf4cb7-f8l2h from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container blackbox-exporter ready: true, restart count 0
Mar  1 07:46:22.603: INFO: kube-proxy-fm85v from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:46:22.603: INFO: calico-node-spl6x from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:46:22.603: INFO: node-exporter-tpmps from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 07:46:22.603: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-sxtcj from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Mar  1 07:46:22.603: INFO: addons-nginx-ingress-controller-7455744d9b-4fsw8 from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:46:22.603: INFO: addons-kubernetes-dashboard-6579b646c5-m9hss from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.603: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  1 07:46:22.603: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j before test
Mar  1 07:46:22.655: INFO: kube-proxy-jgp29 from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.655: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:46:22.655: INFO: calico-node-zxtkb from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.655: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:46:22.655: INFO: node-exporter-lv9s4 from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 07:46:22.655: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
STEP: verifying the node has the label node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j
Mar  1 07:46:22.914: INFO: Pod addons-kube-lego-69bbdc96b6-kq9t6 requesting resource cpu=20m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod addons-kubernetes-dashboard-6579b646c5-m9hss requesting resource cpu=50m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod addons-nginx-ingress-controller-7455744d9b-4fsw8 requesting resource cpu=100m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-sxtcj requesting resource cpu=0m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod blackbox-exporter-86f6cf4cb7-f8l2h requesting resource cpu=5m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod calico-node-spl6x requesting resource cpu=100m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod calico-node-zxtkb requesting resource cpu=100m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j
Mar  1 07:46:22.914: INFO: Pod coredns-67df79bbdd-vvpqk requesting resource cpu=50m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod kube-proxy-fm85v requesting resource cpu=20m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod kube-proxy-jgp29 requesting resource cpu=20m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j
Mar  1 07:46:22.914: INFO: Pod metrics-server-5887bb7679-cp4bx requesting resource cpu=20m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod node-exporter-lv9s4 requesting resource cpu=5m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j
Mar  1 07:46:22.914: INFO: Pod node-exporter-tpmps requesting resource cpu=5m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
Mar  1 07:46:22.914: INFO: Pod vpn-shoot-6f8cffc7cf-dss8s requesting resource cpu=50m on Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1bfe2e52-3bf6-11e9-9193-2e670c8e304c.1587c61352e8590a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-g8ttm/filler-pod-1bfe2e52-3bf6-11e9-9193-2e670c8e304c to shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1bfe2e52-3bf6-11e9-9193-2e670c8e304c.1587c61393a7bc15], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1bfe2e52-3bf6-11e9-9193-2e670c8e304c.1587c613b3026e09], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1bfe2e52-3bf6-11e9-9193-2e670c8e304c.1587c613c82eefd0], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1bfe2e52-3bf6-11e9-9193-2e670c8e304c.1587c613d0ade22c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c054e0e-3bf6-11e9-9193-2e670c8e304c.1587c613569aa8f5], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-g8ttm/filler-pod-1c054e0e-3bf6-11e9-9193-2e670c8e304c to shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c054e0e-3bf6-11e9-9193-2e670c8e304c.1587c6139c8d2bce], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c054e0e-3bf6-11e9-9193-2e670c8e304c.1587c613bd131278], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1c054e0e-3bf6-11e9-9193-2e670c8e304c.1587c613c7431b63], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1587c61450f2bcb2], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:46:28.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-g8ttm" for this suite.
Mar  1 07:46:34.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:46:34.983: INFO: namespace: e2e-tests-sched-pred-g8ttm, resource: bindings, ignored listing per whitelist
Mar  1 07:46:36.014: INFO: namespace e2e-tests-sched-pred-g8ttm deletion completed in 7.499557062s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:15.169 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:46:36.014: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hfdj7
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-24afa976-3bf6-11e9-9193-2e670c8e304c
STEP: Creating secret with name s-test-opt-upd-24afa9bb-3bf6-11e9-9193-2e670c8e304c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-24afa976-3bf6-11e9-9193-2e670c8e304c
STEP: Updating secret s-test-opt-upd-24afa9bb-3bf6-11e9-9193-2e670c8e304c
STEP: Creating secret with name s-test-opt-create-24afa9d5-3bf6-11e9-9193-2e670c8e304c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:48:08.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hfdj7" for this suite.
Mar  1 07:48:30.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:48:31.498: INFO: namespace: e2e-tests-projected-hfdj7, resource: bindings, ignored listing per whitelist
Mar  1 07:48:31.777: INFO: namespace e2e-tests-projected-hfdj7 deletion completed in 23.478208924s

• [SLOW TEST:115.763 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:48:31.777: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7xzh5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 07:48:33.396: INFO: Waiting up to 5m0s for pod "pod-69be6032-3bf6-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-7xzh5" to be "success or failure"
Mar  1 07:48:33.433: INFO: Pod "pod-69be6032-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 36.547739ms
Mar  1 07:48:35.469: INFO: Pod "pod-69be6032-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072736379s
Mar  1 07:48:37.505: INFO: Pod "pod-69be6032-3bf6-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10861617s
STEP: Saw pod success
Mar  1 07:48:37.505: INFO: Pod "pod-69be6032-3bf6-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:48:37.540: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-69be6032-3bf6-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 07:48:37.654: INFO: Waiting for pod pod-69be6032-3bf6-11e9-9193-2e670c8e304c to disappear
Mar  1 07:48:37.688: INFO: Pod pod-69be6032-3bf6-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:48:37.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7xzh5" for this suite.
Mar  1 07:48:43.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:48:44.651: INFO: namespace: e2e-tests-emptydir-7xzh5, resource: bindings, ignored listing per whitelist
Mar  1 07:48:45.205: INFO: namespace e2e-tests-emptydir-7xzh5 deletion completed in 7.48162269s

• [SLOW TEST:13.428 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:48:45.205: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-wx4vm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-wx4vm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wx4vm to expose endpoints map[]
Mar  1 07:48:46.762: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wx4vm exposes endpoints map[] (34.651523ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-wx4vm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wx4vm to expose endpoints map[pod1:[100]]
Mar  1 07:48:50.097: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wx4vm exposes endpoints map[pod1:[100]] (3.291716066s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-wx4vm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wx4vm to expose endpoints map[pod1:[100] pod2:[101]]
Mar  1 07:48:53.577: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wx4vm exposes endpoints map[pod2:[101] pod1:[100]] (3.440613455s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-wx4vm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wx4vm to expose endpoints map[pod2:[101]]
Mar  1 07:48:53.688: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wx4vm exposes endpoints map[pod2:[101]] (72.993195ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-wx4vm
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-wx4vm to expose endpoints map[]
Mar  1 07:48:53.765: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-wx4vm exposes endpoints map[] (35.122757ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:48:53.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wx4vm" for this suite.
Mar  1 07:49:15.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:49:16.074: INFO: namespace: e2e-tests-services-wx4vm, resource: bindings, ignored listing per whitelist
Mar  1 07:49:17.385: INFO: namespace e2e-tests-services-wx4vm deletion completed in 23.532249826s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:32.180 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:49:17.385: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7q4mq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 07:49:18.992: INFO: Waiting up to 5m0s for pod "pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-7q4mq" to be "success or failure"
Mar  1 07:49:19.026: INFO: Pod "pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.355442ms
Mar  1 07:49:21.067: INFO: Pod "pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075395247s
Mar  1 07:49:23.103: INFO: Pod "pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.111387082s
STEP: Saw pod success
Mar  1 07:49:23.103: INFO: Pod "pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:49:23.139: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 07:49:23.229: INFO: Waiting for pod pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c to disappear
Mar  1 07:49:23.264: INFO: Pod pod-84eb95f3-3bf6-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:49:23.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7q4mq" for this suite.
Mar  1 07:49:29.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:49:30.301: INFO: namespace: e2e-tests-emptydir-7q4mq, resource: bindings, ignored listing per whitelist
Mar  1 07:49:30.802: INFO: namespace e2e-tests-emptydir-7q4mq deletion completed in 7.495350656s

• [SLOW TEST:13.417 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:49:30.854: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-674tp
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  1 07:49:32.418: INFO: Waiting up to 5m0s for pod "pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-674tp" to be "success or failure"
Mar  1 07:49:32.453: INFO: Pod "pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.562718ms
Mar  1 07:49:34.490: INFO: Pod "pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071966158s
Mar  1 07:49:36.533: INFO: Pod "pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.1151574s
STEP: Saw pod success
Mar  1 07:49:36.533: INFO: Pod "pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:49:36.568: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 07:49:36.650: INFO: Waiting for pod pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c to disappear
Mar  1 07:49:36.688: INFO: Pod pod-8cec30ed-3bf6-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:49:36.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-674tp" for this suite.
Mar  1 07:49:42.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:49:43.631: INFO: namespace: e2e-tests-emptydir-674tp, resource: bindings, ignored listing per whitelist
Mar  1 07:49:44.222: INFO: namespace e2e-tests-emptydir-674tp deletion completed in 7.49893683s

• [SLOW TEST:13.368 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:49:44.222: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rgnb2
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-94dc2ad4-3bf6-11e9-9193-2e670c8e304c
STEP: Creating secret with name s-test-opt-upd-94dc2b21-3bf6-11e9-9193-2e670c8e304c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-94dc2ad4-3bf6-11e9-9193-2e670c8e304c
STEP: Updating secret s-test-opt-upd-94dc2b21-3bf6-11e9-9193-2e670c8e304c
STEP: Creating secret with name s-test-opt-create-94dc2b38-3bf6-11e9-9193-2e670c8e304c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:51:04.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rgnb2" for this suite.
Mar  1 07:51:28.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:51:28.521: INFO: namespace: e2e-tests-secrets-rgnb2, resource: bindings, ignored listing per whitelist
Mar  1 07:51:29.534: INFO: namespace e2e-tests-secrets-rgnb2 deletion completed in 25.493642627s

• [SLOW TEST:105.312 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:51:29.534: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-79skg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 07:51:31.003: INFO: Waiting up to 5m0s for pod "pod-d39afce3-3bf6-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-79skg" to be "success or failure"
Mar  1 07:51:31.038: INFO: Pod "pod-d39afce3-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.925367ms
Mar  1 07:51:33.074: INFO: Pod "pod-d39afce3-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070450031s
Mar  1 07:51:35.109: INFO: Pod "pod-d39afce3-3bf6-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106378096s
STEP: Saw pod success
Mar  1 07:51:35.109: INFO: Pod "pod-d39afce3-3bf6-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:51:35.144: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-d39afce3-3bf6-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 07:51:35.226: INFO: Waiting for pod pod-d39afce3-3bf6-11e9-9193-2e670c8e304c to disappear
Mar  1 07:51:35.261: INFO: Pod pod-d39afce3-3bf6-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:51:35.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-79skg" for this suite.
Mar  1 07:51:41.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:51:41.837: INFO: namespace: e2e-tests-emptydir-79skg, resource: bindings, ignored listing per whitelist
Mar  1 07:51:42.789: INFO: namespace e2e-tests-emptydir-79skg deletion completed in 7.493164259s

• [SLOW TEST:13.255 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:51:42.790: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-k7d29
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-k7d29/configmap-test-db86b82c-3bf6-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 07:51:44.330: INFO: Waiting up to 5m0s for pod "pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-k7d29" to be "success or failure"
Mar  1 07:51:44.365: INFO: Pod "pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.322009ms
Mar  1 07:51:46.401: INFO: Pod "pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071183881s
Mar  1 07:51:48.437: INFO: Pod "pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10714912s
STEP: Saw pod success
Mar  1 07:51:48.437: INFO: Pod "pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:51:48.472: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c container env-test: <nil>
STEP: delete the pod
Mar  1 07:51:48.562: INFO: Waiting for pod pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c to disappear
Mar  1 07:51:48.596: INFO: Pod pod-configmaps-db8c1731-3bf6-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:51:48.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k7d29" for this suite.
Mar  1 07:51:54.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:51:55.981: INFO: namespace: e2e-tests-configmap-k7d29, resource: bindings, ignored listing per whitelist
Mar  1 07:51:56.051: INFO: namespace e2e-tests-configmap-k7d29 deletion completed in 7.420178708s

• [SLOW TEST:13.262 seconds]
[sig-node] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:51:56.052: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gv2lf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-e373c272-3bf6-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 07:51:57.635: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-gv2lf" to be "success or failure"
Mar  1 07:51:57.673: INFO: Pod "pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 37.769205ms
Mar  1 07:51:59.709: INFO: Pod "pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073772247s
Mar  1 07:52:01.745: INFO: Pod "pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109925065s
STEP: Saw pod success
Mar  1 07:52:01.745: INFO: Pod "pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:52:01.789: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:52:01.888: INFO: Waiting for pod pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c to disappear
Mar  1 07:52:01.934: INFO: Pod pod-projected-secrets-e37919dc-3bf6-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:52:01.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gv2lf" for this suite.
Mar  1 07:52:34.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:52:35.259: INFO: namespace: e2e-tests-projected-gv2lf, resource: bindings, ignored listing per whitelist
Mar  1 07:52:36.307: INFO: namespace e2e-tests-projected-gv2lf deletion completed in 34.337833032s

• [SLOW TEST:40.255 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:52:36.307: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zsgph
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:52:37.906: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-zsgph" to be "success or failure"
Mar  1 07:52:37.941: INFO: Pod "downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.140134ms
Mar  1 07:52:39.978: INFO: Pod "downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072375689s
Mar  1 07:52:42.014: INFO: Pod "downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108068015s
STEP: Saw pod success
Mar  1 07:52:42.014: INFO: Pod "downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:52:42.049: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 07:52:42.141: INFO: Waiting for pod downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c to disappear
Mar  1 07:52:42.180: INFO: Pod downwardapi-volume-fb7b2c98-3bf6-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:52:42.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zsgph" for this suite.
Mar  1 07:52:48.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:52:49.433: INFO: namespace: e2e-tests-projected-zsgph, resource: bindings, ignored listing per whitelist
Mar  1 07:52:49.713: INFO: namespace e2e-tests-projected-zsgph deletion completed in 7.497472655s

• [SLOW TEST:13.406 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:52:49.713: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8j9mz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 07:52:51.288: INFO: Waiting up to 5m0s for pod "downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-8j9mz" to be "success or failure"
Mar  1 07:52:51.335: INFO: Pod "downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 46.907657ms
Mar  1 07:52:53.374: INFO: Pod "downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085442496s
Mar  1 07:52:55.409: INFO: Pod "downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.120856567s
STEP: Saw pod success
Mar  1 07:52:55.409: INFO: Pod "downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:52:55.444: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:52:55.528: INFO: Waiting for pod downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c to disappear
Mar  1 07:52:55.563: INFO: Pod downward-api-037558f7-3bf7-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:52:55.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8j9mz" for this suite.
Mar  1 07:53:01.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:02.888: INFO: namespace: e2e-tests-downward-api-8j9mz, resource: bindings, ignored listing per whitelist
Mar  1 07:53:03.063: INFO: namespace e2e-tests-downward-api-8j9mz deletion completed in 7.465103404s

• [SLOW TEST:13.350 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:53:03.064: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8rm2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 07:53:04.559: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8rm2t'
Mar  1 07:53:06.476: INFO: stderr: ""
Mar  1 07:53:06.476: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar  1 07:53:11.527: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8rm2t -o json'
Mar  1 07:53:11.792: INFO: stderr: ""
Mar  1 07:53:11.792: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.38/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-03-01T07:53:06Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-8rm2t\",\n        \"resourceVersion\": \"5212\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-8rm2t/pods/e2e-test-nginx-pod\",\n        \"uid\": \"0c84de92-3bf7-11e9-a289-2aff89a14c6e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mmh4t\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mmh4t\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mmh4t\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T07:53:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T07:53:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T07:53:08Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T07:53:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://830a44fdb05b89231ce1061a005e56028b19b0f0e6e3ea18223b42e0def284a6\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-01T07:53:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.38\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-01T07:53:06Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  1 07:53:11.792: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml replace -f - --namespace=e2e-tests-kubectl-8rm2t'
Mar  1 07:53:12.376: INFO: stderr: ""
Mar  1 07:53:12.376: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Mar  1 07:53:12.412: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8rm2t'
Mar  1 07:53:25.500: INFO: stderr: ""
Mar  1 07:53:25.500: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:53:25.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8rm2t" for this suite.
Mar  1 07:53:31.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:32.008: INFO: namespace: e2e-tests-kubectl-8rm2t, resource: bindings, ignored listing per whitelist
Mar  1 07:53:33.060: INFO: namespace e2e-tests-kubectl-8rm2t deletion completed in 7.523724073s

• [SLOW TEST:29.996 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:53:33.060: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-s2h7k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-5566b
STEP: Creating secret with name secret-test-1d48a6f3-3bf7-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 07:53:35.033: INFO: Waiting up to 5m0s for pod "pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-s2h7k" to be "success or failure"
Mar  1 07:53:35.072: INFO: Pod "pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 39.544695ms
Mar  1 07:53:37.108: INFO: Pod "pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075085039s
Mar  1 07:53:39.144: INFO: Pod "pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.111212455s
STEP: Saw pod success
Mar  1 07:53:39.144: INFO: Pod "pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:53:39.180: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:53:39.299: INFO: Waiting for pod pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c to disappear
Mar  1 07:53:39.334: INFO: Pod pod-secrets-1d886d9e-3bf7-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:53:39.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s2h7k" for this suite.
Mar  1 07:53:45.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:46.177: INFO: namespace: e2e-tests-secrets-s2h7k, resource: bindings, ignored listing per whitelist
Mar  1 07:53:46.804: INFO: namespace e2e-tests-secrets-s2h7k deletion completed in 7.435283555s
STEP: Destroying namespace "e2e-tests-secret-namespace-5566b" for this suite.
Mar  1 07:53:52.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:54.243: INFO: namespace: e2e-tests-secret-namespace-5566b, resource: bindings, ignored listing per whitelist
Mar  1 07:53:54.278: INFO: namespace e2e-tests-secret-namespace-5566b deletion completed in 7.474238174s

• [SLOW TEST:21.219 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:53:54.279: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-rhs4f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 07:54:04.145: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:04.179: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:06.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:06.219: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:08.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:08.217: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:10.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:10.216: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:12.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:12.315: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:14.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:14.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:16.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:16.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:18.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:18.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:20.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:20.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:22.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:22.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:24.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:24.215: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 07:54:26.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 07:54:26.215: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:54:26.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rhs4f" for this suite.
Mar  1 07:54:50.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:54:51.836: INFO: namespace: e2e-tests-container-lifecycle-hook-rhs4f, resource: bindings, ignored listing per whitelist
Mar  1 07:54:51.836: INFO: namespace e2e-tests-container-lifecycle-hook-rhs4f deletion completed in 25.584839622s

• [SLOW TEST:57.557 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:54:51.836: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-7g4mv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar  1 07:54:53.870: INFO: Waiting up to 5m0s for pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz" in namespace "e2e-tests-svcaccounts-7g4mv" to be "success or failure"
Mar  1 07:54:53.905: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz": Phase="Pending", Reason="", readiness=false. Elapsed: 34.996089ms
Mar  1 07:54:55.941: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070827592s
Mar  1 07:54:57.976: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106187971s
STEP: Saw pod success
Mar  1 07:54:57.976: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz" satisfied condition "success or failure"
Mar  1 07:54:58.012: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz container token-test: <nil>
STEP: delete the pod
Mar  1 07:54:58.102: INFO: Waiting for pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz to disappear
Mar  1 07:54:58.138: INFO: Pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-ssgnz no longer exists
STEP: Creating a pod to test consume service account root CA
Mar  1 07:54:58.174: INFO: Waiting up to 5m0s for pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54" in namespace "e2e-tests-svcaccounts-7g4mv" to be "success or failure"
Mar  1 07:54:58.235: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54": Phase="Pending", Reason="", readiness=false. Elapsed: 59.929409ms
Mar  1 07:55:00.271: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096310897s
Mar  1 07:55:02.308: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54": Phase="Pending", Reason="", readiness=false. Elapsed: 4.133383994s
Mar  1 07:55:04.392: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.216676541s
STEP: Saw pod success
Mar  1 07:55:04.392: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54" satisfied condition "success or failure"
Mar  1 07:55:04.427: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54 container root-ca-test: <nil>
STEP: delete the pod
Mar  1 07:55:04.538: INFO: Waiting for pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54 to disappear
Mar  1 07:55:04.573: INFO: Pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-mgt54 no longer exists
STEP: Creating a pod to test consume service account namespace
Mar  1 07:55:04.609: INFO: Waiting up to 5m0s for pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c" in namespace "e2e-tests-svcaccounts-7g4mv" to be "success or failure"
Mar  1 07:55:04.644: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.021644ms
Mar  1 07:55:06.680: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070865303s
Mar  1 07:55:08.717: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.107974059s
Mar  1 07:55:10.753: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.14362281s
STEP: Saw pod success
Mar  1 07:55:10.753: INFO: Pod "pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c" satisfied condition "success or failure"
Mar  1 07:55:10.787: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c container namespace-test: <nil>
STEP: delete the pod
Mar  1 07:55:10.876: INFO: Waiting for pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c to disappear
Mar  1 07:55:10.910: INFO: Pod pod-service-account-4c85e5fb-3bf7-11e9-9193-2e670c8e304c-thd2c no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:55:10.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-7g4mv" for this suite.
Mar  1 07:55:17.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:55:17.708: INFO: namespace: e2e-tests-svcaccounts-7g4mv, resource: bindings, ignored listing per whitelist
Mar  1 07:55:18.490: INFO: namespace e2e-tests-svcaccounts-7g4mv deletion completed in 7.543672248s

• [SLOW TEST:26.654 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:55:18.490: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xknjt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-5c1d5900-3bf7-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 07:55:20.063: INFO: Waiting up to 5m0s for pod "pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-xknjt" to be "success or failure"
Mar  1 07:55:20.097: INFO: Pod "pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.260636ms
Mar  1 07:55:22.133: INFO: Pod "pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069947757s
Mar  1 07:55:24.168: INFO: Pod "pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105345078s
STEP: Saw pod success
Mar  1 07:55:24.169: INFO: Pod "pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:55:24.203: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:55:24.290: INFO: Waiting for pod pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c to disappear
Mar  1 07:55:24.325: INFO: Pod pod-secrets-5c22b249-3bf7-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:55:24.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xknjt" for this suite.
Mar  1 07:55:30.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:55:30.882: INFO: namespace: e2e-tests-secrets-xknjt, resource: bindings, ignored listing per whitelist
Mar  1 07:55:31.829: INFO: namespace e2e-tests-secrets-xknjt deletion completed in 7.469653662s

• [SLOW TEST:13.339 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:55:31.829: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-qdbg6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0301 07:55:43.488932   31738 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 07:55:43.489: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:55:43.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qdbg6" for this suite.
Mar  1 07:55:49.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:55:50.062: INFO: namespace: e2e-tests-gc-qdbg6, resource: bindings, ignored listing per whitelist
Mar  1 07:55:50.995: INFO: namespace e2e-tests-gc-qdbg6 deletion completed in 7.469463457s

• [SLOW TEST:19.166 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:55:50.995: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pwxcs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6f76665e-3bf7-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 07:55:52.531: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-pwxcs" to be "success or failure"
Mar  1 07:55:52.566: INFO: Pod "pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.888129ms
Mar  1 07:55:54.602: INFO: Pod "pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070705414s
Mar  1 07:55:56.639: INFO: Pod "pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107969748s
STEP: Saw pod success
Mar  1 07:55:56.639: INFO: Pod "pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:55:56.674: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 07:55:56.760: INFO: Waiting for pod pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c to disappear
Mar  1 07:55:56.794: INFO: Pod pod-projected-configmaps-6f7bcdff-3bf7-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:55:56.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pwxcs" for this suite.
Mar  1 07:56:02.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:56:03.258: INFO: namespace: e2e-tests-projected-pwxcs, resource: bindings, ignored listing per whitelist
Mar  1 07:56:04.319: INFO: namespace e2e-tests-projected-pwxcs deletion completed in 7.488998673s

• [SLOW TEST:13.324 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:56:04.319: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-9k2f6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:56:05.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-9k2f6" for this suite.
Mar  1 07:56:28.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:56:29.202: INFO: namespace: e2e-tests-kubelet-test-9k2f6, resource: bindings, ignored listing per whitelist
Mar  1 07:56:29.522: INFO: namespace e2e-tests-kubelet-test-9k2f6 deletion completed in 23.529079763s

• [SLOW TEST:25.203 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:56:29.522: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zpzb5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 07:56:31.132: INFO: Waiting up to 5m0s for pod "downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-zpzb5" to be "success or failure"
Mar  1 07:56:31.169: INFO: Pod "downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 36.825382ms
Mar  1 07:56:33.204: INFO: Pod "downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072561918s
Mar  1 07:56:35.240: INFO: Pod "downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108604321s
STEP: Saw pod success
Mar  1 07:56:35.241: INFO: Pod "downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:56:35.276: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:56:35.359: INFO: Waiting for pod downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c to disappear
Mar  1 07:56:35.400: INFO: Pod downward-api-867ea0cd-3bf7-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:56:35.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zpzb5" for this suite.
Mar  1 07:56:41.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:56:42.084: INFO: namespace: e2e-tests-downward-api-zpzb5, resource: bindings, ignored listing per whitelist
Mar  1 07:56:42.959: INFO: namespace e2e-tests-downward-api-zpzb5 deletion completed in 7.519070912s

• [SLOW TEST:13.437 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:56:42.959: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-h9n58
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:56:48.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-h9n58" for this suite.
Mar  1 07:57:36.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:57:38.022: INFO: namespace: e2e-tests-kubelet-test-h9n58, resource: bindings, ignored listing per whitelist
Mar  1 07:57:38.379: INFO: namespace e2e-tests-kubelet-test-h9n58 deletion completed in 49.575131353s

• [SLOW TEST:55.420 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:57:38.380: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-tkrzf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar  1 07:57:39.992: INFO: Waiting up to 5m0s for pod "var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c" in namespace "e2e-tests-var-expansion-tkrzf" to be "success or failure"
Mar  1 07:57:40.028: INFO: Pod "var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.766562ms
Mar  1 07:57:42.069: INFO: Pod "var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076865692s
Mar  1 07:57:44.106: INFO: Pod "var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113776141s
STEP: Saw pod success
Mar  1 07:57:44.106: INFO: Pod "var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:57:44.141: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 07:57:44.229: INFO: Waiting for pod var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c to disappear
Mar  1 07:57:44.265: INFO: Pod var-expansion-af8a455c-3bf7-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:57:44.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tkrzf" for this suite.
Mar  1 07:57:52.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:57:52.522: INFO: namespace: e2e-tests-var-expansion-tkrzf, resource: bindings, ignored listing per whitelist
Mar  1 07:57:53.762: INFO: namespace e2e-tests-var-expansion-tkrzf deletion completed in 9.459668302s

• [SLOW TEST:15.382 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:57:53.762: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6chwq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  1 07:57:55.367: INFO: namespace e2e-tests-kubectl-6chwq
Mar  1 07:57:55.367: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-6chwq'
Mar  1 07:57:56.022: INFO: stderr: ""
Mar  1 07:57:56.022: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 07:57:57.058: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:57:57.059: INFO: Found 0 / 1
Mar  1 07:57:58.060: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:57:58.060: INFO: Found 0 / 1
Mar  1 07:57:59.060: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:57:59.060: INFO: Found 0 / 1
Mar  1 07:58:00.060: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:58:00.060: INFO: Found 0 / 1
Mar  1 07:58:01.069: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:58:01.069: INFO: Found 1 / 1
Mar  1 07:58:01.069: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 07:58:01.105: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:58:01.105: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 07:58:01.105: INFO: wait on redis-master startup in e2e-tests-kubectl-6chwq 
Mar  1 07:58:01.105: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml logs redis-master-t6grn redis-master --namespace=e2e-tests-kubectl-6chwq'
Mar  1 07:58:01.428: INFO: stderr: ""
Mar  1 07:58:01.428: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 07:57:59.742 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 07:57:59.742 # Server started, Redis version 3.2.12\n1:M 01 Mar 07:57:59.742 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 07:57:59.742 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar  1 07:58:01.428: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-6chwq'
Mar  1 07:58:01.769: INFO: stderr: ""
Mar  1 07:58:01.769: INFO: stdout: "service/rm2 exposed\n"
Mar  1 07:58:01.805: INFO: Service rm2 in namespace e2e-tests-kubectl-6chwq found.
STEP: exposing service
Mar  1 07:58:03.877: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-6chwq'
Mar  1 07:58:04.222: INFO: stderr: ""
Mar  1 07:58:04.222: INFO: stdout: "service/rm3 exposed\n"
Mar  1 07:58:04.257: INFO: Service rm3 in namespace e2e-tests-kubectl-6chwq found.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:58:06.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6chwq" for this suite.
Mar  1 07:58:30.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:58:31.791: INFO: namespace: e2e-tests-kubectl-6chwq, resource: bindings, ignored listing per whitelist
Mar  1 07:58:31.897: INFO: namespace e2e-tests-kubectl-6chwq deletion completed in 25.532461673s

• [SLOW TEST:38.135 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:58:31.897: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-cb8g6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 07:58:55.610: INFO: Container started at 2019-03-01 07:58:37 +0000 UTC, pod became ready at 2019-03-01 07:58:55 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:58:55.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cb8g6" for this suite.
Mar  1 07:59:17.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:59:18.601: INFO: namespace: e2e-tests-container-probe-cb8g6, resource: bindings, ignored listing per whitelist
Mar  1 07:59:19.269: INFO: namespace e2e-tests-container-probe-cb8g6 deletion completed in 23.623553377s

• [SLOW TEST:47.372 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:59:19.542: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-65f66
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar  1 07:59:21.146: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:59:21.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-65f66" for this suite.
Mar  1 07:59:27.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:59:27.772: INFO: namespace: e2e-tests-replication-controller-65f66, resource: bindings, ignored listing per whitelist
Mar  1 07:59:29.099: INFO: namespace e2e-tests-replication-controller-65f66 deletion completed in 7.589366865s

• [SLOW TEST:9.557 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:59:29.099: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-flmnw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f17b3714-3bf7-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 07:59:30.667: INFO: Waiting up to 5m0s for pod "pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-flmnw" to be "success or failure"
Mar  1 07:59:30.708: INFO: Pod "pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 40.989652ms
Mar  1 07:59:32.745: INFO: Pod "pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077745521s
Mar  1 07:59:34.784: INFO: Pod "pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.116826448s
STEP: Saw pod success
Mar  1 07:59:34.784: INFO: Pod "pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 07:59:34.820: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:59:34.918: INFO: Waiting for pod pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c to disappear
Mar  1 07:59:34.957: INFO: Pod pod-secrets-f181db87-3bf7-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 07:59:34.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-flmnw" for this suite.
Mar  1 07:59:41.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:59:41.616: INFO: namespace: e2e-tests-secrets-flmnw, resource: bindings, ignored listing per whitelist
Mar  1 07:59:42.468: INFO: namespace e2e-tests-secrets-flmnw deletion completed in 7.472778301s

• [SLOW TEST:13.369 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 07:59:42.468: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-cgpkw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-cgpkw
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-cgpkw
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-cgpkw
Mar  1 07:59:44.104: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar  1 07:59:54.141: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  1 07:59:54.177: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:59:55.132: INFO: stderr: ""
Mar  1 07:59:55.132: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:59:55.132: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:59:55.168: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 08:00:05.205: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:05.205: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:00:05.355: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999399s
Mar  1 08:00:06.391: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.963084682s
Mar  1 08:00:07.428: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.927241453s
Mar  1 08:00:08.463: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.890624033s
Mar  1 08:00:09.501: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.854846367s
Mar  1 08:00:10.537: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.817163418s
Mar  1 08:00:11.576: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.780913112s
Mar  1 08:00:12.612: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.742131581s
Mar  1 08:00:13.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.705625268s
Mar  1 08:00:14.688: INFO: Verifying statefulset ss doesn't scale past 1 for another 666.505002ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-cgpkw
Mar  1 08:00:15.726: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:16.687: INFO: stderr: ""
Mar  1 08:00:16.687: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:00:16.687: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:00:16.722: INFO: Found 1 stateful pods, waiting for 3
Mar  1 08:00:26.759: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:00:26.759: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:00:26.759: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  1 08:00:26.829: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:00:27.661: INFO: stderr: ""
Mar  1 08:00:27.661: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:00:27.661: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:00:27.661: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:00:28.505: INFO: stderr: ""
Mar  1 08:00:28.505: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:00:28.505: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:00:28.505: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:00:29.369: INFO: stderr: ""
Mar  1 08:00:29.369: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:00:29.369: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:00:29.369: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:00:29.405: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  1 08:00:39.478: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:39.478: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:39.478: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:00:39.585: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999565s
Mar  1 08:00:40.621: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.964356213s
Mar  1 08:00:41.658: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.928521524s
Mar  1 08:00:42.694: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.891692699s
Mar  1 08:00:43.731: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.855165475s
Mar  1 08:00:44.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.818654891s
Mar  1 08:00:45.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.782521647s
Mar  1 08:00:46.841: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.745972833s
Mar  1 08:00:47.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.709224833s
Mar  1 08:00:48.930: INFO: Verifying statefulset ss doesn't scale past 3 for another 657.596193ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-cgpkw
Mar  1 08:00:49.967: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:50.731: INFO: stderr: ""
Mar  1 08:00:50.731: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:00:50.731: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:00:50.731: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:51.601: INFO: stderr: ""
Mar  1 08:00:51.601: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:00:51.602: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:00:51.602: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:52.567: INFO: rc: 1
Mar  1 08:00:52.603: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (c8db14f7a34c347ffe91be0005ae8970ec26aad816e23fd137eb026663e8a1b4)
 [] <nil> 0xc0011f8d80 exit status 1 <nil> <nil> true [0xc0009d4788 0xc0009d47a0 0xc0009d47b8] [0xc0009d4788 0xc0009d47a0 0xc0009d47b8] [0xc0009d4798 0xc0009d47b0] [0x933040 0x933040] 0xc000d10ae0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (c8db14f7a34c347ffe91be0005ae8970ec26aad816e23fd137eb026663e8a1b4)

error:
exit status 1

Mar  1 08:01:02.604: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:03.133: INFO: rc: 1
Mar  1 08:01:03.133: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001512ed0 exit status 1 <nil> <nil> true [0xc0002d1960 0xc0002d1978 0xc0002d19b0] [0xc0002d1960 0xc0002d1978 0xc0002d19b0] [0xc0002d1970 0xc0002d1998] [0x933040 0x933040] 0xc0012b8c00 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Mar  1 08:01:13.133: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:13.372: INFO: rc: 1
Mar  1 08:01:13.372: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011f9200 exit status 1 <nil> <nil> true [0xc0009d47c0 0xc0009d47d8 0xc0009d47f0] [0xc0009d47c0 0xc0009d47d8 0xc0009d47f0] [0xc0009d47d0 0xc0009d47e8] [0x933040 0x933040] 0xc000d10ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:23.373: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:23.579: INFO: rc: 1
Mar  1 08:01:23.579: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011f94d0 exit status 1 <nil> <nil> true [0xc0009d47f8 0xc0009d4810 0xc0009d4828] [0xc0009d47f8 0xc0009d4810 0xc0009d4828] [0xc0009d4808 0xc0009d4820] [0x933040 0x933040] 0xc000d11200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:33.579: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:33.879: INFO: rc: 1
Mar  1 08:01:33.879: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001d78de0 exit status 1 <nil> <nil> true [0xc001416548 0xc001416560 0xc001416580] [0xc001416548 0xc001416560 0xc001416580] [0xc001416558 0xc001416578] [0x933040 0x933040] 0xc0017cafc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:43.879: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:44.099: INFO: rc: 1
Mar  1 08:01:44.099: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00145e2a0 exit status 1 <nil> <nil> true [0xc00000e1c0 0xc00000e880 0xc00000e9f8] [0xc00000e1c0 0xc00000e880 0xc00000e9f8] [0xc00000e6e8 0xc00000e9f0] [0x933040 0x933040] 0xc0006cf740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:54.100: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:54.339: INFO: rc: 1
Mar  1 08:01:54.339: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00064bb00 exit status 1 <nil> <nil> true [0xc0004900e0 0xc0004906f8 0xc000490ed8] [0xc0004900e0 0xc0004906f8 0xc000490ed8] [0xc000490670 0xc000490e08] [0x933040 0x933040] 0xc001c8aea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:04.339: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:04.619: INFO: rc: 1
Mar  1 08:02:04.619: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00145e5a0 exit status 1 <nil> <nil> true [0xc00000ea60 0xc00000ead0 0xc00000eb48] [0xc00000ea60 0xc00000ead0 0xc00000eb48] [0xc00000eaa0 0xc00000eb28] [0x933040 0x933040] 0xc0006cfa40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:14.619: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:14.836: INFO: rc: 1
Mar  1 08:02:14.836: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00145e9f0 exit status 1 <nil> <nil> true [0xc00000ebf8 0xc00000ed30 0xc00000ee90] [0xc00000ebf8 0xc00000ed30 0xc00000ee90] [0xc00000ec98 0xc00000ee08] [0x933040 0x933040] 0xc0006cfd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:24.836: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:25.119: INFO: rc: 1
Mar  1 08:02:25.119: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae8720 exit status 1 <nil> <nil> true [0xc0013e6000 0xc0013e6018 0xc0013e6030] [0xc0013e6000 0xc0013e6018 0xc0013e6030] [0xc0013e6010 0xc0013e6028] [0x933040 0x933040] 0xc0019e2240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:35.119: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:35.349: INFO: rc: 1
Mar  1 08:02:35.349: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae8a20 exit status 1 <nil> <nil> true [0xc0013e6038 0xc0013e6050 0xc0013e6068] [0xc0013e6038 0xc0013e6050 0xc0013e6068] [0xc0013e6048 0xc0013e6060] [0x933040 0x933040] 0xc0019e25a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:45.349: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:45.556: INFO: rc: 1
Mar  1 08:02:45.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae8ed0 exit status 1 <nil> <nil> true [0xc0013e6070 0xc0013e6088 0xc0013e60a0] [0xc0013e6070 0xc0013e6088 0xc0013e60a0] [0xc0013e6080 0xc0013e6098] [0x933040 0x933040] 0xc0019e28a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:55.556: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:55.804: INFO: rc: 1
Mar  1 08:02:55.804: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00145ecc0 exit status 1 <nil> <nil> true [0xc00000eef8 0xc00000ef48 0xc00000f098] [0xc00000eef8 0xc00000ef48 0xc00000f098] [0xc00000ef20 0xc00000f030] [0x933040 0x933040] 0xc001242a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:03:05.804: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:06.062: INFO: rc: 1
Mar  1 08:03:06.063: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae91d0 exit status 1 <nil> <nil> true [0xc0013e60a8 0xc0013e60c0 0xc0013e60d8] [0xc0013e60a8 0xc0013e60c0 0xc0013e60d8] [0xc0013e60b8 0xc0013e60d0] [0x933040 0x933040] 0xc0019e2ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:03:16.063: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:16.271: INFO: rc: 1
Mar  1 08:03:16.272: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a80300 exit status 1 <nil> <nil> true [0xc0009d4000 0xc0009d4018 0xc0009d4030] [0xc0009d4000 0xc0009d4018 0xc0009d4030] [0xc0009d4010 0xc0009d4028] [0x933040 0x933040] 0xc001e0e780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:03:26.272: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:26.521: INFO: rc: 1
Mar  1 08:03:26.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae9500 exit status 1 <nil> <nil> true [0xc0013e60e0 0xc0013e60f8 0xc0013e6110] [0xc0013e60e0 0xc0013e60f8 0xc0013e6110] [0xc0013e60f0 0xc0013e6108] [0x933040 0x933040] 0xc0019e2f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:03:36.521: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:36.736: INFO: rc: 1
Mar  1 08:03:36.736: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae8750 exit status 1 <nil> <nil> true [0xc0013e6008 0xc0013e6020 0xc0013e6038] [0xc0013e6008 0xc0013e6020 0xc0013e6038] [0xc0013e6018 0xc0013e6030] [0x933040 0x933040] 0xc0006cf860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:03:46.737: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:46.956: INFO: rc: 1
Mar  1 08:03:46.956: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00064bb30 exit status 1 <nil> <nil> true [0xc0004900e0 0xc0004906f8 0xc000490ed8] [0xc0004900e0 0xc0004906f8 0xc000490ed8] [0xc000490670 0xc000490e08] [0x933040 0x933040] 0xc0019e2120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:03:56.956: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:57.216: INFO: rc: 1
Mar  1 08:03:57.217: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00145e2d0 exit status 1 <nil> <nil> true [0xc0009d4000 0xc0009d4018 0xc0009d4030] [0xc0009d4000 0xc0009d4018 0xc0009d4030] [0xc0009d4010 0xc0009d4028] [0x933040 0x933040] 0xc001c8aea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:04:07.217: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:04:07.474: INFO: rc: 1
Mar  1 08:04:07.474: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a802a0 exit status 1 <nil> <nil> true [0xc00000e1c0 0xc00000e880 0xc00000e9f8] [0xc00000e1c0 0xc00000e880 0xc00000e9f8] [0xc00000e6e8 0xc00000e9f0] [0x933040 0x933040] 0xc001e0e780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:04:17.474: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:04:17.682: INFO: rc: 1
Mar  1 08:04:17.683: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae8a80 exit status 1 <nil> <nil> true [0xc0013e6040 0xc0013e6058 0xc0013e6070] [0xc0013e6040 0xc0013e6058 0xc0013e6070] [0xc0013e6050 0xc0013e6068] [0x933040 0x933040] 0xc0006cfb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:04:27.683: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:04:28.018: INFO: rc: 1
Mar  1 08:04:28.018: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a806f0 exit status 1 <nil> <nil> true [0xc00000ea60 0xc00000ead0 0xc00000eb48] [0xc00000ea60 0xc00000ead0 0xc00000eb48] [0xc00000eaa0 0xc00000eb28] [0x933040 0x933040] 0xc001e0ea80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:04:38.020: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:04:38.247: INFO: rc: 1
Mar  1 08:04:38.247: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00145e600 exit status 1 <nil> <nil> true [0xc0009d4038 0xc0009d4050 0xc0009d4068] [0xc0009d4038 0xc0009d4050 0xc0009d4068] [0xc0009d4048 0xc0009d4060] [0x933040 0x933040] 0xc001c8b1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:04:48.247: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:04:48.458: INFO: rc: 1
Mar  1 08:04:48.458: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a80ae0 exit status 1 <nil> <nil> true [0xc00000ebf8 0xc00000ed30 0xc00000ee90] [0xc00000ebf8 0xc00000ed30 0xc00000ee90] [0xc00000ec98 0xc00000ee08] [0x933040 0x933040] 0xc001e0f800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:04:58.458: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:04:58.809: INFO: rc: 1
Mar  1 08:04:58.809: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae8f90 exit status 1 <nil> <nil> true [0xc0013e6078 0xc0013e6090 0xc0013e60a8] [0xc0013e6078 0xc0013e6090 0xc0013e60a8] [0xc0013e6088 0xc0013e60a0] [0x933040 0x933040] 0xc0006cfe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:05:08.809: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:05:09.037: INFO: rc: 1
Mar  1 08:05:09.037: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae92c0 exit status 1 <nil> <nil> true [0xc0013e60b0 0xc0013e60c8 0xc0013e60e0] [0xc0013e60b0 0xc0013e60c8 0xc0013e60e0] [0xc0013e60c0 0xc0013e60d8] [0x933040 0x933040] 0xc001242ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:05:19.037: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:05:19.291: INFO: rc: 1
Mar  1 08:05:19.291: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a80de0 exit status 1 <nil> <nil> true [0xc00000eef8 0xc00000ef48 0xc00000f098] [0xc00000eef8 0xc00000ef48 0xc00000f098] [0xc00000ef20 0xc00000f030] [0x933040 0x933040] 0xc001e0fb00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:05:29.292: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:05:29.564: INFO: rc: 1
Mar  1 08:05:29.564: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae9650 exit status 1 <nil> <nil> true [0xc0013e60e8 0xc0013e6100 0xc0013e6118] [0xc0013e60e8 0xc0013e6100 0xc0013e6118] [0xc0013e60f8 0xc0013e6110] [0x933040 0x933040] 0xc001242ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:05:39.564: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:05:39.806: INFO: rc: 1
Mar  1 08:05:39.807: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00145e2a0 exit status 1 <nil> <nil> true [0xc0009d4008 0xc0009d4020 0xc0009d4038] [0xc0009d4008 0xc0009d4020 0xc0009d4038] [0xc0009d4018 0xc0009d4030] [0x933040 0x933040] 0xc0006cf740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:05:49.807: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:05:50.077: INFO: rc: 1
Mar  1 08:05:50.077: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000ae8720 exit status 1 <nil> <nil> true [0xc0013e6000 0xc0013e6018 0xc0013e6030] [0xc0013e6000 0xc0013e6018 0xc0013e6030] [0xc0013e6010 0xc0013e6028] [0x933040 0x933040] 0xc001c8aea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:06:00.077: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cgpkw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:06:00.409: INFO: rc: 1
Mar  1 08:06:00.409: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Mar  1 08:06:00.409: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 08:06:00.517: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cgpkw
Mar  1 08:06:00.553: INFO: Scaling statefulset ss to 0
Mar  1 08:06:00.661: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:06:00.697: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:06:00.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-cgpkw" for this suite.
Mar  1 08:06:06.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:06:07.998: INFO: namespace: e2e-tests-statefulset-cgpkw, resource: bindings, ignored listing per whitelist
Mar  1 08:06:08.353: INFO: namespace e2e-tests-statefulset-cgpkw deletion completed in 7.511632883s

• [SLOW TEST:385.885 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:06:08.353: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vnf9k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:06:09.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-vnf9k" to be "success or failure"
Mar  1 08:06:09.941: INFO: Pod "downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.860877ms
Mar  1 08:06:11.977: INFO: Pod "downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071933475s
Mar  1 08:06:14.014: INFO: Pod "downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108856484s
STEP: Saw pod success
Mar  1 08:06:14.014: INFO: Pod "downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:06:14.049: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 08:06:14.143: INFO: Waiting for pod downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c to disappear
Mar  1 08:06:14.178: INFO: Pod downwardapi-volume-df78b5ff-3bf8-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:06:14.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vnf9k" for this suite.
Mar  1 08:06:20.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:06:20.500: INFO: namespace: e2e-tests-downward-api-vnf9k, resource: bindings, ignored listing per whitelist
Mar  1 08:06:21.708: INFO: namespace e2e-tests-downward-api-vnf9k deletion completed in 7.46978689s

• [SLOW TEST:13.355 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:06:21.709: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7s292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:06:23.159: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml version'
Mar  1 08:06:23.372: INFO: stderr: ""
Mar  1 08:06:23.372: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"archive\", BuildDate:\"2019-03-01T07:36:00Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:06:23.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7s292" for this suite.
Mar  1 08:06:31.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:06:32.796: INFO: namespace: e2e-tests-kubectl-7s292, resource: bindings, ignored listing per whitelist
Mar  1 08:06:32.903: INFO: namespace e2e-tests-kubectl-7s292 deletion completed in 9.484548341s

• [SLOW TEST:11.194 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:06:32.903: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-jb59q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  1 08:06:42.663: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:42.663: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:43.254: INFO: Exec stderr: ""
Mar  1 08:06:43.254: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:43.254: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:43.910: INFO: Exec stderr: ""
Mar  1 08:06:43.910: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:43.910: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:44.482: INFO: Exec stderr: ""
Mar  1 08:06:44.482: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:44.483: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:45.070: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  1 08:06:45.070: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:45.070: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:45.666: INFO: Exec stderr: ""
Mar  1 08:06:45.666: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:45.666: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:46.243: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  1 08:06:46.243: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:46.243: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:46.890: INFO: Exec stderr: ""
Mar  1 08:06:46.890: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:46.890: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:47.513: INFO: Exec stderr: ""
Mar  1 08:06:47.513: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:47.513: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:48.067: INFO: Exec stderr: ""
Mar  1 08:06:48.068: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-jb59q PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:06:48.068: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:06:48.668: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:06:48.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-jb59q" for this suite.
Mar  1 08:07:38.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:07:40.274: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-jb59q, resource: bindings, ignored listing per whitelist
Mar  1 08:07:40.274: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-jb59q deletion completed in 51.568804699s

• [SLOW TEST:67.371 seconds]
[k8s.io] KubeletManagedEtcHosts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:07:40.274: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-ckbms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 08:07:50.104: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:07:50.139: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:07:52.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:07:52.176: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:07:54.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:07:54.175: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:07:56.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:07:56.176: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:07:58.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:07:58.178: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:08:00.142: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:08:00.183: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:08:02.140: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:08:02.180: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:08:04.140: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:08:04.175: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:08:06.140: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:08:06.177: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 08:08:08.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 08:08:08.177: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:08:08.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ckbms" for this suite.
Mar  1 08:08:30.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:08:30.639: INFO: namespace: e2e-tests-container-lifecycle-hook-ckbms, resource: bindings, ignored listing per whitelist
Mar  1 08:08:31.784: INFO: namespace e2e-tests-container-lifecycle-hook-ckbms deletion completed in 23.527665099s

• [SLOW TEST:51.510 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:08:31.784: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-8nk4w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:08:33.283: INFO: Creating deployment "test-recreate-deployment"
Mar  1 08:08:33.319: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  1 08:08:33.395: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  1 08:08:33.431: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-5dfdcc846d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:08:35.467: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024513, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:08:37.467: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  1 08:08:37.546: INFO: Updating deployment test-recreate-deployment
Mar  1 08:08:37.546: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 08:08:37.813: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-8nk4w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8nk4w/deployments/test-recreate-deployment,UID:34f73253-3bf9-11e9-a289-2aff89a14c6e,ResourceVersion:7594,Generation:2,CreationTimestamp:2019-03-01 08:08:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-01 08:08:37 +0000 UTC 2019-03-01 08:08:37 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-01 08:08:37 +0000 UTC 2019-03-01 08:08:33 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar  1 08:08:37.848: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-8nk4w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8nk4w/replicasets/test-recreate-deployment-697fbf54bf,UID:378afea0-3bf9-11e9-a289-2aff89a14c6e,ResourceVersion:7593,Generation:1,CreationTimestamp:2019-03-01 08:08:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 34f73253-3bf9-11e9-a289-2aff89a14c6e 0xc001d2c937 0xc001d2c938}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 08:08:37.848: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  1 08:08:37.849: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-8nk4w,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8nk4w/replicasets/test-recreate-deployment-5dfdcc846d,UID:34f9f240-3bf9-11e9-a289-2aff89a14c6e,ResourceVersion:7586,Generation:2,CreationTimestamp:2019-03-01 08:08:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 34f73253-3bf9-11e9-a289-2aff89a14c6e 0xc001d2c887 0xc001d2c888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 08:08:37.889: INFO: Pod "test-recreate-deployment-697fbf54bf-sjltc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-sjltc,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-8nk4w,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8nk4w/pods/test-recreate-deployment-697fbf54bf-sjltc,UID:378ce910-3bf9-11e9-a289-2aff89a14c6e,ResourceVersion:7590,Generation:0,CreationTimestamp:2019-03-01 08:08:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 378afea0-3bf9-11e9-a289-2aff89a14c6e 0xc000e73a87 0xc000e73a88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sr6hg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sr6hg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sr6hg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e73af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e73b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:08:37 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:08:37.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8nk4w" for this suite.
Mar  1 08:08:44.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:08:45.350: INFO: namespace: e2e-tests-deployment-8nk4w, resource: bindings, ignored listing per whitelist
Mar  1 08:08:45.457: INFO: namespace e2e-tests-deployment-8nk4w deletion completed in 7.530705612s

• [SLOW TEST:13.673 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:08:45.457: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-4h5qb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 08:08:47.263: INFO: Number of nodes with available pods: 0
Mar  1 08:08:47.263: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:08:48.336: INFO: Number of nodes with available pods: 0
Mar  1 08:08:48.336: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:08:49.337: INFO: Number of nodes with available pods: 0
Mar  1 08:08:49.337: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:08:50.336: INFO: Number of nodes with available pods: 1
Mar  1 08:08:50.336: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:08:51.348: INFO: Number of nodes with available pods: 2
Mar  1 08:08:51.348: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  1 08:08:51.528: INFO: Number of nodes with available pods: 1
Mar  1 08:08:51.528: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:08:52.600: INFO: Number of nodes with available pods: 1
Mar  1 08:08:52.600: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:08:53.599: INFO: Number of nodes with available pods: 2
Mar  1 08:08:53.599: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-4h5qb, will wait for the garbage collector to delete the pods
Mar  1 08:08:53.798: INFO: Deleting DaemonSet.extensions daemon-set took: 40.317592ms
Mar  1 08:08:53.900: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.311341ms
Mar  1 08:09:36.638: INFO: Number of nodes with available pods: 0
Mar  1 08:09:36.638: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 08:09:36.673: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-4h5qb/daemonsets","resourceVersion":"7768"},"items":null}

Mar  1 08:09:36.708: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-4h5qb/pods","resourceVersion":"7768"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:09:36.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-4h5qb" for this suite.
Mar  1 08:09:42.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:09:43.318: INFO: namespace: e2e-tests-daemonsets-4h5qb, resource: bindings, ignored listing per whitelist
Mar  1 08:09:44.395: INFO: namespace e2e-tests-daemonsets-4h5qb deletion completed in 7.545286484s

• [SLOW TEST:58.938 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:09:44.395: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6vcck
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:09:45.992: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-6vcck" to be "success or failure"
Mar  1 08:09:46.045: INFO: Pod "downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 53.015936ms
Mar  1 08:09:48.082: INFO: Pod "downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089051685s
Mar  1 08:09:50.118: INFO: Pod "downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.125400354s
STEP: Saw pod success
Mar  1 08:09:50.118: INFO: Pod "downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:09:50.153: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 08:09:50.245: INFO: Waiting for pod downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c to disappear
Mar  1 08:09:50.280: INFO: Pod downwardapi-volume-6044edea-3bf9-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:09:50.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6vcck" for this suite.
Mar  1 08:09:56.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:09:57.283: INFO: namespace: e2e-tests-projected-6vcck, resource: bindings, ignored listing per whitelist
Mar  1 08:09:57.815: INFO: namespace e2e-tests-projected-6vcck deletion completed in 7.499755341s

• [SLOW TEST:13.420 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:09:57.815: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lllmc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:09:59.395: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml version --client'
Mar  1 08:09:59.557: INFO: stderr: ""
Mar  1 08:09:59.557: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"archive\", BuildDate:\"2019-03-01T07:36:00Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar  1 08:09:59.591: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-lllmc'
Mar  1 08:10:02.174: INFO: stderr: ""
Mar  1 08:10:02.174: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  1 08:10:02.174: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-lllmc'
Mar  1 08:10:02.745: INFO: stderr: ""
Mar  1 08:10:02.745: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 08:10:03.781: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:03.781: INFO: Found 0 / 1
Mar  1 08:10:04.781: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:04.781: INFO: Found 0 / 1
Mar  1 08:10:05.782: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:05.782: INFO: Found 1 / 1
Mar  1 08:10:05.782: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 08:10:05.818: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:05.818: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 08:10:05.818: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe pod redis-master-748rd --namespace=e2e-tests-kubectl-lllmc'
Mar  1 08:10:06.250: INFO: stderr: ""
Mar  1 08:10:06.250: INFO: stdout: "Name:               redis-master-748rd\nNamespace:          e2e-tests-kubectl-lllmc\nPriority:           0\nPriorityClassName:  <none>\nNode:               shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j/10.250.0.4\nStart Time:         Fri, 01 Mar 2019 08:10:02 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.1.66/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.1.66\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1f2bf88895b86bf267773d4d5bd752341df5fc1203439f3f20e8828e3c6711b4\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 01 Mar 2019 08:10:04 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rvmxs (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-rvmxs:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-rvmxs\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                          Message\n  ----    ------     ----  ----                                                          -------\n  Normal  Scheduled  4s    default-scheduler                                             Successfully assigned e2e-tests-kubectl-lllmc/redis-master-748rd to shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j\n  Normal  Pulled     3s    kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    3s    kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Created container\n  Normal  Started    2s    kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Started container\n"
Mar  1 08:10:06.250: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe rc redis-master --namespace=e2e-tests-kubectl-lllmc'
Mar  1 08:10:06.736: INFO: stderr: ""
Mar  1 08:10:06.736: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-lllmc\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-748rd\n"
Mar  1 08:10:06.736: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe service redis-master --namespace=e2e-tests-kubectl-lllmc'
Mar  1 08:10:07.149: INFO: stderr: ""
Mar  1 08:10:07.149: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-lllmc\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.70.22.169\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.66:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  1 08:10:07.185: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v'
Mar  1 08:10:07.655: INFO: stderr: ""
Mar  1 08:10:07.655: INFO: stdout: "Name:               shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=1\n                    kubernetes.io/hostname=shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=cpu-worker\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.5/19\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 01 Mar 2019 07:24:41 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 01 Mar 2019 07:25:36 +0000   Fri, 01 Mar 2019 07:25:36 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Fri, 01 Mar 2019 08:10:07 +0000   Fri, 01 Mar 2019 07:24:41 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 01 Mar 2019 08:10:07 +0000   Fri, 01 Mar 2019 07:24:41 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 01 Mar 2019 08:10:07 +0000   Fri, 01 Mar 2019 07:24:41 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 01 Mar 2019 08:10:07 +0000   Fri, 01 Mar 2019 07:24:51 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.0.5\n  Hostname:    shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v\nCapacity:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              33136428Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7115804Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  8\n cpu:                            1920m\n ephemeral-storage:              32235117134\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         5848512302\n pods:                           110\nSystem Info:\n Machine ID:                 62599412268541949f648b6a6a0bccc4\n System UUID:                33C429A8-04B8-A14D-B031-1DB491C2B976\n Boot ID:                    f7034189-3f0e-4689-bd5a-24ad3056e289\n Kernel Version:             4.14.96-coreos\n OS Image:                   Container Linux by CoreOS 1967.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nPodCIDR:                     100.96.0.0/24\nProviderID:                  azure:///subscriptions/00d2caa5-cd29-46f7-845a-2f8ee0360ef5/resourceGroups/shoot--it--pub-az-6tn50/providers/Microsoft.Compute/virtualMachines/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------  ---\n  kube-system                addons-kube-lego-69bbdc96b6-kq9t6                                 20m (1%)      50m (2%)    8Mi (0%)         32Mi (0%)      47m\n  kube-system                addons-kubernetes-dashboard-6579b646c5-m9hss                      50m (2%)      100m (5%)   50Mi (0%)        256Mi (4%)     47m\n  kube-system                addons-nginx-ingress-controller-7455744d9b-4fsw8                  100m (5%)     2 (104%)    100Mi (1%)       800Mi (14%)    47m\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-sxtcj    0 (0%)        0 (0%)      0 (0%)           0 (0%)         47m\n  kube-system                blackbox-exporter-86f6cf4cb7-f8l2h                                5m (0%)       10m (0%)    5Mi (0%)         35Mi (0%)      47m\n  kube-system                calico-node-spl6x                                                 100m (5%)     500m (26%)  100Mi (1%)       700Mi (12%)    45m\n  kube-system                coredns-67df79bbdd-vvpqk                                          50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     47m\n  kube-system                kube-proxy-fm85v                                                  20m (1%)      900m (46%)  64Mi (1%)        200Mi (3%)     45m\n  kube-system                metrics-server-5887bb7679-cp4bx                                   20m (1%)      80m (4%)    100Mi (1%)       400Mi (7%)     47m\n  kube-system                node-exporter-tpmps                                               5m (0%)       15m (0%)    10Mi (0%)        50Mi (0%)      45m\n  kube-system                vpn-shoot-6f8cffc7cf-dss8s                                        50m (2%)      100m (5%)   50Mi (0%)        100Mi (1%)     47m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests    Limits\n  --------                       --------    ------\n  cpu                            420m (21%)  3855m (200%)\n  memory                         502Mi (9%)  2673Mi (47%)\n  ephemeral-storage              0 (0%)      0 (0%)\n  attachable-volumes-azure-disk  0           0\nEvents:\n  Type    Reason                   Age                From                                                             Message\n  ----    ------                   ----               ----                                                             -------\n  Normal  Starting                 45m                kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v     Starting kubelet.\n  Normal  NodeHasSufficientMemory  45m (x2 over 45m)  kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v     Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    45m (x2 over 45m)  kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v     Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     45m (x2 over 45m)  kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v     Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  45m                kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v     Updated Node Allocatable limit across pods\n  Normal  Starting                 45m                kube-proxy, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Starting kube-proxy.\n  Normal  NodeReady                45m                kubelet, shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v     Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v status is now: NodeReady\n"
Mar  1 08:10:07.655: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe namespace e2e-tests-kubectl-lllmc'
Mar  1 08:10:08.103: INFO: stderr: ""
Mar  1 08:10:08.103: INFO: stdout: "Name:         e2e-tests-kubectl-lllmc\nLabels:       e2e-framework=kubectl\n              e2e-run=ef40428f-3bf4-11e9-9193-2e670c8e304c\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:10:08.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lllmc" for this suite.
Mar  1 08:10:32.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:10:32.746: INFO: namespace: e2e-tests-kubectl-lllmc, resource: bindings, ignored listing per whitelist
Mar  1 08:10:33.601: INFO: namespace e2e-tests-kubectl-lllmc deletion completed in 25.461812619s

• [SLOW TEST:35.786 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:10:33.601: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-wk79p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 08:10:35.059: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:10:39.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wk79p" for this suite.
Mar  1 08:10:45.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:10:46.317: INFO: namespace: e2e-tests-init-container-wk79p, resource: bindings, ignored listing per whitelist
Mar  1 08:10:46.825: INFO: namespace e2e-tests-init-container-wk79p deletion completed in 7.534498917s

• [SLOW TEST:13.224 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:10:46.825: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4bbdt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  1 08:10:48.357: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-4bbdt'
Mar  1 08:10:49.015: INFO: stderr: ""
Mar  1 08:10:49.015: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 08:10:50.054: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:50.054: INFO: Found 0 / 1
Mar  1 08:10:51.051: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:51.051: INFO: Found 0 / 1
Mar  1 08:10:52.052: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:52.053: INFO: Found 1 / 1
Mar  1 08:10:52.053: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  1 08:10:52.089: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:52.089: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 08:10:52.089: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml patch pod redis-master-xx7hh --namespace=e2e-tests-kubectl-4bbdt -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  1 08:10:52.387: INFO: stderr: ""
Mar  1 08:10:52.387: INFO: stdout: "pod/redis-master-xx7hh patched\n"
STEP: checking annotations
Mar  1 08:10:52.430: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:10:52.430: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:10:52.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4bbdt" for this suite.
Mar  1 08:11:16.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:11:17.079: INFO: namespace: e2e-tests-kubectl-4bbdt, resource: bindings, ignored listing per whitelist
Mar  1 08:11:18.025: INFO: namespace e2e-tests-kubectl-4bbdt deletion completed in 25.558929711s

• [SLOW TEST:31.200 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:11:18.025: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s2dh8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-98013093-3bf9-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 08:11:19.541: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-s2dh8" to be "success or failure"
Mar  1 08:11:19.583: INFO: Pod "pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.944666ms
Mar  1 08:11:21.620: INFO: Pod "pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078693478s
Mar  1 08:11:23.657: INFO: Pod "pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115672888s
STEP: Saw pod success
Mar  1 08:11:23.657: INFO: Pod "pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:11:23.692: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:11:23.780: INFO: Waiting for pod pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c to disappear
Mar  1 08:11:23.815: INFO: Pod pod-projected-secrets-98069298-3bf9-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:11:23.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s2dh8" for this suite.
Mar  1 08:11:29.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:11:30.926: INFO: namespace: e2e-tests-projected-s2dh8, resource: bindings, ignored listing per whitelist
Mar  1 08:11:31.420: INFO: namespace e2e-tests-projected-s2dh8 deletion completed in 7.569055233s

• [SLOW TEST:13.395 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:11:31.420: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-nrmfn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar  1 08:11:37.076: INFO: Pod pod-hostip-9ffd8e7c-3bf9-11e9-9193-2e670c8e304c has hostIP: 10.250.0.4
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:11:37.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nrmfn" for this suite.
Mar  1 08:12:01.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:12:01.999: INFO: namespace: e2e-tests-pods-nrmfn, resource: bindings, ignored listing per whitelist
Mar  1 08:12:02.686: INFO: namespace e2e-tests-pods-nrmfn deletion completed in 25.574474839s

• [SLOW TEST:31.266 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:12:02.686: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-4xwbt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-xn8b
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 08:12:04.277: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xn8b" in namespace "e2e-tests-subpath-4xwbt" to be "success or failure"
Mar  1 08:12:04.315: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Pending", Reason="", readiness=false. Elapsed: 38.160104ms
Mar  1 08:12:06.354: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077073436s
Mar  1 08:12:08.391: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.114545247s
Mar  1 08:12:10.427: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 6.150089268s
Mar  1 08:12:12.463: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 8.186070339s
Mar  1 08:12:14.510: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 10.233411833s
Mar  1 08:12:16.549: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 12.272249393s
Mar  1 08:12:18.585: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 14.308009767s
Mar  1 08:12:20.625: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 16.347802865s
Mar  1 08:12:22.661: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 18.384043461s
Mar  1 08:12:24.696: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 20.41921151s
Mar  1 08:12:26.733: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Running", Reason="", readiness=false. Elapsed: 22.455653288s
Mar  1 08:12:28.769: INFO: Pod "pod-subpath-test-downwardapi-xn8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.491628269s
STEP: Saw pod success
Mar  1 08:12:28.769: INFO: Pod "pod-subpath-test-downwardapi-xn8b" satisfied condition "success or failure"
Mar  1 08:12:28.803: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-subpath-test-downwardapi-xn8b container test-container-subpath-downwardapi-xn8b: <nil>
STEP: delete the pod
Mar  1 08:12:28.907: INFO: Waiting for pod pod-subpath-test-downwardapi-xn8b to disappear
Mar  1 08:12:28.944: INFO: Pod pod-subpath-test-downwardapi-xn8b no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xn8b
Mar  1 08:12:28.944: INFO: Deleting pod "pod-subpath-test-downwardapi-xn8b" in namespace "e2e-tests-subpath-4xwbt"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:12:28.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4xwbt" for this suite.
Mar  1 08:12:37.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:12:38.371: INFO: namespace: e2e-tests-subpath-4xwbt, resource: bindings, ignored listing per whitelist
Mar  1 08:12:38.511: INFO: namespace e2e-tests-subpath-4xwbt deletion completed in 9.486795496s

• [SLOW TEST:35.825 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:12:38.512: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-h4j7d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0301 08:13:10.386227   31738 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 08:13:10.386: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:13:10.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h4j7d" for this suite.
Mar  1 08:13:16.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:13:17.365: INFO: namespace: e2e-tests-gc-h4j7d, resource: bindings, ignored listing per whitelist
Mar  1 08:13:17.919: INFO: namespace e2e-tests-gc-h4j7d deletion completed in 7.49095432s

• [SLOW TEST:39.408 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:13:17.920: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-9kl98
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-9kl98
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 08:13:19.359: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 08:13:42.007: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.96.0.20 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9kl98 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:13:42.007: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:13:43.698: INFO: Found all expected endpoints: [netserver-0]
Mar  1 08:13:43.750: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 100.96.1.73 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9kl98 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:13:43.750: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:13:45.397: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:13:45.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-9kl98" for this suite.
Mar  1 08:14:09.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:14:10.730: INFO: namespace: e2e-tests-pod-network-test-9kl98, resource: bindings, ignored listing per whitelist
Mar  1 08:14:10.905: INFO: namespace e2e-tests-pod-network-test-9kl98 deletion completed in 25.472305009s

• [SLOW TEST:52.985 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:14:10.906: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-v9gdm
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ff21926c-3bf9-11e9-9193-2e670c8e304c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:14:16.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v9gdm" for this suite.
Mar  1 08:14:38.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:14:40.067: INFO: namespace: e2e-tests-configmap-v9gdm, resource: bindings, ignored listing per whitelist
Mar  1 08:14:40.278: INFO: namespace e2e-tests-configmap-v9gdm deletion completed in 23.45053868s

• [SLOW TEST:29.372 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:14:40.278: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-llbwb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar  1 08:14:48.049: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:14:48.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-llbwb" for this suite.
Mar  1 08:15:12.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:15:13.523: INFO: namespace: e2e-tests-replicaset-llbwb, resource: bindings, ignored listing per whitelist
Mar  1 08:15:13.661: INFO: namespace e2e-tests-replicaset-llbwb deletion completed in 25.463160133s

• [SLOW TEST:33.383 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:15:13.662: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-swpqf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 08:15:15.212: INFO: Waiting up to 5m0s for pod "downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-swpqf" to be "success or failure"
Mar  1 08:15:15.246: INFO: Pod "downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.338151ms
Mar  1 08:15:17.282: INFO: Pod "downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069935516s
Mar  1 08:15:19.317: INFO: Pod "downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105225253s
STEP: Saw pod success
Mar  1 08:15:19.317: INFO: Pod "downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:15:19.353: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 08:15:19.436: INFO: Waiting for pod downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c to disappear
Mar  1 08:15:19.470: INFO: Pod downward-api-247fe997-3bfa-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:15:19.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-swpqf" for this suite.
Mar  1 08:15:25.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:15:25.894: INFO: namespace: e2e-tests-downward-api-swpqf, resource: bindings, ignored listing per whitelist
Mar  1 08:15:27.019: INFO: namespace e2e-tests-downward-api-swpqf deletion completed in 7.513197102s

• [SLOW TEST:13.357 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:15:27.019: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lfhpx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lfhpx
Mar  1 08:15:34.588: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lfhpx
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 08:15:34.623: INFO: Initial restart count of pod liveness-http is 0
Mar  1 08:15:44.841: INFO: Restart count of pod e2e-tests-container-probe-lfhpx/liveness-http is now 1 (10.218146074s elapsed)
Mar  1 08:16:05.206: INFO: Restart count of pod e2e-tests-container-probe-lfhpx/liveness-http is now 2 (30.583277625s elapsed)
Mar  1 08:16:25.588: INFO: Restart count of pod e2e-tests-container-probe-lfhpx/liveness-http is now 3 (50.965674929s elapsed)
Mar  1 08:16:45.960: INFO: Restart count of pod e2e-tests-container-probe-lfhpx/liveness-http is now 4 (1m11.336912059s elapsed)
Mar  1 08:17:57.321: INFO: Restart count of pod e2e-tests-container-probe-lfhpx/liveness-http is now 5 (2m22.698301499s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:17:57.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lfhpx" for this suite.
Mar  1 08:18:03.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:18:04.660: INFO: namespace: e2e-tests-container-probe-lfhpx, resource: bindings, ignored listing per whitelist
Mar  1 08:18:04.902: INFO: namespace e2e-tests-container-probe-lfhpx deletion completed in 7.464392835s

• [SLOW TEST:157.883 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:18:04.902: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-wtlfq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wtlfq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 08:18:06.350: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 08:18:33.005: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.21:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wtlfq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:18:33.005: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:18:34.245: INFO: Found all expected endpoints: [netserver-0]
Mar  1 08:18:34.281: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.80:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wtlfq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:18:34.281: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:18:34.868: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:18:34.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wtlfq" for this suite.
Mar  1 08:18:57.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:18:58.011: INFO: namespace: e2e-tests-pod-network-test-wtlfq, resource: bindings, ignored listing per whitelist
Mar  1 08:18:58.403: INFO: namespace e2e-tests-pod-network-test-wtlfq deletion completed in 23.499248331s

• [SLOW TEST:53.502 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:18:58.404: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-s6rgj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 08:19:04.651: INFO: Successfully updated pod "annotationupdateaa6bb894-3bfa-11e9-9193-2e670c8e304c"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:19:06.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s6rgj" for this suite.
Mar  1 08:19:28.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:19:29.468: INFO: namespace: e2e-tests-downward-api-s6rgj, resource: bindings, ignored listing per whitelist
Mar  1 08:19:30.259: INFO: namespace e2e-tests-downward-api-s6rgj deletion completed in 23.490001966s

• [SLOW TEST:31.856 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:19:30.260: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-mhhkp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-h9tv
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 08:19:32.066: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-h9tv" in namespace "e2e-tests-subpath-mhhkp" to be "success or failure"
Mar  1 08:19:32.101: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Pending", Reason="", readiness=false. Elapsed: 35.020783ms
Mar  1 08:19:34.140: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074503108s
Mar  1 08:19:36.176: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110579572s
Mar  1 08:19:38.212: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 6.146532417s
Mar  1 08:19:40.249: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 8.183253538s
Mar  1 08:19:42.287: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 10.221723131s
Mar  1 08:19:44.323: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 12.25781592s
Mar  1 08:19:46.361: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 14.295427775s
Mar  1 08:19:48.397: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 16.331193515s
Mar  1 08:19:50.432: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 18.366305875s
Mar  1 08:19:52.468: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 20.402432053s
Mar  1 08:19:54.503: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Running", Reason="", readiness=false. Elapsed: 22.437792655s
Mar  1 08:19:56.539: INFO: Pod "pod-subpath-test-secret-h9tv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.473782265s
STEP: Saw pod success
Mar  1 08:19:56.539: INFO: Pod "pod-subpath-test-secret-h9tv" satisfied condition "success or failure"
Mar  1 08:19:56.575: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-subpath-test-secret-h9tv container test-container-subpath-secret-h9tv: <nil>
STEP: delete the pod
Mar  1 08:19:56.657: INFO: Waiting for pod pod-subpath-test-secret-h9tv to disappear
Mar  1 08:19:56.692: INFO: Pod pod-subpath-test-secret-h9tv no longer exists
STEP: Deleting pod pod-subpath-test-secret-h9tv
Mar  1 08:19:56.692: INFO: Deleting pod "pod-subpath-test-secret-h9tv" in namespace "e2e-tests-subpath-mhhkp"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:19:56.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mhhkp" for this suite.
Mar  1 08:20:02.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:20:03.721: INFO: namespace: e2e-tests-subpath-mhhkp, resource: bindings, ignored listing per whitelist
Mar  1 08:20:04.203: INFO: namespace e2e-tests-subpath-mhhkp deletion completed in 7.441084383s

• [SLOW TEST:33.944 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:20:04.204: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qhqgm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d1a65bc8-3bfa-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 08:20:05.744: INFO: Waiting up to 5m0s for pod "pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-qhqgm" to be "success or failure"
Mar  1 08:20:05.786: INFO: Pod "pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.999981ms
Mar  1 08:20:07.822: INFO: Pod "pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077621765s
Mar  1 08:20:09.858: INFO: Pod "pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113570646s
STEP: Saw pod success
Mar  1 08:20:09.858: INFO: Pod "pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:20:09.894: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:20:09.985: INFO: Waiting for pod pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c to disappear
Mar  1 08:20:10.020: INFO: Pod pod-secrets-d1abb5de-3bfa-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:20:10.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qhqgm" for this suite.
Mar  1 08:20:16.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:20:16.480: INFO: namespace: e2e-tests-secrets-qhqgm, resource: bindings, ignored listing per whitelist
Mar  1 08:20:17.580: INFO: namespace e2e-tests-secrets-qhqgm deletion completed in 7.525156453s

• [SLOW TEST:13.376 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:20:17.580: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-j8g56
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-j8g56.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-j8g56.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-j8g56.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-j8g56.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-j8g56.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-j8g56.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 08:20:38.615: INFO: DNS probes using e2e-tests-dns-j8g56/dns-test-d9a04c0c-3bfa-11e9-9193-2e670c8e304c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:20:38.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-j8g56" for this suite.
Mar  1 08:20:44.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:20:45.986: INFO: namespace: e2e-tests-dns-j8g56, resource: bindings, ignored listing per whitelist
Mar  1 08:20:46.229: INFO: namespace e2e-tests-dns-j8g56 deletion completed in 7.502935335s

• [SLOW TEST:28.649 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:20:46.229: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-4km49
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar  1 08:20:51.975: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-eab7e7ab-3bfa-11e9-9193-2e670c8e304c", GenerateName:"", Namespace:"e2e-tests-pods-4km49", SelfLink:"/api/v1/namespaces/e2e-tests-pods-4km49/pods/pod-submit-remove-eab7e7ab-3bfa-11e9-9193-2e670c8e304c", UID:"eac5960e-3bfa-11e9-a289-2aff89a14c6e", ResourceVersion:"9571", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687025247, loc:(*time.Location)(0x791ea40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"729455889"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.86/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hgdvh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0021fc780), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hgdvh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002228768), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0021382a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022287a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022287c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0022287c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0022287cc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025247, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025250, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025250, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025247, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.4", PodIP:"100.96.1.86", StartTime:(*v1.Time)(0xc002216ae0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc002216b00), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://cc312c454278a90d6127723abb1d1f2fb385ae67264851d9830a4adc488ec90d"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:21:05.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4km49" for this suite.
Mar  1 08:21:11.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:21:12.338: INFO: namespace: e2e-tests-pods-4km49, resource: bindings, ignored listing per whitelist
Mar  1 08:21:13.246: INFO: namespace e2e-tests-pods-4km49 deletion completed in 7.678767166s

• [SLOW TEST:27.017 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:21:13.246: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-w4svt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:21:19.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-w4svt" for this suite.
Mar  1 08:21:25.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:21:25.687: INFO: namespace: e2e-tests-emptydir-wrapper-w4svt, resource: bindings, ignored listing per whitelist
Mar  1 08:21:26.660: INFO: namespace e2e-tests-emptydir-wrapper-w4svt deletion completed in 7.4270339s

• [SLOW TEST:13.414 seconds]
[sig-storage] EmptyDir wrapper volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:21:26.661: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-kbqcs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0301 08:21:38.643821   31738 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 08:21:38.643: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:21:38.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kbqcs" for this suite.
Mar  1 08:21:46.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:21:47.980: INFO: namespace: e2e-tests-gc-kbqcs, resource: bindings, ignored listing per whitelist
Mar  1 08:21:48.119: INFO: namespace e2e-tests-gc-kbqcs deletion completed in 9.440398452s

• [SLOW TEST:21.458 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:21:48.119: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-d28zm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 08:21:54.327: INFO: Successfully updated pod "pod-update-activedeadlineseconds-0f921908-3bfb-11e9-9193-2e670c8e304c"
Mar  1 08:21:54.327: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-0f921908-3bfb-11e9-9193-2e670c8e304c" in namespace "e2e-tests-pods-d28zm" to be "terminated due to deadline exceeded"
Mar  1 08:21:54.362: INFO: Pod "pod-update-activedeadlineseconds-0f921908-3bfb-11e9-9193-2e670c8e304c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 34.3134ms
Mar  1 08:21:54.362: INFO: Pod "pod-update-activedeadlineseconds-0f921908-3bfb-11e9-9193-2e670c8e304c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:21:54.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-d28zm" for this suite.
Mar  1 08:22:02.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:22:03.465: INFO: namespace: e2e-tests-pods-d28zm, resource: bindings, ignored listing per whitelist
Mar  1 08:22:03.888: INFO: namespace e2e-tests-pods-d28zm deletion completed in 9.477118506s

• [SLOW TEST:15.769 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:22:03.888: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-46j9n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:22:05.397: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-46j9n" to be "success or failure"
Mar  1 08:22:05.432: INFO: Pod "downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.13699ms
Mar  1 08:22:07.468: INFO: Pod "downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071344481s
Mar  1 08:22:09.504: INFO: Pod "downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107415313s
STEP: Saw pod success
Mar  1 08:22:09.504: INFO: Pod "downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:22:09.543: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 08:22:09.633: INFO: Waiting for pod downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c to disappear
Mar  1 08:22:09.668: INFO: Pod downwardapi-volume-18fd4637-3bfb-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:22:09.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-46j9n" for this suite.
Mar  1 08:22:15.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:22:16.380: INFO: namespace: e2e-tests-projected-46j9n, resource: bindings, ignored listing per whitelist
Mar  1 08:22:17.205: INFO: namespace e2e-tests-projected-46j9n deletion completed in 7.491278904s

• [SLOW TEST:13.317 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:22:17.205: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4rfbx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:23:18.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4rfbx" for this suite.
Mar  1 08:23:42.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:23:43.456: INFO: namespace: e2e-tests-container-probe-4rfbx, resource: bindings, ignored listing per whitelist
Mar  1 08:23:44.420: INFO: namespace e2e-tests-container-probe-4rfbx deletion completed in 25.560731098s

• [SLOW TEST:87.215 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:23:44.420: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5qzdl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  1 08:23:45.862: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:48.303: INFO: stderr: ""
Mar  1 08:23:48.304: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:23:48.304: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:48.562: INFO: stderr: ""
Mar  1 08:23:48.562: INFO: stdout: "update-demo-nautilus-6d94v update-demo-nautilus-9cxk8 "
Mar  1 08:23:48.562: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-6d94v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:48.806: INFO: stderr: ""
Mar  1 08:23:48.806: INFO: stdout: ""
Mar  1 08:23:48.806: INFO: update-demo-nautilus-6d94v is created but not running
Mar  1 08:23:53.806: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:54.041: INFO: stderr: ""
Mar  1 08:23:54.041: INFO: stdout: "update-demo-nautilus-6d94v update-demo-nautilus-9cxk8 "
Mar  1 08:23:54.041: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-6d94v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:54.286: INFO: stderr: ""
Mar  1 08:23:54.286: INFO: stdout: "true"
Mar  1 08:23:54.286: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-6d94v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:54.505: INFO: stderr: ""
Mar  1 08:23:54.505: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:23:54.505: INFO: validating pod update-demo-nautilus-6d94v
Mar  1 08:23:54.626: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:23:54.626: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:23:54.626: INFO: update-demo-nautilus-6d94v is verified up and running
Mar  1 08:23:54.626: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:54.845: INFO: stderr: ""
Mar  1 08:23:54.845: INFO: stdout: "true"
Mar  1 08:23:54.845: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:55.077: INFO: stderr: ""
Mar  1 08:23:55.078: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:23:55.078: INFO: validating pod update-demo-nautilus-9cxk8
Mar  1 08:23:55.197: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:23:55.197: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:23:55.197: INFO: update-demo-nautilus-9cxk8 is verified up and running
STEP: scaling down the replication controller
Mar  1 08:23:55.210: INFO: scanned /root for discovery docs: <nil>
Mar  1 08:23:55.211: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:56.622: INFO: stderr: ""
Mar  1 08:23:56.622: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:23:56.622: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:23:56.892: INFO: stderr: ""
Mar  1 08:23:56.892: INFO: stdout: "update-demo-nautilus-6d94v update-demo-nautilus-9cxk8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  1 08:24:01.892: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:02.197: INFO: stderr: ""
Mar  1 08:24:02.200: INFO: stdout: "update-demo-nautilus-9cxk8 "
Mar  1 08:24:02.203: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:02.530: INFO: stderr: ""
Mar  1 08:24:02.531: INFO: stdout: "true"
Mar  1 08:24:02.532: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:02.799: INFO: stderr: ""
Mar  1 08:24:02.799: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:24:02.799: INFO: validating pod update-demo-nautilus-9cxk8
Mar  1 08:24:02.836: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:24:02.836: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:24:02.836: INFO: update-demo-nautilus-9cxk8 is verified up and running
STEP: scaling up the replication controller
Mar  1 08:24:02.840: INFO: scanned /root for discovery docs: <nil>
Mar  1 08:24:02.840: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:04.271: INFO: stderr: ""
Mar  1 08:24:04.271: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:24:04.271: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:04.488: INFO: stderr: ""
Mar  1 08:24:04.488: INFO: stdout: "update-demo-nautilus-9cxk8 update-demo-nautilus-zcbjw "
Mar  1 08:24:04.488: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:04.726: INFO: stderr: ""
Mar  1 08:24:04.726: INFO: stdout: "true"
Mar  1 08:24:04.726: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:04.948: INFO: stderr: ""
Mar  1 08:24:04.948: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:24:04.948: INFO: validating pod update-demo-nautilus-9cxk8
Mar  1 08:24:04.985: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:24:04.985: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:24:04.985: INFO: update-demo-nautilus-9cxk8 is verified up and running
Mar  1 08:24:04.985: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-zcbjw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:05.223: INFO: stderr: ""
Mar  1 08:24:05.223: INFO: stdout: ""
Mar  1 08:24:05.223: INFO: update-demo-nautilus-zcbjw is created but not running
Mar  1 08:24:10.223: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:10.478: INFO: stderr: ""
Mar  1 08:24:10.478: INFO: stdout: "update-demo-nautilus-9cxk8 update-demo-nautilus-zcbjw "
Mar  1 08:24:10.478: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:10.703: INFO: stderr: ""
Mar  1 08:24:10.703: INFO: stdout: "true"
Mar  1 08:24:10.703: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-9cxk8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:10.973: INFO: stderr: ""
Mar  1 08:24:10.973: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:24:10.973: INFO: validating pod update-demo-nautilus-9cxk8
Mar  1 08:24:11.010: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:24:11.010: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:24:11.010: INFO: update-demo-nautilus-9cxk8 is verified up and running
Mar  1 08:24:11.010: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-zcbjw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:11.248: INFO: stderr: ""
Mar  1 08:24:11.248: INFO: stdout: "true"
Mar  1 08:24:11.248: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-zcbjw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:11.492: INFO: stderr: ""
Mar  1 08:24:11.492: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:24:11.492: INFO: validating pod update-demo-nautilus-zcbjw
Mar  1 08:24:11.612: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:24:11.612: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:24:11.612: INFO: update-demo-nautilus-zcbjw is verified up and running
STEP: using delete to clean up resources
Mar  1 08:24:11.613: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:11.921: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:24:11.921: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 08:24:11.921: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-5qzdl'
Mar  1 08:24:12.219: INFO: stderr: "No resources found.\n"
Mar  1 08:24:12.219: INFO: stdout: ""
Mar  1 08:24:12.219: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-5qzdl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 08:24:12.543: INFO: stderr: ""
Mar  1 08:24:12.544: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:24:12.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5qzdl" for this suite.
Mar  1 08:24:34.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:24:35.283: INFO: namespace: e2e-tests-kubectl-5qzdl, resource: bindings, ignored listing per whitelist
Mar  1 08:24:36.023: INFO: namespace e2e-tests-kubectl-5qzdl deletion completed in 23.444202516s

• [SLOW TEST:51.603 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:24:36.024: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-bttkf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar  1 08:24:38.140: INFO: created pod pod-service-account-defaultsa
Mar  1 08:24:38.140: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  1 08:24:38.180: INFO: created pod pod-service-account-mountsa
Mar  1 08:24:38.180: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  1 08:24:38.243: INFO: created pod pod-service-account-nomountsa
Mar  1 08:24:38.243: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  1 08:24:38.280: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  1 08:24:38.280: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  1 08:24:38.318: INFO: created pod pod-service-account-mountsa-mountspec
Mar  1 08:24:38.318: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  1 08:24:38.363: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  1 08:24:38.363: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  1 08:24:38.403: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  1 08:24:38.404: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  1 08:24:38.440: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  1 08:24:38.440: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  1 08:24:38.475: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  1 08:24:38.475: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:24:38.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bttkf" for this suite.
Mar  1 08:25:02.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:25:03.046: INFO: namespace: e2e-tests-svcaccounts-bttkf, resource: bindings, ignored listing per whitelist
Mar  1 08:25:04.033: INFO: namespace e2e-tests-svcaccounts-bttkf deletion completed in 25.521379515s

• [SLOW TEST:28.009 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:25:04.033: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zccpm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar  1 08:25:05.462: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:25:05.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zccpm" for this suite.
Mar  1 08:25:11.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:25:12.906: INFO: namespace: e2e-tests-kubectl-zccpm, resource: bindings, ignored listing per whitelist
Mar  1 08:25:13.262: INFO: namespace e2e-tests-kubectl-zccpm deletion completed in 7.4504376s

• [SLOW TEST:9.229 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:25:13.262: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fd7rk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-89e050e6-3bfb-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 08:25:14.825: INFO: Waiting up to 5m0s for pod "pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-fd7rk" to be "success or failure"
Mar  1 08:25:14.868: INFO: Pod "pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 42.693337ms
Mar  1 08:25:16.904: INFO: Pod "pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078444624s
Mar  1 08:25:18.939: INFO: Pod "pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113883266s
STEP: Saw pod success
Mar  1 08:25:18.939: INFO: Pod "pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:25:18.974: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:25:19.064: INFO: Waiting for pod pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c to disappear
Mar  1 08:25:19.100: INFO: Pod pod-configmaps-89e5bf24-3bfb-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:25:19.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fd7rk" for this suite.
Mar  1 08:25:25.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:25:25.907: INFO: namespace: e2e-tests-configmap-fd7rk, resource: bindings, ignored listing per whitelist
Mar  1 08:25:26.640: INFO: namespace e2e-tests-configmap-fd7rk deletion completed in 7.504480442s

• [SLOW TEST:13.378 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:25:26.640: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bbhn5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 08:25:28.194: INFO: Waiting up to 5m0s for pod "pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-bbhn5" to be "success or failure"
Mar  1 08:25:28.229: INFO: Pod "pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.068166ms
Mar  1 08:25:30.265: INFO: Pod "pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070341814s
Mar  1 08:25:32.300: INFO: Pod "pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105929996s
STEP: Saw pod success
Mar  1 08:25:32.300: INFO: Pod "pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:25:32.335: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 08:25:32.419: INFO: Waiting for pod pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c to disappear
Mar  1 08:25:32.453: INFO: Pod pod-91ddc0af-3bfb-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:25:32.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bbhn5" for this suite.
Mar  1 08:25:38.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:25:38.870: INFO: namespace: e2e-tests-emptydir-bbhn5, resource: bindings, ignored listing per whitelist
Mar  1 08:25:39.945: INFO: namespace e2e-tests-emptydir-bbhn5 deletion completed in 7.456758214s

• [SLOW TEST:13.305 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:25:39.946: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wzztj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 08:25:46.123: INFO: Successfully updated pod "labelsupdate99bc788b-3bfb-11e9-9193-2e670c8e304c"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:25:48.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wzztj" for this suite.
Mar  1 08:26:10.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:26:11.108: INFO: namespace: e2e-tests-downward-api-wzztj, resource: bindings, ignored listing per whitelist
Mar  1 08:26:11.807: INFO: namespace e2e-tests-downward-api-wzztj deletion completed in 23.565693522s

• [SLOW TEST:31.861 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:26:11.807: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-vmnzx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:26:19.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-vmnzx" for this suite.
Mar  1 08:26:43.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:26:44.114: INFO: namespace: e2e-tests-replication-controller-vmnzx, resource: bindings, ignored listing per whitelist
Mar  1 08:26:45.158: INFO: namespace e2e-tests-replication-controller-vmnzx deletion completed in 25.437697557s

• [SLOW TEST:33.351 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:26:45.158: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ld6bj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-72pp
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 08:26:46.675: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-72pp" in namespace "e2e-tests-subpath-ld6bj" to be "success or failure"
Mar  1 08:26:46.710: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Pending", Reason="", readiness=false. Elapsed: 34.537365ms
Mar  1 08:26:48.746: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07014611s
Mar  1 08:26:50.781: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.105892778s
Mar  1 08:26:52.817: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 6.141889512s
Mar  1 08:26:54.854: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 8.178217738s
Mar  1 08:26:56.889: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 10.213870963s
Mar  1 08:26:58.925: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 12.249702215s
Mar  1 08:27:00.962: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 14.286131347s
Mar  1 08:27:02.998: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 16.322456983s
Mar  1 08:27:05.034: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 18.358360389s
Mar  1 08:27:07.070: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 20.394384999s
Mar  1 08:27:09.106: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Running", Reason="", readiness=false. Elapsed: 22.430469304s
Mar  1 08:27:11.141: INFO: Pod "pod-subpath-test-configmap-72pp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.465874477s
STEP: Saw pod success
Mar  1 08:27:11.141: INFO: Pod "pod-subpath-test-configmap-72pp" satisfied condition "success or failure"
Mar  1 08:27:11.176: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-subpath-test-configmap-72pp container test-container-subpath-configmap-72pp: <nil>
STEP: delete the pod
Mar  1 08:27:11.278: INFO: Waiting for pod pod-subpath-test-configmap-72pp to disappear
Mar  1 08:27:11.313: INFO: Pod pod-subpath-test-configmap-72pp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-72pp
Mar  1 08:27:11.313: INFO: Deleting pod "pod-subpath-test-configmap-72pp" in namespace "e2e-tests-subpath-ld6bj"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:27:11.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ld6bj" for this suite.
Mar  1 08:27:17.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:27:18.491: INFO: namespace: e2e-tests-subpath-ld6bj, resource: bindings, ignored listing per whitelist
Mar  1 08:27:18.886: INFO: namespace e2e-tests-subpath-ld6bj deletion completed in 7.498669869s

• [SLOW TEST:33.729 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:27:18.887: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-pvltw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d4c680c3-3bfb-11e9-9193-2e670c8e304c
STEP: Creating configMap with name cm-test-opt-upd-d4c6810a-3bfb-11e9-9193-2e670c8e304c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d4c680c3-3bfb-11e9-9193-2e670c8e304c
STEP: Updating configmap cm-test-opt-upd-d4c6810a-3bfb-11e9-9193-2e670c8e304c
STEP: Creating configMap with name cm-test-opt-create-d4c68127-3bfb-11e9-9193-2e670c8e304c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:28:49.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pvltw" for this suite.
Mar  1 08:29:13.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:29:13.442: INFO: namespace: e2e-tests-configmap-pvltw, resource: bindings, ignored listing per whitelist
Mar  1 08:29:14.493: INFO: namespace e2e-tests-configmap-pvltw deletion completed in 25.443201435s

• [SLOW TEST:115.611 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:29:14.498: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4jlg4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar  1 08:29:15.957: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml --namespace=e2e-tests-kubectl-4jlg4 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  1 08:29:19.657: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  1 08:29:19.657: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:29:21.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4jlg4" for this suite.
Mar  1 08:29:27.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:29:29.124: INFO: namespace: e2e-tests-kubectl-4jlg4, resource: bindings, ignored listing per whitelist
Mar  1 08:29:29.298: INFO: namespace e2e-tests-kubectl-4jlg4 deletion completed in 7.536460002s

• [SLOW TEST:14.800 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:29:29.298: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6flbr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 08:29:35.584: INFO: Successfully updated pod "annotationupdate2277332d-3bfc-11e9-9193-2e670c8e304c"
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:29:37.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6flbr" for this suite.
Mar  1 08:29:59.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:30:00.090: INFO: namespace: e2e-tests-projected-6flbr, resource: bindings, ignored listing per whitelist
Mar  1 08:30:01.197: INFO: namespace e2e-tests-projected-6flbr deletion completed in 23.492810006s

• [SLOW TEST:31.899 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:30:01.197: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-856j5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-856j5
Mar  1 08:30:06.768: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-856j5
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 08:30:06.803: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:34:07.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-856j5" for this suite.
Mar  1 08:34:13.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:34:13.646: INFO: namespace: e2e-tests-container-probe-856j5, resource: bindings, ignored listing per whitelist
Mar  1 08:34:14.658: INFO: namespace e2e-tests-container-probe-856j5 deletion completed in 7.429203611s

• [SLOW TEST:253.461 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:34:14.658: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-bldmv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:34:45.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-bldmv" for this suite.
Mar  1 08:34:51.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:34:52.117: INFO: namespace: e2e-tests-container-runtime-bldmv, resource: bindings, ignored listing per whitelist
Mar  1 08:34:52.568: INFO: namespace e2e-tests-container-runtime-bldmv deletion completed in 7.480304753s

• [SLOW TEST:37.910 seconds]
[k8s.io] Container Runtime
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:34:52.568: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4vdkt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 08:34:54.098: INFO: Waiting up to 5m0s for pod "pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-4vdkt" to be "success or failure"
Mar  1 08:34:54.134: INFO: Pod "pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.96462ms
Mar  1 08:34:56.170: INFO: Pod "pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071840272s
Mar  1 08:34:58.206: INFO: Pod "pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10719565s
STEP: Saw pod success
Mar  1 08:34:58.206: INFO: Pod "pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:34:58.242: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 08:34:58.336: INFO: Waiting for pod pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c to disappear
Mar  1 08:34:58.371: INFO: Pod pod-e32bdc7d-3bfc-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:34:58.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4vdkt" for this suite.
Mar  1 08:35:04.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:35:04.618: INFO: namespace: e2e-tests-emptydir-4vdkt, resource: bindings, ignored listing per whitelist
Mar  1 08:35:05.901: INFO: namespace e2e-tests-emptydir-4vdkt deletion completed in 7.494902395s

• [SLOW TEST:13.333 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:35:05.901: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-2lvzb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:35:07.592: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 08:35:07.722: INFO: Number of nodes with available pods: 0
Mar  1 08:35:07.722: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:35:08.802: INFO: Number of nodes with available pods: 0
Mar  1 08:35:08.802: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:35:09.793: INFO: Number of nodes with available pods: 0
Mar  1 08:35:09.793: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:35:10.793: INFO: Number of nodes with available pods: 2
Mar  1 08:35:10.793: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  1 08:35:11.007: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:11.008: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:12.083: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:12.083: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:13.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:13.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:14.081: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:14.081: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:15.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:15.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:16.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:16.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:17.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:17.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:18.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:18.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:19.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:19.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:20.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:20.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:21.082: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:21.082: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:22.082: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:22.082: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:23.077: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:23.077: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:24.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:24.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:25.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:25.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:26.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:26.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:27.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:27.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:28.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:28.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:29.080: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:29.080: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:30.082: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:30.082: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:31.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:31.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:32.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:32.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:33.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:33.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:34.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:34.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:35.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:35.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:36.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:36.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:37.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:37.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:38.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:38.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:39.080: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:39.080: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:40.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:40.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:41.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:41.079: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:42.080: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:42.080: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:43.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:43.078: INFO: Wrong image for pod: daemon-set-vvc7l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:43.078: INFO: Pod daemon-set-vvc7l is not available
Mar  1 08:35:44.090: INFO: Pod daemon-set-nzpr2 is not available
Mar  1 08:35:44.090: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:45.078: INFO: Pod daemon-set-nzpr2 is not available
Mar  1 08:35:45.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:46.086: INFO: Pod daemon-set-nzpr2 is not available
Mar  1 08:35:46.086: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:47.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:48.083: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:49.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:50.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:51.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:52.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:53.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:54.082: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:55.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:56.085: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:57.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:58.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:35:59.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:00.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:01.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:02.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:03.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:04.082: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:05.083: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:06.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:07.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:08.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:09.078: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:10.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:11.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:12.082: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:13.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:14.140: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:15.083: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:16.079: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:17.080: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:18.080: INFO: Wrong image for pod: daemon-set-r46pr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 08:36:18.080: INFO: Pod daemon-set-r46pr is not available
Mar  1 08:36:19.078: INFO: Pod daemon-set-8xjn8 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  1 08:36:19.188: INFO: Number of nodes with available pods: 1
Mar  1 08:36:19.188: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:36:20.263: INFO: Number of nodes with available pods: 1
Mar  1 08:36:20.263: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:36:21.260: INFO: Number of nodes with available pods: 1
Mar  1 08:36:21.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:36:22.261: INFO: Number of nodes with available pods: 1
Mar  1 08:36:22.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 08:36:23.259: INFO: Number of nodes with available pods: 2
Mar  1 08:36:23.259: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2lvzb, will wait for the garbage collector to delete the pods
Mar  1 08:36:23.562: INFO: Deleting DaemonSet.extensions daemon-set took: 37.585327ms
Mar  1 08:36:23.662: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.25512ms
Mar  1 08:36:27.297: INFO: Number of nodes with available pods: 0
Mar  1 08:36:27.297: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 08:36:27.332: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2lvzb/daemonsets","resourceVersion":"12067"},"items":null}

Mar  1 08:36:27.367: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2lvzb/pods","resourceVersion":"12067"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:36:27.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2lvzb" for this suite.
Mar  1 08:36:33.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:36:33.981: INFO: namespace: e2e-tests-daemonsets-2lvzb, resource: bindings, ignored listing per whitelist
Mar  1 08:36:34.994: INFO: namespace e2e-tests-daemonsets-2lvzb deletion completed in 7.487182955s

• [SLOW TEST:89.093 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:36:34.994: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-6zbxx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-27rg8 in namespace e2e-tests-proxy-6zbxx
I0301 08:36:36.591217   31738 runners.go:184] Created replication controller with name: proxy-service-27rg8, namespace: e2e-tests-proxy-6zbxx, replica count: 1
I0301 08:36:37.643582   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:36:38.643819   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:36:39.644087   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:36:40.644323   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:36:41.644648   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:42.644904   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:43.645112   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:44.645386   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:45.645587   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:46.645817   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:47.646069   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:48.646243   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:36:49.646422   31738 runners.go:184] proxy-service-27rg8 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 08:36:49.681: INFO: setup took 13.219667918s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  1 08:36:49.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 57.478651ms)
Mar  1 08:36:49.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 57.594085ms)
Mar  1 08:36:49.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 57.767687ms)
Mar  1 08:36:49.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 62.837622ms)
Mar  1 08:36:49.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 62.800402ms)
Mar  1 08:36:49.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 62.916738ms)
Mar  1 08:36:49.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 62.735388ms)
Mar  1 08:36:49.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 62.963671ms)
Mar  1 08:36:49.747: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 65.98461ms)
Mar  1 08:36:49.747: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 65.971739ms)
Mar  1 08:36:49.747: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 65.975669ms)
Mar  1 08:36:49.749: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 67.925316ms)
Mar  1 08:36:49.749: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 67.909579ms)
Mar  1 08:36:49.749: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 68.19308ms)
Mar  1 08:36:49.750: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 68.722759ms)
Mar  1 08:36:49.758: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 76.577165ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.957282ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 37.192876ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 37.204525ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 37.024197ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.195269ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 37.065865ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 37.293908ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 37.244128ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.149293ms)
Mar  1 08:36:49.795: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 37.202313ms)
Mar  1 08:36:49.837: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 79.611431ms)
Mar  1 08:36:49.837: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 79.121183ms)
Mar  1 08:36:49.837: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 79.357562ms)
Mar  1 08:36:49.837: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 79.719853ms)
Mar  1 08:36:49.838: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 79.718445ms)
Mar  1 08:36:49.838: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 79.50512ms)
Mar  1 08:36:49.876: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 37.738341ms)
Mar  1 08:36:49.876: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 38.101959ms)
Mar  1 08:36:49.876: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 38.434284ms)
Mar  1 08:36:49.876: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 38.51887ms)
Mar  1 08:36:49.876: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 38.124329ms)
Mar  1 08:36:49.876: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 38.00645ms)
Mar  1 08:36:49.876: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 38.639126ms)
Mar  1 08:36:49.877: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 38.256204ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 39.857985ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 40.022383ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 39.927953ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 40.008739ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 39.948526ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 40.037672ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 40.026903ms)
Mar  1 08:36:49.878: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 40.719869ms)
Mar  1 08:36:49.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.799197ms)
Mar  1 08:36:49.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.917646ms)
Mar  1 08:36:49.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.865351ms)
Mar  1 08:36:49.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.963302ms)
Mar  1 08:36:49.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.773242ms)
Mar  1 08:36:49.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.970134ms)
Mar  1 08:36:49.915: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.76533ms)
Mar  1 08:36:49.916: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.882948ms)
Mar  1 08:36:49.916: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.78592ms)
Mar  1 08:36:49.916: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.793906ms)
Mar  1 08:36:49.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 66.762665ms)
Mar  1 08:36:49.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 66.581514ms)
Mar  1 08:36:49.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 66.646408ms)
Mar  1 08:36:49.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 66.585806ms)
Mar  1 08:36:49.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 66.596195ms)
Mar  1 08:36:49.945: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 66.82391ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.829933ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 35.815106ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.37542ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.712768ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.45075ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.032946ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 35.953822ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.546018ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.654927ms)
Mar  1 08:36:49.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.718265ms)
Mar  1 08:36:49.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.69738ms)
Mar  1 08:36:49.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 38.404437ms)
Mar  1 08:36:49.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.968531ms)
Mar  1 08:36:49.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.788624ms)
Mar  1 08:36:49.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 37.94057ms)
Mar  1 08:36:49.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.877975ms)
Mar  1 08:36:50.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.234595ms)
Mar  1 08:36:50.020: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.096804ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.205563ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 37.192052ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 37.137292ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 37.177924ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.165317ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 37.242442ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 37.224443ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 37.221705ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 37.273768ms)
Mar  1 08:36:50.021: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 37.217801ms)
Mar  1 08:36:50.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.744542ms)
Mar  1 08:36:50.022: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.853345ms)
Mar  1 08:36:50.023: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 38.818733ms)
Mar  1 08:36:50.023: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 38.875611ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 37.753991ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.758802ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 37.283744ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 38.160088ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 37.208406ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 37.461211ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 37.535528ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 37.825461ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 38.011327ms)
Mar  1 08:36:50.061: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 37.472899ms)
Mar  1 08:36:50.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 69.342183ms)
Mar  1 08:36:50.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 69.852645ms)
Mar  1 08:36:50.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 69.493009ms)
Mar  1 08:36:50.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 69.390113ms)
Mar  1 08:36:50.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 69.123957ms)
Mar  1 08:36:50.093: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 69.874591ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 35.749043ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.275908ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.012141ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 35.915439ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.397533ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.953189ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.320349ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.415099ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.26665ms)
Mar  1 08:36:50.130: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.167208ms)
Mar  1 08:36:50.131: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.397932ms)
Mar  1 08:36:50.131: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.695668ms)
Mar  1 08:36:50.131: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 37.114172ms)
Mar  1 08:36:50.131: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.539797ms)
Mar  1 08:36:50.131: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.671066ms)
Mar  1 08:36:50.131: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 37.761654ms)
Mar  1 08:36:50.168: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.265781ms)
Mar  1 08:36:50.168: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.670379ms)
Mar  1 08:36:50.168: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.295068ms)
Mar  1 08:36:50.168: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.433409ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.534585ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 37.43181ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.822442ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.669302ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.292423ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.99088ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.271104ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.660102ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.879055ms)
Mar  1 08:36:50.169: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.528624ms)
Mar  1 08:36:50.170: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 38.260643ms)
Mar  1 08:36:50.170: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 38.185005ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 37.882739ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 38.344926ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.593921ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 37.728308ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 37.694263ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 38.151156ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 38.328806ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 38.528938ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 38.735439ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 38.442659ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 38.299334ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 38.21069ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 38.022719ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.978738ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 38.153593ms)
Mar  1 08:36:50.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 38.744195ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 65.888539ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 65.775697ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 66.209237ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 65.465137ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 65.781593ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 66.10816ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 65.464171ms)
Mar  1 08:36:50.275: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 65.450511ms)
Mar  1 08:36:50.276: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 65.321574ms)
Mar  1 08:36:50.276: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 66.083706ms)
Mar  1 08:36:50.276: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 66.040942ms)
Mar  1 08:36:50.276: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 66.485812ms)
Mar  1 08:36:50.277: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 66.818419ms)
Mar  1 08:36:50.277: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 66.978024ms)
Mar  1 08:36:50.277: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 66.83066ms)
Mar  1 08:36:50.277: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 66.613147ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.485086ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.531478ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.422055ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.789922ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.310638ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.246678ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.060178ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.692293ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.509857ms)
Mar  1 08:36:50.314: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.275578ms)
Mar  1 08:36:50.337: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 60.028171ms)
Mar  1 08:36:50.337: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 60.334614ms)
Mar  1 08:36:50.337: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 60.178943ms)
Mar  1 08:36:50.337: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 59.212494ms)
Mar  1 08:36:50.337: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 60.309009ms)
Mar  1 08:36:50.337: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 59.885197ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 37.62019ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.601744ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 38.231449ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 38.446968ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 38.111749ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 38.246705ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 38.032739ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 37.717334ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 38.025309ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.92712ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 38.291474ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 37.872071ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 38.268331ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 39.066639ms)
Mar  1 08:36:50.376: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 38.6104ms)
Mar  1 08:36:50.377: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 39.230267ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.18606ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.339974ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 37.070152ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.824213ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 37.167224ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 37.026632ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.738736ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.136644ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.82536ms)
Mar  1 08:36:50.414: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.388894ms)
Mar  1 08:36:50.415: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.624844ms)
Mar  1 08:36:50.415: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.602149ms)
Mar  1 08:36:50.415: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 38.451124ms)
Mar  1 08:36:50.418: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 39.745752ms)
Mar  1 08:36:50.418: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 39.895213ms)
Mar  1 08:36:50.418: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 39.860502ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.303548ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.945269ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.703147ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 37.07943ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.692816ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.612765ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.678866ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.430604ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.557546ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 36.777933ms)
Mar  1 08:36:50.455: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 37.434439ms)
Mar  1 08:36:50.456: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.607337ms)
Mar  1 08:36:50.456: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.696951ms)
Mar  1 08:36:50.456: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.862102ms)
Mar  1 08:36:50.456: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 37.562833ms)
Mar  1 08:36:50.456: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 38.270239ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 37.584166ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.8925ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.968436ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.839391ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 37.619368ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 37.741837ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 37.501177ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.919178ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.326542ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 37.43924ms)
Mar  1 08:36:50.494: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 38.000979ms)
Mar  1 08:36:50.495: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 38.214863ms)
Mar  1 08:36:50.495: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.97606ms)
Mar  1 08:36:50.495: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.567675ms)
Mar  1 08:36:50.495: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 38.048384ms)
Mar  1 08:36:50.495: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 38.37065ms)
Mar  1 08:36:50.532: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.032229ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.420949ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.045017ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.703645ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.244037ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.423242ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.388891ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.421673ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.925945ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 37.026985ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.405294ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 38.048676ms)
Mar  1 08:36:50.533: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.963585ms)
Mar  1 08:36:50.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 64.821924ms)
Mar  1 08:36:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 64.029052ms)
Mar  1 08:36:50.561: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 64.715749ms)
Mar  1 08:36:50.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 35.396773ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 36.4458ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 37.197331ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.929913ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.998009ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.868195ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.831954ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.425191ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.492928ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 37.20841ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 37.169887ms)
Mar  1 08:36:50.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.752797ms)
Mar  1 08:36:50.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.178734ms)
Mar  1 08:36:50.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.628015ms)
Mar  1 08:36:50.638: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 77.037193ms)
Mar  1 08:36:50.638: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 77.181151ms)
Mar  1 08:36:50.678: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 39.923504ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 39.822954ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 39.208683ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 39.472991ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 39.30794ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 39.568843ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 39.409104ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 39.772276ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 40.113404ms)
Mar  1 08:36:50.679: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 39.830906ms)
Mar  1 08:36:50.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 41.368582ms)
Mar  1 08:36:50.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 41.013008ms)
Mar  1 08:36:50.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 40.69185ms)
Mar  1 08:36:50.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 41.11215ms)
Mar  1 08:36:50.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 41.028498ms)
Mar  1 08:36:50.680: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 40.519239ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 35.988466ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:160/proxy/: foo (200; 36.853508ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:462/proxy/: tls qux (200; 36.376396ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:460/proxy/: tls baz (200; 36.796862ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:1080/proxy/... (200; 36.253948ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b/proxy/rewriteme"... (200; 36.580215ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/http:proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.520235ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:1080/proxy/rewri... (200; 36.979264ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/proxy-service-27rg8-2vq7b:162/proxy/: bar (200; 36.178703ms)
Mar  1 08:36:50.717: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6zbxx/pods/https:proxy-service-27rg8-2vq7b:443/proxy/... (200; 36.485602ms)
Mar  1 08:36:50.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname1/proxy/: tls baz (200; 37.201043ms)
Mar  1 08:36:50.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname1/proxy/: foo (200; 37.815175ms)
Mar  1 08:36:50.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/https:proxy-service-27rg8:tlsportname2/proxy/: tls qux (200; 37.232757ms)
Mar  1 08:36:50.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname1/proxy/: foo (200; 37.92555ms)
Mar  1 08:36:50.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/http:proxy-service-27rg8:portname2/proxy/: bar (200; 38.248846ms)
Mar  1 08:36:50.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6zbxx/services/proxy-service-27rg8:portname2/proxy/: bar (200; 37.511417ms)
STEP: deleting ReplicationController proxy-service-27rg8 in namespace e2e-tests-proxy-6zbxx, will wait for the garbage collector to delete the pods
Mar  1 08:36:50.841: INFO: Deleting ReplicationController proxy-service-27rg8 took: 37.093609ms
Mar  1 08:36:50.942: INFO: Terminating ReplicationController proxy-service-27rg8 pods took: 100.327687ms
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:36:55.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6zbxx" for this suite.
Mar  1 08:37:01.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:37:02.379: INFO: namespace: e2e-tests-proxy-6zbxx, resource: bindings, ignored listing per whitelist
Mar  1 08:37:03.005: INFO: namespace e2e-tests-proxy-6zbxx deletion completed in 7.426379813s

• [SLOW TEST:28.011 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:37:03.005: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-bqbv2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-bqbv2
I0301 08:37:04.500842   31738 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-bqbv2, replica count: 1
I0301 08:37:05.551225   31738 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:37:06.551458   31738 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:37:07.551696   31738 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 08:37:07.704: INFO: Created: latency-svc-qxb7l
Mar  1 08:37:07.713: INFO: Got endpoints: latency-svc-qxb7l [61.997114ms]
Mar  1 08:37:07.763: INFO: Created: latency-svc-tdm7c
Mar  1 08:37:07.785: INFO: Got endpoints: latency-svc-tdm7c [70.893689ms]
Mar  1 08:37:07.786: INFO: Created: latency-svc-2rk6x
Mar  1 08:37:07.798: INFO: Got endpoints: latency-svc-2rk6x [83.308604ms]
Mar  1 08:37:07.806: INFO: Created: latency-svc-5szwr
Mar  1 08:37:07.816: INFO: Got endpoints: latency-svc-5szwr [102.814001ms]
Mar  1 08:37:07.827: INFO: Created: latency-svc-7s44x
Mar  1 08:37:07.838: INFO: Got endpoints: latency-svc-7s44x [123.121072ms]
Mar  1 08:37:07.847: INFO: Created: latency-svc-4hsvb
Mar  1 08:37:07.865: INFO: Got endpoints: latency-svc-4hsvb [150.684776ms]
Mar  1 08:37:07.883: INFO: Created: latency-svc-zn69s
Mar  1 08:37:07.900: INFO: Got endpoints: latency-svc-zn69s [186.245901ms]
Mar  1 08:37:07.905: INFO: Created: latency-svc-l64cb
Mar  1 08:37:07.916: INFO: Got endpoints: latency-svc-l64cb [201.621276ms]
Mar  1 08:37:07.928: INFO: Created: latency-svc-zckb6
Mar  1 08:37:07.939: INFO: Got endpoints: latency-svc-zckb6 [224.65745ms]
Mar  1 08:37:07.951: INFO: Created: latency-svc-nx2s2
Mar  1 08:37:07.962: INFO: Got endpoints: latency-svc-nx2s2 [247.548289ms]
Mar  1 08:37:07.975: INFO: Created: latency-svc-lldfl
Mar  1 08:37:07.986: INFO: Got endpoints: latency-svc-lldfl [271.452529ms]
Mar  1 08:37:07.997: INFO: Created: latency-svc-g9j2l
Mar  1 08:37:08.029: INFO: Got endpoints: latency-svc-g9j2l [315.10915ms]
Mar  1 08:37:08.031: INFO: Created: latency-svc-rbkvg
Mar  1 08:37:08.036: INFO: Got endpoints: latency-svc-rbkvg [321.273457ms]
Mar  1 08:37:08.052: INFO: Created: latency-svc-6sxtd
Mar  1 08:37:08.064: INFO: Got endpoints: latency-svc-6sxtd [348.522078ms]
Mar  1 08:37:08.081: INFO: Created: latency-svc-8lw6f
Mar  1 08:37:08.087: INFO: Got endpoints: latency-svc-8lw6f [371.240823ms]
Mar  1 08:37:08.098: INFO: Created: latency-svc-f54hc
Mar  1 08:37:08.110: INFO: Got endpoints: latency-svc-f54hc [394.141544ms]
Mar  1 08:37:08.120: INFO: Created: latency-svc-rhmpz
Mar  1 08:37:08.157: INFO: Got endpoints: latency-svc-rhmpz [372.330888ms]
Mar  1 08:37:08.158: INFO: Created: latency-svc-z7vlz
Mar  1 08:37:08.161: INFO: Got endpoints: latency-svc-z7vlz [363.550263ms]
Mar  1 08:37:08.176: INFO: Created: latency-svc-dpkjk
Mar  1 08:37:08.188: INFO: Got endpoints: latency-svc-dpkjk [371.539452ms]
Mar  1 08:37:08.199: INFO: Created: latency-svc-skkwk
Mar  1 08:37:08.211: INFO: Got endpoints: latency-svc-skkwk [373.251051ms]
Mar  1 08:37:08.221: INFO: Created: latency-svc-dzdtj
Mar  1 08:37:08.235: INFO: Got endpoints: latency-svc-dzdtj [369.762055ms]
Mar  1 08:37:08.248: INFO: Created: latency-svc-zfhxw
Mar  1 08:37:08.284: INFO: Got endpoints: latency-svc-zfhxw [383.321658ms]
Mar  1 08:37:08.285: INFO: Created: latency-svc-qqdgk
Mar  1 08:37:08.296: INFO: Got endpoints: latency-svc-qqdgk [379.81343ms]
Mar  1 08:37:08.319: INFO: Created: latency-svc-bcx5b
Mar  1 08:37:08.330: INFO: Got endpoints: latency-svc-bcx5b [390.399706ms]
Mar  1 08:37:08.341: INFO: Created: latency-svc-49mr4
Mar  1 08:37:08.353: INFO: Got endpoints: latency-svc-49mr4 [390.627063ms]
Mar  1 08:37:08.364: INFO: Created: latency-svc-jkvfc
Mar  1 08:37:08.376: INFO: Got endpoints: latency-svc-jkvfc [389.230551ms]
Mar  1 08:37:08.425: INFO: Created: latency-svc-w4kzf
Mar  1 08:37:08.438: INFO: Got endpoints: latency-svc-w4kzf [408.345416ms]
Mar  1 08:37:08.438: INFO: Created: latency-svc-smrts
Mar  1 08:37:08.448: INFO: Got endpoints: latency-svc-smrts [411.856917ms]
Mar  1 08:37:08.461: INFO: Created: latency-svc-hmb5v
Mar  1 08:37:08.477: INFO: Got endpoints: latency-svc-hmb5v [413.414317ms]
Mar  1 08:37:08.495: INFO: Created: latency-svc-4nr4d
Mar  1 08:37:08.506: INFO: Got endpoints: latency-svc-4nr4d [419.552737ms]
Mar  1 08:37:08.515: INFO: Created: latency-svc-ktknz
Mar  1 08:37:08.548: INFO: Got endpoints: latency-svc-ktknz [438.432197ms]
Mar  1 08:37:08.549: INFO: Created: latency-svc-hsgxl
Mar  1 08:37:08.552: INFO: Got endpoints: latency-svc-hsgxl [394.899681ms]
Mar  1 08:37:08.566: INFO: Created: latency-svc-4qppp
Mar  1 08:37:08.578: INFO: Got endpoints: latency-svc-4qppp [416.02357ms]
Mar  1 08:37:08.588: INFO: Created: latency-svc-r972q
Mar  1 08:37:08.605: INFO: Got endpoints: latency-svc-r972q [417.34564ms]
Mar  1 08:37:08.625: INFO: Created: latency-svc-tzvr8
Mar  1 08:37:08.637: INFO: Got endpoints: latency-svc-tzvr8 [425.72624ms]
Mar  1 08:37:08.683: INFO: Created: latency-svc-lhwcz
Mar  1 08:37:08.691: INFO: Got endpoints: latency-svc-lhwcz [456.51173ms]
Mar  1 08:37:08.692: INFO: Created: latency-svc-cx7nd
Mar  1 08:37:08.702: INFO: Got endpoints: latency-svc-cx7nd [418.906829ms]
Mar  1 08:37:08.714: INFO: Created: latency-svc-7d6t4
Mar  1 08:37:08.724: INFO: Got endpoints: latency-svc-7d6t4 [428.208642ms]
Mar  1 08:37:08.735: INFO: Created: latency-svc-pvqkf
Mar  1 08:37:08.747: INFO: Got endpoints: latency-svc-pvqkf [417.309462ms]
Mar  1 08:37:08.757: INFO: Created: latency-svc-mdn8x
Mar  1 08:37:08.779: INFO: Created: latency-svc-78gqm
Mar  1 08:37:08.812: INFO: Created: latency-svc-sp88r
Mar  1 08:37:08.828: INFO: Created: latency-svc-v46pk
Mar  1 08:37:08.840: INFO: Got endpoints: latency-svc-v46pk [391.901489ms]
Mar  1 08:37:08.841: INFO: Got endpoints: latency-svc-sp88r [402.898362ms]
Mar  1 08:37:08.841: INFO: Got endpoints: latency-svc-78gqm [464.920334ms]
Mar  1 08:37:08.841: INFO: Got endpoints: latency-svc-mdn8x [487.725844ms]
Mar  1 08:37:08.850: INFO: Created: latency-svc-9rr95
Mar  1 08:37:08.861: INFO: Got endpoints: latency-svc-9rr95 [384.01014ms]
Mar  1 08:37:08.871: INFO: Created: latency-svc-z8frq
Mar  1 08:37:08.883: INFO: Got endpoints: latency-svc-z8frq [376.325515ms]
Mar  1 08:37:08.892: INFO: Created: latency-svc-gbcms
Mar  1 08:37:08.903: INFO: Got endpoints: latency-svc-gbcms [354.947352ms]
Mar  1 08:37:08.950: INFO: Created: latency-svc-7pr9w
Mar  1 08:37:08.954: INFO: Got endpoints: latency-svc-7pr9w [401.39314ms]
Mar  1 08:37:08.968: INFO: Created: latency-svc-dc2sq
Mar  1 08:37:08.980: INFO: Got endpoints: latency-svc-dc2sq [402.247243ms]
Mar  1 08:37:08.990: INFO: Created: latency-svc-9krq4
Mar  1 08:37:09.007: INFO: Got endpoints: latency-svc-9krq4 [402.017302ms]
Mar  1 08:37:09.025: INFO: Created: latency-svc-jmkns
Mar  1 08:37:09.041: INFO: Got endpoints: latency-svc-jmkns [404.006904ms]
Mar  1 08:37:09.084: INFO: Created: latency-svc-9xsz2
Mar  1 08:37:09.087: INFO: Got endpoints: latency-svc-9xsz2 [395.639911ms]
Mar  1 08:37:09.111: INFO: Created: latency-svc-65phd
Mar  1 08:37:09.122: INFO: Got endpoints: latency-svc-65phd [419.604358ms]
Mar  1 08:37:09.155: INFO: Created: latency-svc-9v98f
Mar  1 08:37:09.167: INFO: Got endpoints: latency-svc-9v98f [442.605102ms]
Mar  1 08:37:09.177: INFO: Created: latency-svc-hpqwm
Mar  1 08:37:09.211: INFO: Got endpoints: latency-svc-hpqwm [464.380629ms]
Mar  1 08:37:09.213: INFO: Created: latency-svc-hsdvt
Mar  1 08:37:09.216: INFO: Got endpoints: latency-svc-hsdvt [375.274444ms]
Mar  1 08:37:09.230: INFO: Created: latency-svc-7kz2s
Mar  1 08:37:09.249: INFO: Got endpoints: latency-svc-7kz2s [408.102812ms]
Mar  1 08:37:09.269: INFO: Created: latency-svc-6r5wk
Mar  1 08:37:09.280: INFO: Got endpoints: latency-svc-6r5wk [439.666509ms]
Mar  1 08:37:09.293: INFO: Created: latency-svc-krgm4
Mar  1 08:37:09.301: INFO: Got endpoints: latency-svc-krgm4 [460.389641ms]
Mar  1 08:37:09.311: INFO: Created: latency-svc-g5c9l
Mar  1 08:37:09.348: INFO: Got endpoints: latency-svc-g5c9l [486.307985ms]
Mar  1 08:37:09.348: INFO: Created: latency-svc-fkbkj
Mar  1 08:37:09.350: INFO: Got endpoints: latency-svc-fkbkj [467.648999ms]
Mar  1 08:37:09.360: INFO: Created: latency-svc-gg2nr
Mar  1 08:37:09.371: INFO: Got endpoints: latency-svc-gg2nr [468.200806ms]
Mar  1 08:37:09.382: INFO: Created: latency-svc-xf26z
Mar  1 08:37:09.394: INFO: Got endpoints: latency-svc-xf26z [439.956723ms]
Mar  1 08:37:09.405: INFO: Created: latency-svc-s2j6g
Mar  1 08:37:09.416: INFO: Got endpoints: latency-svc-s2j6g [435.929817ms]
Mar  1 08:37:09.430: INFO: Created: latency-svc-66sgg
Mar  1 08:37:09.442: INFO: Got endpoints: latency-svc-66sgg [433.966817ms]
Mar  1 08:37:09.485: INFO: Created: latency-svc-r57rx
Mar  1 08:37:09.498: INFO: Got endpoints: latency-svc-r57rx [457.488702ms]
Mar  1 08:37:09.498: INFO: Created: latency-svc-59js6
Mar  1 08:37:09.516: INFO: Got endpoints: latency-svc-59js6 [429.232451ms]
Mar  1 08:37:09.536: INFO: Created: latency-svc-vkb29
Mar  1 08:37:09.559: INFO: Created: latency-svc-49b2x
Mar  1 08:37:09.570: INFO: Got endpoints: latency-svc-vkb29 [447.342527ms]
Mar  1 08:37:09.580: INFO: Created: latency-svc-hrs28
Mar  1 08:37:09.631: INFO: Got endpoints: latency-svc-49b2x [463.476023ms]
Mar  1 08:37:09.637: INFO: Created: latency-svc-d2qvq
Mar  1 08:37:09.658: INFO: Created: latency-svc-lnx8q
Mar  1 08:37:09.675: INFO: Got endpoints: latency-svc-hrs28 [463.696303ms]
Mar  1 08:37:09.680: INFO: Created: latency-svc-h5gwh
Mar  1 08:37:09.702: INFO: Created: latency-svc-4dsg5
Mar  1 08:37:09.722: INFO: Created: latency-svc-dq68g
Mar  1 08:37:09.722: INFO: Got endpoints: latency-svc-d2qvq [506.170093ms]
Mar  1 08:37:09.761: INFO: Created: latency-svc-xrvtb
Mar  1 08:37:09.772: INFO: Got endpoints: latency-svc-lnx8q [523.299597ms]
Mar  1 08:37:09.783: INFO: Created: latency-svc-96nvx
Mar  1 08:37:09.804: INFO: Created: latency-svc-9q6mb
Mar  1 08:37:09.827: INFO: Created: latency-svc-4bdg7
Mar  1 08:37:09.827: INFO: Got endpoints: latency-svc-h5gwh [546.29096ms]
Mar  1 08:37:09.853: INFO: Created: latency-svc-st2qw
Mar  1 08:37:09.884: INFO: Got endpoints: latency-svc-4dsg5 [583.07189ms]
Mar  1 08:37:09.891: INFO: Created: latency-svc-xlcst
Mar  1 08:37:09.914: INFO: Created: latency-svc-qb8zf
Mar  1 08:37:09.925: INFO: Got endpoints: latency-svc-dq68g [577.501581ms]
Mar  1 08:37:09.937: INFO: Created: latency-svc-klvpz
Mar  1 08:37:09.960: INFO: Created: latency-svc-dchb2
Mar  1 08:37:09.971: INFO: Got endpoints: latency-svc-xrvtb [620.837758ms]
Mar  1 08:37:09.983: INFO: Created: latency-svc-9k4hv
Mar  1 08:37:10.038: INFO: Created: latency-svc-lncrj
Mar  1 08:37:10.044: INFO: Got endpoints: latency-svc-96nvx [672.158495ms]
Mar  1 08:37:10.055: INFO: Created: latency-svc-j759t
Mar  1 08:37:10.152: INFO: Got endpoints: latency-svc-9q6mb [758.248193ms]
Mar  1 08:37:10.157: INFO: Got endpoints: latency-svc-4bdg7 [741.275982ms]
Mar  1 08:37:10.175: INFO: Created: latency-svc-tf459
Mar  1 08:37:10.175: INFO: Got endpoints: latency-svc-st2qw [733.946981ms]
Mar  1 08:37:10.198: INFO: Created: latency-svc-qf4rr
Mar  1 08:37:10.218: INFO: Created: latency-svc-jj5vg
Mar  1 08:37:10.218: INFO: Got endpoints: latency-svc-xlcst [719.575854ms]
Mar  1 08:37:10.239: INFO: Created: latency-svc-jgc8x
Mar  1 08:37:10.291: INFO: Got endpoints: latency-svc-qb8zf [774.554406ms]
Mar  1 08:37:10.300: INFO: Created: latency-svc-22svz
Mar  1 08:37:10.317: INFO: Got endpoints: latency-svc-klvpz [747.86956ms]
Mar  1 08:37:10.328: INFO: Created: latency-svc-wkr5z
Mar  1 08:37:10.375: INFO: Got endpoints: latency-svc-dchb2 [744.106523ms]
Mar  1 08:37:10.375: INFO: Created: latency-svc-67jvw
Mar  1 08:37:10.427: INFO: Got endpoints: latency-svc-9k4hv [751.449887ms]
Mar  1 08:37:10.428: INFO: Created: latency-svc-ccbb5
Mar  1 08:37:10.445: INFO: Created: latency-svc-ctgst
Mar  1 08:37:10.492: INFO: Created: latency-svc-wkmd9
Mar  1 08:37:10.492: INFO: Got endpoints: latency-svc-lncrj [768.399836ms]
Mar  1 08:37:10.554: INFO: Got endpoints: latency-svc-j759t [781.604135ms]
Mar  1 08:37:10.556: INFO: Created: latency-svc-8cchb
Mar  1 08:37:10.586: INFO: Got endpoints: latency-svc-tf459 [759.074133ms]
Mar  1 08:37:10.586: INFO: Created: latency-svc-mvvmr
Mar  1 08:37:10.608: INFO: Created: latency-svc-9twxc
Mar  1 08:37:10.622: INFO: Got endpoints: latency-svc-qf4rr [737.858238ms]
Mar  1 08:37:10.632: INFO: Created: latency-svc-wchw5
Mar  1 08:37:10.682: INFO: Got endpoints: latency-svc-jj5vg [757.037215ms]
Mar  1 08:37:10.683: INFO: Created: latency-svc-sjwls
Mar  1 08:37:10.696: INFO: Created: latency-svc-wvqvh
Mar  1 08:37:10.721: INFO: Got endpoints: latency-svc-jgc8x [749.362598ms]
Mar  1 08:37:10.721: INFO: Created: latency-svc-8w96l
Mar  1 08:37:10.745: INFO: Created: latency-svc-rl8c7
Mar  1 08:37:10.767: INFO: Created: latency-svc-wmcnk
Mar  1 08:37:10.849: INFO: Got endpoints: latency-svc-22svz [805.41613ms]
Mar  1 08:37:10.854: INFO: Got endpoints: latency-svc-wkr5z [702.107801ms]
Mar  1 08:37:10.867: INFO: Got endpoints: latency-svc-67jvw [709.605333ms]
Mar  1 08:37:10.897: INFO: Created: latency-svc-fwc4d
Mar  1 08:37:10.918: INFO: Created: latency-svc-r28zp
Mar  1 08:37:10.918: INFO: Got endpoints: latency-svc-ccbb5 [742.967357ms]
Mar  1 08:37:10.969: INFO: Got endpoints: latency-svc-ctgst [751.240633ms]
Mar  1 08:37:10.970: INFO: Created: latency-svc-65b9b
Mar  1 08:37:10.984: INFO: Created: latency-svc-dp7fb
Mar  1 08:37:11.018: INFO: Got endpoints: latency-svc-wkmd9 [727.204499ms]
Mar  1 08:37:11.019: INFO: Created: latency-svc-ts26g
Mar  1 08:37:11.068: INFO: Created: latency-svc-mxwtf
Mar  1 08:37:11.068: INFO: Got endpoints: latency-svc-8cchb [750.963358ms]
Mar  1 08:37:11.122: INFO: Got endpoints: latency-svc-mvvmr [746.431307ms]
Mar  1 08:37:11.122: INFO: Created: latency-svc-42vww
Mar  1 08:37:11.171: INFO: Got endpoints: latency-svc-9twxc [743.253512ms]
Mar  1 08:37:11.171: INFO: Created: latency-svc-dpr8j
Mar  1 08:37:11.228: INFO: Got endpoints: latency-svc-wchw5 [735.981857ms]
Mar  1 08:37:11.285: INFO: Got endpoints: latency-svc-sjwls [731.040419ms]
Mar  1 08:37:11.304: INFO: Created: latency-svc-6ct5m
Mar  1 08:37:11.324: INFO: Created: latency-svc-6479n
Mar  1 08:37:11.324: INFO: Got endpoints: latency-svc-wvqvh [738.541772ms]
Mar  1 08:37:11.361: INFO: Created: latency-svc-7hdqp
Mar  1 08:37:11.376: INFO: Got endpoints: latency-svc-8w96l [753.507158ms]
Mar  1 08:37:11.376: INFO: Created: latency-svc-gprfw
Mar  1 08:37:11.426: INFO: Created: latency-svc-qfnc4
Mar  1 08:37:11.426: INFO: Got endpoints: latency-svc-rl8c7 [743.501769ms]
Mar  1 08:37:11.488: INFO: Got endpoints: latency-svc-wmcnk [767.768586ms]
Mar  1 08:37:11.502: INFO: Created: latency-svc-lwrz5
Mar  1 08:37:11.516: INFO: Got endpoints: latency-svc-fwc4d [667.133052ms]
Mar  1 08:37:11.566: INFO: Created: latency-svc-k8bmn
Mar  1 08:37:11.578: INFO: Got endpoints: latency-svc-r28zp [723.11402ms]
Mar  1 08:37:11.588: INFO: Created: latency-svc-krd2f
Mar  1 08:37:11.620: INFO: Got endpoints: latency-svc-65b9b [753.617527ms]
Mar  1 08:37:11.634: INFO: Created: latency-svc-fzlts
Mar  1 08:37:11.674: INFO: Created: latency-svc-5zxjf
Mar  1 08:37:11.674: INFO: Got endpoints: latency-svc-dp7fb [755.416257ms]
Mar  1 08:37:11.758: INFO: Created: latency-svc-j2fm6
Mar  1 08:37:11.759: INFO: Got endpoints: latency-svc-ts26g [789.167153ms]
Mar  1 08:37:11.766: INFO: Got endpoints: latency-svc-mxwtf [747.640341ms]
Mar  1 08:37:11.811: INFO: Created: latency-svc-v6wwg
Mar  1 08:37:11.823: INFO: Got endpoints: latency-svc-42vww [754.448625ms]
Mar  1 08:37:11.842: INFO: Created: latency-svc-sthz5
Mar  1 08:37:11.893: INFO: Got endpoints: latency-svc-dpr8j [771.772263ms]
Mar  1 08:37:11.905: INFO: Created: latency-svc-gmsgs
Mar  1 08:37:11.916: INFO: Got endpoints: latency-svc-6ct5m [745.317845ms]
Mar  1 08:37:11.942: INFO: Created: latency-svc-sqkh5
Mar  1 08:37:11.967: INFO: Created: latency-svc-k4ftg
Mar  1 08:37:11.967: INFO: Got endpoints: latency-svc-6479n [738.451312ms]
Mar  1 08:37:12.018: INFO: Got endpoints: latency-svc-7hdqp [733.070167ms]
Mar  1 08:37:12.031: INFO: Created: latency-svc-kc28g
Mar  1 08:37:12.066: INFO: Created: latency-svc-mnc6c
Mar  1 08:37:12.066: INFO: Got endpoints: latency-svc-gprfw [741.899695ms]
Mar  1 08:37:12.157: INFO: Got endpoints: latency-svc-qfnc4 [780.563568ms]
Mar  1 08:37:12.171: INFO: Got endpoints: latency-svc-lwrz5 [745.199771ms]
Mar  1 08:37:12.171: INFO: Created: latency-svc-pqf78
Mar  1 08:37:12.205: INFO: Created: latency-svc-p2kjr
Mar  1 08:37:12.217: INFO: Got endpoints: latency-svc-k8bmn [728.600043ms]
Mar  1 08:37:12.246: INFO: Created: latency-svc-f7hws
Mar  1 08:37:12.285: INFO: Got endpoints: latency-svc-krd2f [768.652567ms]
Mar  1 08:37:12.302: INFO: Created: latency-svc-9g9fq
Mar  1 08:37:12.316: INFO: Got endpoints: latency-svc-fzlts [738.019903ms]
Mar  1 08:37:12.334: INFO: Created: latency-svc-mpd9j
Mar  1 08:37:12.366: INFO: Created: latency-svc-xfx66
Mar  1 08:37:12.417: INFO: Got endpoints: latency-svc-j2fm6 [743.036844ms]
Mar  1 08:37:12.418: INFO: Got endpoints: latency-svc-5zxjf [797.29572ms]
Mar  1 08:37:12.469: INFO: Created: latency-svc-7wl96
Mar  1 08:37:12.469: INFO: Got endpoints: latency-svc-v6wwg [710.429202ms]
Mar  1 08:37:12.512: INFO: Created: latency-svc-gwwl2
Mar  1 08:37:12.546: INFO: Got endpoints: latency-svc-sthz5 [780.014907ms]
Mar  1 08:37:12.559: INFO: Created: latency-svc-4xfcq
Mar  1 08:37:12.570: INFO: Got endpoints: latency-svc-gmsgs [747.031025ms]
Mar  1 08:37:12.595: INFO: Created: latency-svc-bhxwz
Mar  1 08:37:12.619: INFO: Created: latency-svc-cf244
Mar  1 08:37:12.619: INFO: Got endpoints: latency-svc-sqkh5 [725.657661ms]
Mar  1 08:37:12.671: INFO: Got endpoints: latency-svc-k4ftg [754.682506ms]
Mar  1 08:37:12.698: INFO: Created: latency-svc-s5qs9
Mar  1 08:37:12.724: INFO: Got endpoints: latency-svc-kc28g [756.567799ms]
Mar  1 08:37:12.724: INFO: Created: latency-svc-7bv5x
Mar  1 08:37:12.832: INFO: Created: latency-svc-r2cqv
Mar  1 08:37:12.832: INFO: Got endpoints: latency-svc-pqf78 [765.608569ms]
Mar  1 08:37:12.832: INFO: Got endpoints: latency-svc-mnc6c [814.085274ms]
Mar  1 08:37:12.866: INFO: Got endpoints: latency-svc-p2kjr [709.576273ms]
Mar  1 08:37:12.884: INFO: Created: latency-svc-vk7tb
Mar  1 08:37:12.917: INFO: Created: latency-svc-mvkbk
Mar  1 08:37:12.926: INFO: Got endpoints: latency-svc-f7hws [754.7671ms]
Mar  1 08:37:12.968: INFO: Got endpoints: latency-svc-9g9fq [751.218042ms]
Mar  1 08:37:12.969: INFO: Created: latency-svc-bpwzx
Mar  1 08:37:12.982: INFO: Created: latency-svc-lqjpn
Mar  1 08:37:13.021: INFO: Created: latency-svc-fdwjb
Mar  1 08:37:13.021: INFO: Got endpoints: latency-svc-mpd9j [736.098282ms]
Mar  1 08:37:13.104: INFO: Created: latency-svc-lws92
Mar  1 08:37:13.104: INFO: Got endpoints: latency-svc-xfx66 [788.553747ms]
Mar  1 08:37:13.118: INFO: Got endpoints: latency-svc-7wl96 [700.435203ms]
Mar  1 08:37:13.162: INFO: Created: latency-svc-pct5s
Mar  1 08:37:13.174: INFO: Got endpoints: latency-svc-gwwl2 [756.236784ms]
Mar  1 08:37:13.184: INFO: Created: latency-svc-54hfh
Mar  1 08:37:13.256: INFO: Got endpoints: latency-svc-4xfcq [787.344162ms]
Mar  1 08:37:13.286: INFO: Got endpoints: latency-svc-bhxwz [739.930535ms]
Mar  1 08:37:13.286: INFO: Created: latency-svc-pqg27
Mar  1 08:37:13.325: INFO: Created: latency-svc-mnlk5
Mar  1 08:37:13.325: INFO: Got endpoints: latency-svc-cf244 [755.047716ms]
Mar  1 08:37:13.350: INFO: Created: latency-svc-g5c5c
Mar  1 08:37:13.424: INFO: Got endpoints: latency-svc-7bv5x [752.792877ms]
Mar  1 08:37:13.424: INFO: Got endpoints: latency-svc-s5qs9 [804.999965ms]
Mar  1 08:37:13.438: INFO: Created: latency-svc-tpsmr
Mar  1 08:37:13.475: INFO: Created: latency-svc-mqcst
Mar  1 08:37:13.475: INFO: Got endpoints: latency-svc-r2cqv [751.278361ms]
Mar  1 08:37:13.497: INFO: Created: latency-svc-qptgg
Mar  1 08:37:13.525: INFO: Got endpoints: latency-svc-vk7tb [692.574353ms]
Mar  1 08:37:13.525: INFO: Created: latency-svc-2pjt4
Mar  1 08:37:13.567: INFO: Got endpoints: latency-svc-mvkbk [734.744708ms]
Mar  1 08:37:13.594: INFO: Created: latency-svc-9gg5x
Mar  1 08:37:13.618: INFO: Got endpoints: latency-svc-bpwzx [751.459082ms]
Mar  1 08:37:13.618: INFO: Created: latency-svc-8dwh7
Mar  1 08:37:13.703: INFO: Created: latency-svc-6wvwc
Mar  1 08:37:13.703: INFO: Got endpoints: latency-svc-lqjpn [777.317044ms]
Mar  1 08:37:13.717: INFO: Got endpoints: latency-svc-fdwjb [748.383322ms]
Mar  1 08:37:13.783: INFO: Created: latency-svc-9qdbw
Mar  1 08:37:13.783: INFO: Got endpoints: latency-svc-lws92 [761.49109ms]
Mar  1 08:37:13.844: INFO: Created: latency-svc-hkg7m
Mar  1 08:37:13.845: INFO: Got endpoints: latency-svc-pct5s [741.062733ms]
Mar  1 08:37:13.858: INFO: Created: latency-svc-w2kbn
Mar  1 08:37:13.869: INFO: Got endpoints: latency-svc-54hfh [751.395354ms]
Mar  1 08:37:13.897: INFO: Created: latency-svc-frcpr
Mar  1 08:37:13.921: INFO: Got endpoints: latency-svc-pqg27 [746.694486ms]
Mar  1 08:37:13.921: INFO: Created: latency-svc-8bjzl
Mar  1 08:37:13.970: INFO: Got endpoints: latency-svc-mnlk5 [713.16195ms]
Mar  1 08:37:13.983: INFO: Created: latency-svc-kx2t6
Mar  1 08:37:14.019: INFO: Got endpoints: latency-svc-g5c5c [732.615052ms]
Mar  1 08:37:14.019: INFO: Created: latency-svc-wgh5t
Mar  1 08:37:14.106: INFO: Got endpoints: latency-svc-tpsmr [781.226223ms]
Mar  1 08:37:14.107: INFO: Created: latency-svc-hlmvz
Mar  1 08:37:14.117: INFO: Got endpoints: latency-svc-mqcst [692.413121ms]
Mar  1 08:37:14.179: INFO: Created: latency-svc-krf8x
Mar  1 08:37:14.179: INFO: Got endpoints: latency-svc-qptgg [755.528637ms]
Mar  1 08:37:14.228: INFO: Got endpoints: latency-svc-2pjt4 [752.9951ms]
Mar  1 08:37:14.228: INFO: Created: latency-svc-v426n
Mar  1 08:37:14.243: INFO: Created: latency-svc-5mfn6
Mar  1 08:37:14.268: INFO: Got endpoints: latency-svc-9gg5x [743.049409ms]
Mar  1 08:37:14.283: INFO: Created: latency-svc-v9gp7
Mar  1 08:37:14.315: INFO: Created: latency-svc-vp8c7
Mar  1 08:37:14.434: INFO: Got endpoints: latency-svc-9qdbw [730.650634ms]
Mar  1 08:37:14.434: INFO: Got endpoints: latency-svc-8dwh7 [867.175375ms]
Mar  1 08:37:14.435: INFO: Got endpoints: latency-svc-6wvwc [816.817694ms]
Mar  1 08:37:14.468: INFO: Got endpoints: latency-svc-hkg7m [751.083065ms]
Mar  1 08:37:14.520: INFO: Got endpoints: latency-svc-w2kbn [737.466785ms]
Mar  1 08:37:14.521: INFO: Created: latency-svc-8hggt
Mar  1 08:37:14.557: INFO: Created: latency-svc-h2rct
Mar  1 08:37:14.572: INFO: Created: latency-svc-d8j2f
Mar  1 08:37:14.572: INFO: Got endpoints: latency-svc-frcpr [726.435781ms]
Mar  1 08:37:14.595: INFO: Created: latency-svc-s9plb
Mar  1 08:37:14.619: INFO: Created: latency-svc-5qrkh
Mar  1 08:37:14.619: INFO: Got endpoints: latency-svc-8bjzl [750.044705ms]
Mar  1 08:37:14.655: INFO: Created: latency-svc-f2dp8
Mar  1 08:37:14.691: INFO: Got endpoints: latency-svc-kx2t6 [770.211822ms]
Mar  1 08:37:14.692: INFO: Created: latency-svc-q5gp8
Mar  1 08:37:14.717: INFO: Got endpoints: latency-svc-wgh5t [746.922047ms]
Mar  1 08:37:14.739: INFO: Created: latency-svc-gkp84
Mar  1 08:37:14.765: INFO: Created: latency-svc-mrcjs
Mar  1 08:37:14.776: INFO: Got endpoints: latency-svc-hlmvz [756.773474ms]
Mar  1 08:37:14.818: INFO: Got endpoints: latency-svc-krf8x [711.587119ms]
Mar  1 08:37:14.831: INFO: Created: latency-svc-zkwpm
Mar  1 08:37:14.866: INFO: Created: latency-svc-82btf
Mar  1 08:37:14.876: INFO: Got endpoints: latency-svc-v426n [759.864895ms]
Mar  1 08:37:14.944: INFO: Created: latency-svc-prpt2
Mar  1 08:37:14.944: INFO: Got endpoints: latency-svc-5mfn6 [764.718055ms]
Mar  1 08:37:14.967: INFO: Got endpoints: latency-svc-v9gp7 [738.584983ms]
Mar  1 08:37:14.993: INFO: Created: latency-svc-dqvwt
Mar  1 08:37:15.019: INFO: Created: latency-svc-bjbwc
Mar  1 08:37:15.019: INFO: Got endpoints: latency-svc-vp8c7 [751.068757ms]
Mar  1 08:37:15.074: INFO: Got endpoints: latency-svc-8hggt [639.781635ms]
Mar  1 08:37:15.096: INFO: Created: latency-svc-5pztj
Mar  1 08:37:15.139: INFO: Got endpoints: latency-svc-h2rct [703.897567ms]
Mar  1 08:37:15.139: INFO: Created: latency-svc-s6mv9
Mar  1 08:37:15.166: INFO: Got endpoints: latency-svc-d8j2f [731.493176ms]
Mar  1 08:37:15.211: INFO: Created: latency-svc-6w5lh
Mar  1 08:37:15.229: INFO: Got endpoints: latency-svc-s9plb [761.446686ms]
Mar  1 08:37:15.248: INFO: Created: latency-svc-slhkz
Mar  1 08:37:15.266: INFO: Got endpoints: latency-svc-5qrkh [745.434687ms]
Mar  1 08:37:15.280: INFO: Created: latency-svc-msd65
Mar  1 08:37:15.352: INFO: Got endpoints: latency-svc-f2dp8 [780.417252ms]
Mar  1 08:37:15.366: INFO: Created: latency-svc-qx78q
Mar  1 08:37:15.369: INFO: Got endpoints: latency-svc-q5gp8 [750.227101ms]
Mar  1 08:37:15.403: INFO: Created: latency-svc-2q95x
Mar  1 08:37:15.419: INFO: Got endpoints: latency-svc-gkp84 [728.220419ms]
Mar  1 08:37:15.420: INFO: Created: latency-svc-wl9zk
Mar  1 08:37:15.483: INFO: Got endpoints: latency-svc-mrcjs [766.800306ms]
Mar  1 08:37:15.497: INFO: Created: latency-svc-rkz46
Mar  1 08:37:15.517: INFO: Got endpoints: latency-svc-zkwpm [741.590866ms]
Mar  1 08:37:15.533: INFO: Created: latency-svc-4wqr7
Mar  1 08:37:15.567: INFO: Got endpoints: latency-svc-82btf [749.077184ms]
Mar  1 08:37:15.567: INFO: Created: latency-svc-xsx9f
Mar  1 08:37:15.623: INFO: Got endpoints: latency-svc-prpt2 [746.522585ms]
Mar  1 08:37:15.666: INFO: Got endpoints: latency-svc-dqvwt [721.861244ms]
Mar  1 08:37:15.717: INFO: Got endpoints: latency-svc-bjbwc [749.904074ms]
Mar  1 08:37:15.766: INFO: Got endpoints: latency-svc-5pztj [746.864785ms]
Mar  1 08:37:15.816: INFO: Got endpoints: latency-svc-s6mv9 [742.395477ms]
Mar  1 08:37:15.866: INFO: Got endpoints: latency-svc-6w5lh [727.079468ms]
Mar  1 08:37:15.916: INFO: Got endpoints: latency-svc-slhkz [750.281378ms]
Mar  1 08:37:15.967: INFO: Got endpoints: latency-svc-msd65 [737.260159ms]
Mar  1 08:37:16.017: INFO: Got endpoints: latency-svc-qx78q [750.840132ms]
Mar  1 08:37:16.080: INFO: Got endpoints: latency-svc-2q95x [727.535228ms]
Mar  1 08:37:16.116: INFO: Got endpoints: latency-svc-wl9zk [746.747872ms]
Mar  1 08:37:16.166: INFO: Got endpoints: latency-svc-rkz46 [747.010873ms]
Mar  1 08:37:16.216: INFO: Got endpoints: latency-svc-4wqr7 [732.769002ms]
Mar  1 08:37:16.266: INFO: Got endpoints: latency-svc-xsx9f [748.471021ms]
Mar  1 08:37:16.266: INFO: Latencies: [70.893689ms 83.308604ms 102.814001ms 123.121072ms 150.684776ms 186.245901ms 201.621276ms 224.65745ms 247.548289ms 271.452529ms 315.10915ms 321.273457ms 348.522078ms 354.947352ms 363.550263ms 369.762055ms 371.240823ms 371.539452ms 372.330888ms 373.251051ms 375.274444ms 376.325515ms 379.81343ms 383.321658ms 384.01014ms 389.230551ms 390.399706ms 390.627063ms 391.901489ms 394.141544ms 394.899681ms 395.639911ms 401.39314ms 402.017302ms 402.247243ms 402.898362ms 404.006904ms 408.102812ms 408.345416ms 411.856917ms 413.414317ms 416.02357ms 417.309462ms 417.34564ms 418.906829ms 419.552737ms 419.604358ms 425.72624ms 428.208642ms 429.232451ms 433.966817ms 435.929817ms 438.432197ms 439.666509ms 439.956723ms 442.605102ms 447.342527ms 456.51173ms 457.488702ms 460.389641ms 463.476023ms 463.696303ms 464.380629ms 464.920334ms 467.648999ms 468.200806ms 486.307985ms 487.725844ms 506.170093ms 523.299597ms 546.29096ms 577.501581ms 583.07189ms 620.837758ms 639.781635ms 667.133052ms 672.158495ms 692.413121ms 692.574353ms 700.435203ms 702.107801ms 703.897567ms 709.576273ms 709.605333ms 710.429202ms 711.587119ms 713.16195ms 719.575854ms 721.861244ms 723.11402ms 725.657661ms 726.435781ms 727.079468ms 727.204499ms 727.535228ms 728.220419ms 728.600043ms 730.650634ms 731.040419ms 731.493176ms 732.615052ms 732.769002ms 733.070167ms 733.946981ms 734.744708ms 735.981857ms 736.098282ms 737.260159ms 737.466785ms 737.858238ms 738.019903ms 738.451312ms 738.541772ms 738.584983ms 739.930535ms 741.062733ms 741.275982ms 741.590866ms 741.899695ms 742.395477ms 742.967357ms 743.036844ms 743.049409ms 743.253512ms 743.501769ms 744.106523ms 745.199771ms 745.317845ms 745.434687ms 746.431307ms 746.522585ms 746.694486ms 746.747872ms 746.864785ms 746.922047ms 747.010873ms 747.031025ms 747.640341ms 747.86956ms 748.383322ms 748.471021ms 749.077184ms 749.362598ms 749.904074ms 750.044705ms 750.227101ms 750.281378ms 750.840132ms 750.963358ms 751.068757ms 751.083065ms 751.218042ms 751.240633ms 751.278361ms 751.395354ms 751.449887ms 751.459082ms 752.792877ms 752.9951ms 753.507158ms 753.617527ms 754.448625ms 754.682506ms 754.7671ms 755.047716ms 755.416257ms 755.528637ms 756.236784ms 756.567799ms 756.773474ms 757.037215ms 758.248193ms 759.074133ms 759.864895ms 761.446686ms 761.49109ms 764.718055ms 765.608569ms 766.800306ms 767.768586ms 768.399836ms 768.652567ms 770.211822ms 771.772263ms 774.554406ms 777.317044ms 780.014907ms 780.417252ms 780.563568ms 781.226223ms 781.604135ms 787.344162ms 788.553747ms 789.167153ms 797.29572ms 804.999965ms 805.41613ms 814.085274ms 816.817694ms 867.175375ms]
Mar  1 08:37:16.266: INFO: 50 %ile: 732.615052ms
Mar  1 08:37:16.266: INFO: 90 %ile: 768.399836ms
Mar  1 08:37:16.266: INFO: 99 %ile: 816.817694ms
Mar  1 08:37:16.266: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:37:16.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-bqbv2" for this suite.
Mar  1 08:37:34.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:37:35.508: INFO: namespace: e2e-tests-svc-latency-bqbv2, resource: bindings, ignored listing per whitelist
Mar  1 08:37:35.752: INFO: namespace e2e-tests-svc-latency-bqbv2 deletion completed in 19.444669069s

• [SLOW TEST:32.747 seconds]
[sig-network] Service endpoints latency
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:37:35.752: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-xbwsz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  1 08:37:37.295: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13529,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 08:37:37.295: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13529,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  1 08:37:47.368: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13550,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 08:37:47.368: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13550,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  1 08:37:57.439: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13570,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 08:37:57.439: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13570,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  1 08:38:07.477: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13590,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 08:38:07.477: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-a,UID:4474c210-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13590,Generation:0,CreationTimestamp:2019-03-01 08:37:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  1 08:38:17.515: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-b,UID:5c6d93a4-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13611,Generation:0,CreationTimestamp:2019-03-01 08:38:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 08:38:17.515: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-b,UID:5c6d93a4-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13611,Generation:0,CreationTimestamp:2019-03-01 08:38:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  1 08:38:27.552: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-b,UID:5c6d93a4-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13632,Generation:0,CreationTimestamp:2019-03-01 08:38:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 08:38:27.552: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-xbwsz,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbwsz/configmaps/e2e-watch-test-configmap-b,UID:5c6d93a4-3bfd-11e9-a289-2aff89a14c6e,ResourceVersion:13632,Generation:0,CreationTimestamp:2019-03-01 08:38:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:38:37.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xbwsz" for this suite.
Mar  1 08:38:43.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:38:43.835: INFO: namespace: e2e-tests-watch-xbwsz, resource: bindings, ignored listing per whitelist
Mar  1 08:38:45.071: INFO: namespace e2e-tests-watch-xbwsz deletion completed in 7.481923082s

• [SLOW TEST:69.318 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:38:45.071: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rs5r4
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-6dc5cfa4-3bfd-11e9-9193-2e670c8e304c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-6dc5cfa4-3bfd-11e9-9193-2e670c8e304c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:40:00.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rs5r4" for this suite.
Mar  1 08:40:22.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:40:23.005: INFO: namespace: e2e-tests-projected-rs5r4, resource: bindings, ignored listing per whitelist
Mar  1 08:40:23.873: INFO: namespace e2e-tests-projected-rs5r4 deletion completed in 23.435571966s

• [SLOW TEST:98.802 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:40:23.873: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qnq52
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:40:25.406: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-qnq52" to be "success or failure"
Mar  1 08:40:25.441: INFO: Pod "downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.607035ms
Mar  1 08:40:27.477: INFO: Pod "downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070443595s
Mar  1 08:40:29.514: INFO: Pod "downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108051985s
STEP: Saw pod success
Mar  1 08:40:29.514: INFO: Pod "downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:40:29.549: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 08:40:29.652: INFO: Waiting for pod downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c to disappear
Mar  1 08:40:29.687: INFO: Pod downwardapi-volume-a8a53681-3bfd-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:40:29.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qnq52" for this suite.
Mar  1 08:40:35.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:40:36.877: INFO: namespace: e2e-tests-downward-api-qnq52, resource: bindings, ignored listing per whitelist
Mar  1 08:40:37.202: INFO: namespace e2e-tests-downward-api-qnq52 deletion completed in 7.46719889s

• [SLOW TEST:13.329 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:40:37.203: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-r58ts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:40:38.836: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b09f62e4-3bfd-11e9-a289-2aff89a14c6e", Controller:(*bool)(0xc002094e32), BlockOwnerDeletion:(*bool)(0xc002094e33)}}
Mar  1 08:40:38.873: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b0948da1-3bfd-11e9-a289-2aff89a14c6e", Controller:(*bool)(0xc002072b06), BlockOwnerDeletion:(*bool)(0xc002072b07)}}
Mar  1 08:40:38.911: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b099f592-3bfd-11e9-a289-2aff89a14c6e", Controller:(*bool)(0xc002072fce), BlockOwnerDeletion:(*bool)(0xc002072fcf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:40:43.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-r58ts" for this suite.
Mar  1 08:40:50.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:40:51.423: INFO: namespace: e2e-tests-gc-r58ts, resource: bindings, ignored listing per whitelist
Mar  1 08:40:51.492: INFO: namespace e2e-tests-gc-r58ts deletion completed in 7.473506021s

• [SLOW TEST:14.290 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:40:51.493: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rjnh6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 08:40:52.957: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-rjnh6'
Mar  1 08:40:54.785: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 08:40:54.785: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Mar  1 08:40:56.864: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-rjnh6'
Mar  1 08:40:57.187: INFO: stderr: ""
Mar  1 08:40:57.187: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:40:57.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rjnh6" for this suite.
Mar  1 08:42:17.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:42:18.401: INFO: namespace: e2e-tests-kubectl-rjnh6, resource: bindings, ignored listing per whitelist
Mar  1 08:42:18.679: INFO: namespace e2e-tests-kubectl-rjnh6 deletion completed in 1m21.456693788s

• [SLOW TEST:87.187 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:42:18.679: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xzssc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ed0f8231-3bfd-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 08:42:20.223: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-xzssc" to be "success or failure"
Mar  1 08:42:20.266: INFO: Pod "pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 43.111379ms
Mar  1 08:42:22.301: INFO: Pod "pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078174251s
Mar  1 08:42:24.342: INFO: Pod "pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.118831717s
STEP: Saw pod success
Mar  1 08:42:24.342: INFO: Pod "pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:42:24.379: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:42:24.460: INFO: Waiting for pod pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c to disappear
Mar  1 08:42:24.495: INFO: Pod pod-projected-configmaps-ed14dff7-3bfd-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:42:24.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xzssc" for this suite.
Mar  1 08:42:30.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:42:31.743: INFO: namespace: e2e-tests-projected-xzssc, resource: bindings, ignored listing per whitelist
Mar  1 08:42:32.058: INFO: namespace e2e-tests-projected-xzssc deletion completed in 7.527571843s

• [SLOW TEST:13.378 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:42:32.058: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-vm8kp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vm8kp
Mar  1 08:42:37.599: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vm8kp
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 08:42:37.634: INFO: Initial restart count of pod liveness-http is 0
Mar  1 08:42:55.989: INFO: Restart count of pod e2e-tests-container-probe-vm8kp/liveness-http is now 1 (18.355359324s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:42:56.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vm8kp" for this suite.
Mar  1 08:43:02.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:43:03.140: INFO: namespace: e2e-tests-container-probe-vm8kp, resource: bindings, ignored listing per whitelist
Mar  1 08:43:03.597: INFO: namespace e2e-tests-container-probe-vm8kp deletion completed in 7.464208938s

• [SLOW TEST:31.540 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:43:03.598: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gvv4s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0802fa2a-3bfe-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 08:43:05.442: INFO: Waiting up to 5m0s for pod "pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-gvv4s" to be "success or failure"
Mar  1 08:43:05.478: INFO: Pod "pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.71668ms
Mar  1 08:43:07.514: INFO: Pod "pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071770443s
Mar  1 08:43:09.549: INFO: Pod "pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107450634s
STEP: Saw pod success
Mar  1 08:43:09.549: INFO: Pod "pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:43:09.585: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:43:09.679: INFO: Waiting for pod pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c to disappear
Mar  1 08:43:09.713: INFO: Pod pod-configmaps-08087066-3bfe-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:43:09.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gvv4s" for this suite.
Mar  1 08:43:15.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:43:16.440: INFO: namespace: e2e-tests-configmap-gvv4s, resource: bindings, ignored listing per whitelist
Mar  1 08:43:17.201: INFO: namespace e2e-tests-configmap-gvv4s deletion completed in 7.452636993s

• [SLOW TEST:13.603 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:43:17.202: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-fjgq9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar  1 08:43:18.673: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 08:43:18.742: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 08:43:18.778: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v before test
Mar  1 08:43:18.834: INFO: vpn-shoot-6f8cffc7cf-dss8s from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container vpn-shoot ready: true, restart count 0
Mar  1 08:43:18.834: INFO: addons-kube-lego-69bbdc96b6-kq9t6 from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container kube-lego ready: true, restart count 0
Mar  1 08:43:18.834: INFO: metrics-server-5887bb7679-cp4bx from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 08:43:18.834: INFO: blackbox-exporter-86f6cf4cb7-f8l2h from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container blackbox-exporter ready: true, restart count 0
Mar  1 08:43:18.834: INFO: kube-proxy-fm85v from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 08:43:18.834: INFO: addons-nginx-ingress-controller-7455744d9b-4fsw8 from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 08:43:18.834: INFO: addons-kubernetes-dashboard-6579b646c5-m9hss from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  1 08:43:18.834: INFO: coredns-67df79bbdd-vvpqk from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container coredns ready: true, restart count 0
Mar  1 08:43:18.834: INFO: calico-node-spl6x from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 08:43:18.834: INFO: node-exporter-tpmps from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 08:43:18.834: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-sxtcj from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.834: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Mar  1 08:43:18.834: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j before test
Mar  1 08:43:18.877: INFO: kube-proxy-jgp29 from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.877: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 08:43:18.877: INFO: calico-node-zxtkb from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.877: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 08:43:18.877: INFO: node-exporter-lv9s4 from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 08:43:18.877: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1290029e-3bfe-11e9-9193-2e670c8e304c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-1290029e-3bfe-11e9-9193-2e670c8e304c off the node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1290029e-3bfe-11e9-9193-2e670c8e304c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:43:27.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-fjgq9" for this suite.
Mar  1 08:43:49.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:43:50.801: INFO: namespace: e2e-tests-sched-pred-fjgq9, resource: bindings, ignored listing per whitelist
Mar  1 08:43:50.871: INFO: namespace e2e-tests-sched-pred-fjgq9 deletion completed in 23.448762272s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:33.669 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:43:50.871: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n2vfg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2402a3c8-3bfe-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 08:43:52.413: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-n2vfg" to be "success or failure"
Mar  1 08:43:52.448: INFO: Pod "pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.722492ms
Mar  1 08:43:54.484: INFO: Pod "pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070423112s
Mar  1 08:43:56.519: INFO: Pod "pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105922713s
STEP: Saw pod success
Mar  1 08:43:56.519: INFO: Pod "pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:43:56.554: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:43:56.639: INFO: Waiting for pod pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c to disappear
Mar  1 08:43:56.717: INFO: Pod pod-projected-configmaps-2407f6f1-3bfe-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:43:56.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n2vfg" for this suite.
Mar  1 08:44:02.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:44:03.704: INFO: namespace: e2e-tests-projected-n2vfg, resource: bindings, ignored listing per whitelist
Mar  1 08:44:04.232: INFO: namespace e2e-tests-projected-n2vfg deletion completed in 7.479806395s

• [SLOW TEST:13.361 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:44:04.232: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7ktdp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 08:44:10.538: INFO: Successfully updated pod "labelsupdate2c04db16-3bfe-11e9-9193-2e670c8e304c"
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:44:12.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7ktdp" for this suite.
Mar  1 08:44:34.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:44:35.007: INFO: namespace: e2e-tests-projected-7ktdp, resource: bindings, ignored listing per whitelist
Mar  1 08:44:36.093: INFO: namespace e2e-tests-projected-7ktdp deletion completed in 23.435651818s

• [SLOW TEST:31.861 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:44:36.093: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nl585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-nl585/configmap-test-3ef6fb3c-3bfe-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 08:44:37.635: INFO: Waiting up to 5m0s for pod "pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-nl585" to be "success or failure"
Mar  1 08:44:37.676: INFO: Pod "pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 40.934695ms
Mar  1 08:44:39.712: INFO: Pod "pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077105444s
Mar  1 08:44:41.752: INFO: Pod "pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.116990845s
STEP: Saw pod success
Mar  1 08:44:41.752: INFO: Pod "pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:44:41.788: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c container env-test: <nil>
STEP: delete the pod
Mar  1 08:44:41.874: INFO: Waiting for pod pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c to disappear
Mar  1 08:44:41.910: INFO: Pod pod-configmaps-3efc61e7-3bfe-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-node] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:44:41.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nl585" for this suite.
Mar  1 08:44:48.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:44:49.272: INFO: namespace: e2e-tests-configmap-nl585, resource: bindings, ignored listing per whitelist
Mar  1 08:44:49.410: INFO: namespace e2e-tests-configmap-nl585 deletion completed in 7.464214967s

• [SLOW TEST:13.317 seconds]
[sig-node] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:44:49.410: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-qtrcm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:44:50.935: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 08:44:55.005: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 08:44:59.322: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-qtrcm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qtrcm/deployments/test-cleanup-deployment,UID:4969f173-3bfe-11e9-a289-2aff89a14c6e,ResourceVersion:14682,Generation:1,CreationTimestamp:2019-03-01 08:44:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 08:44:55 +0000 UTC 2019-03-01 08:44:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 08:44:57 +0000 UTC 2019-03-01 08:44:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 08:44:59.357: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-qtrcm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qtrcm/replicasets/test-cleanup-deployment-7dbbfcf846,UID:496c1ece-3bfe-11e9-a289-2aff89a14c6e,ResourceVersion:14675,Generation:1,CreationTimestamp:2019-03-01 08:44:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 4969f173-3bfe-11e9-a289-2aff89a14c6e 0xc00245e807 0xc00245e808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 08:44:59.394: INFO: Pod "test-cleanup-deployment-7dbbfcf846-zqj9n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-zqj9n,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-qtrcm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qtrcm/pods/test-cleanup-deployment-7dbbfcf846-zqj9n,UID:496d3fc8-3bfe-11e9-a289-2aff89a14c6e,ResourceVersion:14674,Generation:0,CreationTimestamp:2019-03-01 08:44:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.133/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 496c1ece-3bfe-11e9-a289-2aff89a14c6e 0xc00245ede7 0xc00245ede8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4nkst {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4nkst,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4nkst true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00245ee50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00245ee70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:44:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:44:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:44:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:44:55 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.133,StartTime:2019-03-01 08:44:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 08:44:57 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1efbff74b8821aa2f42bddce82d299176589c05c429f6c9c8b6d1ca017ccf7fd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:44:59.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qtrcm" for this suite.
Mar  1 08:45:05.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:45:06.707: INFO: namespace: e2e-tests-deployment-qtrcm, resource: bindings, ignored listing per whitelist
Mar  1 08:45:06.953: INFO: namespace e2e-tests-deployment-qtrcm deletion completed in 7.523320988s

• [SLOW TEST:17.543 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:45:06.953: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-p95wp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:45:08.454: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:45:12.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-p95wp" for this suite.
Mar  1 08:45:53.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:45:53.629: INFO: namespace: e2e-tests-pods-p95wp, resource: bindings, ignored listing per whitelist
Mar  1 08:45:54.402: INFO: namespace e2e-tests-pods-p95wp deletion completed in 41.467043524s

• [SLOW TEST:47.449 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:45:54.402: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-8cqzj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0301 08:45:56.187948   31738 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 08:45:56.188: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:45:56.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8cqzj" for this suite.
Mar  1 08:46:02.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:46:03.153: INFO: namespace: e2e-tests-gc-8cqzj, resource: bindings, ignored listing per whitelist
Mar  1 08:46:03.707: INFO: namespace e2e-tests-gc-8cqzj deletion completed in 7.484359851s

• [SLOW TEST:9.305 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:46:03.707: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2fqv6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 08:46:05.210: INFO: Waiting up to 5m0s for pod "pod-732f6161-3bfe-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-2fqv6" to be "success or failure"
Mar  1 08:46:05.246: INFO: Pod "pod-732f6161-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.999694ms
Mar  1 08:46:07.283: INFO: Pod "pod-732f6161-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072425471s
Mar  1 08:46:09.319: INFO: Pod "pod-732f6161-3bfe-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108615432s
STEP: Saw pod success
Mar  1 08:46:09.319: INFO: Pod "pod-732f6161-3bfe-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:46:09.354: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-732f6161-3bfe-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 08:46:09.443: INFO: Waiting for pod pod-732f6161-3bfe-11e9-9193-2e670c8e304c to disappear
Mar  1 08:46:09.478: INFO: Pod pod-732f6161-3bfe-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:46:09.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2fqv6" for this suite.
Mar  1 08:46:15.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:46:16.113: INFO: namespace: e2e-tests-emptydir-2fqv6, resource: bindings, ignored listing per whitelist
Mar  1 08:46:16.987: INFO: namespace e2e-tests-emptydir-2fqv6 deletion completed in 7.473143513s

• [SLOW TEST:13.279 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:46:16.987: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-42w8m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:46:18.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-42w8m" to be "success or failure"
Mar  1 08:46:18.526: INFO: Pod "downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.923559ms
Mar  1 08:46:20.562: INFO: Pod "downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069986971s
Mar  1 08:46:22.597: INFO: Pod "downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105290773s
STEP: Saw pod success
Mar  1 08:46:22.597: INFO: Pod "downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:46:22.632: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 08:46:22.720: INFO: Waiting for pod downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c to disappear
Mar  1 08:46:22.764: INFO: Pod downwardapi-volume-7b19e891-3bfe-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:46:22.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-42w8m" for this suite.
Mar  1 08:46:28.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:46:29.031: INFO: namespace: e2e-tests-downward-api-42w8m, resource: bindings, ignored listing per whitelist
Mar  1 08:46:30.302: INFO: namespace e2e-tests-downward-api-42w8m deletion completed in 7.503019035s

• [SLOW TEST:13.315 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:46:30.302: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rtdqj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar  1 08:46:31.773: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  1 08:46:31.773: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:46:32.256: INFO: stderr: ""
Mar  1 08:46:32.256: INFO: stdout: "service/redis-slave created\n"
Mar  1 08:46:32.256: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  1 08:46:32.256: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:46:32.650: INFO: stderr: ""
Mar  1 08:46:32.650: INFO: stdout: "service/redis-master created\n"
Mar  1 08:46:32.650: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  1 08:46:32.650: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:46:33.022: INFO: stderr: ""
Mar  1 08:46:33.022: INFO: stdout: "service/frontend created\n"
Mar  1 08:46:33.022: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  1 08:46:33.022: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:46:33.383: INFO: stderr: ""
Mar  1 08:46:33.383: INFO: stdout: "deployment.extensions/frontend created\n"
Mar  1 08:46:33.383: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  1 08:46:33.383: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:46:33.734: INFO: stderr: ""
Mar  1 08:46:33.734: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar  1 08:46:33.734: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  1 08:46:33.734: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:46:34.094: INFO: stderr: ""
Mar  1 08:46:34.094: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar  1 08:46:34.094: INFO: Waiting for all frontend pods to be Running.
Mar  1 08:47:04.146: INFO: Waiting for frontend to serve content.
Mar  1 08:47:04.337: INFO: Trying to add a new entry to the guestbook.
Mar  1 08:47:04.462: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  1 08:47:04.508: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:47:04.827: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:47:04.827: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 08:47:04.827: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:47:05.100: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:47:05.100: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 08:47:05.101: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:47:05.400: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:47:05.400: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 08:47:05.400: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:47:05.697: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:47:05.697: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 08:47:05.697: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:47:05.982: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:47:05.982: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 08:47:05.982: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rtdqj'
Mar  1 08:47:06.252: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:47:06.252: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:47:06.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rtdqj" for this suite.
Mar  1 08:47:48.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:47:48.740: INFO: namespace: e2e-tests-kubectl-rtdqj, resource: bindings, ignored listing per whitelist
Mar  1 08:47:49.830: INFO: namespace e2e-tests-kubectl-rtdqj deletion completed in 43.541864924s

• [SLOW TEST:79.528 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:47:49.830: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-hhmn5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b27768ca-3bfe-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 08:47:51.421: INFO: Waiting up to 5m0s for pod "pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-hhmn5" to be "success or failure"
Mar  1 08:47:51.464: INFO: Pod "pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 42.996358ms
Mar  1 08:47:53.499: INFO: Pod "pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078651583s
Mar  1 08:47:55.535: INFO: Pod "pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114256062s
STEP: Saw pod success
Mar  1 08:47:55.535: INFO: Pod "pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:47:55.570: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:47:55.654: INFO: Waiting for pod pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c to disappear
Mar  1 08:47:55.720: INFO: Pod pod-configmaps-b27d4044-3bfe-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:47:55.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hhmn5" for this suite.
Mar  1 08:48:01.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:48:02.421: INFO: namespace: e2e-tests-configmap-hhmn5, resource: bindings, ignored listing per whitelist
Mar  1 08:48:03.293: INFO: namespace e2e-tests-configmap-hhmn5 deletion completed in 7.536438817s

• [SLOW TEST:13.463 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:48:03.293: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-tpqvr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar  1 08:48:04.791: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-tpqvr" to be "success or failure"
Mar  1 08:48:04.825: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 34.549525ms
Mar  1 08:48:06.861: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070174203s
Mar  1 08:48:08.896: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105559399s
STEP: Saw pod success
Mar  1 08:48:08.896: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  1 08:48:08.932: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  1 08:48:09.057: INFO: Waiting for pod pod-host-path-test to disappear
Mar  1 08:48:09.093: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:48:09.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-tpqvr" for this suite.
Mar  1 08:48:15.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:48:16.214: INFO: namespace: e2e-tests-hostpath-tpqvr, resource: bindings, ignored listing per whitelist
Mar  1 08:48:16.561: INFO: namespace e2e-tests-hostpath-tpqvr deletion completed in 7.431827006s

• [SLOW TEST:13.267 seconds]
[sig-storage] HostPath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:48:16.561: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-97xqx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:48:22.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-97xqx" for this suite.
Mar  1 08:49:02.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:49:03.668: INFO: namespace: e2e-tests-kubelet-test-97xqx, resource: bindings, ignored listing per whitelist
Mar  1 08:49:03.710: INFO: namespace e2e-tests-kubelet-test-97xqx deletion completed in 41.521977912s

• [SLOW TEST:47.149 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:49:03.710: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-88bwn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:49:05.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-88bwn" for this suite.
Mar  1 08:49:29.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:49:30.061: INFO: namespace: e2e-tests-pods-88bwn, resource: bindings, ignored listing per whitelist
Mar  1 08:49:30.727: INFO: namespace e2e-tests-pods-88bwn deletion completed in 25.434407133s

• [SLOW TEST:27.017 seconds]
[k8s.io] [sig-node] Pods Extended
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:49:30.728: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-ktht6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ktht6
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-ktht6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-ktht6
Mar  1 08:49:32.276: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar  1 08:49:42.313: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  1 08:49:42.349: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-ktht6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:49:43.288: INFO: stderr: ""
Mar  1 08:49:43.288: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:49:43.288: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:49:43.324: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 08:49:53.359: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:49:53.359: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:49:53.501: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999954s
Mar  1 08:49:54.537: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.964512162s
Mar  1 08:49:55.574: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.92856284s
Mar  1 08:49:56.610: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.891921302s
Mar  1 08:49:57.646: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.855677357s
Mar  1 08:49:58.681: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.820166791s
Mar  1 08:49:59.722: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.784463551s
Mar  1 08:50:00.757: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.744309214s
Mar  1 08:50:01.794: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.708422136s
Mar  1 08:50:02.830: INFO: Verifying statefulset ss doesn't scale past 3 for another 672.336444ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-ktht6
Mar  1 08:50:03.866: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-ktht6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:50:04.759: INFO: stderr: ""
Mar  1 08:50:04.759: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:50:04.759: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:50:04.759: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-ktht6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:50:05.648: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  1 08:50:05.648: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:50:05.648: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:50:05.648: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-ktht6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:50:06.463: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  1 08:50:06.463: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:50:06.463: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:50:06.499: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:50:06.499: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:50:06.499: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  1 08:50:06.536: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-ktht6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:50:07.322: INFO: stderr: ""
Mar  1 08:50:07.322: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:50:07.322: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:50:07.322: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-ktht6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:50:08.218: INFO: stderr: ""
Mar  1 08:50:08.218: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:50:08.218: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:50:08.218: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-ktht6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:50:09.026: INFO: stderr: ""
Mar  1 08:50:09.026: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:50:09.026: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:50:09.026: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:50:09.061: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  1 08:50:19.132: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:50:19.132: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:50:19.132: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:50:19.259: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:19.259: INFO: ss-0  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  }]
Mar  1 08:50:19.259: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:19.259: INFO: ss-2  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:19.259: INFO: 
Mar  1 08:50:19.259: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:50:20.295: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:20.295: INFO: ss-0  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  }]
Mar  1 08:50:20.295: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:20.295: INFO: ss-2  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:20.295: INFO: 
Mar  1 08:50:20.295: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:50:21.332: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:21.332: INFO: ss-0  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  }]
Mar  1 08:50:21.332: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:21.332: INFO: ss-2  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:21.332: INFO: 
Mar  1 08:50:21.332: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:50:22.368: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:22.368: INFO: ss-0  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  }]
Mar  1 08:50:22.368: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:22.368: INFO: ss-2  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:22.368: INFO: 
Mar  1 08:50:22.368: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:50:23.404: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:23.404: INFO: ss-0  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  }]
Mar  1 08:50:23.404: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:23.404: INFO: ss-2  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:23.404: INFO: 
Mar  1 08:50:23.404: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:50:24.440: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:24.440: INFO: ss-0  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  }]
Mar  1 08:50:24.440: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:24.440: INFO: ss-2  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:24.440: INFO: 
Mar  1 08:50:24.440: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:50:25.499: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:25.499: INFO: ss-0  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:32 +0000 UTC  }]
Mar  1 08:50:25.499: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:25.499: INFO: ss-2  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:25.499: INFO: 
Mar  1 08:50:25.499: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:50:26.534: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:50:26.535: INFO: ss-1  shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:50:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:49:53 +0000 UTC  }]
Mar  1 08:50:26.535: INFO: 
Mar  1 08:50:26.535: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  1 08:50:27.573: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.671175587s
Mar  1 08:50:28.609: INFO: Verifying statefulset ss doesn't scale past 0 for another 632.492743ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-ktht6
Mar  1 08:50:29.647: INFO: Scaling statefulset ss to 0
Mar  1 08:50:29.752: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 08:50:29.788: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ktht6
Mar  1 08:50:29.823: INFO: Scaling statefulset ss to 0
Mar  1 08:50:29.929: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:50:29.964: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:50:30.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ktht6" for this suite.
Mar  1 08:50:36.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:50:37.088: INFO: namespace: e2e-tests-statefulset-ktht6, resource: bindings, ignored listing per whitelist
Mar  1 08:50:37.539: INFO: namespace e2e-tests-statefulset-ktht6 deletion completed in 7.427823059s

• [SLOW TEST:66.811 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:50:37.539: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k48s7
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-16738a0a-3bff-11e9-9193-2e670c8e304c
STEP: Creating configMap with name cm-test-opt-upd-16738a47-3bff-11e9-9193-2e670c8e304c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-16738a0a-3bff-11e9-9193-2e670c8e304c
STEP: Updating configmap cm-test-opt-upd-16738a47-3bff-11e9-9193-2e670c8e304c
STEP: Creating configMap with name cm-test-opt-create-16738a5b-3bff-11e9-9193-2e670c8e304c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:50:47.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k48s7" for this suite.
Mar  1 08:51:12.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:51:12.274: INFO: namespace: e2e-tests-projected-k48s7, resource: bindings, ignored listing per whitelist
Mar  1 08:51:13.718: INFO: namespace e2e-tests-projected-k48s7 deletion completed in 25.728820941s

• [SLOW TEST:36.179 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:51:13.718: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hcc6j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 08:51:15.395: INFO: Waiting up to 5m0s for pod "pod-2c11ad49-3bff-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-hcc6j" to be "success or failure"
Mar  1 08:51:15.442: INFO: Pod "pod-2c11ad49-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 47.209459ms
Mar  1 08:51:17.478: INFO: Pod "pod-2c11ad49-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083267918s
Mar  1 08:51:19.514: INFO: Pod "pod-2c11ad49-3bff-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.118831783s
STEP: Saw pod success
Mar  1 08:51:19.514: INFO: Pod "pod-2c11ad49-3bff-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:51:19.557: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-2c11ad49-3bff-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 08:51:19.645: INFO: Waiting for pod pod-2c11ad49-3bff-11e9-9193-2e670c8e304c to disappear
Mar  1 08:51:19.680: INFO: Pod pod-2c11ad49-3bff-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:51:19.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hcc6j" for this suite.
Mar  1 08:51:25.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:51:26.732: INFO: namespace: e2e-tests-emptydir-hcc6j, resource: bindings, ignored listing per whitelist
Mar  1 08:51:27.157: INFO: namespace e2e-tests-emptydir-hcc6j deletion completed in 7.442252349s

• [SLOW TEST:13.439 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:51:27.157: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-rtc67
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-2nfw
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 08:51:28.801: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2nfw" in namespace "e2e-tests-subpath-rtc67" to be "success or failure"
Mar  1 08:51:28.836: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Pending", Reason="", readiness=false. Elapsed: 34.980687ms
Mar  1 08:51:30.873: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071487936s
Mar  1 08:51:32.910: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108747567s
Mar  1 08:51:34.946: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 6.14441025s
Mar  1 08:51:36.982: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 8.180364905s
Mar  1 08:51:39.018: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 10.217043964s
Mar  1 08:51:41.057: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 12.255748994s
Mar  1 08:51:43.096: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 14.294994984s
Mar  1 08:51:45.133: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 16.331487137s
Mar  1 08:51:47.172: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 18.371221604s
Mar  1 08:51:49.208: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 20.40688054s
Mar  1 08:51:51.244: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Running", Reason="", readiness=false. Elapsed: 22.442817766s
Mar  1 08:51:53.283: INFO: Pod "pod-subpath-test-projected-2nfw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.481678406s
STEP: Saw pod success
Mar  1 08:51:53.283: INFO: Pod "pod-subpath-test-projected-2nfw" satisfied condition "success or failure"
Mar  1 08:51:53.318: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-subpath-test-projected-2nfw container test-container-subpath-projected-2nfw: <nil>
STEP: delete the pod
Mar  1 08:51:53.409: INFO: Waiting for pod pod-subpath-test-projected-2nfw to disappear
Mar  1 08:51:53.443: INFO: Pod pod-subpath-test-projected-2nfw no longer exists
STEP: Deleting pod pod-subpath-test-projected-2nfw
Mar  1 08:51:53.443: INFO: Deleting pod "pod-subpath-test-projected-2nfw" in namespace "e2e-tests-subpath-rtc67"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:51:53.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rtc67" for this suite.
Mar  1 08:51:59.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:00.797: INFO: namespace: e2e-tests-subpath-rtc67, resource: bindings, ignored listing per whitelist
Mar  1 08:52:01.163: INFO: namespace e2e-tests-subpath-rtc67 deletion completed in 7.648423034s

• [SLOW TEST:34.006 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:52:01.163: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-r5k8b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-484869a8-3bff-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 08:52:02.770: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-r5k8b" to be "success or failure"
Mar  1 08:52:02.827: INFO: Pod "pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 57.174774ms
Mar  1 08:52:04.864: INFO: Pod "pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09460111s
Mar  1 08:52:06.901: INFO: Pod "pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.131176265s
STEP: Saw pod success
Mar  1 08:52:06.901: INFO: Pod "pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:52:06.936: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:52:07.031: INFO: Waiting for pod pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c to disappear
Mar  1 08:52:07.067: INFO: Pod pod-projected-secrets-484e8648-3bff-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:52:07.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r5k8b" for this suite.
Mar  1 08:52:13.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:14.304: INFO: namespace: e2e-tests-projected-r5k8b, resource: bindings, ignored listing per whitelist
Mar  1 08:52:14.583: INFO: namespace e2e-tests-projected-r5k8b deletion completed in 7.480522097s

• [SLOW TEST:13.420 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:52:14.584: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-lf8kg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 08:52:16.136: INFO: Waiting up to 5m0s for pod "pod-504611ae-3bff-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-lf8kg" to be "success or failure"
Mar  1 08:52:16.207: INFO: Pod "pod-504611ae-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 71.101465ms
Mar  1 08:52:18.243: INFO: Pod "pod-504611ae-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107350957s
Mar  1 08:52:20.279: INFO: Pod "pod-504611ae-3bff-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.143015077s
STEP: Saw pod success
Mar  1 08:52:20.279: INFO: Pod "pod-504611ae-3bff-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:52:20.313: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-504611ae-3bff-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 08:52:20.395: INFO: Waiting for pod pod-504611ae-3bff-11e9-9193-2e670c8e304c to disappear
Mar  1 08:52:20.461: INFO: Pod pod-504611ae-3bff-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:52:20.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lf8kg" for this suite.
Mar  1 08:52:26.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:27.604: INFO: namespace: e2e-tests-emptydir-lf8kg, resource: bindings, ignored listing per whitelist
Mar  1 08:52:28.039: INFO: namespace e2e-tests-emptydir-lf8kg deletion completed in 7.541647023s

• [SLOW TEST:13.455 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:52:28.039: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-nngnw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-nngnw
[It] Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-nngnw
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-nngnw
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-nngnw
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-nngnw
Mar  1 08:52:33.864: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-nngnw, name: ss-0, uid: 59b9fb58-3bff-11e9-a289-2aff89a14c6e, status phase: Pending. Waiting for statefulset controller to delete.
Mar  1 08:52:36.560: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-nngnw, name: ss-0, uid: 59b9fb58-3bff-11e9-a289-2aff89a14c6e, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 08:52:36.586: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-nngnw, name: ss-0, uid: 59b9fb58-3bff-11e9-a289-2aff89a14c6e, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 08:52:36.612: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-nngnw
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-nngnw
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-nngnw and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 08:52:40.789: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nngnw
Mar  1 08:52:40.825: INFO: Scaling statefulset ss to 0
Mar  1 08:52:50.976: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:52:51.011: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:52:51.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-nngnw" for this suite.
Mar  1 08:52:57.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:57.721: INFO: namespace: e2e-tests-statefulset-nngnw, resource: bindings, ignored listing per whitelist
Mar  1 08:52:58.697: INFO: namespace e2e-tests-statefulset-nngnw deletion completed in 7.543533642s

• [SLOW TEST:30.657 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:52:58.697: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cddr2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar  1 08:53:00.280: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml api-versions'
Mar  1 08:53:02.165: INFO: stderr: ""
Mar  1 08:53:02.165: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:53:02.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cddr2" for this suite.
Mar  1 08:53:08.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:53:08.527: INFO: namespace: e2e-tests-kubectl-cddr2, resource: bindings, ignored listing per whitelist
Mar  1 08:53:09.669: INFO: namespace e2e-tests-kubectl-cddr2 deletion completed in 7.46502318s

• [SLOW TEST:10.972 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:53:09.670: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mrt2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:53:11.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-mrt2p" to be "success or failure"
Mar  1 08:53:11.244: INFO: Pod "downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 36.983885ms
Mar  1 08:53:13.282: INFO: Pod "downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075372459s
Mar  1 08:53:15.318: INFO: Pod "downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110554816s
STEP: Saw pod success
Mar  1 08:53:15.318: INFO: Pod "downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:53:15.353: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 08:53:15.442: INFO: Waiting for pod downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c to disappear
Mar  1 08:53:15.477: INFO: Pod downwardapi-volume-711936a9-3bff-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:53:15.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mrt2p" for this suite.
Mar  1 08:53:21.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:53:23.013: INFO: namespace: e2e-tests-projected-mrt2p, resource: bindings, ignored listing per whitelist
Mar  1 08:53:23.116: INFO: namespace e2e-tests-projected-mrt2p deletion completed in 7.57970336s

• [SLOW TEST:13.447 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:53:23.116: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-9q9zt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9q9zt.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 37.71.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.71.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.71.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.71.37_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9q9zt;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9q9zt.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9q9zt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9q9zt.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 37.71.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.71.37_udp@PTR;check="$$(dig +tcp +noall +answer +search 37.71.68.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.68.71.37_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 08:53:30.915: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:30.957: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:30.994: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.031: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.068: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.106: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.143: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.179: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.594: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.630: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.667: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.703: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.740: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.777: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.813: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:31.850: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:32.279: INFO: Lookups using e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9q9zt jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc]

Mar  1 08:53:37.316: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:37.360: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:37.397: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:37.433: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:37.470: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:37.506: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:37.543: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:37.598: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.001: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.040: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.077: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.114: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.151: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.188: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.224: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.260: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:38.622: INFO: Lookups using e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9q9zt jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc]

Mar  1 08:53:42.320: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:42.358: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:42.395: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:42.433: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:42.470: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:42.554: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:42.595: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:42.633: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.088: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.126: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.163: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.202: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.238: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.279: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.317: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.354: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:43.726: INFO: Lookups using e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9q9zt jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc]

Mar  1 08:53:47.317: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.353: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.390: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.433: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.469: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.505: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.542: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.582: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:47.996: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.032: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.069: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.106: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.142: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.178: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.261: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.302: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:48.716: INFO: Lookups using e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9q9zt jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc]

Mar  1 08:53:52.320: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:52.362: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:52.404: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:52.441: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:52.477: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:52.513: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:52.551: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:52.587: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.001: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.037: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.073: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.111: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.147: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.184: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.223: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.260: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:53.631: INFO: Lookups using e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9q9zt jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt jessie_udp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc]

Mar  1 08:53:57.318: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:57.355: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:57.392: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:57.428: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:57.468: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:57.504: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:57.541: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:57.580: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc from pod e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c: the server could not find the requested resource (get pods dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c)
Mar  1 08:53:58.840: INFO: Lookups using e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt wheezy_udp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9q9zt.svc]

Mar  1 08:54:04.112: INFO: DNS probes using e2e-tests-dns-9q9zt/dns-test-7920f59b-3bff-11e9-9193-2e670c8e304c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:54:04.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-9q9zt" for this suite.
Mar  1 08:54:10.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:54:10.683: INFO: namespace: e2e-tests-dns-9q9zt, resource: bindings, ignored listing per whitelist
Mar  1 08:54:11.803: INFO: namespace e2e-tests-dns-9q9zt deletion completed in 7.510161675s

• [SLOW TEST:48.687 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:54:11.803: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-6dfgn
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:54:13.375: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:54:13.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-6dfgn" for this suite.
Mar  1 08:54:19.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:54:19.966: INFO: namespace: e2e-tests-custom-resource-definition-6dfgn, resource: bindings, ignored listing per whitelist
Mar  1 08:54:21.159: INFO: namespace e2e-tests-custom-resource-definition-6dfgn deletion completed in 7.474664475s

• [SLOW TEST:9.356 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:54:21.159: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qxcvv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9bb6612a-3bff-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 08:54:22.746: INFO: Waiting up to 5m0s for pod "pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-qxcvv" to be "success or failure"
Mar  1 08:54:22.781: INFO: Pod "pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.845274ms
Mar  1 08:54:24.817: INFO: Pod "pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071168515s
Mar  1 08:54:26.854: INFO: Pod "pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107519465s
STEP: Saw pod success
Mar  1 08:54:26.854: INFO: Pod "pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:54:26.888: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:54:26.981: INFO: Waiting for pod pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c to disappear
Mar  1 08:54:27.022: INFO: Pod pod-secrets-9bbba83e-3bff-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:54:27.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qxcvv" for this suite.
Mar  1 08:54:33.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:54:33.315: INFO: namespace: e2e-tests-secrets-qxcvv, resource: bindings, ignored listing per whitelist
Mar  1 08:54:34.546: INFO: namespace e2e-tests-secrets-qxcvv deletion completed in 7.488024113s

• [SLOW TEST:13.387 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:54:34.546: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jv64c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 08:54:35.995: INFO: Waiting up to 5m0s for pod "pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-jv64c" to be "success or failure"
Mar  1 08:54:36.030: INFO: Pod "pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.811087ms
Mar  1 08:54:38.066: INFO: Pod "pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070623909s
Mar  1 08:54:40.103: INFO: Pod "pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10852821s
STEP: Saw pod success
Mar  1 08:54:40.103: INFO: Pod "pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:54:40.138: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 08:54:40.231: INFO: Waiting for pod pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c to disappear
Mar  1 08:54:40.266: INFO: Pod pod-a3a2ec31-3bff-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:54:40.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jv64c" for this suite.
Mar  1 08:54:46.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:54:47.601: INFO: namespace: e2e-tests-emptydir-jv64c, resource: bindings, ignored listing per whitelist
Mar  1 08:54:47.811: INFO: namespace e2e-tests-emptydir-jv64c deletion completed in 7.509793056s

• [SLOW TEST:13.265 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:54:47.811: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-pwxn6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0301 08:54:55.641775   31738 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 08:54:55.641: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:54:55.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pwxn6" for this suite.
Mar  1 08:55:01.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:55:01.925: INFO: namespace: e2e-tests-gc-pwxn6, resource: bindings, ignored listing per whitelist
Mar  1 08:55:03.171: INFO: namespace e2e-tests-gc-pwxn6 deletion completed in 7.494204863s

• [SLOW TEST:15.360 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:55:03.171: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-5v97f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:55:08.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5v97f" for this suite.
Mar  1 08:55:56.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:55:57.526: INFO: namespace: e2e-tests-kubelet-test-5v97f, resource: bindings, ignored listing per whitelist
Mar  1 08:55:58.332: INFO: namespace e2e-tests-kubelet-test-5v97f deletion completed in 49.446486095s

• [SLOW TEST:55.161 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:55:58.333: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-gpbqg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d5960807-3bff-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 08:55:59.834: INFO: Waiting up to 5m0s for pod "pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-gpbqg" to be "success or failure"
Mar  1 08:55:59.902: INFO: Pod "pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 68.013418ms
Mar  1 08:56:01.938: INFO: Pod "pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103121084s
Mar  1 08:56:03.974: INFO: Pod "pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.139648182s
STEP: Saw pod success
Mar  1 08:56:03.974: INFO: Pod "pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:56:04.009: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c container secret-env-test: <nil>
STEP: delete the pod
Mar  1 08:56:04.118: INFO: Waiting for pod pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c to disappear
Mar  1 08:56:04.153: INFO: Pod pod-secrets-d59b7797-3bff-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:56:04.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gpbqg" for this suite.
Mar  1 08:56:10.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:56:11.374: INFO: namespace: e2e-tests-secrets-gpbqg, resource: bindings, ignored listing per whitelist
Mar  1 08:56:11.922: INFO: namespace e2e-tests-secrets-gpbqg deletion completed in 7.73330986s

• [SLOW TEST:13.589 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:56:11.922: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-lftzn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  1 08:56:13.922: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lftzn,SelfLink:/api/v1/namespaces/e2e-tests-watch-lftzn/configmaps/e2e-watch-test-resource-version,UID:dde42f94-3bff-11e9-a289-2aff89a14c6e,ResourceVersion:16887,Generation:0,CreationTimestamp:2019-03-01 08:56:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 08:56:13.922: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-lftzn,SelfLink:/api/v1/namespaces/e2e-tests-watch-lftzn/configmaps/e2e-watch-test-resource-version,UID:dde42f94-3bff-11e9-a289-2aff89a14c6e,ResourceVersion:16888,Generation:0,CreationTimestamp:2019-03-01 08:56:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:56:13.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-lftzn" for this suite.
Mar  1 08:56:20.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:56:21.153: INFO: namespace: e2e-tests-watch-lftzn, resource: bindings, ignored listing per whitelist
Mar  1 08:56:21.470: INFO: namespace e2e-tests-watch-lftzn deletion completed in 7.505542984s

• [SLOW TEST:9.549 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:56:21.471: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9qmh9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 08:56:22.952: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9qmh9'
Mar  1 08:56:25.066: INFO: stderr: ""
Mar  1 08:56:25.066: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Mar  1 08:56:25.103: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-9qmh9'
Mar  1 08:56:28.677: INFO: stderr: ""
Mar  1 08:56:28.677: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:56:28.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9qmh9" for this suite.
Mar  1 08:56:34.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:56:35.325: INFO: namespace: e2e-tests-kubectl-9qmh9, resource: bindings, ignored listing per whitelist
Mar  1 08:56:36.213: INFO: namespace e2e-tests-kubectl-9qmh9 deletion completed in 7.500805209s

• [SLOW TEST:14.743 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:56:36.214: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-f7v7b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  1 08:56:41.946: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-ec3d428e-3bff-11e9-9193-2e670c8e304c,GenerateName:,Namespace:e2e-tests-events-f7v7b,SelfLink:/api/v1/namespaces/e2e-tests-events-f7v7b/pods/send-events-ec3d428e-3bff-11e9-9193-2e670c8e304c,UID:ec40607f-3bff-11e9-a289-2aff89a14c6e,ResourceVersion:16974,Generation:0,CreationTimestamp:2019-03-01 08:56:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 764784345,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.164/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cslsg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cslsg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-cslsg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d25810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d25830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:56:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:56:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:56:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:56:37 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.164,StartTime:2019-03-01 08:56:37 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-01 08:56:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://3c6fd6a957e952f365ce6a111663fda5e964f621fedd0bc5306a749791d0c181}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar  1 08:56:43.984: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  1 08:56:46.020: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:56:46.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-f7v7b" for this suite.
Mar  1 08:57:32.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:57:32.836: INFO: namespace: e2e-tests-events-f7v7b, resource: bindings, ignored listing per whitelist
Mar  1 08:57:33.578: INFO: namespace e2e-tests-events-f7v7b deletion completed in 47.485870071s

• [SLOW TEST:57.364 seconds]
[k8s.io] [sig-node] Events
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:57:33.578: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lh5nk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-0e623113-3c00-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 08:57:35.123: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-lh5nk" to be "success or failure"
Mar  1 08:57:35.157: INFO: Pod "pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 33.989182ms
Mar  1 08:57:37.192: INFO: Pod "pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069466147s
Mar  1 08:57:39.235: INFO: Pod "pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.112279507s
STEP: Saw pod success
Mar  1 08:57:39.235: INFO: Pod "pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:57:39.277: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:57:39.363: INFO: Waiting for pod pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 08:57:39.401: INFO: Pod pod-projected-secrets-0e67b5f7-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:57:39.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lh5nk" for this suite.
Mar  1 08:57:45.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:57:46.179: INFO: namespace: e2e-tests-projected-lh5nk, resource: bindings, ignored listing per whitelist
Mar  1 08:57:46.908: INFO: namespace e2e-tests-projected-lh5nk deletion completed in 7.471236227s

• [SLOW TEST:13.330 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:57:46.909: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lvlj8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1659c376-3c00-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 08:57:48.488: INFO: Waiting up to 5m0s for pod "pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-lvlj8" to be "success or failure"
Mar  1 08:57:48.537: INFO: Pod "pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 49.140612ms
Mar  1 08:57:50.573: INFO: Pod "pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084717739s
Mar  1 08:57:52.608: INFO: Pod "pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.120077744s
STEP: Saw pod success
Mar  1 08:57:52.608: INFO: Pod "pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:57:52.643: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:57:52.724: INFO: Waiting for pod pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 08:57:52.760: INFO: Pod pod-configmaps-165f1bc8-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:57:52.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lvlj8" for this suite.
Mar  1 08:57:58.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:57:59.117: INFO: namespace: e2e-tests-configmap-lvlj8, resource: bindings, ignored listing per whitelist
Mar  1 08:58:00.286: INFO: namespace e2e-tests-configmap-lvlj8 deletion completed in 7.489920226s

• [SLOW TEST:13.377 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:58:00.286: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-d6bvk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1e5a8362-3c00-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 08:58:01.915: INFO: Waiting up to 5m0s for pod "pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-secrets-d6bvk" to be "success or failure"
Mar  1 08:58:01.950: INFO: Pod "pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.795391ms
Mar  1 08:58:03.985: INFO: Pod "pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070131284s
Mar  1 08:58:06.021: INFO: Pod "pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105543588s
STEP: Saw pod success
Mar  1 08:58:06.021: INFO: Pod "pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:58:06.055: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:58:06.156: INFO: Waiting for pod pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 08:58:06.192: INFO: Pod pod-secrets-1e5fd5b0-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:58:06.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d6bvk" for this suite.
Mar  1 08:58:12.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:58:13.201: INFO: namespace: e2e-tests-secrets-d6bvk, resource: bindings, ignored listing per whitelist
Mar  1 08:58:13.696: INFO: namespace e2e-tests-secrets-d6bvk deletion completed in 7.469276853s

• [SLOW TEST:13.410 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:58:13.696: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cqlm5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 08:58:15.262: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-cqlm5'
Mar  1 08:58:15.614: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 08:58:15.614: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar  1 08:58:15.701: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-2z4b2]
Mar  1 08:58:15.701: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-2z4b2" in namespace "e2e-tests-kubectl-cqlm5" to be "running and ready"
Mar  1 08:58:15.737: INFO: Pod "e2e-test-nginx-rc-2z4b2": Phase="Pending", Reason="", readiness=false. Elapsed: 35.359922ms
Mar  1 08:58:17.772: INFO: Pod "e2e-test-nginx-rc-2z4b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070439783s
Mar  1 08:58:19.809: INFO: Pod "e2e-test-nginx-rc-2z4b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.107499579s
Mar  1 08:58:19.809: INFO: Pod "e2e-test-nginx-rc-2z4b2" satisfied condition "running and ready"
Mar  1 08:58:19.809: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-2z4b2]
Mar  1 08:58:19.809: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-cqlm5'
Mar  1 08:58:20.244: INFO: stderr: ""
Mar  1 08:58:20.244: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Mar  1 08:58:20.244: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-cqlm5'
Mar  1 08:58:20.532: INFO: stderr: ""
Mar  1 08:58:20.532: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:58:20.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cqlm5" for this suite.
Mar  1 08:58:26.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:58:27.694: INFO: namespace: e2e-tests-kubectl-cqlm5, resource: bindings, ignored listing per whitelist
Mar  1 08:58:28.087: INFO: namespace e2e-tests-kubectl-cqlm5 deletion completed in 7.505625598s

• [SLOW TEST:14.391 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:58:28.087: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-trw9j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:58:33.805: INFO: Waiting up to 5m0s for pod "client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-pods-trw9j" to be "success or failure"
Mar  1 08:58:33.840: INFO: Pod "client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.68752ms
Mar  1 08:58:35.877: INFO: Pod "client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072077703s
Mar  1 08:58:37.913: INFO: Pod "client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108450367s
STEP: Saw pod success
Mar  1 08:58:37.913: INFO: Pod "client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 08:58:37.950: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c container env3cont: <nil>
STEP: delete the pod
Mar  1 08:58:38.041: INFO: Waiting for pod client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 08:58:38.076: INFO: Pod client-envvars-31606fcc-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 08:58:38.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-trw9j" for this suite.
Mar  1 08:59:28.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:59:28.844: INFO: namespace: e2e-tests-pods-trw9j, resource: bindings, ignored listing per whitelist
Mar  1 08:59:29.548: INFO: namespace e2e-tests-pods-trw9j deletion completed in 51.43717823s

• [SLOW TEST:61.461 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 08:59:29.549: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-4d9h5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 08:59:31.085: INFO: PodSpec: initContainers in spec.initContainers
Mar  1 09:00:19.373: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-538bf046-3c00-11e9-9193-2e670c8e304c", GenerateName:"", Namespace:"e2e-tests-init-container-4d9h5", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-4d9h5/pods/pod-init-538bf046-3c00-11e9-9193-2e670c8e304c", UID:"538eeee7-3c00-11e9-a289-2aff89a14c6e", ResourceVersion:"17542", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687027571, loc:(*time.Location)(0x791ea40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"85734952"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.171/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2vd6w", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001c647c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2vd6w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2vd6w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2vd6w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001fef868), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0015cc420), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fef8e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fef900)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001fef908), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001fef90c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027571, loc:(*time.Location)(0x791ea40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027571, loc:(*time.Location)(0x791ea40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027571, loc:(*time.Location)(0x791ea40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027571, loc:(*time.Location)(0x791ea40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.4", PodIP:"100.96.1.171", StartTime:(*v1.Time)(0xc001e0a320), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0012caf50)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0012cafc0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://080289faabe2c9581cbe369f3d846a0dd61c0d663df0e6a300a57c1cfd887dbe"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001e0a460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001e0a3c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:00:19.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4d9h5" for this suite.
Mar  1 09:00:41.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:00:42.347: INFO: namespace: e2e-tests-init-container-4d9h5, resource: bindings, ignored listing per whitelist
Mar  1 09:00:42.925: INFO: namespace e2e-tests-init-container-4d9h5 deletion completed in 23.516851065s

• [SLOW TEST:73.377 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:00:42.926: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zh49j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7f5641e7-3c00-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 09:00:44.629: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-zh49j" to be "success or failure"
Mar  1 09:00:44.666: INFO: Pod "pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 37.280829ms
Mar  1 09:00:46.703: INFO: Pod "pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074365315s
Mar  1 09:00:48.746: INFO: Pod "pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117494007s
STEP: Saw pod success
Mar  1 09:00:48.746: INFO: Pod "pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:00:48.781: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:00:48.925: INFO: Waiting for pod pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 09:00:48.961: INFO: Pod pod-projected-configmaps-7f5bb7c6-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:00:48.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zh49j" for this suite.
Mar  1 09:00:55.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:00:55.594: INFO: namespace: e2e-tests-projected-zh49j, resource: bindings, ignored listing per whitelist
Mar  1 09:00:56.480: INFO: namespace e2e-tests-projected-zh49j deletion completed in 7.481899737s

• [SLOW TEST:13.554 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:00:56.480: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-k6vcg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Mar  1 09:00:57.953: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 09:00:58.025: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 09:00:58.060: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v before test
Mar  1 09:00:58.103: INFO: vpn-shoot-6f8cffc7cf-dss8s from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container vpn-shoot ready: true, restart count 0
Mar  1 09:00:58.103: INFO: addons-kube-lego-69bbdc96b6-kq9t6 from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container kube-lego ready: true, restart count 0
Mar  1 09:00:58.103: INFO: metrics-server-5887bb7679-cp4bx from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 09:00:58.103: INFO: blackbox-exporter-86f6cf4cb7-f8l2h from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container blackbox-exporter ready: true, restart count 0
Mar  1 09:00:58.103: INFO: kube-proxy-fm85v from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 09:00:58.103: INFO: addons-nginx-ingress-controller-7455744d9b-4fsw8 from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 09:00:58.103: INFO: addons-kubernetes-dashboard-6579b646c5-m9hss from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  1 09:00:58.103: INFO: coredns-67df79bbdd-vvpqk from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container coredns ready: true, restart count 0
Mar  1 09:00:58.103: INFO: calico-node-spl6x from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 09:00:58.103: INFO: node-exporter-tpmps from kube-system started at 2019-03-01 07:24:42 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 09:00:58.103: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-74b5975d7-sxtcj from kube-system started at 2019-03-01 07:24:53 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.103: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Mar  1 09:00:58.103: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j before test
Mar  1 09:00:58.151: INFO: calico-node-zxtkb from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.151: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 09:00:58.151: INFO: node-exporter-lv9s4 from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.151: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 09:00:58.151: INFO: kube-proxy-jgp29 from kube-system started at 2019-03-01 07:24:51 +0000 UTC (1 container statuses recorded)
Mar  1 09:00:58.151: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1587ca25514aed91], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:00:59.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-k6vcg" for this suite.
Mar  1 09:01:05.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:01:05.831: INFO: namespace: e2e-tests-sched-pred-k6vcg, resource: bindings, ignored listing per whitelist
Mar  1 09:01:06.870: INFO: namespace e2e-tests-sched-pred-k6vcg deletion completed in 7.503227437s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:10.390 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:01:06.870: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lmjxh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:01:08.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-lmjxh" to be "success or failure"
Mar  1 09:01:08.434: INFO: Pod "downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 37.763252ms
Mar  1 09:01:10.469: INFO: Pod "downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072942158s
Mar  1 09:01:12.505: INFO: Pod "downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108729512s
STEP: Saw pod success
Mar  1 09:01:12.505: INFO: Pod "downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:01:12.553: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:01:12.640: INFO: Waiting for pod downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 09:01:12.674: INFO: Pod downwardapi-volume-8d8684c2-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:01:12.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lmjxh" for this suite.
Mar  1 09:01:18.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:01:19.598: INFO: namespace: e2e-tests-downward-api-lmjxh, resource: bindings, ignored listing per whitelist
Mar  1 09:01:20.210: INFO: namespace e2e-tests-downward-api-lmjxh deletion completed in 7.500138686s

• [SLOW TEST:13.340 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:01:20.210: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-q4qlt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:01:25.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-q4qlt" for this suite.
Mar  1 09:01:31.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:01:32.686: INFO: namespace: e2e-tests-kubelet-test-q4qlt, resource: bindings, ignored listing per whitelist
Mar  1 09:01:33.389: INFO: namespace e2e-tests-kubelet-test-q4qlt deletion completed in 7.550265848s

• [SLOW TEST:13.179 seconds]
[k8s.io] Kubelet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:01:33.389: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6tr5x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:01:34.901: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-6tr5x" to be "success or failure"
Mar  1 09:01:34.959: INFO: Pod "downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 57.555059ms
Mar  1 09:01:36.998: INFO: Pod "downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097192864s
Mar  1 09:01:39.035: INFO: Pod "downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.133387568s
STEP: Saw pod success
Mar  1 09:01:39.035: INFO: Pod "downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:01:39.069: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:01:39.159: INFO: Waiting for pod downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 09:01:39.195: INFO: Pod downwardapi-volume-9d520585-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:01:39.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6tr5x" for this suite.
Mar  1 09:01:45.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:01:45.876: INFO: namespace: e2e-tests-projected-6tr5x, resource: bindings, ignored listing per whitelist
Mar  1 09:01:46.748: INFO: namespace e2e-tests-projected-6tr5x deletion completed in 7.46652247s

• [SLOW TEST:13.359 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:01:46.748: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9p7nm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a55f0f4a-3c00-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 09:01:48.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-9p7nm" to be "success or failure"
Mar  1 09:01:48.477: INFO: Pod "pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.985985ms
Mar  1 09:01:50.513: INFO: Pod "pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071243411s
Mar  1 09:01:52.549: INFO: Pod "pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107318171s
STEP: Saw pod success
Mar  1 09:01:52.549: INFO: Pod "pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:01:52.584: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:01:52.684: INFO: Waiting for pod pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 09:01:52.718: INFO: Pod pod-projected-secrets-a5647bd4-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:01:52.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9p7nm" for this suite.
Mar  1 09:01:58.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:02:00.088: INFO: namespace: e2e-tests-projected-9p7nm, resource: bindings, ignored listing per whitelist
Mar  1 09:02:00.235: INFO: namespace e2e-tests-projected-9p7nm deletion completed in 7.481059801s

• [SLOW TEST:13.486 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:02:00.235: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qlhzk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 09:02:01.663: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-qlhzk'
Mar  1 09:02:02.034: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  1 09:02:02.034: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Mar  1 09:02:02.113: INFO: scanned /root for discovery docs: <nil>
Mar  1 09:02:02.113: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-qlhzk'
Mar  1 09:02:14.758: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 09:02:14.758: INFO: stdout: "Created e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426\nScaling up e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar  1 09:02:14.758: INFO: stdout: "Created e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426\nScaling up e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar  1 09:02:14.758: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qlhzk'
Mar  1 09:02:15.034: INFO: stderr: ""
Mar  1 09:02:15.034: INFO: stdout: "e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426-6g99k e2e-test-nginx-rc-pf6fc "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Mar  1 09:02:20.034: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qlhzk'
Mar  1 09:02:20.346: INFO: stderr: ""
Mar  1 09:02:20.346: INFO: stdout: "e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426-6g99k "
Mar  1 09:02:20.346: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426-6g99k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qlhzk'
Mar  1 09:02:20.609: INFO: stderr: ""
Mar  1 09:02:20.609: INFO: stdout: "true"
Mar  1 09:02:20.609: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426-6g99k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qlhzk'
Mar  1 09:02:20.889: INFO: stderr: ""
Mar  1 09:02:20.889: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Mar  1 09:02:20.889: INFO: e2e-test-nginx-rc-3bced1818a1c58caa673a26ecc396426-6g99k is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Mar  1 09:02:20.889: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qlhzk'
Mar  1 09:02:21.177: INFO: stderr: ""
Mar  1 09:02:21.177: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:02:21.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qlhzk" for this suite.
Mar  1 09:02:27.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:02:28.478: INFO: namespace: e2e-tests-kubectl-qlhzk, resource: bindings, ignored listing per whitelist
Mar  1 09:02:28.689: INFO: namespace e2e-tests-kubectl-qlhzk deletion completed in 7.475980971s

• [SLOW TEST:28.454 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:02:28.690: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-vvrh9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 09:02:35.520: INFO: Successfully updated pod "pod-update-bea3655f-3c00-11e9-9193-2e670c8e304c"
STEP: verifying the updated pod is in kubernetes
Mar  1 09:02:35.590: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:02:35.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vvrh9" for this suite.
Mar  1 09:02:59.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:03:00.471: INFO: namespace: e2e-tests-pods-vvrh9, resource: bindings, ignored listing per whitelist
Mar  1 09:03:01.104: INFO: namespace e2e-tests-pods-vvrh9 deletion completed in 25.477568603s

• [SLOW TEST:32.415 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:03:01.104: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j2h4q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d19ab1ca-3c00-11e9-9193-2e670c8e304c
STEP: Creating secret with name secret-projected-all-test-volume-d19ab1b4-3c00-11e9-9193-2e670c8e304c
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  1 09:03:02.698: INFO: Waiting up to 5m0s for pod "projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-j2h4q" to be "success or failure"
Mar  1 09:03:02.733: INFO: Pod "projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.736807ms
Mar  1 09:03:04.768: INFO: Pod "projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070012003s
Mar  1 09:03:06.816: INFO: Pod "projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117534651s
STEP: Saw pod success
Mar  1 09:03:06.816: INFO: Pod "projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:03:06.853: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  1 09:03:06.942: INFO: Waiting for pod projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 09:03:06.978: INFO: Pod projected-volume-d19ab12d-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected combined
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:03:06.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j2h4q" for this suite.
Mar  1 09:03:13.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:03:14.143: INFO: namespace: e2e-tests-projected-j2h4q, resource: bindings, ignored listing per whitelist
Mar  1 09:03:14.479: INFO: namespace e2e-tests-projected-j2h4q deletion completed in 7.464388055s

• [SLOW TEST:13.374 seconds]
[sig-storage] Projected combined
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:03:14.479: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kfq5b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 09:03:15.998: INFO: Waiting up to 5m0s for pod "pod-d9952a20-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-kfq5b" to be "success or failure"
Mar  1 09:03:16.033: INFO: Pod "pod-d9952a20-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.174987ms
Mar  1 09:03:18.069: INFO: Pod "pod-d9952a20-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071095579s
Mar  1 09:03:20.106: INFO: Pod "pod-d9952a20-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108308204s
STEP: Saw pod success
Mar  1 09:03:20.106: INFO: Pod "pod-d9952a20-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:03:20.142: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-d9952a20-3c00-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 09:03:20.227: INFO: Waiting for pod pod-d9952a20-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 09:03:20.263: INFO: Pod pod-d9952a20-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:03:20.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kfq5b" for this suite.
Mar  1 09:03:26.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:03:26.759: INFO: namespace: e2e-tests-emptydir-kfq5b, resource: bindings, ignored listing per whitelist
Mar  1 09:03:27.786: INFO: namespace e2e-tests-emptydir-kfq5b deletion completed in 7.48753571s

• [SLOW TEST:13.307 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:03:27.786: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8vgb8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 09:03:29.321: INFO: Waiting up to 5m0s for pod "pod-e1861792-3c00-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-8vgb8" to be "success or failure"
Mar  1 09:03:29.356: INFO: Pod "pod-e1861792-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.142891ms
Mar  1 09:03:31.394: INFO: Pod "pod-e1861792-3c00-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072871715s
Mar  1 09:03:33.431: INFO: Pod "pod-e1861792-3c00-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110243791s
STEP: Saw pod success
Mar  1 09:03:33.431: INFO: Pod "pod-e1861792-3c00-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:03:33.467: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-e1861792-3c00-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 09:03:33.559: INFO: Waiting for pod pod-e1861792-3c00-11e9-9193-2e670c8e304c to disappear
Mar  1 09:03:33.593: INFO: Pod pod-e1861792-3c00-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:03:33.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8vgb8" for this suite.
Mar  1 09:03:39.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:03:41.089: INFO: namespace: e2e-tests-emptydir-8vgb8, resource: bindings, ignored listing per whitelist
Mar  1 09:03:41.162: INFO: namespace e2e-tests-emptydir-8vgb8 deletion completed in 7.533027038s

• [SLOW TEST:13.376 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:03:41.162: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-qvq8r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qvq8r
Mar  1 09:03:46.760: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qvq8r
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 09:03:46.795: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:07:47.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qvq8r" for this suite.
Mar  1 09:07:53.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:07:53.533: INFO: namespace: e2e-tests-container-probe-qvq8r, resource: bindings, ignored listing per whitelist
Mar  1 09:07:54.797: INFO: namespace e2e-tests-container-probe-qvq8r deletion completed in 7.476444452s

• [SLOW TEST:253.635 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:07:54.797: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-p9cj2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-p9cj2
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar  1 09:07:56.376: INFO: Found 1 stateful pods, waiting for 3
Mar  1 09:08:06.412: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 09:08:06.412: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 09:08:06.412: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 09:08:06.523: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-p9cj2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 09:08:07.478: INFO: stderr: ""
Mar  1 09:08:07.478: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 09:08:07.478: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 09:08:17.718: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  1 09:08:17.836: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-p9cj2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 09:08:18.719: INFO: stderr: ""
Mar  1 09:08:18.719: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 09:08:18.719: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Mar  1 09:08:48.930: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-p9cj2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 09:08:49.778: INFO: stderr: ""
Mar  1 09:08:49.778: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 09:08:49.778: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 09:08:59.999: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  1 09:09:00.113: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-p9cj2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 09:09:01.012: INFO: stderr: ""
Mar  1 09:09:01.012: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 09:09:01.012: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 09:09:21.228: INFO: Deleting all statefulset in ns e2e-tests-statefulset-p9cj2
Mar  1 09:09:21.263: INFO: Scaling statefulset ss2 to 0
Mar  1 09:09:51.408: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 09:09:51.444: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:09:51.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-p9cj2" for this suite.
Mar  1 09:09:57.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:09:57.946: INFO: namespace: e2e-tests-statefulset-p9cj2, resource: bindings, ignored listing per whitelist
Mar  1 09:09:59.025: INFO: namespace e2e-tests-statefulset-p9cj2 deletion completed in 7.432460515s

• [SLOW TEST:124.228 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:09:59.026: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-r57xw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 09:10:09.014: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 09:10:09.049: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 09:10:11.049: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 09:10:11.086: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 09:10:13.049: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 09:10:13.085: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 09:10:15.049: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 09:10:15.085: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 09:10:17.049: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 09:10:17.085: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:10:17.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-r57xw" for this suite.
Mar  1 09:10:39.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:10:39.650: INFO: namespace: e2e-tests-container-lifecycle-hook-r57xw, resource: bindings, ignored listing per whitelist
Mar  1 09:10:40.616: INFO: namespace e2e-tests-container-lifecycle-hook-r57xw deletion completed in 23.496121507s

• [SLOW TEST:41.591 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:10:40.616: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sjtrf
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  1 09:10:42.124: INFO: Waiting up to 5m0s for pod "pod-e37e916e-3c01-11e9-9193-2e670c8e304c" in namespace "e2e-tests-emptydir-sjtrf" to be "success or failure"
Mar  1 09:10:42.159: INFO: Pod "pod-e37e916e-3c01-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.635833ms
Mar  1 09:10:44.194: INFO: Pod "pod-e37e916e-3c01-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070132254s
Mar  1 09:10:46.230: INFO: Pod "pod-e37e916e-3c01-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106325712s
STEP: Saw pod success
Mar  1 09:10:46.230: INFO: Pod "pod-e37e916e-3c01-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:10:46.265: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-e37e916e-3c01-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 09:10:46.357: INFO: Waiting for pod pod-e37e916e-3c01-11e9-9193-2e670c8e304c to disappear
Mar  1 09:10:46.392: INFO: Pod pod-e37e916e-3c01-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:10:46.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sjtrf" for this suite.
Mar  1 09:10:52.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:10:53.831: INFO: namespace: e2e-tests-emptydir-sjtrf, resource: bindings, ignored listing per whitelist
Mar  1 09:10:53.901: INFO: namespace e2e-tests-emptydir-sjtrf deletion completed in 7.473384043s

• [SLOW TEST:13.284 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:10:53.901: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-qxc8j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:10:55.354: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:10:59.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qxc8j" for this suite.
Mar  1 09:11:48.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:11:49.216: INFO: namespace: e2e-tests-pods-qxc8j, resource: bindings, ignored listing per whitelist
Mar  1 09:11:49.495: INFO: namespace e2e-tests-pods-qxc8j deletion completed in 49.534565312s

• [SLOW TEST:55.594 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:11:49.495: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-6ljf7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-6ljf7
Mar  1 09:11:55.066: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-6ljf7
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 09:11:55.102: INFO: Initial restart count of pod liveness-exec is 0
Mar  1 09:12:44.023: INFO: Restart count of pod e2e-tests-container-probe-6ljf7/liveness-exec is now 1 (48.920589955s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:12:44.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6ljf7" for this suite.
Mar  1 09:12:50.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:12:50.708: INFO: namespace: e2e-tests-container-probe-6ljf7, resource: bindings, ignored listing per whitelist
Mar  1 09:12:51.597: INFO: namespace e2e-tests-container-probe-6ljf7 deletion completed in 7.483312299s

• [SLOW TEST:62.102 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:12:51.597: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zs2j8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-318f9b10-3c02-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 09:12:53.134: INFO: Waiting up to 5m0s for pod "pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-zs2j8" to be "success or failure"
Mar  1 09:12:53.168: INFO: Pod "pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.448887ms
Mar  1 09:12:55.203: INFO: Pod "pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069716857s
Mar  1 09:12:57.239: INFO: Pod "pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105653131s
STEP: Saw pod success
Mar  1 09:12:57.239: INFO: Pod "pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:12:57.274: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:12:57.374: INFO: Waiting for pod pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c to disappear
Mar  1 09:12:57.409: INFO: Pod pod-configmaps-3194ff6e-3c02-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:12:57.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zs2j8" for this suite.
Mar  1 09:13:05.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:13:05.793: INFO: namespace: e2e-tests-configmap-zs2j8, resource: bindings, ignored listing per whitelist
Mar  1 09:13:06.968: INFO: namespace e2e-tests-configmap-zs2j8 deletion completed in 9.522890017s

• [SLOW TEST:15.371 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:13:06.968: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fzf4g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  1 09:13:08.465: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:10.828: INFO: stderr: ""
Mar  1 09:13:10.828: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 09:13:10.828: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:11.062: INFO: stderr: ""
Mar  1 09:13:11.062: INFO: stdout: "update-demo-nautilus-l68n2 update-demo-nautilus-x8r4s "
Mar  1 09:13:11.062: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-l68n2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:11.290: INFO: stderr: ""
Mar  1 09:13:11.290: INFO: stdout: ""
Mar  1 09:13:11.290: INFO: update-demo-nautilus-l68n2 is created but not running
Mar  1 09:13:16.291: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:16.510: INFO: stderr: ""
Mar  1 09:13:16.510: INFO: stdout: "update-demo-nautilus-l68n2 update-demo-nautilus-x8r4s "
Mar  1 09:13:16.510: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-l68n2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:16.760: INFO: stderr: ""
Mar  1 09:13:16.760: INFO: stdout: "true"
Mar  1 09:13:16.760: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-l68n2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:16.982: INFO: stderr: ""
Mar  1 09:13:16.982: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 09:13:16.982: INFO: validating pod update-demo-nautilus-l68n2
Mar  1 09:13:17.113: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 09:13:17.113: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 09:13:17.113: INFO: update-demo-nautilus-l68n2 is verified up and running
Mar  1 09:13:17.113: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-x8r4s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:17.324: INFO: stderr: ""
Mar  1 09:13:17.324: INFO: stdout: "true"
Mar  1 09:13:17.324: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-x8r4s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:17.540: INFO: stderr: ""
Mar  1 09:13:17.540: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 09:13:17.540: INFO: validating pod update-demo-nautilus-x8r4s
Mar  1 09:13:17.660: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 09:13:17.660: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 09:13:17.660: INFO: update-demo-nautilus-x8r4s is verified up and running
STEP: using delete to clean up resources
Mar  1 09:13:17.660: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:17.908: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:13:17.908: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 09:13:17.908: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-fzf4g'
Mar  1 09:13:18.175: INFO: stderr: "No resources found.\n"
Mar  1 09:13:18.175: INFO: stdout: ""
Mar  1 09:13:18.175: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-fzf4g -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 09:13:18.395: INFO: stderr: ""
Mar  1 09:13:18.395: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:13:18.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fzf4g" for this suite.
Mar  1 09:13:24.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:13:25.600: INFO: namespace: e2e-tests-kubectl-fzf4g, resource: bindings, ignored listing per whitelist
Mar  1 09:13:25.957: INFO: namespace e2e-tests-kubectl-fzf4g deletion completed in 7.526241981s

• [SLOW TEST:18.989 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:13:25.957: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-kh7qk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:13:27.542: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  1 09:13:27.627: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 09:13:31.703: INFO: Creating deployment "test-rolling-update-deployment"
Mar  1 09:13:31.738: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  1 09:13:31.817: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  1 09:13:31.852: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:13:33.887: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028411, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:13:35.887: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 09:13:35.993: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-kh7qk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kh7qk/deployments/test-rolling-update-deployment,UID:489a69a2-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:19740,Generation:1,CreationTimestamp:2019-03-01 09:13:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 09:13:31 +0000 UTC 2019-03-01 09:13:31 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 09:13:34 +0000 UTC 2019-03-01 09:13:31 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 09:13:36.029: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-kh7qk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kh7qk/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:489d9d70-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:19733,Generation:1,CreationTimestamp:2019-03-01 09:13:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 489a69a2-3c02-11e9-a289-2aff89a14c6e 0xc0023deb57 0xc0023deb58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 09:13:36.029: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  1 09:13:36.029: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-kh7qk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kh7qk/replicasets/test-rolling-update-controller,UID:461f921e-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:19739,Generation:2,CreationTimestamp:2019-03-01 09:13:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 489a69a2-3c02-11e9-a289-2aff89a14c6e 0xc0023dea97 0xc0023dea98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 09:13:36.065: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-fpmk8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-fpmk8,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-kh7qk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kh7qk/pods/test-rolling-update-deployment-68b55d7bc6-fpmk8,UID:489e661d-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:19732,Generation:0,CreationTimestamp:2019-03-01 09:13:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.198/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 489d9d70-3c02-11e9-a289-2aff89a14c6e 0xc0023df537 0xc0023df538}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tn6tk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn6tk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tn6tk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023df5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023df5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:13:31 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:13:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:13:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:13:31 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.198,StartTime:2019-03-01 09:13:31 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 09:13:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a5f7aef7ae38e24e272e6ed7c141e3949e74b0a992177958ad5f2268a716e9c2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:13:36.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-kh7qk" for this suite.
Mar  1 09:13:42.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:13:43.541: INFO: namespace: e2e-tests-deployment-kh7qk, resource: bindings, ignored listing per whitelist
Mar  1 09:13:43.541: INFO: namespace e2e-tests-deployment-kh7qk deletion completed in 7.441057475s

• [SLOW TEST:17.584 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:13:43.541: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dzvjq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-508c5552-3c02-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 09:13:45.121: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-dzvjq" to be "success or failure"
Mar  1 09:13:45.164: INFO: Pod "pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 42.7017ms
Mar  1 09:13:47.199: INFO: Pod "pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078172786s
Mar  1 09:13:49.235: INFO: Pod "pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114002451s
STEP: Saw pod success
Mar  1 09:13:49.235: INFO: Pod "pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:13:49.270: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:13:49.380: INFO: Waiting for pod pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c to disappear
Mar  1 09:13:49.481: INFO: Pod pod-projected-configmaps-5091aa24-3c02-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:13:49.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dzvjq" for this suite.
Mar  1 09:13:55.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:13:55.980: INFO: namespace: e2e-tests-projected-dzvjq, resource: bindings, ignored listing per whitelist
Mar  1 09:13:56.974: INFO: namespace e2e-tests-projected-dzvjq deletion completed in 7.458336745s

• [SLOW TEST:13.433 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:13:56.975: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nmp7m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar  1 09:13:58.471: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml proxy --unix-socket=/tmp/kubectl-proxy-unix646340988/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:13:58.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nmp7m" for this suite.
Mar  1 09:14:04.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:14:05.704: INFO: namespace: e2e-tests-kubectl-nmp7m, resource: bindings, ignored listing per whitelist
Mar  1 09:14:06.053: INFO: namespace e2e-tests-kubectl-nmp7m deletion completed in 7.44921244s

• [SLOW TEST:9.078 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:14:06.053: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fzt2k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:14:07.502: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-fzt2k" to be "success or failure"
Mar  1 09:14:07.536: INFO: Pod "downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.680322ms
Mar  1 09:14:09.574: INFO: Pod "downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07174131s
Mar  1 09:14:11.612: INFO: Pod "downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109719878s
STEP: Saw pod success
Mar  1 09:14:11.612: INFO: Pod "downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:14:11.647: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:14:11.735: INFO: Waiting for pod downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c to disappear
Mar  1 09:14:11.770: INFO: Pod downwardapi-volume-5de89f4e-3c02-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:14:11.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fzt2k" for this suite.
Mar  1 09:14:17.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:14:18.801: INFO: namespace: e2e-tests-downward-api-fzt2k, resource: bindings, ignored listing per whitelist
Mar  1 09:14:19.357: INFO: namespace e2e-tests-downward-api-fzt2k deletion completed in 7.551996802s

• [SLOW TEST:13.304 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:14:19.357: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9z59x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:14:20.886: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-9z59x" to be "success or failure"
Mar  1 09:14:20.921: INFO: Pod "downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.547087ms
Mar  1 09:14:22.957: INFO: Pod "downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070058896s
Mar  1 09:14:24.991: INFO: Pod "downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.104918476s
STEP: Saw pod success
Mar  1 09:14:24.991: INFO: Pod "downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:14:25.039: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:14:25.147: INFO: Waiting for pod downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c to disappear
Mar  1 09:14:25.183: INFO: Pod downwardapi-volume-65e2f909-3c02-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:14:25.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9z59x" for this suite.
Mar  1 09:14:31.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:14:32.413: INFO: namespace: e2e-tests-projected-9z59x, resource: bindings, ignored listing per whitelist
Mar  1 09:14:32.693: INFO: namespace e2e-tests-projected-9z59x deletion completed in 7.475196173s

• [SLOW TEST:13.336 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:14:32.693: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-c8xns
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:14:34.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-c8xns" to be "success or failure"
Mar  1 09:14:34.385: INFO: Pod "downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 47.593629ms
Mar  1 09:14:36.421: INFO: Pod "downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083373108s
Mar  1 09:14:38.457: INFO: Pod "downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.119359824s
STEP: Saw pod success
Mar  1 09:14:38.457: INFO: Pod "downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:14:38.492: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:14:38.573: INFO: Waiting for pod downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c to disappear
Mar  1 09:14:38.607: INFO: Pod downwardapi-volume-6de76d35-3c02-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:14:38.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c8xns" for this suite.
Mar  1 09:14:44.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:14:44.896: INFO: namespace: e2e-tests-downward-api-c8xns, resource: bindings, ignored listing per whitelist
Mar  1 09:14:46.133: INFO: namespace e2e-tests-downward-api-c8xns deletion completed in 7.488543406s

• [SLOW TEST:13.440 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:14:46.134: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-8pd5r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar  1 09:14:47.625: INFO: Waiting up to 5m0s for pod "client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c" in namespace "e2e-tests-containers-8pd5r" to be "success or failure"
Mar  1 09:14:47.668: INFO: Pod "client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 42.547083ms
Mar  1 09:14:49.704: INFO: Pod "client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078912918s
Mar  1 09:14:51.740: INFO: Pod "client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114521269s
STEP: Saw pod success
Mar  1 09:14:51.740: INFO: Pod "client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:14:51.775: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 09:14:51.873: INFO: Waiting for pod client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c to disappear
Mar  1 09:14:51.908: INFO: Pod client-containers-75d318a3-3c02-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:14:51.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8pd5r" for this suite.
Mar  1 09:14:58.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:14:58.195: INFO: namespace: e2e-tests-containers-8pd5r, resource: bindings, ignored listing per whitelist
Mar  1 09:14:59.494: INFO: namespace e2e-tests-containers-8pd5r deletion completed in 7.550257945s

• [SLOW TEST:13.360 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:14:59.494: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-rsc65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:15:01.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rsc65" for this suite.
Mar  1 09:15:07.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:15:08.472: INFO: namespace: e2e-tests-services-rsc65, resource: bindings, ignored listing per whitelist
Mar  1 09:15:08.578: INFO: namespace e2e-tests-services-rsc65 deletion completed in 7.49196988s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:9.084 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:15:08.579: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-crz7h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar  1 09:15:10.102: INFO: Waiting up to 5m0s for pod "var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c" in namespace "e2e-tests-var-expansion-crz7h" to be "success or failure"
Mar  1 09:15:10.136: INFO: Pod "var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 33.985695ms
Mar  1 09:15:12.173: INFO: Pod "var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070365264s
Mar  1 09:15:14.209: INFO: Pod "var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106819443s
STEP: Saw pod success
Mar  1 09:15:14.209: INFO: Pod "var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:15:14.245: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 09:15:14.331: INFO: Waiting for pod var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c to disappear
Mar  1 09:15:14.367: INFO: Pod var-expansion-8338d9f1-3c02-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:15:14.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-crz7h" for this suite.
Mar  1 09:15:20.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:15:21.575: INFO: namespace: e2e-tests-var-expansion-crz7h, resource: bindings, ignored listing per whitelist
Mar  1 09:15:21.896: INFO: namespace e2e-tests-var-expansion-crz7h deletion completed in 7.489897776s

• [SLOW TEST:13.318 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:15:21.897: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-2z7p5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-2z7p5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 09:15:23.456: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 09:15:48.080: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.206:8080/dial?request=hostName&protocol=http&host=100.96.1.205&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-2z7p5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:15:48.080: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:15:48.644: INFO: Waiting for endpoints: map[]
Mar  1 09:15:48.680: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.206:8080/dial?request=hostName&protocol=http&host=100.96.0.47&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-2z7p5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:15:48.680: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:15:49.196: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:15:49.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-2z7p5" for this suite.
Mar  1 09:16:13.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:16:14.727: INFO: namespace: e2e-tests-pod-network-test-2z7p5, resource: bindings, ignored listing per whitelist
Mar  1 09:16:14.831: INFO: namespace e2e-tests-pod-network-test-2z7p5 deletion completed in 25.598816861s

• [SLOW TEST:52.934 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:16:14.831: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-gmlqz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-v7v6v
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Mar  1 09:16:28.298: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-4rwr2
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:16:45.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-gmlqz" for this suite.
Mar  1 09:16:51.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:16:52.786: INFO: namespace: e2e-tests-namespaces-gmlqz, resource: bindings, ignored listing per whitelist
Mar  1 09:16:52.856: INFO: namespace e2e-tests-namespaces-gmlqz deletion completed in 7.427130171s
STEP: Destroying namespace "e2e-tests-nsdeletetest-v7v6v" for this suite.
Mar  1 09:16:52.890: INFO: Namespace e2e-tests-nsdeletetest-v7v6v was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-4rwr2" for this suite.
Mar  1 09:17:01.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:17:01.254: INFO: namespace: e2e-tests-nsdeletetest-4rwr2, resource: bindings, ignored listing per whitelist
Mar  1 09:17:02.370: INFO: namespace e2e-tests-nsdeletetest-4rwr2 deletion completed in 9.479412444s

• [SLOW TEST:47.539 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:17:02.370: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-b85bv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  1 09:17:03.975: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b85bv,SelfLink:/api/v1/namespaces/e2e-tests-watch-b85bv/configmaps/e2e-watch-test-label-changed,UID:c7050b93-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20393,Generation:0,CreationTimestamp:2019-03-01 09:17:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 09:17:03.975: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b85bv,SelfLink:/api/v1/namespaces/e2e-tests-watch-b85bv/configmaps/e2e-watch-test-label-changed,UID:c7050b93-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20394,Generation:0,CreationTimestamp:2019-03-01 09:17:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 09:17:03.975: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b85bv,SelfLink:/api/v1/namespaces/e2e-tests-watch-b85bv/configmaps/e2e-watch-test-label-changed,UID:c7050b93-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20395,Generation:0,CreationTimestamp:2019-03-01 09:17:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  1 09:17:14.235: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b85bv,SelfLink:/api/v1/namespaces/e2e-tests-watch-b85bv/configmaps/e2e-watch-test-label-changed,UID:c7050b93-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20417,Generation:0,CreationTimestamp:2019-03-01 09:17:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 09:17:14.235: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b85bv,SelfLink:/api/v1/namespaces/e2e-tests-watch-b85bv/configmaps/e2e-watch-test-label-changed,UID:c7050b93-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20418,Generation:0,CreationTimestamp:2019-03-01 09:17:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  1 09:17:14.235: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-b85bv,SelfLink:/api/v1/namespaces/e2e-tests-watch-b85bv/configmaps/e2e-watch-test-label-changed,UID:c7050b93-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20419,Generation:0,CreationTimestamp:2019-03-01 09:17:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:17:14.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-b85bv" for this suite.
Mar  1 09:17:20.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:17:20.853: INFO: namespace: e2e-tests-watch-b85bv, resource: bindings, ignored listing per whitelist
Mar  1 09:17:21.765: INFO: namespace e2e-tests-watch-b85bv deletion completed in 7.489424728s

• [SLOW TEST:19.395 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:17:21.765: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-f7nfc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:17:23.271: INFO: Creating deployment "nginx-deployment"
Mar  1 09:17:23.310: INFO: Waiting for observed generation 1
Mar  1 09:17:23.349: INFO: Waiting for all required pods to come up
Mar  1 09:17:23.434: INFO: Pod name nginx: Found 9 pods out of 10
Mar  1 09:17:28.471: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  1 09:17:32.542: INFO: Waiting for deployment "nginx-deployment" to complete
Mar  1 09:17:32.612: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar  1 09:17:32.683: INFO: Updating deployment nginx-deployment
Mar  1 09:17:32.683: INFO: Waiting for observed generation 2
Mar  1 09:17:34.789: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  1 09:17:34.824: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  1 09:17:34.859: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 09:17:34.969: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  1 09:17:34.969: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  1 09:17:35.006: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 09:17:35.076: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar  1 09:17:35.076: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar  1 09:17:35.147: INFO: Updating deployment nginx-deployment
Mar  1 09:17:35.147: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar  1 09:17:35.274: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  1 09:17:37.357: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 09:17:37.430: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f7nfc/deployments/nginx-deployment,UID:d2a0ec27-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20638,Generation:3,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-03-01 09:17:35 +0000 UTC 2019-03-01 09:17:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-01 09:17:35 +0000 UTC 2019-03-01 09:17:23 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar  1 09:17:37.467: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f7nfc/replicasets/nginx-deployment-65bbdb5f8,UID:d8384018-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20637,Generation:3,CreationTimestamp:2019-03-01 09:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment d2a0ec27-3c02-11e9-a289-2aff89a14c6e 0xc000cb08c7 0xc000cb08c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 09:17:37.467: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar  1 09:17:37.467: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f7nfc/replicasets/nginx-deployment-555b55d965,UID:d2a2b67a-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20632,Generation:3,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment d2a0ec27-3c02-11e9-a289-2aff89a14c6e 0xc000cb0797 0xc000cb0798}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar  1 09:17:37.506: INFO: Pod "nginx-deployment-555b55d965-4clrl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4clrl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-4clrl,UID:d2aa23ad-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20523,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.209/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197efb7 0xc00197efb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.209,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:28 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://37357faff1f12c8c948f433002d036b3053b566db94efaed662ef16335428ce6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.506: INFO: Pod "nginx-deployment-555b55d965-76xfh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-76xfh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-76xfh,UID:d2a7f1bc-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20528,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.210/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197f1a0 0xc00197f1a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.210,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:28 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://76536ce40a8fdbcb218f2814c0ad3216baa668591e80128fd215c8f996e30e71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.506: INFO: Pod "nginx-deployment-555b55d965-8mhc6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8mhc6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-8mhc6,UID:d9b6b781-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20631,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197f2e0 0xc00197f2e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.507: INFO: Pod "nginx-deployment-555b55d965-8nnwt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8nnwt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-8nnwt,UID:d9b6cf98-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20633,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197f470 0xc00197f471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.507: INFO: Pod "nginx-deployment-555b55d965-bb247" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bb247,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-bb247,UID:d9b6c6d9-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20640,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197f660 0xc00197f661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.507: INFO: Pod "nginx-deployment-555b55d965-c4jwx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c4jwx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-c4jwx,UID:d2a6d02e-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20518,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.208/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197f960 0xc00197f961}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197f9c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197f9e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.208,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:27 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1d1176d4f395bba3886cdf595ca870f4f01392de6a6602ea55f30a971fa96d71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.507: INFO: Pod "nginx-deployment-555b55d965-cgz9l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cgz9l,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-cgz9l,UID:d9b51ee6-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20608,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197fae0 0xc00197fae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197fb40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197fb60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.508: INFO: Pod "nginx-deployment-555b55d965-k8wcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k8wcw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-k8wcw,UID:d9c3c073-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20648,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197fc10 0xc00197fc11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197fc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197fc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.508: INFO: Pod "nginx-deployment-555b55d965-kgq58" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kgq58,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-kgq58,UID:d2abdeb8-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20531,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.213/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc00197fe60 0xc00197fe61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00197fee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00197fff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.213,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:29 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://45acfb81f7c58f471fd0778bb2b15c410e90c8457c0915b90e704dbc261a4b0e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.508: INFO: Pod "nginx-deployment-555b55d965-ljl4c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ljl4c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-ljl4c,UID:d9b5263a-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20628,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001136130 0xc001136131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011361d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001136220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.508: INFO: Pod "nginx-deployment-555b55d965-lmq9g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lmq9g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-lmq9g,UID:d9c3b775-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20646,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001136310 0xc001136311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001136410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001136430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.509: INFO: Pod "nginx-deployment-555b55d965-m25zp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-m25zp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-m25zp,UID:d9b46596-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20610,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001136580 0xc001136581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011365e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001136610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.509: INFO: Pod "nginx-deployment-555b55d965-m878d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-m878d,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-m878d,UID:d2aa2164-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20510,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.51/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc0011366d0 0xc0011366d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001136730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001136750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.51,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://dee758238e6ff3acc6bc4277ca0fb6e2c589a60453fdf9d6b150250fa08de90b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.509: INFO: Pod "nginx-deployment-555b55d965-mk65s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mk65s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-mk65s,UID:d2aa2887-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20499,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.50/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001136820 0xc001136821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001136880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011368a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.50,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://14208ac085c21450c0eb4b4501e47c90b332a09b847acfa4104f155e30b0efee}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.509: INFO: Pod "nginx-deployment-555b55d965-msckr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-msckr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-msckr,UID:d9c3c20c-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20647,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001136980 0xc001136981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001136ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001136ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.509: INFO: Pod "nginx-deployment-555b55d965-n8jwc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n8jwc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-n8jwc,UID:d9c3baf3-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20645,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001136d90 0xc001136d91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001136e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001136e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.509: INFO: Pod "nginx-deployment-555b55d965-srl74" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-srl74,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-srl74,UID:d2a7e80d-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20502,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.48/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001136f90 0xc001136f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011370b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011370d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.48,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://bea120d452db4aabdf88ba46449ec64bc9a493d7f45ec8b6f0d2450e78a46211}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.510: INFO: Pod "nginx-deployment-555b55d965-tmxdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tmxdj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-tmxdj,UID:d9c3c104-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20651,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001137220 0xc001137221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001137360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001137390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.510: INFO: Pod "nginx-deployment-555b55d965-xshrn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xshrn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-xshrn,UID:d9bdbefd-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20639,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc0011374c0 0xc0011374c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001137520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001137540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.510: INFO: Pod "nginx-deployment-555b55d965-zqk9c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zqk9c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-555b55d965-zqk9c,UID:d2abd9ea-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20513,Generation:0,CreationTimestamp:2019-03-01 09:17:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.49/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 d2a2b67a-3c02-11e9-a289-2aff89a14c6e 0xc001137660 0xc001137661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001137770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001137800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.49,StartTime:2019-03-01 09:17:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:17:26 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://e9041949706b723257d75e73844f290aaf29e56b8465ce1ac636e8f0a803eff3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.510: INFO: Pod "nginx-deployment-65bbdb5f8-6pcps" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6pcps,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-6pcps,UID:d83b1631-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20658,Generation:0,CreationTimestamp:2019-03-01 09:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.216/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc001137900 0xc001137901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001137970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001137990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.510: INFO: Pod "nginx-deployment-65bbdb5f8-9zg2r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9zg2r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-9zg2r,UID:d83b091c-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20659,Generation:0,CreationTimestamp:2019-03-01 09:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.52/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc001137bd0 0xc001137bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001137c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001137c60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.52,StartTime:2019-03-01 09:17:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.511: INFO: Pod "nginx-deployment-65bbdb5f8-cvxck" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cvxck,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-cvxck,UID:d9bdcd5c-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20644,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc001137e90 0xc001137e91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001137f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001137f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.511: INFO: Pod "nginx-deployment-65bbdb5f8-df44f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-df44f,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-df44f,UID:d9cd2da5-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20653,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145c200 0xc00145c201}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00145c280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00145c2a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.511: INFO: Pod "nginx-deployment-65bbdb5f8-fww89" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fww89,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-fww89,UID:d9c3c136-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20649,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145c540 0xc00145c541}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00145c740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00145c760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.511: INFO: Pod "nginx-deployment-65bbdb5f8-jnrtd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jnrtd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-jnrtd,UID:d9b680f3-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20627,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145c930 0xc00145c931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00145d0c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00145d0e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.511: INFO: Pod "nginx-deployment-65bbdb5f8-m29cb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-m29cb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-m29cb,UID:d845bab3-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20580,Generation:0,CreationTimestamp:2019-03-01 09:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.214/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145d220 0xc00145d221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00145d430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00145d450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.512: INFO: Pod "nginx-deployment-65bbdb5f8-m7k5h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-m7k5h,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-m7k5h,UID:d9c3d432-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20652,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145d510 0xc00145d511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00145d6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00145d6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.512: INFO: Pod "nginx-deployment-65bbdb5f8-qtnqm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qtnqm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-qtnqm,UID:d9bdc919-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20643,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145d8a0 0xc00145d8a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00145daa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00145dac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.512: INFO: Pod "nginx-deployment-65bbdb5f8-z4hgc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z4hgc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-z4hgc,UID:d838bc9b-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20656,Generation:0,CreationTimestamp:2019-03-01 09:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.215/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145dd80 0xc00145dd81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00145ddf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00145de10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.512: INFO: Pod "nginx-deployment-65bbdb5f8-z5lfp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z5lfp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-z5lfp,UID:d9c3cfeb-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20655,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc00145df50 0xc00145df51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012641c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012641e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.512: INFO: Pod "nginx-deployment-65bbdb5f8-zjthd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zjthd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-zjthd,UID:d843f0e8-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20579,Generation:0,CreationTimestamp:2019-03-01 09:17:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.53/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc001264460 0xc001264461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001264510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001264530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:17:32 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:17:37.512: INFO: Pod "nginx-deployment-65bbdb5f8-znxqm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-znxqm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-f7nfc,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f7nfc/pods/nginx-deployment-65bbdb5f8-znxqm,UID:d9c3cca9-3c02-11e9-a289-2aff89a14c6e,ResourceVersion:20650,Generation:0,CreationTimestamp:2019-03-01 09:17:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 d8384018-3c02-11e9-a289-2aff89a14c6e 0xc0012646b0 0xc0012646b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wrxzx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wrxzx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wrxzx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001264760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001264780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:17:35 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:17:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:17:37.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-f7nfc" for this suite.
Mar  1 09:17:45.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:17:46.694: INFO: namespace: e2e-tests-deployment-f7nfc, resource: bindings, ignored listing per whitelist
Mar  1 09:17:47.009: INFO: namespace e2e-tests-deployment-f7nfc deletion completed in 9.461111212s

• [SLOW TEST:25.244 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:17:47.010: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6kf2q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar  1 09:17:48.548: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:49.281: INFO: stderr: ""
Mar  1 09:17:49.281: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 09:17:49.281: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:49.608: INFO: stderr: ""
Mar  1 09:17:49.608: INFO: stdout: "update-demo-nautilus-blkbl update-demo-nautilus-z7rwt "
Mar  1 09:17:49.608: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-blkbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:49.871: INFO: stderr: ""
Mar  1 09:17:49.871: INFO: stdout: ""
Mar  1 09:17:49.871: INFO: update-demo-nautilus-blkbl is created but not running
Mar  1 09:17:54.871: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:55.174: INFO: stderr: ""
Mar  1 09:17:55.174: INFO: stdout: "update-demo-nautilus-blkbl update-demo-nautilus-z7rwt "
Mar  1 09:17:55.174: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-blkbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:55.404: INFO: stderr: ""
Mar  1 09:17:55.404: INFO: stdout: "true"
Mar  1 09:17:55.404: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-blkbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:55.626: INFO: stderr: ""
Mar  1 09:17:55.626: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 09:17:55.626: INFO: validating pod update-demo-nautilus-blkbl
Mar  1 09:17:55.746: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 09:17:55.746: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 09:17:55.746: INFO: update-demo-nautilus-blkbl is verified up and running
Mar  1 09:17:55.746: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-z7rwt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:55.998: INFO: stderr: ""
Mar  1 09:17:55.998: INFO: stdout: "true"
Mar  1 09:17:55.998: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-z7rwt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:17:56.256: INFO: stderr: ""
Mar  1 09:17:56.256: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 09:17:56.256: INFO: validating pod update-demo-nautilus-z7rwt
Mar  1 09:17:56.377: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 09:17:56.377: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 09:17:56.377: INFO: update-demo-nautilus-z7rwt is verified up and running
STEP: rolling-update to new replication controller
Mar  1 09:17:56.382: INFO: scanned /root for discovery docs: <nil>
Mar  1 09:17:56.382: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:18:17.758: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 09:18:17.758: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 09:18:17.758: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:18:18.050: INFO: stderr: ""
Mar  1 09:18:18.050: INFO: stdout: "update-demo-kitten-6bm9v update-demo-kitten-lbd5x "
Mar  1 09:18:18.050: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-6bm9v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:18:18.267: INFO: stderr: ""
Mar  1 09:18:18.267: INFO: stdout: "true"
Mar  1 09:18:18.267: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-6bm9v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:18:18.500: INFO: stderr: ""
Mar  1 09:18:18.500: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 09:18:18.500: INFO: validating pod update-demo-kitten-6bm9v
Mar  1 09:18:18.619: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 09:18:18.619: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 09:18:18.619: INFO: update-demo-kitten-6bm9v is verified up and running
Mar  1 09:18:18.619: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-lbd5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:18:18.839: INFO: stderr: ""
Mar  1 09:18:18.839: INFO: stdout: "true"
Mar  1 09:18:18.839: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-lbd5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6kf2q'
Mar  1 09:18:19.064: INFO: stderr: ""
Mar  1 09:18:19.064: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 09:18:19.064: INFO: validating pod update-demo-kitten-lbd5x
Mar  1 09:18:19.184: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 09:18:19.184: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 09:18:19.184: INFO: update-demo-kitten-lbd5x is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:18:19.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6kf2q" for this suite.
Mar  1 09:18:43.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:18:43.731: INFO: namespace: e2e-tests-kubectl-6kf2q, resource: bindings, ignored listing per whitelist
Mar  1 09:18:44.749: INFO: namespace e2e-tests-kubectl-6kf2q deletion completed in 25.528895945s

• [SLOW TEST:57.739 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:18:44.749: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9xwtr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0412ec49-3c03-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 09:18:46.316: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-9xwtr" to be "success or failure"
Mar  1 09:18:46.351: INFO: Pod "pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.515316ms
Mar  1 09:18:48.387: INFO: Pod "pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070660412s
Mar  1 09:18:50.423: INFO: Pod "pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106685889s
STEP: Saw pod success
Mar  1 09:18:50.423: INFO: Pod "pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:18:50.459: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:18:50.549: INFO: Waiting for pod pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c to disappear
Mar  1 09:18:50.583: INFO: Pod pod-projected-configmaps-041868bf-3c03-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:18:50.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9xwtr" for this suite.
Mar  1 09:18:56.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:18:57.578: INFO: namespace: e2e-tests-projected-9xwtr, resource: bindings, ignored listing per whitelist
Mar  1 09:18:58.086: INFO: namespace e2e-tests-projected-9xwtr deletion completed in 7.464924949s

• [SLOW TEST:13.337 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:18:58.086: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ztfpd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0c03f9fe-3c03-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 09:18:59.649: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-ztfpd" to be "success or failure"
Mar  1 09:18:59.690: INFO: Pod "pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.477861ms
Mar  1 09:19:01.726: INFO: Pod "pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077349983s
Mar  1 09:19:03.763: INFO: Pod "pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114390935s
STEP: Saw pod success
Mar  1 09:19:03.763: INFO: Pod "pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:19:03.798: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:19:03.880: INFO: Waiting for pod pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c to disappear
Mar  1 09:19:03.921: INFO: Pod pod-configmaps-0c0959e7-3c03-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:19:03.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ztfpd" for this suite.
Mar  1 09:19:10.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:19:11.160: INFO: namespace: e2e-tests-configmap-ztfpd, resource: bindings, ignored listing per whitelist
Mar  1 09:19:11.453: INFO: namespace e2e-tests-configmap-ztfpd deletion completed in 7.496894337s

• [SLOW TEST:13.367 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:19:11.453: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6czqq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar  1 09:19:12.966: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml cluster-info'
Mar  1 09:19:13.404: INFO: stderr: ""
Mar  1 09:19:13.404: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:19:13.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6czqq" for this suite.
Mar  1 09:19:19.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:19:20.639: INFO: namespace: e2e-tests-kubectl-6czqq, resource: bindings, ignored listing per whitelist
Mar  1 09:19:20.931: INFO: namespace e2e-tests-kubectl-6czqq deletion completed in 7.489818498s

• [SLOW TEST:9.478 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:19:20.931: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rl6lr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:19:22.399: INFO: Waiting up to 5m0s for pod "downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-rl6lr" to be "success or failure"
Mar  1 09:19:22.434: INFO: Pod "downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.868028ms
Mar  1 09:19:24.469: INFO: Pod "downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069993059s
Mar  1 09:19:26.505: INFO: Pod "downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106084209s
STEP: Saw pod success
Mar  1 09:19:26.505: INFO: Pod "downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:19:26.540: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:19:26.625: INFO: Waiting for pod downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c to disappear
Mar  1 09:19:26.659: INFO: Pod downwardapi-volume-199a133a-3c03-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:19:26.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rl6lr" for this suite.
Mar  1 09:19:32.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:19:33.992: INFO: namespace: e2e-tests-projected-rl6lr, resource: bindings, ignored listing per whitelist
Mar  1 09:19:34.134: INFO: namespace e2e-tests-projected-rl6lr deletion completed in 7.439968951s

• [SLOW TEST:13.203 seconds]
[sig-storage] Projected downwardAPI
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:19:34.134: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-jqh7d
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-218cd05e-3c03-11e9-9193-2e670c8e304c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-218cd05e-3c03-11e9-9193-2e670c8e304c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:21:03.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jqh7d" for this suite.
Mar  1 09:21:28.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:21:28.132: INFO: namespace: e2e-tests-configmap-jqh7d, resource: bindings, ignored listing per whitelist
Mar  1 09:21:29.420: INFO: namespace e2e-tests-configmap-jqh7d deletion completed in 25.501101184s

• [SLOW TEST:115.286 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:21:29.420: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-v2w6x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:21:31.021: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 09:21:35.094: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  1 09:21:37.132: INFO: Creating deployment "test-rollover-deployment"
Mar  1 09:21:37.208: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  1 09:21:39.278: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  1 09:21:39.348: INFO: Ensure that both replica sets have 1 created replica
Mar  1 09:21:39.420: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  1 09:21:39.491: INFO: Updating deployment test-rollover-deployment
Mar  1 09:21:39.491: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  1 09:21:41.578: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  1 09:21:41.648: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  1 09:21:41.722: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 09:21:41.722: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028899, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:21:43.794: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 09:21:43.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028903, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:21:45.794: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 09:21:45.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028903, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:21:47.794: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 09:21:47.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028903, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:21:49.794: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 09:21:49.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028903, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:21:51.794: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 09:21:51.794: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028903, loc:(*time.Location)(0x791ea40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028897, loc:(*time.Location)(0x791ea40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:21:53.793: INFO: 
Mar  1 09:21:53.793: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 09:21:53.936: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-v2w6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v2w6x/deployments/test-rollover-deployment,UID:69f114fc-3c03-11e9-a289-2aff89a14c6e,ResourceVersion:21526,Generation:2,CreationTimestamp:2019-03-01 09:21:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 09:21:37 +0000 UTC 2019-03-01 09:21:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 09:21:53 +0000 UTC 2019-03-01 09:21:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 09:21:53.975: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-v2w6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v2w6x/replicasets/test-rollover-deployment-6b7f9d6597,UID:6b5425bb-3c03-11e9-a289-2aff89a14c6e,ResourceVersion:21519,Generation:2,CreationTimestamp:2019-03-01 09:21:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 69f114fc-3c03-11e9-a289-2aff89a14c6e 0xc001137617 0xc001137618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 09:21:53.975: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  1 09:21:53.976: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-v2w6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v2w6x/replicasets/test-rollover-controller,UID:6640cabd-3c03-11e9-a289-2aff89a14c6e,ResourceVersion:21525,Generation:2,CreationTimestamp:2019-03-01 09:21:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 69f114fc-3c03-11e9-a289-2aff89a14c6e 0xc0011373a7 0xc0011373a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 09:21:53.976: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-v2w6x,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-v2w6x/replicasets/test-rollover-deployment-6586df867b,UID:69f60daf-3c03-11e9-a289-2aff89a14c6e,ResourceVersion:21483,Generation:2,CreationTimestamp:2019-03-01 09:21:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 69f114fc-3c03-11e9-a289-2aff89a14c6e 0xc0011374f7 0xc0011374f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 09:21:54.012: INFO: Pod "test-rollover-deployment-6b7f9d6597-6c6dz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-6c6dz,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-v2w6x,SelfLink:/api/v1/namespaces/e2e-tests-deployment-v2w6x/pods/test-rollover-deployment-6b7f9d6597-6c6dz,UID:6b5a557f-3c03-11e9-a289-2aff89a14c6e,ResourceVersion:21496,Generation:0,CreationTimestamp:2019-03-01 09:21:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.234/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 6b5425bb-3c03-11e9-a289-2aff89a14c6e 0xc001265d37 0xc001265d38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-z2pjh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z2pjh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-z2pjh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001265f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001265fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:21:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:21:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:21:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:21:39 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.234,StartTime:2019-03-01 09:21:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 09:21:42 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://0d4770d50ad2497c675f31215c0e5729c6cba93f4cfb151edd1b5c636e28dd82}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:21:54.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-v2w6x" for this suite.
Mar  1 09:22:00.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:22:00.884: INFO: namespace: e2e-tests-deployment-v2w6x, resource: bindings, ignored listing per whitelist
Mar  1 09:22:01.614: INFO: namespace e2e-tests-deployment-v2w6x deletion completed in 7.566609593s

• [SLOW TEST:32.194 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:22:01.614: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r525h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 09:22:03.283: INFO: Waiting up to 5m0s for pod "downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-r525h" to be "success or failure"
Mar  1 09:22:03.318: INFO: Pod "downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.77489ms
Mar  1 09:22:05.353: INFO: Pod "downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070187144s
Mar  1 09:22:07.389: INFO: Pod "downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106273447s
STEP: Saw pod success
Mar  1 09:22:07.389: INFO: Pod "downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:22:07.424: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 09:22:07.517: INFO: Waiting for pod downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c to disappear
Mar  1 09:22:07.557: INFO: Pod downward-api-797f10e6-3c03-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-node] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:22:07.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r525h" for this suite.
Mar  1 09:22:13.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:22:14.637: INFO: namespace: e2e-tests-downward-api-r525h, resource: bindings, ignored listing per whitelist
Mar  1 09:22:15.101: INFO: namespace e2e-tests-downward-api-r525h deletion completed in 7.507808699s

• [SLOW TEST:13.487 seconds]
[sig-node] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:22:15.101: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-kv8jh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar  1 09:22:16.691: INFO: Waiting up to 5m0s for pod "var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c" in namespace "e2e-tests-var-expansion-kv8jh" to be "success or failure"
Mar  1 09:22:16.730: INFO: Pod "var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 38.430064ms
Mar  1 09:22:18.765: INFO: Pod "var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073657072s
Mar  1 09:22:20.800: INFO: Pod "var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109078989s
STEP: Saw pod success
Mar  1 09:22:20.800: INFO: Pod "var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:22:20.839: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c container dapi-container: <nil>
STEP: delete the pod
Mar  1 09:22:20.922: INFO: Waiting for pod var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c to disappear
Mar  1 09:22:20.957: INFO: Pod var-expansion-817d1145-3c03-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:22:20.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kv8jh" for this suite.
Mar  1 09:22:27.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:22:27.287: INFO: namespace: e2e-tests-var-expansion-kv8jh, resource: bindings, ignored listing per whitelist
Mar  1 09:22:28.465: INFO: namespace e2e-tests-var-expansion-kv8jh deletion completed in 7.460510404s

• [SLOW TEST:13.364 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:22:28.465: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qld24
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 09:22:30.274: INFO: Number of nodes with available pods: 0
Mar  1 09:22:30.274: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:31.348: INFO: Number of nodes with available pods: 0
Mar  1 09:22:31.348: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:32.345: INFO: Number of nodes with available pods: 1
Mar  1 09:22:32.345: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j is running more than one daemon pod
Mar  1 09:22:33.346: INFO: Number of nodes with available pods: 2
Mar  1 09:22:33.346: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  1 09:22:33.524: INFO: Number of nodes with available pods: 1
Mar  1 09:22:33.524: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:34.597: INFO: Number of nodes with available pods: 1
Mar  1 09:22:34.597: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:35.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:35.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:36.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:36.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:37.597: INFO: Number of nodes with available pods: 1
Mar  1 09:22:37.597: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:38.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:38.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:39.594: INFO: Number of nodes with available pods: 1
Mar  1 09:22:39.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:40.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:40.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:41.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:41.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:42.599: INFO: Number of nodes with available pods: 1
Mar  1 09:22:42.599: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:43.602: INFO: Number of nodes with available pods: 1
Mar  1 09:22:43.602: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:44.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:44.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:45.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:45.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:46.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:46.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:47.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:47.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:48.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:48.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:49.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:49.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:50.599: INFO: Number of nodes with available pods: 1
Mar  1 09:22:50.599: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:51.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:51.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:52.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:52.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:53.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:53.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:54.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:54.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:55.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:55.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:56.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:56.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:57.596: INFO: Number of nodes with available pods: 1
Mar  1 09:22:57.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:58.597: INFO: Number of nodes with available pods: 1
Mar  1 09:22:58.597: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:22:59.595: INFO: Number of nodes with available pods: 1
Mar  1 09:22:59.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:00.595: INFO: Number of nodes with available pods: 1
Mar  1 09:23:00.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:01.595: INFO: Number of nodes with available pods: 1
Mar  1 09:23:01.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:02.597: INFO: Number of nodes with available pods: 1
Mar  1 09:23:02.597: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:03.595: INFO: Number of nodes with available pods: 1
Mar  1 09:23:03.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:04.594: INFO: Number of nodes with available pods: 1
Mar  1 09:23:04.594: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:05.595: INFO: Number of nodes with available pods: 1
Mar  1 09:23:05.595: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:06.596: INFO: Number of nodes with available pods: 1
Mar  1 09:23:06.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:07.597: INFO: Number of nodes with available pods: 1
Mar  1 09:23:07.597: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:08.595: INFO: Number of nodes with available pods: 1
Mar  1 09:23:08.596: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:23:09.597: INFO: Number of nodes with available pods: 2
Mar  1 09:23:09.597: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qld24, will wait for the garbage collector to delete the pods
Mar  1 09:23:09.757: INFO: Deleting DaemonSet.extensions daemon-set took: 37.246344ms
Mar  1 09:23:09.857: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.224795ms
Mar  1 09:23:46.692: INFO: Number of nodes with available pods: 0
Mar  1 09:23:46.692: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 09:23:46.727: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qld24/daemonsets","resourceVersion":"21838"},"items":null}

Mar  1 09:23:46.762: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qld24/pods","resourceVersion":"21838"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:23:46.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qld24" for this suite.
Mar  1 09:23:53.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:23:53.610: INFO: namespace: e2e-tests-daemonsets-qld24, resource: bindings, ignored listing per whitelist
Mar  1 09:23:54.370: INFO: namespace e2e-tests-daemonsets-qld24 deletion completed in 7.466881871s

• [SLOW TEST:85.905 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:23:54.371: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-8nrlt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0301 09:24:36.103551   31738 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 09:24:36.103: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:24:36.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8nrlt" for this suite.
Mar  1 09:24:44.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:24:44.994: INFO: namespace: e2e-tests-gc-8nrlt, resource: bindings, ignored listing per whitelist
Mar  1 09:24:45.621: INFO: namespace e2e-tests-gc-8nrlt deletion completed in 9.483113103s

• [SLOW TEST:51.251 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:24:45.622: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9r7dd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-db221c13-3c03-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 09:24:47.126: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-9r7dd" to be "success or failure"
Mar  1 09:24:47.166: INFO: Pod "pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 39.882355ms
Mar  1 09:24:49.202: INFO: Pod "pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075974016s
Mar  1 09:24:51.238: INFO: Pod "pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.11193977s
STEP: Saw pod success
Mar  1 09:24:51.238: INFO: Pod "pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:24:51.273: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:24:51.363: INFO: Waiting for pod pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c to disappear
Mar  1 09:24:51.398: INFO: Pod pod-projected-configmaps-db2788e9-3c03-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:24:51.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9r7dd" for this suite.
Mar  1 09:24:59.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:25:00.617: INFO: namespace: e2e-tests-projected-9r7dd, resource: bindings, ignored listing per whitelist
Mar  1 09:25:00.944: INFO: namespace e2e-tests-projected-9r7dd deletion completed in 9.506138016s

• [SLOW TEST:15.322 seconds]
[sig-storage] Projected configMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:25:00.945: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-5669j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-5669j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5669j to expose endpoints map[]
Mar  1 09:25:02.552: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5669j exposes endpoints map[] (34.650023ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5669j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5669j to expose endpoints map[pod1:[80]]
Mar  1 09:25:05.884: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5669j exposes endpoints map[pod1:[80]] (3.294251943s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5669j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5669j to expose endpoints map[pod1:[80] pod2:[80]]
Mar  1 09:25:08.245: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5669j exposes endpoints map[pod1:[80] pod2:[80]] (2.323436027s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5669j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5669j to expose endpoints map[pod2:[80]]
Mar  1 09:25:08.354: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5669j exposes endpoints map[pod2:[80]] (72.664425ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5669j
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5669j to expose endpoints map[]
Mar  1 09:25:08.427: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5669j exposes endpoints map[] (34.59696ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:25:08.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5669j" for this suite.
Mar  1 09:25:30.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:25:31.794: INFO: namespace: e2e-tests-services-5669j, resource: bindings, ignored listing per whitelist
Mar  1 09:25:32.049: INFO: namespace e2e-tests-services-5669j deletion completed in 23.531886064s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:31.104 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:25:32.049: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-662fp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Mar  1 09:25:33.459: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-662fp'
Mar  1 09:25:35.806: INFO: stderr: ""
Mar  1 09:25:35.806: INFO: stdout: "pod/pause created\n"
Mar  1 09:25:35.806: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  1 09:25:35.806: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-662fp" to be "running and ready"
Mar  1 09:25:35.843: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 37.575013ms
Mar  1 09:25:37.881: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07509221s
Mar  1 09:25:39.916: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.110070987s
Mar  1 09:25:39.916: INFO: Pod "pause" satisfied condition "running and ready"
Mar  1 09:25:39.916: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  1 09:25:39.916: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-662fp'
Mar  1 09:25:40.276: INFO: stderr: ""
Mar  1 09:25:40.276: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  1 09:25:40.276: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-662fp'
Mar  1 09:25:40.574: INFO: stderr: ""
Mar  1 09:25:40.574: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  1 09:25:40.574: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml label pods pause testing-label- --namespace=e2e-tests-kubectl-662fp'
Mar  1 09:25:40.941: INFO: stderr: ""
Mar  1 09:25:40.941: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  1 09:25:40.941: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-662fp'
Mar  1 09:25:41.243: INFO: stderr: ""
Mar  1 09:25:41.243: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          6s    \n"
[AfterEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Mar  1 09:25:41.243: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-662fp'
Mar  1 09:25:41.744: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:25:41.744: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  1 09:25:41.747: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-662fp'
Mar  1 09:25:42.095: INFO: stderr: "No resources found.\n"
Mar  1 09:25:42.095: INFO: stdout: ""
Mar  1 09:25:42.095: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=pause --namespace=e2e-tests-kubectl-662fp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 09:25:42.484: INFO: stderr: ""
Mar  1 09:25:42.484: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:25:42.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-662fp" for this suite.
Mar  1 09:25:48.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:25:48.768: INFO: namespace: e2e-tests-kubectl-662fp, resource: bindings, ignored listing per whitelist
Mar  1 09:25:49.981: INFO: namespace e2e-tests-kubectl-662fp deletion completed in 7.46154478s

• [SLOW TEST:17.932 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:25:49.981: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-52pfj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar  1 09:25:53.503: INFO: Pod name wrapped-volume-race-02a9a47f-3c04-11e9-9193-2e670c8e304c: Found 3 pods out of 5
Mar  1 09:25:58.543: INFO: Pod name wrapped-volume-race-02a9a47f-3c04-11e9-9193-2e670c8e304c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-02a9a47f-3c04-11e9-9193-2e670c8e304c in namespace e2e-tests-emptydir-wrapper-52pfj, will wait for the garbage collector to delete the pods
Mar  1 09:26:06.926: INFO: Deleting ReplicationController wrapped-volume-race-02a9a47f-3c04-11e9-9193-2e670c8e304c took: 38.675056ms
Mar  1 09:26:07.127: INFO: Terminating ReplicationController wrapped-volume-race-02a9a47f-3c04-11e9-9193-2e670c8e304c pods took: 200.230849ms
STEP: Creating RC which spawns configmap-volume pods
Mar  1 09:26:46.981: INFO: Pod name wrapped-volume-race-2286597e-3c04-11e9-9193-2e670c8e304c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2286597e-3c04-11e9-9193-2e670c8e304c in namespace e2e-tests-emptydir-wrapper-52pfj, will wait for the garbage collector to delete the pods
Mar  1 09:26:55.326: INFO: Deleting ReplicationController wrapped-volume-race-2286597e-3c04-11e9-9193-2e670c8e304c took: 38.151187ms
Mar  1 09:26:55.427: INFO: Terminating ReplicationController wrapped-volume-race-2286597e-3c04-11e9-9193-2e670c8e304c pods took: 100.922123ms
STEP: Creating RC which spawns configmap-volume pods
Mar  1 09:27:36.959: INFO: Pod name wrapped-volume-race-4053bb35-3c04-11e9-9193-2e670c8e304c: Found 3 pods out of 5
Mar  1 09:27:42.000: INFO: Pod name wrapped-volume-race-4053bb35-3c04-11e9-9193-2e670c8e304c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4053bb35-3c04-11e9-9193-2e670c8e304c in namespace e2e-tests-emptydir-wrapper-52pfj, will wait for the garbage collector to delete the pods
Mar  1 09:27:46.336: INFO: Deleting ReplicationController wrapped-volume-race-4053bb35-3c04-11e9-9193-2e670c8e304c took: 38.130569ms
Mar  1 09:27:46.836: INFO: Terminating ReplicationController wrapped-volume-race-4053bb35-3c04-11e9-9193-2e670c8e304c pods took: 500.237195ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:28:28.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-52pfj" for this suite.
Mar  1 09:28:36.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:28:37.732: INFO: namespace: e2e-tests-emptydir-wrapper-52pfj, resource: bindings, ignored listing per whitelist
Mar  1 09:28:38.025: INFO: namespace e2e-tests-emptydir-wrapper-52pfj deletion completed in 9.471081519s

• [SLOW TEST:168.044 seconds]
[sig-storage] EmptyDir wrapper volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:28:38.026: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-989xt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:28:39.734: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  1 09:28:39.806: INFO: Number of nodes with available pods: 0
Mar  1 09:28:39.806: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  1 09:28:39.963: INFO: Number of nodes with available pods: 0
Mar  1 09:28:39.963: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:40.999: INFO: Number of nodes with available pods: 0
Mar  1 09:28:40.999: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:41.999: INFO: Number of nodes with available pods: 0
Mar  1 09:28:41.999: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:42.999: INFO: Number of nodes with available pods: 0
Mar  1 09:28:42.999: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:44.000: INFO: Number of nodes with available pods: 1
Mar  1 09:28:44.000: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  1 09:28:44.149: INFO: Number of nodes with available pods: 0
Mar  1 09:28:44.149: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  1 09:28:44.224: INFO: Number of nodes with available pods: 0
Mar  1 09:28:44.224: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:45.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:45.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:46.262: INFO: Number of nodes with available pods: 0
Mar  1 09:28:46.262: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:47.262: INFO: Number of nodes with available pods: 0
Mar  1 09:28:47.262: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:48.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:48.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:49.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:49.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:50.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:50.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:51.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:51.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:52.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:52.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:53.261: INFO: Number of nodes with available pods: 0
Mar  1 09:28:53.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:54.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:54.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:55.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:55.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:56.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:56.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:57.260: INFO: Number of nodes with available pods: 0
Mar  1 09:28:57.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:58.261: INFO: Number of nodes with available pods: 0
Mar  1 09:28:58.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:28:59.261: INFO: Number of nodes with available pods: 0
Mar  1 09:28:59.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:00.273: INFO: Number of nodes with available pods: 0
Mar  1 09:29:00.273: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:01.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:01.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:02.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:02.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:03.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:03.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:04.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:04.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:05.261: INFO: Number of nodes with available pods: 0
Mar  1 09:29:05.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:06.261: INFO: Number of nodes with available pods: 0
Mar  1 09:29:06.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:07.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:07.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:08.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:08.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:09.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:09.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:10.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:10.259: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:11.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:11.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:12.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:12.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:13.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:13.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:14.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:14.259: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:15.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:15.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:16.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:16.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:17.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:17.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:18.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:18.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:19.261: INFO: Number of nodes with available pods: 0
Mar  1 09:29:19.261: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:20.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:20.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:21.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:21.259: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:22.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:22.259: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:23.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:23.259: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:24.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:24.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:25.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:25.259: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:26.259: INFO: Number of nodes with available pods: 0
Mar  1 09:29:26.259: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:27.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:27.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:28.260: INFO: Number of nodes with available pods: 0
Mar  1 09:29:28.260: INFO: Node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v is running more than one daemon pod
Mar  1 09:29:29.259: INFO: Number of nodes with available pods: 1
Mar  1 09:29:29.259: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-989xt, will wait for the garbage collector to delete the pods
Mar  1 09:29:29.451: INFO: Deleting DaemonSet.extensions daemon-set took: 38.10901ms
Mar  1 09:29:29.552: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.305531ms
Mar  1 09:30:06.688: INFO: Number of nodes with available pods: 0
Mar  1 09:30:06.688: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 09:30:06.722: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-989xt/daemonsets","resourceVersion":"23081"},"items":null}

Mar  1 09:30:06.790: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-989xt/pods","resourceVersion":"23081"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:30:06.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-989xt" for this suite.
Mar  1 09:30:13.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:30:13.811: INFO: namespace: e2e-tests-daemonsets-989xt, resource: bindings, ignored listing per whitelist
Mar  1 09:30:14.524: INFO: namespace e2e-tests-daemonsets-989xt deletion completed in 7.541580951s

• [SLOW TEST:96.498 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:30:14.524: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-j8gmd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:30:16.037: INFO: (0) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 39.31421ms)
Mar  1 09:30:16.079: INFO: (1) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 41.016045ms)
Mar  1 09:30:16.115: INFO: (2) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.603419ms)
Mar  1 09:30:16.152: INFO: (3) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.018586ms)
Mar  1 09:30:16.189: INFO: (4) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.281815ms)
Mar  1 09:30:16.226: INFO: (5) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.876047ms)
Mar  1 09:30:16.262: INFO: (6) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.20564ms)
Mar  1 09:30:16.299: INFO: (7) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.663287ms)
Mar  1 09:30:16.337: INFO: (8) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.781134ms)
Mar  1 09:30:16.373: INFO: (9) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.429759ms)
Mar  1 09:30:16.410: INFO: (10) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.109086ms)
Mar  1 09:30:16.446: INFO: (11) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.008463ms)
Mar  1 09:30:16.484: INFO: (12) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.990548ms)
Mar  1 09:30:16.522: INFO: (13) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.526275ms)
Mar  1 09:30:16.560: INFO: (14) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.813984ms)
Mar  1 09:30:16.596: INFO: (15) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.031272ms)
Mar  1 09:30:16.633: INFO: (16) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.95101ms)
Mar  1 09:30:16.670: INFO: (17) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.55386ms)
Mar  1 09:30:16.709: INFO: (18) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 39.636974ms)
Mar  1 09:30:16.749: INFO: (19) /api/v1/nodes/shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-4pc5v/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 39.560529ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:30:16.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j8gmd" for this suite.
Mar  1 09:30:22.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:30:23.549: INFO: namespace: e2e-tests-proxy-j8gmd, resource: bindings, ignored listing per whitelist
Mar  1 09:30:24.245: INFO: namespace e2e-tests-proxy-j8gmd deletion completed in 7.460523542s

• [SLOW TEST:9.721 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:30:24.248: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nnxdr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:30:25.804: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-nnxdr" to be "success or failure"
Mar  1 09:30:25.847: INFO: Pod "downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 42.910431ms
Mar  1 09:30:27.883: INFO: Pod "downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078701045s
Mar  1 09:30:29.921: INFO: Pod "downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117128023s
STEP: Saw pod success
Mar  1 09:30:29.921: INFO: Pod "downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:30:29.957: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:30:30.053: INFO: Waiting for pod downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c to disappear
Mar  1 09:30:30.087: INFO: Pod downwardapi-volume-a505a372-3c04-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:30:30.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nnxdr" for this suite.
Mar  1 09:30:36.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:30:37.205: INFO: namespace: e2e-tests-downward-api-nnxdr, resource: bindings, ignored listing per whitelist
Mar  1 09:30:37.694: INFO: namespace e2e-tests-downward-api-nnxdr deletion completed in 7.571203711s

• [SLOW TEST:13.446 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:30:37.694: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kc8nz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:30:39.300: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-kc8nz" to be "success or failure"
Mar  1 09:30:39.341: INFO: Pod "downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 40.718994ms
Mar  1 09:30:41.377: INFO: Pod "downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077174661s
Mar  1 09:30:43.413: INFO: Pod "downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.1130987s
STEP: Saw pod success
Mar  1 09:30:43.413: INFO: Pod "downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:30:43.449: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:30:43.541: INFO: Waiting for pod downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c to disappear
Mar  1 09:30:43.575: INFO: Pod downwardapi-volume-ad110c02-3c04-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:30:43.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kc8nz" for this suite.
Mar  1 09:30:49.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:30:49.865: INFO: namespace: e2e-tests-downward-api-kc8nz, resource: bindings, ignored listing per whitelist
Mar  1 09:30:51.091: INFO: namespace e2e-tests-downward-api-kc8nz deletion completed in 7.480119809s

• [SLOW TEST:13.397 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:30:51.091: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-x55pd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-x55pd
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-x55pd
STEP: Deleting pre-stop pod
Mar  1 09:31:07.970: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:31:08.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-x55pd" for this suite.
Mar  1 09:31:48.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:31:49.164: INFO: namespace: e2e-tests-prestop-x55pd, resource: bindings, ignored listing per whitelist
Mar  1 09:31:49.476: INFO: namespace e2e-tests-prestop-x55pd deletion completed in 41.43367087s

• [SLOW TEST:58.385 seconds]
[k8s.io] [sig-node] PreStop
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:31:49.477: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2rnpz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Mar  1 09:31:51.020: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-2rnpz'
Mar  1 09:31:51.515: INFO: stderr: ""
Mar  1 09:31:51.515: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar  1 09:31:52.552: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:31:52.552: INFO: Found 0 / 1
Mar  1 09:31:53.553: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:31:53.553: INFO: Found 0 / 1
Mar  1 09:31:54.553: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:31:54.553: INFO: Found 0 / 1
Mar  1 09:31:55.552: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:31:55.552: INFO: Found 1 / 1
Mar  1 09:31:55.552: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 09:31:55.593: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:31:55.593: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar  1 09:31:55.593: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml logs redis-master-ncnpr redis-master --namespace=e2e-tests-kubectl-2rnpz'
Mar  1 09:31:55.865: INFO: stderr: ""
Mar  1 09:31:55.865: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 09:31:53.531 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 09:31:53.531 # Server started, Redis version 3.2.12\n1:M 01 Mar 09:31:53.531 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 09:31:53.531 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar  1 09:31:55.865: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-ncnpr redis-master --namespace=e2e-tests-kubectl-2rnpz --tail=1'
Mar  1 09:31:56.154: INFO: stderr: ""
Mar  1 09:31:56.154: INFO: stdout: "1:M 01 Mar 09:31:53.531 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar  1 09:31:56.154: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-ncnpr redis-master --namespace=e2e-tests-kubectl-2rnpz --limit-bytes=1'
Mar  1 09:31:56.420: INFO: stderr: ""
Mar  1 09:31:56.420: INFO: stdout: " "
STEP: exposing timestamps
Mar  1 09:31:56.420: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-ncnpr redis-master --namespace=e2e-tests-kubectl-2rnpz --tail=1 --timestamps'
Mar  1 09:31:56.700: INFO: stderr: ""
Mar  1 09:31:56.700: INFO: stdout: "2019-03-01T09:31:53.53165859Z 1:M 01 Mar 09:31:53.531 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar  1 09:31:59.200: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-ncnpr redis-master --namespace=e2e-tests-kubectl-2rnpz --since=1s'
Mar  1 09:31:59.489: INFO: stderr: ""
Mar  1 09:31:59.489: INFO: stdout: ""
Mar  1 09:31:59.489: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-ncnpr redis-master --namespace=e2e-tests-kubectl-2rnpz --since=24h'
Mar  1 09:31:59.783: INFO: stderr: ""
Mar  1 09:31:59.783: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 09:31:53.531 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 09:31:53.531 # Server started, Redis version 3.2.12\n1:M 01 Mar 09:31:53.531 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 09:31:53.531 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Mar  1 09:31:59.784: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2rnpz'
Mar  1 09:32:00.061: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:32:00.061: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar  1 09:32:00.061: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-2rnpz'
Mar  1 09:32:00.326: INFO: stderr: "No resources found.\n"
Mar  1 09:32:00.326: INFO: stdout: ""
Mar  1 09:32:00.326: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-6tn50.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=nginx --namespace=e2e-tests-kubectl-2rnpz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 09:32:00.560: INFO: stderr: ""
Mar  1 09:32:00.560: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:32:00.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2rnpz" for this suite.
Mar  1 09:32:06.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:32:08.058: INFO: namespace: e2e-tests-kubectl-2rnpz, resource: bindings, ignored listing per whitelist
Mar  1 09:32:08.058: INFO: namespace e2e-tests-kubectl-2rnpz deletion completed in 7.462137226s

• [SLOW TEST:18.581 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:32:08.058: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vtftn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e2e1b037-3c04-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume secrets
Mar  1 09:32:09.624: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c" in namespace "e2e-tests-projected-vtftn" to be "success or failure"
Mar  1 09:32:09.660: INFO: Pod "pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 35.219564ms
Mar  1 09:32:11.695: INFO: Pod "pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070839576s
Mar  1 09:32:13.732: INFO: Pod "pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107575702s
STEP: Saw pod success
Mar  1 09:32:13.732: INFO: Pod "pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:32:13.771: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:32:13.855: INFO: Waiting for pod pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c to disappear
Mar  1 09:32:13.892: INFO: Pod pod-projected-secrets-e2e76116-3c04-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Projected secret
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:32:13.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vtftn" for this suite.
Mar  1 09:32:20.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:32:21.230: INFO: namespace: e2e-tests-projected-vtftn, resource: bindings, ignored listing per whitelist
Mar  1 09:32:21.643: INFO: namespace e2e-tests-projected-vtftn deletion completed in 7.715942108s

• [SLOW TEST:13.586 seconds]
[sig-storage] Projected secret
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:32:21.644: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-l4lgq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-eaf1e994-3c04-11e9-9193-2e670c8e304c
STEP: Creating a pod to test consume configMaps
Mar  1 09:32:23.152: INFO: Waiting up to 5m0s for pod "pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c" in namespace "e2e-tests-configmap-l4lgq" to be "success or failure"
Mar  1 09:32:23.187: INFO: Pod "pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.803814ms
Mar  1 09:32:25.223: INFO: Pod "pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071031451s
Mar  1 09:32:27.259: INFO: Pod "pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106392314s
STEP: Saw pod success
Mar  1 09:32:27.259: INFO: Pod "pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:32:27.293: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:32:27.375: INFO: Waiting for pod pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c to disappear
Mar  1 09:32:27.418: INFO: Pod pod-configmaps-eaf7acf6-3c04-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:32:27.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-l4lgq" for this suite.
Mar  1 09:32:33.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:32:34.113: INFO: namespace: e2e-tests-configmap-l4lgq, resource: bindings, ignored listing per whitelist
Mar  1 09:32:34.897: INFO: namespace e2e-tests-configmap-l4lgq deletion completed in 7.444250646s

• [SLOW TEST:13.254 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:32:34.898: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-rj5cf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar  1 09:32:36.411: INFO: Waiting up to 5m0s for pod "client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c" in namespace "e2e-tests-containers-rj5cf" to be "success or failure"
Mar  1 09:32:36.454: INFO: Pod "client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 43.585122ms
Mar  1 09:32:38.492: INFO: Pod "client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081642631s
Mar  1 09:32:40.528: INFO: Pod "client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117109774s
STEP: Saw pod success
Mar  1 09:32:40.528: INFO: Pod "client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:32:40.562: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 09:32:40.644: INFO: Waiting for pod client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c to disappear
Mar  1 09:32:40.679: INFO: Pod client-containers-f2debb1f-3c04-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:32:40.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rj5cf" for this suite.
Mar  1 09:32:46.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:32:47.001: INFO: namespace: e2e-tests-containers-rj5cf, resource: bindings, ignored listing per whitelist
Mar  1 09:32:48.224: INFO: namespace e2e-tests-containers-rj5cf deletion completed in 7.509036593s

• [SLOW TEST:13.326 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:32:48.224: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-zkznf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar  1 09:32:49.815: INFO: Waiting up to 5m0s for pod "client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c" in namespace "e2e-tests-containers-zkznf" to be "success or failure"
Mar  1 09:32:49.883: INFO: Pod "client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 68.334748ms
Mar  1 09:32:51.919: INFO: Pod "client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104016035s
Mar  1 09:32:53.954: INFO: Pod "client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.139062521s
STEP: Saw pod success
Mar  1 09:32:53.954: INFO: Pod "client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:32:53.989: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c container test-container: <nil>
STEP: delete the pod
Mar  1 09:32:54.070: INFO: Waiting for pod client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c to disappear
Mar  1 09:32:54.105: INFO: Pod client-containers-fadbe005-3c04-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:32:54.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-zkznf" for this suite.
Mar  1 09:33:00.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:33:00.464: INFO: namespace: e2e-tests-containers-zkznf, resource: bindings, ignored listing per whitelist
Mar  1 09:33:01.622: INFO: namespace e2e-tests-containers-zkznf deletion completed in 7.482285264s

• [SLOW TEST:13.399 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Mar  1 09:33:01.623: INFO: >>> kubeConfig: /tmp/build/3ab43379/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rldx8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:33:03.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c" in namespace "e2e-tests-downward-api-rldx8" to be "success or failure"
Mar  1 09:33:03.136: INFO: Pod "downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 36.615352ms
Mar  1 09:33:05.173: INFO: Pod "downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072997446s
Mar  1 09:33:07.208: INFO: Pod "downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.1084483s
STEP: Saw pod success
Mar  1 09:33:07.208: INFO: Pod "downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c" satisfied condition "success or failure"
Mar  1 09:33:07.244: INFO: Trying to get logs from node shoot--it--pub-az-6tn50-cpu-worker-6f6846fbdd-zw89j pod downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c container client-container: <nil>
STEP: delete the pod
Mar  1 09:33:07.335: INFO: Waiting for pod downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c to disappear
Mar  1 09:33:07.371: INFO: Pod downwardapi-volume-02c6c7e7-3c05-11e9-9193-2e670c8e304c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Mar  1 09:33:07.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rldx8" for this suite.
Mar  1 09:33:13.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:33:14.808: INFO: namespace: e2e-tests-downward-api-rldx8, resource: bindings, ignored listing per whitelist
Mar  1 09:33:14.954: INFO: namespace e2e-tests-downward-api-rldx8 deletion completed in 7.503215912s

• [SLOW TEST:13.331 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSMar  1 09:33:14.954: INFO: Running AfterSuite actions on all nodes
Mar  1 09:33:14.954: INFO: Running AfterSuite actions on node 1
Mar  1 09:33:14.954: INFO: Skipping dumping logs from cluster

Ran 200 of 2161 Specs in 6915.744 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Flaked | 0 Pending | 1961 Skipped PASS

Ginkgo ran 1 suite in 1h55m16.701960945s
Test Suite Passed
