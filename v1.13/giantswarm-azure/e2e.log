I0226 23:55:03.685874      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-167492786
I0226 23:55:03.686278      17 e2e.go:224] Starting e2e run "ef1347d9-3a21-11e9-9b83-4a9a78a986da" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551225302 - Will randomize all specs
Will run 201 of 1946 specs

Feb 26 23:55:03.866: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 26 23:55:03.869: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 26 23:55:03.881: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 26 23:55:03.917: INFO: 27 / 27 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 26 23:55:03.917: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
Feb 26 23:55:03.917: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 26 23:55:03.926: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 26 23:55:03.926: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cert-exporter' (0 seconds elapsed)
Feb 26 23:55:03.926: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 26 23:55:03.926: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'net-exporter' (0 seconds elapsed)
Feb 26 23:55:03.926: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Feb 26 23:55:03.926: INFO: e2e test version: v1.13.0
Feb 26 23:55:03.928: INFO: kube-apiserver version: v1.13.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:55:03.929: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pod-network-test
Feb 26 23:55:04.045: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 26 23:55:04.060: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hpqvj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hpqvj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 26 23:55:04.190: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 26 23:55:28.564: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.1.130.12 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hpqvj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 23:55:28.564: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 26 23:55:29.685: INFO: Found all expected endpoints: [netserver-0]
Feb 26 23:55:29.690: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.1.129.11 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hpqvj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 26 23:55:29.690: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 26 23:55:30.808: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:55:30.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hpqvj" for this suite.
Feb 26 23:55:52.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:55:52.885: INFO: namespace: e2e-tests-pod-network-test-hpqvj, resource: bindings, ignored listing per whitelist
Feb 26 23:55:52.965: INFO: namespace e2e-tests-pod-network-test-hpqvj deletion completed in 22.149133113s

• [SLOW TEST:49.036 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:55:52.966: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rmjcf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-0cf07014-3a22-11e9-9b83-4a9a78a986da
STEP: Creating secret with name secret-projected-all-test-volume-0cf06ff2-3a22-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 26 23:55:53.206: INFO: Waiting up to 5m0s for pod "projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-rmjcf" to be "success or failure"
Feb 26 23:55:53.213: INFO: Pod "projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.038245ms
Feb 26 23:55:55.217: INFO: Pod "projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011441751s
Feb 26 23:55:57.282: INFO: Pod "projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07570167s
STEP: Saw pod success
Feb 26 23:55:57.282: INFO: Pod "projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 26 23:55:57.288: INFO: Trying to get logs from node 9cy76-worker-000000 pod projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 26 23:55:57.313: INFO: Waiting for pod projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da to disappear
Feb 26 23:55:57.318: INFO: Pod projected-volume-0cf06f2d-3a22-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:55:57.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rmjcf" for this suite.
Feb 26 23:56:03.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:56:03.469: INFO: namespace: e2e-tests-projected-rmjcf, resource: bindings, ignored listing per whitelist
Feb 26 23:56:03.519: INFO: namespace e2e-tests-projected-rmjcf deletion completed in 6.150594347s

• [SLOW TEST:10.554 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:56:03.520: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9whv6
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1337c446-3a22-11e9-9b83-4a9a78a986da
STEP: Creating secret with name s-test-opt-upd-1337c498-3a22-11e9-9b83-4a9a78a986da
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1337c446-3a22-11e9-9b83-4a9a78a986da
STEP: Updating secret s-test-opt-upd-1337c498-3a22-11e9-9b83-4a9a78a986da
STEP: Creating secret with name s-test-opt-create-1337c4b1-3a22-11e9-9b83-4a9a78a986da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:56:11.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9whv6" for this suite.
Feb 26 23:56:33.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:56:33.971: INFO: namespace: e2e-tests-projected-9whv6, resource: bindings, ignored listing per whitelist
Feb 26 23:56:34.000: INFO: namespace e2e-tests-projected-9whv6 deletion completed in 22.157015848s

• [SLOW TEST:30.480 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:56:34.000: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-zf678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 26 23:56:34.249: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zf678,SelfLink:/api/v1/namespaces/e2e-tests-watch-zf678/configmaps/e2e-watch-test-resource-version,UID:2567517f-3a22-11e9-9b3e-000d3a2390ff,ResourceVersion:51055,Generation:0,CreationTimestamp:2019-02-26 23:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 26 23:56:34.250: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zf678,SelfLink:/api/v1/namespaces/e2e-tests-watch-zf678/configmaps/e2e-watch-test-resource-version,UID:2567517f-3a22-11e9-9b3e-000d3a2390ff,ResourceVersion:51056,Generation:0,CreationTimestamp:2019-02-26 23:56:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:56:34.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zf678" for this suite.
Feb 26 23:56:40.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:56:40.314: INFO: namespace: e2e-tests-watch-zf678, resource: bindings, ignored listing per whitelist
Feb 26 23:56:40.397: INFO: namespace e2e-tests-watch-zf678 deletion completed in 6.141440252s

• [SLOW TEST:6.397 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:56:40.397: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wwhxs
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2937038b-3a22-11e9-9b83-4a9a78a986da
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-2937038b-3a22-11e9-9b83-4a9a78a986da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:56:44.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wwhxs" for this suite.
Feb 26 23:57:06.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:57:06.805: INFO: namespace: e2e-tests-configmap-wwhxs, resource: bindings, ignored listing per whitelist
Feb 26 23:57:06.842: INFO: namespace e2e-tests-configmap-wwhxs deletion completed in 22.14292749s

• [SLOW TEST:26.444 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:57:06.842: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gt8kp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 26 23:57:07.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-gt8kp'
Feb 26 23:57:09.843: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 26 23:57:09.843: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 26 23:57:09.872: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-4tjrw]
Feb 26 23:57:09.872: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-4tjrw" in namespace "e2e-tests-kubectl-gt8kp" to be "running and ready"
Feb 26 23:57:09.876: INFO: Pod "e2e-test-nginx-rc-4tjrw": Phase="Pending", Reason="", readiness=false. Elapsed: 3.32816ms
Feb 26 23:57:11.879: INFO: Pod "e2e-test-nginx-rc-4tjrw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006503836s
Feb 26 23:57:13.884: INFO: Pod "e2e-test-nginx-rc-4tjrw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011273866s
Feb 26 23:57:15.887: INFO: Pod "e2e-test-nginx-rc-4tjrw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015122034s
Feb 26 23:57:17.891: INFO: Pod "e2e-test-nginx-rc-4tjrw": Phase="Running", Reason="", readiness=true. Elapsed: 8.018418099s
Feb 26 23:57:17.891: INFO: Pod "e2e-test-nginx-rc-4tjrw" satisfied condition "running and ready"
Feb 26 23:57:17.891: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-4tjrw]
Feb 26 23:57:17.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gt8kp'
Feb 26 23:57:17.993: INFO: stderr: ""
Feb 26 23:57:17.994: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 26 23:57:17.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-gt8kp'
Feb 26 23:57:18.156: INFO: stderr: ""
Feb 26 23:57:18.156: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:57:18.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gt8kp" for this suite.
Feb 26 23:57:40.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:57:40.218: INFO: namespace: e2e-tests-kubectl-gt8kp, resource: bindings, ignored listing per whitelist
Feb 26 23:57:40.310: INFO: namespace e2e-tests-kubectl-gt8kp deletion completed in 22.148798465s

• [SLOW TEST:33.468 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:57:40.310: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-nsj4j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-nsj4j;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-nsj4j;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-nsj4j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.104.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.104.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.104.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.104.202_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-nsj4j;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-nsj4j;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-nsj4j.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-nsj4j.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-nsj4j.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.104.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.104.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.104.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.104.202_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 26 23:58:08.576: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.585: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.605: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.609: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.640: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.643: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.652: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-nsj4j from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.663: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.667: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc from pod e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da: the server could not find the requested resource (get pods dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da)
Feb 26 23:58:08.690: INFO: Lookups using e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_tcp@dns-test-service.e2e-tests-dns-nsj4j jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-nsj4j.svc]

Feb 26 23:58:13.807: INFO: DNS probes using e2e-tests-dns-nsj4j/dns-test-4cecd028-3a22-11e9-9b83-4a9a78a986da succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:58:13.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-nsj4j" for this suite.
Feb 26 23:58:19.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:58:20.003: INFO: namespace: e2e-tests-dns-nsj4j, resource: bindings, ignored listing per whitelist
Feb 26 23:58:20.029: INFO: namespace e2e-tests-dns-nsj4j deletion completed in 6.151590652s

• [SLOW TEST:39.718 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:58:20.029: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-842k6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 26 23:58:20.254: INFO: Waiting up to 5m0s for pod "downwardapi-volume-649782b0-3a22-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-842k6" to be "success or failure"
Feb 26 23:58:20.261: INFO: Pod "downwardapi-volume-649782b0-3a22-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.4474ms
Feb 26 23:58:22.265: INFO: Pod "downwardapi-volume-649782b0-3a22-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010936108s
STEP: Saw pod success
Feb 26 23:58:22.265: INFO: Pod "downwardapi-volume-649782b0-3a22-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 26 23:58:22.269: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-649782b0-3a22-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 26 23:58:22.295: INFO: Waiting for pod downwardapi-volume-649782b0-3a22-11e9-9b83-4a9a78a986da to disappear
Feb 26 23:58:22.298: INFO: Pod downwardapi-volume-649782b0-3a22-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:58:22.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-842k6" for this suite.
Feb 26 23:58:28.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:58:28.384: INFO: namespace: e2e-tests-downward-api-842k6, resource: bindings, ignored listing per whitelist
Feb 26 23:58:28.490: INFO: namespace e2e-tests-downward-api-842k6 deletion completed in 6.168277694s

• [SLOW TEST:8.461 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:58:28.490: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ps2q6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-67gq
STEP: Creating a pod to test atomic-volume-subpath
Feb 26 23:58:28.716: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-67gq" in namespace "e2e-tests-subpath-ps2q6" to be "success or failure"
Feb 26 23:58:28.720: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Pending", Reason="", readiness=false. Elapsed: 3.23595ms
Feb 26 23:58:30.724: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007661505s
Feb 26 23:58:32.728: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 4.011665215s
Feb 26 23:58:34.732: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 6.015980837s
Feb 26 23:58:36.737: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 8.020025384s
Feb 26 23:58:38.740: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 10.023508752s
Feb 26 23:58:40.744: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 12.027728762s
Feb 26 23:58:42.748: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 14.031229091s
Feb 26 23:58:44.751: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 16.034843952s
Feb 26 23:58:46.755: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 18.038683348s
Feb 26 23:58:48.759: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 20.042661277s
Feb 26 23:58:50.765: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Running", Reason="", readiness=false. Elapsed: 22.04808196s
Feb 26 23:58:52.768: INFO: Pod "pod-subpath-test-downwardapi-67gq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051833862s
STEP: Saw pod success
Feb 26 23:58:52.768: INFO: Pod "pod-subpath-test-downwardapi-67gq" satisfied condition "success or failure"
Feb 26 23:58:52.771: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-subpath-test-downwardapi-67gq container test-container-subpath-downwardapi-67gq: <nil>
STEP: delete the pod
Feb 26 23:58:52.810: INFO: Waiting for pod pod-subpath-test-downwardapi-67gq to disappear
Feb 26 23:58:52.812: INFO: Pod pod-subpath-test-downwardapi-67gq no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-67gq
Feb 26 23:58:52.813: INFO: Deleting pod "pod-subpath-test-downwardapi-67gq" in namespace "e2e-tests-subpath-ps2q6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:58:52.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ps2q6" for this suite.
Feb 26 23:58:58.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:58:58.919: INFO: namespace: e2e-tests-subpath-ps2q6, resource: bindings, ignored listing per whitelist
Feb 26 23:58:58.942: INFO: namespace e2e-tests-subpath-ps2q6 deletion completed in 6.121944654s

• [SLOW TEST:30.451 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:58:58.942: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ws6zl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-7bc9451f-3a22-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 26 23:58:59.188: INFO: Waiting up to 5m0s for pod "pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-ws6zl" to be "success or failure"
Feb 26 23:58:59.193: INFO: Pod "pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.37218ms
Feb 26 23:59:01.197: INFO: Pod "pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008947581s
Feb 26 23:59:03.201: INFO: Pod "pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012378765s
STEP: Saw pod success
Feb 26 23:59:03.201: INFO: Pod "pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 26 23:59:03.203: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 26 23:59:03.238: INFO: Waiting for pod pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da to disappear
Feb 26 23:59:03.241: INFO: Pod pod-secrets-7bc9ccc0-3a22-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:59:03.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ws6zl" for this suite.
Feb 26 23:59:09.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:59:09.369: INFO: namespace: e2e-tests-secrets-ws6zl, resource: bindings, ignored listing per whitelist
Feb 26 23:59:09.434: INFO: namespace e2e-tests-secrets-ws6zl deletion completed in 6.188097953s

• [SLOW TEST:10.492 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:59:09.434: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-q2c4n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 26 23:59:09.643: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:59:14.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-q2c4n" for this suite.
Feb 26 23:59:20.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:59:20.087: INFO: namespace: e2e-tests-init-container-q2c4n, resource: bindings, ignored listing per whitelist
Feb 26 23:59:20.257: INFO: namespace e2e-tests-init-container-q2c4n deletion completed in 6.20688644s

• [SLOW TEST:10.823 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:59:20.258: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8p42g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 26 23:59:20.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 cluster-info'
Feb 26 23:59:20.560: INFO: stderr: ""
Feb 26 23:59:20.560: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 26 23:59:20.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8p42g" for this suite.
Feb 26 23:59:26.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 26 23:59:26.648: INFO: namespace: e2e-tests-kubectl-8p42g, resource: bindings, ignored listing per whitelist
Feb 26 23:59:26.680: INFO: namespace e2e-tests-kubectl-8p42g deletion completed in 6.116990485s

• [SLOW TEST:6.423 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 26 23:59:26.681: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-f6plf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:00:26.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-f6plf" for this suite.
Feb 27 00:00:48.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:00:49.009: INFO: namespace: e2e-tests-container-probe-f6plf, resource: bindings, ignored listing per whitelist
Feb 27 00:00:49.024: INFO: namespace e2e-tests-container-probe-f6plf deletion completed in 22.125597514s

• [SLOW TEST:82.343 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:00:49.025: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-c9n8c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 27 00:00:49.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-c9n8c'
Feb 27 00:00:49.601: INFO: stderr: ""
Feb 27 00:00:49.601: INFO: stdout: "pod/pause created\n"
Feb 27 00:00:49.601: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 27 00:00:49.601: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-c9n8c" to be "running and ready"
Feb 27 00:00:49.608: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.643689ms
Feb 27 00:00:51.613: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011918755s
Feb 27 00:00:53.617: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.015894584s
Feb 27 00:00:53.617: INFO: Pod "pause" satisfied condition "running and ready"
Feb 27 00:00:53.617: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 27 00:00:53.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-c9n8c'
Feb 27 00:00:53.715: INFO: stderr: ""
Feb 27 00:00:53.715: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 27 00:00:53.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pod pause -L testing-label --namespace=e2e-tests-kubectl-c9n8c'
Feb 27 00:00:53.802: INFO: stderr: ""
Feb 27 00:00:53.802: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 27 00:00:53.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 label pods pause testing-label- --namespace=e2e-tests-kubectl-c9n8c'
Feb 27 00:00:53.890: INFO: stderr: ""
Feb 27 00:00:53.890: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 27 00:00:53.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pod pause -L testing-label --namespace=e2e-tests-kubectl-c9n8c'
Feb 27 00:00:53.965: INFO: stderr: ""
Feb 27 00:00:53.965: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 27 00:00:53.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-c9n8c'
Feb 27 00:00:54.061: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:00:54.061: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 27 00:00:54.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-c9n8c'
Feb 27 00:00:54.215: INFO: stderr: "No resources found.\n"
Feb 27 00:00:54.215: INFO: stdout: ""
Feb 27 00:00:54.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -l name=pause --namespace=e2e-tests-kubectl-c9n8c -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 00:00:54.357: INFO: stderr: ""
Feb 27 00:00:54.357: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:00:54.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c9n8c" for this suite.
Feb 27 00:01:00.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:01:00.478: INFO: namespace: e2e-tests-kubectl-c9n8c, resource: bindings, ignored listing per whitelist
Feb 27 00:01:00.489: INFO: namespace e2e-tests-kubectl-c9n8c deletion completed in 6.127525797s

• [SLOW TEST:11.464 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:01:00.490: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-pr82h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:01:04.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-pr82h" for this suite.
Feb 27 00:01:56.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:01:56.820: INFO: namespace: e2e-tests-kubelet-test-pr82h, resource: bindings, ignored listing per whitelist
Feb 27 00:01:56.886: INFO: namespace e2e-tests-kubelet-test-pr82h deletion completed in 52.134924923s

• [SLOW TEST:56.397 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:01:56.886: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-bpr7k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 27 00:01:57.629: INFO: created pod pod-service-account-defaultsa
Feb 27 00:01:57.629: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 27 00:01:57.636: INFO: created pod pod-service-account-mountsa
Feb 27 00:01:57.636: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 27 00:01:57.648: INFO: created pod pod-service-account-nomountsa
Feb 27 00:01:57.648: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 27 00:01:57.657: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 27 00:01:57.657: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 27 00:01:57.684: INFO: created pod pod-service-account-mountsa-mountspec
Feb 27 00:01:57.684: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 27 00:01:57.699: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 27 00:01:57.699: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 27 00:01:57.706: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 27 00:01:57.706: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 27 00:01:57.717: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 27 00:01:57.717: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 27 00:01:57.731: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 27 00:01:57.732: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:01:57.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bpr7k" for this suite.
Feb 27 00:02:19.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:02:19.823: INFO: namespace: e2e-tests-svcaccounts-bpr7k, resource: bindings, ignored listing per whitelist
Feb 27 00:02:19.915: INFO: namespace e2e-tests-svcaccounts-bpr7k deletion completed in 22.168435326s

• [SLOW TEST:23.028 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:02:19.915: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t6jfg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 27 00:02:20.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:20.486: INFO: stderr: ""
Feb 27 00:02:20.486: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 00:02:20.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:20.583: INFO: stderr: ""
Feb 27 00:02:20.583: INFO: stdout: "update-demo-nautilus-727f6 update-demo-nautilus-b92zp "
Feb 27 00:02:20.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-727f6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:20.659: INFO: stderr: ""
Feb 27 00:02:20.659: INFO: stdout: ""
Feb 27 00:02:20.659: INFO: update-demo-nautilus-727f6 is created but not running
Feb 27 00:02:25.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:25.748: INFO: stderr: ""
Feb 27 00:02:25.748: INFO: stdout: "update-demo-nautilus-727f6 update-demo-nautilus-b92zp "
Feb 27 00:02:25.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-727f6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:25.822: INFO: stderr: ""
Feb 27 00:02:25.822: INFO: stdout: "true"
Feb 27 00:02:25.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-727f6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:25.896: INFO: stderr: ""
Feb 27 00:02:25.896: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:02:25.896: INFO: validating pod update-demo-nautilus-727f6
Feb 27 00:02:25.903: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:02:25.903: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:02:25.903: INFO: update-demo-nautilus-727f6 is verified up and running
Feb 27 00:02:25.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-b92zp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:25.976: INFO: stderr: ""
Feb 27 00:02:25.976: INFO: stdout: "true"
Feb 27 00:02:25.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-b92zp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:26.049: INFO: stderr: ""
Feb 27 00:02:26.049: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:02:26.049: INFO: validating pod update-demo-nautilus-b92zp
Feb 27 00:02:26.055: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:02:26.056: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:02:26.056: INFO: update-demo-nautilus-b92zp is verified up and running
STEP: using delete to clean up resources
Feb 27 00:02:26.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:26.138: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:02:26.138: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 27 00:02:26.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-t6jfg'
Feb 27 00:02:26.292: INFO: stderr: "No resources found.\n"
Feb 27 00:02:26.292: INFO: stdout: ""
Feb 27 00:02:26.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -l name=update-demo --namespace=e2e-tests-kubectl-t6jfg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 00:02:26.464: INFO: stderr: ""
Feb 27 00:02:26.464: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:02:26.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t6jfg" for this suite.
Feb 27 00:02:32.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:02:32.545: INFO: namespace: e2e-tests-kubectl-t6jfg, resource: bindings, ignored listing per whitelist
Feb 27 00:02:32.602: INFO: namespace e2e-tests-kubectl-t6jfg deletion completed in 6.132307088s

• [SLOW TEST:12.687 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:02:32.602: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vddj9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 27 00:02:32.854: INFO: Waiting up to 5m0s for pod "pod-fb272113-3a22-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-vddj9" to be "success or failure"
Feb 27 00:02:32.861: INFO: Pod "pod-fb272113-3a22-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.695253ms
Feb 27 00:02:34.865: INFO: Pod "pod-fb272113-3a22-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0114756s
Feb 27 00:02:36.993: INFO: Pod "pod-fb272113-3a22-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.139557971s
STEP: Saw pod success
Feb 27 00:02:36.993: INFO: Pod "pod-fb272113-3a22-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:02:36.999: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-fb272113-3a22-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:02:37.021: INFO: Waiting for pod pod-fb272113-3a22-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:02:37.025: INFO: Pod pod-fb272113-3a22-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:02:37.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vddj9" for this suite.
Feb 27 00:02:43.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:02:43.093: INFO: namespace: e2e-tests-emptydir-vddj9, resource: bindings, ignored listing per whitelist
Feb 27 00:02:43.172: INFO: namespace e2e-tests-emptydir-vddj9 deletion completed in 6.126947762s

• [SLOW TEST:10.570 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:02:43.173: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5bbhj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:02:43.402: INFO: Waiting up to 5m0s for pod "downwardapi-volume-017087cd-3a23-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-5bbhj" to be "success or failure"
Feb 27 00:02:43.420: INFO: Pod "downwardapi-volume-017087cd-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 17.791213ms
Feb 27 00:02:45.423: INFO: Pod "downwardapi-volume-017087cd-3a23-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021409286s
STEP: Saw pod success
Feb 27 00:02:45.424: INFO: Pod "downwardapi-volume-017087cd-3a23-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:02:45.427: INFO: Trying to get logs from node 9cy76-worker-000001 pod downwardapi-volume-017087cd-3a23-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:02:45.464: INFO: Waiting for pod downwardapi-volume-017087cd-3a23-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:02:45.468: INFO: Pod downwardapi-volume-017087cd-3a23-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:02:45.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5bbhj" for this suite.
Feb 27 00:02:51.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:02:51.594: INFO: namespace: e2e-tests-downward-api-5bbhj, resource: bindings, ignored listing per whitelist
Feb 27 00:02:51.615: INFO: namespace e2e-tests-downward-api-5bbhj deletion completed in 6.142611933s

• [SLOW TEST:8.443 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:02:51.616: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9gzb8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:02:51.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 version --client'
Feb 27 00:02:51.886: INFO: stderr: ""
Feb 27 00:02:51.886: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 27 00:02:51.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-9gzb8'
Feb 27 00:02:52.187: INFO: stderr: ""
Feb 27 00:02:52.187: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 27 00:02:52.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-9gzb8'
Feb 27 00:02:52.565: INFO: stderr: ""
Feb 27 00:02:52.565: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 00:02:53.570: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:02:53.570: INFO: Found 0 / 1
Feb 27 00:02:54.569: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:02:54.570: INFO: Found 0 / 1
Feb 27 00:02:55.569: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:02:55.569: INFO: Found 1 / 1
Feb 27 00:02:55.569: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 00:02:55.573: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:02:55.573: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 00:02:55.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 describe pod redis-master-7z6t5 --namespace=e2e-tests-kubectl-9gzb8'
Feb 27 00:02:55.708: INFO: stderr: ""
Feb 27 00:02:55.708: INFO: stdout: "Name:               redis-master-7z6t5\nNamespace:          e2e-tests-kubectl-9gzb8\nPriority:           0\nPriorityClassName:  <none>\nNode:               9cy76-worker-000000/10.1.1.4\nStart Time:         Wed, 27 Feb 2019 00:02:52 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.1.130.32/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 10.1.130.32\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://ab1cddbab885b6bc2227f2999456bec79c95da67df71a157b2ee7b44f11d8097\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 27 Feb 2019 00:02:55 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gmtdj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gmtdj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gmtdj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                          Message\n  ----    ------     ----  ----                          -------\n  Normal  Scheduled  3s    default-scheduler             Successfully assigned e2e-tests-kubectl-9gzb8/redis-master-7z6t5 to 9cy76-worker-000000\n  Normal  Pulling    2s    kubelet, 9cy76-worker-000000  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     1s    kubelet, 9cy76-worker-000000  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    1s    kubelet, 9cy76-worker-000000  Created container\n  Normal  Started    0s    kubelet, 9cy76-worker-000000  Started container\n"
Feb 27 00:02:55.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 describe rc redis-master --namespace=e2e-tests-kubectl-9gzb8'
Feb 27 00:02:55.801: INFO: stderr: ""
Feb 27 00:02:55.801: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-9gzb8\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-7z6t5\n"
Feb 27 00:02:55.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 describe service redis-master --namespace=e2e-tests-kubectl-9gzb8'
Feb 27 00:02:55.898: INFO: stderr: ""
Feb 27 00:02:55.898: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-9gzb8\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.31.126.175\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.1.130.32:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 27 00:02:55.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 describe node 9cy76-master-000000'
Feb 27 00:02:56.006: INFO: stderr: ""
Feb 27 00:02:56.006: INFO: stdout: "Name:               9cy76-master-000000\nRoles:              master\nLabels:             azure-operator.giantswarm.io/version=2.1.0\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D2s_v3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=0\n                    giantswarm.io/provider=azure\n                    ip=10.1.0.5\n                    kubernetes.io/hostname=9cy76-master-000000\n                    node-role.kubernetes.io/master=\n                    role=master\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Feb 2019 14:58:49 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 26 Feb 2019 15:00:56 +0000   Tue, 26 Feb 2019 15:00:56 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Wed, 27 Feb 2019 00:02:53 +0000   Tue, 26 Feb 2019 14:58:33 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 27 Feb 2019 00:02:53 +0000   Tue, 26 Feb 2019 14:58:33 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 27 Feb 2019 00:02:53 +0000   Tue, 26 Feb 2019 14:58:33 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 27 Feb 2019 00:02:53 +0000   Tue, 26 Feb 2019 14:59:39 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.1.0.5\n  Hostname:    9cy76-master-000000\nCapacity:\n attachable-volumes-azure-disk:  4\n cpu:                            2\n ephemeral-storage:              28454196Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         8147996Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  4\n cpu:                            2\n ephemeral-storage:              28454196Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7943196Ki\n pods:                           110\nSystem Info:\n Machine ID:                 3f2f94080e564e7ca3eb488837de38ed\n System UUID:                E7936C75-523F-F54F-B70B-A1CF39672A6B\n Boot ID:                    96b0894b-dc9c-4a7f-8c80-05ae5da64879\n Kernel Version:             4.14.96-coreos\n OS Image:                   Container Linux by CoreOS 1967.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nPodCIDR:                     10.1.128.0/24\nProviderID:                  azure:///subscriptions/1be3b2e6-497b-45b9-915f-eb35cae23c6a/resourceGroups/9cy76/providers/Microsoft.Compute/virtualMachineScaleSets/9cy76-master/virtualMachines/0\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  giantswarm                 chart-operator-68fd597646-9pw9l                            250m (12%)    250m (12%)  250Mi (3%)       250Mi (3%)     9h\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-d15354df4d564054-s98td    0 (0%)        0 (0%)      0 (0%)           0 (0%)         9m5s\n  kube-system                calico-node-k2r58                                          250m (12%)    250m (12%)  150Mi (1%)       150Mi (1%)     9h\n  kube-system                cert-exporter-g6cck                                        50m (2%)      50m (2%)    50Mi (0%)        50Mi (0%)      9h\n  kube-system                k8s-api-server-9cy76-master-000000                         300m (15%)    0 (0%)      300Mi (3%)       0 (0%)         9h\n  kube-system                k8s-controller-manager-9cy76-master-000000                 200m (10%)    0 (0%)      200Mi (2%)       0 (0%)         9h\n  kube-system                k8s-scheduler-9cy76-master-000000                          100m (5%)     0 (0%)      100Mi (1%)       0 (0%)         9h\n  kube-system                kube-proxy-wx5hc                                           75m (3%)      0 (0%)      80Mi (1%)        0 (0%)         9h\n  kube-system                net-exporter-7xszl                                         50m (2%)      50m (2%)    50Mi (0%)        50Mi (0%)      9h\n  kube-system                node-exporter-5m5j9                                        55m (2%)      55m (2%)    75Mi (0%)        75Mi (0%)      8h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests      Limits\n  --------                       --------      ------\n  cpu                            1330m (66%)   655m (32%)\n  memory                         1255Mi (16%)  575Mi (7%)\n  ephemeral-storage              0 (0%)        0 (0%)\n  attachable-volumes-azure-disk  0             0\nEvents:                          <none>\n"
Feb 27 00:02:56.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 describe namespace e2e-tests-kubectl-9gzb8'
Feb 27 00:02:56.102: INFO: stderr: ""
Feb 27 00:02:56.102: INFO: stdout: "Name:         e2e-tests-kubectl-9gzb8\nLabels:       e2e-framework=kubectl\n              e2e-run=ef1347d9-3a21-11e9-9b83-4a9a78a986da\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:02:56.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9gzb8" for this suite.
Feb 27 00:03:18.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:03:18.146: INFO: namespace: e2e-tests-kubectl-9gzb8, resource: bindings, ignored listing per whitelist
Feb 27 00:03:18.240: INFO: namespace e2e-tests-kubectl-9gzb8 deletion completed in 22.131872734s

• [SLOW TEST:26.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:03:18.242: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mf7mf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:03:18.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 version'
Feb 27 00:03:18.542: INFO: stderr: ""
Feb 27 00:03:18.542: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:03:18.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mf7mf" for this suite.
Feb 27 00:03:24.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:03:24.679: INFO: namespace: e2e-tests-kubectl-mf7mf, resource: bindings, ignored listing per whitelist
Feb 27 00:03:24.689: INFO: namespace e2e-tests-kubectl-mf7mf deletion completed in 6.143029407s

• [SLOW TEST:6.448 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:03:24.690: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-4lfbj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4lfbj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 00:03:24.882: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 00:03:50.972: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.129.19:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4lfbj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 00:03:50.972: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 00:03:51.086: INFO: Found all expected endpoints: [netserver-0]
Feb 27 00:03:51.089: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.130.33:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-4lfbj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 00:03:51.089: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 00:03:51.205: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:03:51.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4lfbj" for this suite.
Feb 27 00:04:13.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:04:13.334: INFO: namespace: e2e-tests-pod-network-test-4lfbj, resource: bindings, ignored listing per whitelist
Feb 27 00:04:13.337: INFO: namespace e2e-tests-pod-network-test-4lfbj deletion completed in 22.126411488s

• [SLOW TEST:48.647 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:04:13.337: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-95x2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:04:17.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-95x2t" for this suite.
Feb 27 00:04:23.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:04:23.622: INFO: namespace: e2e-tests-kubelet-test-95x2t, resource: bindings, ignored listing per whitelist
Feb 27 00:04:23.713: INFO: namespace e2e-tests-kubelet-test-95x2t deletion completed in 6.133233846s

• [SLOW TEST:10.376 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:04:23.713: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gcn4w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3d5b78dc-3a23-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:04:23.934: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-gcn4w" to be "success or failure"
Feb 27 00:04:23.940: INFO: Pod "pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.452516ms
Feb 27 00:04:25.944: INFO: Pod "pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010298618s
Feb 27 00:04:27.948: INFO: Pod "pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014062168s
STEP: Saw pod success
Feb 27 00:04:27.948: INFO: Pod "pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:04:27.951: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:04:27.992: INFO: Waiting for pod pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:04:27.994: INFO: Pod pod-projected-secrets-3d5c13eb-3a23-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:04:27.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gcn4w" for this suite.
Feb 27 00:04:34.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:04:34.118: INFO: namespace: e2e-tests-projected-gcn4w, resource: bindings, ignored listing per whitelist
Feb 27 00:04:34.134: INFO: namespace e2e-tests-projected-gcn4w deletion completed in 6.135367529s

• [SLOW TEST:10.421 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:04:34.135: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rnxvk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:04:34.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43979956-3a23-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-rnxvk" to be "success or failure"
Feb 27 00:04:34.390: INFO: Pod "downwardapi-volume-43979956-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.803514ms
Feb 27 00:04:36.394: INFO: Pod "downwardapi-volume-43979956-3a23-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006985842s
STEP: Saw pod success
Feb 27 00:04:36.394: INFO: Pod "downwardapi-volume-43979956-3a23-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:04:36.398: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-43979956-3a23-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:04:36.432: INFO: Waiting for pod downwardapi-volume-43979956-3a23-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:04:36.446: INFO: Pod downwardapi-volume-43979956-3a23-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:04:36.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rnxvk" for this suite.
Feb 27 00:04:42.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:04:42.591: INFO: namespace: e2e-tests-projected-rnxvk, resource: bindings, ignored listing per whitelist
Feb 27 00:04:42.604: INFO: namespace e2e-tests-projected-rnxvk deletion completed in 6.146381055s

• [SLOW TEST:8.469 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:04:42.604: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-59dhp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 27 00:04:42.827: INFO: Waiting up to 5m0s for pod "pod-489f06ed-3a23-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-59dhp" to be "success or failure"
Feb 27 00:04:42.836: INFO: Pod "pod-489f06ed-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.291331ms
Feb 27 00:04:44.840: INFO: Pod "pod-489f06ed-3a23-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012724907s
STEP: Saw pod success
Feb 27 00:04:44.840: INFO: Pod "pod-489f06ed-3a23-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:04:44.844: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-489f06ed-3a23-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:04:44.874: INFO: Waiting for pod pod-489f06ed-3a23-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:04:44.878: INFO: Pod pod-489f06ed-3a23-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:04:44.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-59dhp" for this suite.
Feb 27 00:04:50.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:04:50.973: INFO: namespace: e2e-tests-emptydir-59dhp, resource: bindings, ignored listing per whitelist
Feb 27 00:04:51.054: INFO: namespace e2e-tests-emptydir-59dhp deletion completed in 6.163043571s

• [SLOW TEST:8.450 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:04:51.054: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jf4x6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-4da8ad7a-3a23-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:04:51.289: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4da994ba-3a23-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-jf4x6" to be "success or failure"
Feb 27 00:04:51.302: INFO: Pod "pod-projected-secrets-4da994ba-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 12.667771ms
Feb 27 00:04:53.310: INFO: Pod "pod-projected-secrets-4da994ba-3a23-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020714194s
STEP: Saw pod success
Feb 27 00:04:53.310: INFO: Pod "pod-projected-secrets-4da994ba-3a23-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:04:53.317: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-secrets-4da994ba-3a23-11e9-9b83-4a9a78a986da container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:04:53.356: INFO: Waiting for pod pod-projected-secrets-4da994ba-3a23-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:04:53.359: INFO: Pod pod-projected-secrets-4da994ba-3a23-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:04:53.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jf4x6" for this suite.
Feb 27 00:04:59.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:04:59.483: INFO: namespace: e2e-tests-projected-jf4x6, resource: bindings, ignored listing per whitelist
Feb 27 00:04:59.506: INFO: namespace e2e-tests-projected-jf4x6 deletion completed in 6.142971458s

• [SLOW TEST:8.452 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:04:59.506: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-blhb6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 00:05:02.250: INFO: Successfully updated pod "labelsupdate52b0d53e-3a23-11e9-9b83-4a9a78a986da"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:05:04.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-blhb6" for this suite.
Feb 27 00:05:26.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:05:26.416: INFO: namespace: e2e-tests-projected-blhb6, resource: bindings, ignored listing per whitelist
Feb 27 00:05:26.434: INFO: namespace e2e-tests-projected-blhb6 deletion completed in 22.157912395s

• [SLOW TEST:26.928 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:05:26.442: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-l8zdc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:05:26.690: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-l8zdc" to be "success or failure"
Feb 27 00:05:26.706: INFO: Pod "downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 15.938071ms
Feb 27 00:05:28.711: INFO: Pod "downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da": Phase="Running", Reason="", readiness=true. Elapsed: 2.020118596s
Feb 27 00:05:30.714: INFO: Pod "downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023919555s
STEP: Saw pod success
Feb 27 00:05:30.715: INFO: Pod "downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:05:30.717: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:05:30.740: INFO: Waiting for pod downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:05:30.753: INFO: Pod downwardapi-volume-62c48af0-3a23-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:05:30.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l8zdc" for this suite.
Feb 27 00:05:36.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:05:36.889: INFO: namespace: e2e-tests-projected-l8zdc, resource: bindings, ignored listing per whitelist
Feb 27 00:05:36.914: INFO: namespace e2e-tests-projected-l8zdc deletion completed in 6.146823675s

• [SLOW TEST:10.472 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:05:36.914: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-rglp4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-wc9b
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 00:05:37.139: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wc9b" in namespace "e2e-tests-subpath-rglp4" to be "success or failure"
Feb 27 00:05:37.150: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.629454ms
Feb 27 00:05:39.154: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014444847s
Feb 27 00:05:41.256: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 4.116883501s
Feb 27 00:05:43.260: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 6.12070144s
Feb 27 00:05:45.268: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 8.128948307s
Feb 27 00:05:47.272: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 10.133047553s
Feb 27 00:05:49.279: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 12.139930519s
Feb 27 00:05:51.283: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 14.143413167s
Feb 27 00:05:53.286: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 16.146853018s
Feb 27 00:05:55.290: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 18.150150371s
Feb 27 00:05:57.292: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 20.153040324s
Feb 27 00:05:59.296: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Running", Reason="", readiness=false. Elapsed: 22.156888086s
Feb 27 00:06:01.299: INFO: Pod "pod-subpath-test-secret-wc9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.159838751s
STEP: Saw pod success
Feb 27 00:06:01.299: INFO: Pod "pod-subpath-test-secret-wc9b" satisfied condition "success or failure"
Feb 27 00:06:01.302: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-subpath-test-secret-wc9b container test-container-subpath-secret-wc9b: <nil>
STEP: delete the pod
Feb 27 00:06:01.345: INFO: Waiting for pod pod-subpath-test-secret-wc9b to disappear
Feb 27 00:06:01.354: INFO: Pod pod-subpath-test-secret-wc9b no longer exists
STEP: Deleting pod pod-subpath-test-secret-wc9b
Feb 27 00:06:01.354: INFO: Deleting pod "pod-subpath-test-secret-wc9b" in namespace "e2e-tests-subpath-rglp4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:06:01.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rglp4" for this suite.
Feb 27 00:06:07.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:06:07.440: INFO: namespace: e2e-tests-subpath-rglp4, resource: bindings, ignored listing per whitelist
Feb 27 00:06:07.493: INFO: namespace e2e-tests-subpath-rglp4 deletion completed in 6.131024984s

• [SLOW TEST:30.579 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:06:07.494: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-2v9j2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:06:07.715: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 00:06:07.724: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:07.729: INFO: Number of nodes with available pods: 0
Feb 27 00:06:07.729: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:06:08.738: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:08.741: INFO: Number of nodes with available pods: 0
Feb 27 00:06:08.741: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:06:09.733: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:09.736: INFO: Number of nodes with available pods: 0
Feb 27 00:06:09.736: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:06:10.733: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:10.736: INFO: Number of nodes with available pods: 0
Feb 27 00:06:10.736: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:06:11.734: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:11.737: INFO: Number of nodes with available pods: 2
Feb 27 00:06:11.737: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 27 00:06:11.762: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:11.762: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:11.779: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:12.782: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:12.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:12.786: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:13.782: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:13.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:13.785: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:14.784: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:14.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:14.791: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:15.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:15.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:15.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:16.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:16.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:16.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:17.782: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:17.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:17.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:18.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:18.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:18.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:19.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:19.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:19.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:20.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:20.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:20.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:21.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:21.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:21.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:22.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:22.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:22.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:23.784: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:23.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:23.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:24.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:24.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:24.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:25.784: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:25.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:25.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:26.938: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:26.938: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:26.942: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:27.782: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:27.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:27.786: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:28.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:28.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:28.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:29.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:29.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:29.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:30.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:30.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:30.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:31.784: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:31.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:31.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:32.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:32.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:32.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:33.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:33.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:33.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:34.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:34.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:34.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:35.782: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:35.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:35.785: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:36.786: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:36.786: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:36.792: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:37.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:37.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:37.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:38.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:38.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:38.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:39.784: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:39.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:39.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:40.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:40.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:40.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:41.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:41.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:41.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:42.783: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:42.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:42.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:43.784: INFO: Wrong image for pod: daemon-set-p9p44. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:43.784: INFO: Pod daemon-set-p9p44 is not available
Feb 27 00:06:43.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:43.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:44.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:44.784: INFO: Pod daemon-set-wpdtk is not available
Feb 27 00:06:44.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:45.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:45.782: INFO: Pod daemon-set-wpdtk is not available
Feb 27 00:06:45.785: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:46.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:46.783: INFO: Pod daemon-set-wpdtk is not available
Feb 27 00:06:46.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:47.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:47.783: INFO: Pod daemon-set-wpdtk is not available
Feb 27 00:06:47.786: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:48.786: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:48.790: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:49.796: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:49.809: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:50.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:50.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:51.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:51.789: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:52.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:52.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:53.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:53.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:54.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:54.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:55.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:55.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:56.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:56.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:57.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:57.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:58.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:58.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:06:59.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:06:59.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:00.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:00.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:01.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:01.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:02.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:02.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:03.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:03.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:04.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:04.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:05.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:05.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:06.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:06.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:07.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:07.786: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:08.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:08.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:09.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:09.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:10.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:10.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:11.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:11.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:12.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:12.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:13.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:13.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:14.784: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:14.789: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:15.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:15.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:16.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:16.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:17.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:17.788: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:18.782: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:18.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:19.783: INFO: Wrong image for pod: daemon-set-wm6bh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 00:07:19.783: INFO: Pod daemon-set-wm6bh is not available
Feb 27 00:07:19.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:20.783: INFO: Pod daemon-set-vxc7c is not available
Feb 27 00:07:20.787: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 27 00:07:20.791: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:20.794: INFO: Number of nodes with available pods: 1
Feb 27 00:07:20.794: INFO: Node 9cy76-worker-000001 is running more than one daemon pod
Feb 27 00:07:21.799: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:21.802: INFO: Number of nodes with available pods: 1
Feb 27 00:07:21.802: INFO: Node 9cy76-worker-000001 is running more than one daemon pod
Feb 27 00:07:22.800: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:22.803: INFO: Number of nodes with available pods: 1
Feb 27 00:07:22.803: INFO: Node 9cy76-worker-000001 is running more than one daemon pod
Feb 27 00:07:23.799: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:23.802: INFO: Number of nodes with available pods: 1
Feb 27 00:07:23.802: INFO: Node 9cy76-worker-000001 is running more than one daemon pod
Feb 27 00:07:24.799: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:07:24.802: INFO: Number of nodes with available pods: 2
Feb 27 00:07:24.802: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2v9j2, will wait for the garbage collector to delete the pods
Feb 27 00:07:24.880: INFO: Deleting DaemonSet.extensions daemon-set took: 10.324755ms
Feb 27 00:07:24.981: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.189233ms
Feb 27 00:07:37.284: INFO: Number of nodes with available pods: 0
Feb 27 00:07:37.284: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 00:07:37.287: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2v9j2/daemonsets","resourceVersion":"53141"},"items":null}

Feb 27 00:07:37.290: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2v9j2/pods","resourceVersion":"53141"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:07:37.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2v9j2" for this suite.
Feb 27 00:07:43.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:07:43.390: INFO: namespace: e2e-tests-daemonsets-2v9j2, resource: bindings, ignored listing per whitelist
Feb 27 00:07:43.453: INFO: namespace e2e-tests-daemonsets-2v9j2 deletion completed in 6.148118897s

• [SLOW TEST:95.959 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:07:43.455: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4wwnw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 00:07:43.678: INFO: Waiting up to 5m0s for pod "downward-api-b46b2a8c-3a23-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-4wwnw" to be "success or failure"
Feb 27 00:07:43.685: INFO: Pod "downward-api-b46b2a8c-3a23-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.726439ms
Feb 27 00:07:45.688: INFO: Pod "downward-api-b46b2a8c-3a23-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00963875s
STEP: Saw pod success
Feb 27 00:07:45.688: INFO: Pod "downward-api-b46b2a8c-3a23-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:07:45.691: INFO: Trying to get logs from node 9cy76-worker-000000 pod downward-api-b46b2a8c-3a23-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 00:07:45.730: INFO: Waiting for pod downward-api-b46b2a8c-3a23-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:07:45.748: INFO: Pod downward-api-b46b2a8c-3a23-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:07:45.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4wwnw" for this suite.
Feb 27 00:07:51.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:07:51.862: INFO: namespace: e2e-tests-downward-api-4wwnw, resource: bindings, ignored listing per whitelist
Feb 27 00:07:51.945: INFO: namespace e2e-tests-downward-api-4wwnw deletion completed in 6.179126531s

• [SLOW TEST:8.490 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:07:51.946: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-k7fc7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0227 00:08:02.227917      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 00:08:02.227: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:08:02.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k7fc7" for this suite.
Feb 27 00:08:08.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:08:08.456: INFO: namespace: e2e-tests-gc-k7fc7, resource: bindings, ignored listing per whitelist
Feb 27 00:08:08.479: INFO: namespace e2e-tests-gc-k7fc7 deletion completed in 6.248086878s

• [SLOW TEST:16.533 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:08:08.479: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-d79cq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-d79cq
Feb 27 00:08:12.710: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-d79cq
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 00:08:12.713: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:12:13.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-d79cq" for this suite.
Feb 27 00:12:19.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:12:19.368: INFO: namespace: e2e-tests-container-probe-d79cq, resource: bindings, ignored listing per whitelist
Feb 27 00:12:19.385: INFO: namespace e2e-tests-container-probe-d79cq deletion completed in 6.153677788s

• [SLOW TEST:250.906 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:12:19.385: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qcknx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:12:19.633: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 27 00:12:19.641: INFO: Number of nodes with available pods: 0
Feb 27 00:12:19.641: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 27 00:12:19.663: INFO: Number of nodes with available pods: 0
Feb 27 00:12:19.663: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:20.667: INFO: Number of nodes with available pods: 0
Feb 27 00:12:20.667: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:21.666: INFO: Number of nodes with available pods: 1
Feb 27 00:12:21.667: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 27 00:12:21.685: INFO: Number of nodes with available pods: 1
Feb 27 00:12:21.685: INFO: Number of running nodes: 0, number of available pods: 1
Feb 27 00:12:22.689: INFO: Number of nodes with available pods: 0
Feb 27 00:12:22.689: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 27 00:12:22.698: INFO: Number of nodes with available pods: 0
Feb 27 00:12:22.698: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:23.701: INFO: Number of nodes with available pods: 0
Feb 27 00:12:23.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:24.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:24.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:25.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:25.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:26.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:26.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:27.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:27.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:28.705: INFO: Number of nodes with available pods: 0
Feb 27 00:12:28.705: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:29.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:29.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:30.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:30.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:31.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:31.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:32.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:32.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:33.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:33.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:34.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:34.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:35.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:35.704: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:36.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:36.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:37.704: INFO: Number of nodes with available pods: 0
Feb 27 00:12:37.705: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:38.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:38.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:39.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:39.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:40.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:40.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:41.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:41.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:42.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:42.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:43.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:43.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:44.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:44.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:45.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:45.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:46.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:46.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:47.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:47.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:48.704: INFO: Number of nodes with available pods: 0
Feb 27 00:12:48.704: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:49.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:49.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:50.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:50.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:51.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:51.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:52.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:52.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:53.704: INFO: Number of nodes with available pods: 0
Feb 27 00:12:53.704: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:54.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:54.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:55.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:55.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:56.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:56.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:57.702: INFO: Number of nodes with available pods: 0
Feb 27 00:12:57.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:58.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:58.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:12:59.703: INFO: Number of nodes with available pods: 0
Feb 27 00:12:59.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:13:00.702: INFO: Number of nodes with available pods: 0
Feb 27 00:13:00.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:13:01.703: INFO: Number of nodes with available pods: 0
Feb 27 00:13:01.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:13:02.702: INFO: Number of nodes with available pods: 0
Feb 27 00:13:02.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:13:03.703: INFO: Number of nodes with available pods: 0
Feb 27 00:13:03.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:13:04.703: INFO: Number of nodes with available pods: 0
Feb 27 00:13:04.703: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:13:05.702: INFO: Number of nodes with available pods: 0
Feb 27 00:13:05.702: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:13:06.703: INFO: Number of nodes with available pods: 1
Feb 27 00:13:06.703: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qcknx, will wait for the garbage collector to delete the pods
Feb 27 00:13:06.769: INFO: Deleting DaemonSet.extensions daemon-set took: 7.130947ms
Feb 27 00:13:06.870: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.329572ms
Feb 27 00:13:44.473: INFO: Number of nodes with available pods: 0
Feb 27 00:13:44.473: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 00:13:44.476: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qcknx/daemonsets","resourceVersion":"54059"},"items":null}

Feb 27 00:13:44.481: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qcknx/pods","resourceVersion":"54059"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:13:44.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qcknx" for this suite.
Feb 27 00:13:50.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:13:50.581: INFO: namespace: e2e-tests-daemonsets-qcknx, resource: bindings, ignored listing per whitelist
Feb 27 00:13:50.682: INFO: namespace e2e-tests-daemonsets-qcknx deletion completed in 6.175587123s

• [SLOW TEST:91.297 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:13:50.683: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-rwhd2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 27 00:13:50.931: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rwhd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-rwhd2/configmaps/e2e-watch-test-label-changed,UID:8f4fdc27-3a24-11e9-9b3e-000d3a2390ff,ResourceVersion:54097,Generation:0,CreationTimestamp:2019-02-27 00:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 00:13:50.931: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rwhd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-rwhd2/configmaps/e2e-watch-test-label-changed,UID:8f4fdc27-3a24-11e9-9b3e-000d3a2390ff,ResourceVersion:54098,Generation:0,CreationTimestamp:2019-02-27 00:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 27 00:13:50.931: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rwhd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-rwhd2/configmaps/e2e-watch-test-label-changed,UID:8f4fdc27-3a24-11e9-9b3e-000d3a2390ff,ResourceVersion:54099,Generation:0,CreationTimestamp:2019-02-27 00:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 27 00:14:00.963: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rwhd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-rwhd2/configmaps/e2e-watch-test-label-changed,UID:8f4fdc27-3a24-11e9-9b3e-000d3a2390ff,ResourceVersion:54117,Generation:0,CreationTimestamp:2019-02-27 00:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 00:14:00.964: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rwhd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-rwhd2/configmaps/e2e-watch-test-label-changed,UID:8f4fdc27-3a24-11e9-9b3e-000d3a2390ff,ResourceVersion:54118,Generation:0,CreationTimestamp:2019-02-27 00:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 27 00:14:00.964: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-rwhd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-rwhd2/configmaps/e2e-watch-test-label-changed,UID:8f4fdc27-3a24-11e9-9b3e-000d3a2390ff,ResourceVersion:54119,Generation:0,CreationTimestamp:2019-02-27 00:13:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:14:00.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-rwhd2" for this suite.
Feb 27 00:14:06.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:14:07.084: INFO: namespace: e2e-tests-watch-rwhd2, resource: bindings, ignored listing per whitelist
Feb 27 00:14:07.100: INFO: namespace e2e-tests-watch-rwhd2 deletion completed in 6.131896084s

• [SLOW TEST:16.416 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:14:07.100: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zfv6p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 00:14:11.855: INFO: Successfully updated pod "labelsupdate99152689-3a24-11e9-9b83-4a9a78a986da"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:14:13.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zfv6p" for this suite.
Feb 27 00:14:35.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:14:35.934: INFO: namespace: e2e-tests-downward-api-zfv6p, resource: bindings, ignored listing per whitelist
Feb 27 00:14:36.009: INFO: namespace e2e-tests-downward-api-zfv6p deletion completed in 22.123821332s

• [SLOW TEST:28.909 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:14:36.010: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-skpgr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-skpgr
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 27 00:14:36.242: INFO: Found 0 stateful pods, waiting for 3
Feb 27 00:14:46.248: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 00:14:46.248: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 00:14:46.248: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 27 00:14:46.280: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 27 00:14:56.338: INFO: Updating stateful set ss2
Feb 27 00:14:56.351: INFO: Waiting for Pod e2e-tests-statefulset-skpgr/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 27 00:15:06.466: INFO: Found 2 stateful pods, waiting for 3
Feb 27 00:15:16.471: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 00:15:16.471: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 00:15:16.471: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 27 00:15:16.499: INFO: Updating stateful set ss2
Feb 27 00:15:16.512: INFO: Waiting for Pod e2e-tests-statefulset-skpgr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 27 00:15:26.521: INFO: Waiting for Pod e2e-tests-statefulset-skpgr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 27 00:15:36.538: INFO: Updating stateful set ss2
Feb 27 00:15:36.551: INFO: Waiting for StatefulSet e2e-tests-statefulset-skpgr/ss2 to complete update
Feb 27 00:15:36.551: INFO: Waiting for Pod e2e-tests-statefulset-skpgr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 00:15:46.559: INFO: Deleting all statefulset in ns e2e-tests-statefulset-skpgr
Feb 27 00:15:46.562: INFO: Scaling statefulset ss2 to 0
Feb 27 00:16:06.576: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 00:16:06.579: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:16:06.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-skpgr" for this suite.
Feb 27 00:16:12.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:16:12.672: INFO: namespace: e2e-tests-statefulset-skpgr, resource: bindings, ignored listing per whitelist
Feb 27 00:16:12.726: INFO: namespace e2e-tests-statefulset-skpgr deletion completed in 6.129381578s

• [SLOW TEST:96.717 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:16:12.727: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-ncw5b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-ncw5b
I0227 00:16:12.936711      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-ncw5b, replica count: 1
I0227 00:16:13.987244      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 00:16:14.987461      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 00:16:15.987693      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 00:16:16.987891      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 27 00:16:17.111: INFO: Created: latency-svc-kpmh6
Feb 27 00:16:17.123: INFO: Got endpoints: latency-svc-kpmh6 [35.410842ms]
Feb 27 00:16:17.146: INFO: Created: latency-svc-wsnd8
Feb 27 00:16:17.168: INFO: Got endpoints: latency-svc-wsnd8 [43.720775ms]
Feb 27 00:16:17.168: INFO: Created: latency-svc-rjg8t
Feb 27 00:16:17.176: INFO: Got endpoints: latency-svc-rjg8t [51.910508ms]
Feb 27 00:16:17.188: INFO: Created: latency-svc-pcbks
Feb 27 00:16:17.196: INFO: Created: latency-svc-67rqv
Feb 27 00:16:17.198: INFO: Got endpoints: latency-svc-pcbks [74.362697ms]
Feb 27 00:16:17.213: INFO: Got endpoints: latency-svc-67rqv [89.306158ms]
Feb 27 00:16:17.214: INFO: Created: latency-svc-t4zt4
Feb 27 00:16:17.226: INFO: Created: latency-svc-nnz9l
Feb 27 00:16:17.226: INFO: Got endpoints: latency-svc-t4zt4 [101.801707ms]
Feb 27 00:16:17.234: INFO: Got endpoints: latency-svc-nnz9l [109.74994ms]
Feb 27 00:16:17.236: INFO: Created: latency-svc-srxsd
Feb 27 00:16:17.240: INFO: Got endpoints: latency-svc-srxsd [116.013465ms]
Feb 27 00:16:17.247: INFO: Created: latency-svc-gwc26
Feb 27 00:16:17.258: INFO: Got endpoints: latency-svc-gwc26 [133.321533ms]
Feb 27 00:16:17.264: INFO: Created: latency-svc-4tj4p
Feb 27 00:16:17.278: INFO: Got endpoints: latency-svc-4tj4p [153.156113ms]
Feb 27 00:16:17.283: INFO: Created: latency-svc-qnzdn
Feb 27 00:16:17.305: INFO: Created: latency-svc-w26hp
Feb 27 00:16:17.305: INFO: Got endpoints: latency-svc-qnzdn [180.829524ms]
Feb 27 00:16:17.310: INFO: Got endpoints: latency-svc-w26hp [185.841544ms]
Feb 27 00:16:17.313: INFO: Created: latency-svc-d572l
Feb 27 00:16:17.323: INFO: Got endpoints: latency-svc-d572l [198.093393ms]
Feb 27 00:16:17.327: INFO: Created: latency-svc-dmslz
Feb 27 00:16:17.333: INFO: Got endpoints: latency-svc-dmslz [207.878733ms]
Feb 27 00:16:17.337: INFO: Created: latency-svc-qsdck
Feb 27 00:16:17.346: INFO: Got endpoints: latency-svc-qsdck [221.481987ms]
Feb 27 00:16:17.348: INFO: Created: latency-svc-kwjpj
Feb 27 00:16:17.353: INFO: Got endpoints: latency-svc-kwjpj [228.579216ms]
Feb 27 00:16:17.362: INFO: Created: latency-svc-4nxk5
Feb 27 00:16:17.375: INFO: Got endpoints: latency-svc-4nxk5 [206.804328ms]
Feb 27 00:16:17.379: INFO: Created: latency-svc-rz7nl
Feb 27 00:16:17.397: INFO: Got endpoints: latency-svc-rz7nl [219.972781ms]
Feb 27 00:16:17.398: INFO: Created: latency-svc-kg244
Feb 27 00:16:17.408: INFO: Created: latency-svc-gckvn
Feb 27 00:16:17.412: INFO: Got endpoints: latency-svc-kg244 [211.988449ms]
Feb 27 00:16:17.418: INFO: Got endpoints: latency-svc-gckvn [204.686719ms]
Feb 27 00:16:17.430: INFO: Created: latency-svc-gz9f6
Feb 27 00:16:17.441: INFO: Created: latency-svc-bf49h
Feb 27 00:16:17.445: INFO: Got endpoints: latency-svc-gz9f6 [215.853064ms]
Feb 27 00:16:17.449: INFO: Got endpoints: latency-svc-bf49h [215.203962ms]
Feb 27 00:16:17.466: INFO: Created: latency-svc-2vtfz
Feb 27 00:16:17.473: INFO: Got endpoints: latency-svc-2vtfz [232.999933ms]
Feb 27 00:16:17.479: INFO: Created: latency-svc-x9cwd
Feb 27 00:16:17.481: INFO: Got endpoints: latency-svc-x9cwd [223.247994ms]
Feb 27 00:16:17.486: INFO: Created: latency-svc-54c96
Feb 27 00:16:17.497: INFO: Created: latency-svc-tbpdk
Feb 27 00:16:17.499: INFO: Got endpoints: latency-svc-54c96 [221.367787ms]
Feb 27 00:16:17.510: INFO: Got endpoints: latency-svc-tbpdk [199.7995ms]
Feb 27 00:16:17.515: INFO: Created: latency-svc-gg8w7
Feb 27 00:16:17.532: INFO: Got endpoints: latency-svc-gg8w7 [221.959089ms]
Feb 27 00:16:17.536: INFO: Created: latency-svc-7mnfb
Feb 27 00:16:17.542: INFO: Created: latency-svc-9bwrw
Feb 27 00:16:17.546: INFO: Got endpoints: latency-svc-7mnfb [223.256794ms]
Feb 27 00:16:17.557: INFO: Created: latency-svc-8zs94
Feb 27 00:16:17.557: INFO: Got endpoints: latency-svc-9bwrw [224.160897ms]
Feb 27 00:16:17.569: INFO: Got endpoints: latency-svc-8zs94 [222.770092ms]
Feb 27 00:16:17.572: INFO: Created: latency-svc-4vhct
Feb 27 00:16:17.574: INFO: Got endpoints: latency-svc-4vhct [220.408083ms]
Feb 27 00:16:17.587: INFO: Created: latency-svc-5zjhs
Feb 27 00:16:17.596: INFO: Got endpoints: latency-svc-5zjhs [221.050385ms]
Feb 27 00:16:17.597: INFO: Created: latency-svc-c7jdj
Feb 27 00:16:17.603: INFO: Created: latency-svc-w4tvf
Feb 27 00:16:17.625: INFO: Got endpoints: latency-svc-c7jdj [227.970812ms]
Feb 27 00:16:17.625: INFO: Got endpoints: latency-svc-w4tvf [212.968752ms]
Feb 27 00:16:17.630: INFO: Created: latency-svc-6xm5l
Feb 27 00:16:17.635: INFO: Got endpoints: latency-svc-6xm5l [216.458967ms]
Feb 27 00:16:17.641: INFO: Created: latency-svc-kk5cd
Feb 27 00:16:17.647: INFO: Got endpoints: latency-svc-kk5cd [201.071605ms]
Feb 27 00:16:17.656: INFO: Created: latency-svc-7phk6
Feb 27 00:16:17.664: INFO: Created: latency-svc-qdsvd
Feb 27 00:16:17.666: INFO: Got endpoints: latency-svc-7phk6 [216.335666ms]
Feb 27 00:16:17.677: INFO: Created: latency-svc-dsxvr
Feb 27 00:16:17.679: INFO: Got endpoints: latency-svc-qdsvd [205.668924ms]
Feb 27 00:16:17.692: INFO: Got endpoints: latency-svc-dsxvr [208.920137ms]
Feb 27 00:16:17.696: INFO: Created: latency-svc-dkj8v
Feb 27 00:16:17.706: INFO: Got endpoints: latency-svc-dkj8v [207.029029ms]
Feb 27 00:16:17.709: INFO: Created: latency-svc-l858c
Feb 27 00:16:17.712: INFO: Got endpoints: latency-svc-l858c [201.592307ms]
Feb 27 00:16:17.720: INFO: Created: latency-svc-v2dlm
Feb 27 00:16:17.746: INFO: Got endpoints: latency-svc-v2dlm [214.525759ms]
Feb 27 00:16:17.748: INFO: Created: latency-svc-hr9fm
Feb 27 00:16:17.767: INFO: Created: latency-svc-6hkht
Feb 27 00:16:17.777: INFO: Created: latency-svc-jmd8n
Feb 27 00:16:17.779: INFO: Got endpoints: latency-svc-hr9fm [232.711431ms]
Feb 27 00:16:17.790: INFO: Created: latency-svc-xkmc8
Feb 27 00:16:17.810: INFO: Created: latency-svc-pdrqh
Feb 27 00:16:17.816: INFO: Got endpoints: latency-svc-6hkht [256.135426ms]
Feb 27 00:16:17.819: INFO: Created: latency-svc-mg6th
Feb 27 00:16:17.827: INFO: Created: latency-svc-fhldx
Feb 27 00:16:17.839: INFO: Created: latency-svc-xqt5l
Feb 27 00:16:17.859: INFO: Created: latency-svc-gzr4f
Feb 27 00:16:17.873: INFO: Got endpoints: latency-svc-jmd8n [303.652716ms]
Feb 27 00:16:17.874: INFO: Created: latency-svc-xj5dt
Feb 27 00:16:17.883: INFO: Created: latency-svc-n2k8t
Feb 27 00:16:17.896: INFO: Created: latency-svc-nw556
Feb 27 00:16:17.906: INFO: Created: latency-svc-rbg9x
Feb 27 00:16:17.918: INFO: Got endpoints: latency-svc-xkmc8 [344.051478ms]
Feb 27 00:16:17.923: INFO: Created: latency-svc-m5dd8
Feb 27 00:16:17.929: INFO: Created: latency-svc-sjqwz
Feb 27 00:16:17.946: INFO: Created: latency-svc-9k5nk
Feb 27 00:16:17.950: INFO: Created: latency-svc-86647
Feb 27 00:16:17.973: INFO: Created: latency-svc-9tsxn
Feb 27 00:16:17.980: INFO: Got endpoints: latency-svc-pdrqh [383.844238ms]
Feb 27 00:16:17.985: INFO: Created: latency-svc-5d8g6
Feb 27 00:16:17.997: INFO: Created: latency-svc-lqfl6
Feb 27 00:16:18.015: INFO: Got endpoints: latency-svc-mg6th [389.444859ms]
Feb 27 00:16:18.037: INFO: Created: latency-svc-nfbbr
Feb 27 00:16:18.069: INFO: Got endpoints: latency-svc-fhldx [443.099075ms]
Feb 27 00:16:18.105: INFO: Created: latency-svc-vb59j
Feb 27 00:16:18.116: INFO: Got endpoints: latency-svc-xqt5l [480.910226ms]
Feb 27 00:16:18.139: INFO: Created: latency-svc-7rrlj
Feb 27 00:16:18.165: INFO: Got endpoints: latency-svc-gzr4f [518.273376ms]
Feb 27 00:16:18.184: INFO: Created: latency-svc-lxkbl
Feb 27 00:16:18.218: INFO: Got endpoints: latency-svc-xj5dt [552.009111ms]
Feb 27 00:16:18.238: INFO: Created: latency-svc-2g9ld
Feb 27 00:16:18.266: INFO: Got endpoints: latency-svc-n2k8t [586.680251ms]
Feb 27 00:16:18.286: INFO: Created: latency-svc-d6hqm
Feb 27 00:16:18.315: INFO: Got endpoints: latency-svc-nw556 [622.723195ms]
Feb 27 00:16:18.384: INFO: Got endpoints: latency-svc-rbg9x [678.078317ms]
Feb 27 00:16:18.385: INFO: Created: latency-svc-rz46s
Feb 27 00:16:18.402: INFO: Created: latency-svc-xz9xk
Feb 27 00:16:18.428: INFO: Got endpoints: latency-svc-m5dd8 [716.32217ms]
Feb 27 00:16:18.555: INFO: Created: latency-svc-wg6j6
Feb 27 00:16:18.555: INFO: Got endpoints: latency-svc-9k5nk [776.07641ms]
Feb 27 00:16:18.556: INFO: Got endpoints: latency-svc-sjqwz [809.225143ms]
Feb 27 00:16:18.573: INFO: Got endpoints: latency-svc-86647 [756.344131ms]
Feb 27 00:16:18.596: INFO: Created: latency-svc-69n79
Feb 27 00:16:18.596: INFO: Created: latency-svc-vkdzc
Feb 27 00:16:18.600: INFO: Created: latency-svc-khq6d
Feb 27 00:16:18.616: INFO: Got endpoints: latency-svc-9tsxn [742.085075ms]
Feb 27 00:16:18.645: INFO: Created: latency-svc-cmw6d
Feb 27 00:16:18.674: INFO: Got endpoints: latency-svc-5d8g6 [756.213031ms]
Feb 27 00:16:18.687: INFO: Created: latency-svc-pg7fz
Feb 27 00:16:18.717: INFO: Got endpoints: latency-svc-lqfl6 [737.082554ms]
Feb 27 00:16:18.737: INFO: Created: latency-svc-dbq4v
Feb 27 00:16:18.768: INFO: Got endpoints: latency-svc-nfbbr [752.520117ms]
Feb 27 00:16:18.794: INFO: Created: latency-svc-spqwm
Feb 27 00:16:18.907: INFO: Got endpoints: latency-svc-7rrlj [791.484373ms]
Feb 27 00:16:18.908: INFO: Got endpoints: latency-svc-vb59j [837.648858ms]
Feb 27 00:16:18.920: INFO: Got endpoints: latency-svc-lxkbl [754.722626ms]
Feb 27 00:16:18.923: INFO: Created: latency-svc-9r2jq
Feb 27 00:16:18.966: INFO: Got endpoints: latency-svc-2g9ld [747.863898ms]
Feb 27 00:16:18.967: INFO: Created: latency-svc-qcdzm
Feb 27 00:16:18.967: INFO: Created: latency-svc-42lnh
Feb 27 00:16:18.983: INFO: Created: latency-svc-hhbw4
Feb 27 00:16:19.016: INFO: Got endpoints: latency-svc-d6hqm [747.044395ms]
Feb 27 00:16:19.031: INFO: Created: latency-svc-2j4n8
Feb 27 00:16:19.076: INFO: Got endpoints: latency-svc-rz46s [761.135651ms]
Feb 27 00:16:19.097: INFO: Created: latency-svc-zdrgr
Feb 27 00:16:19.114: INFO: Got endpoints: latency-svc-xz9xk [729.432525ms]
Feb 27 00:16:19.136: INFO: Created: latency-svc-85t5m
Feb 27 00:16:19.164: INFO: Got endpoints: latency-svc-wg6j6 [735.355349ms]
Feb 27 00:16:19.185: INFO: Created: latency-svc-4s89w
Feb 27 00:16:19.214: INFO: Got endpoints: latency-svc-69n79 [658.44464ms]
Feb 27 00:16:19.236: INFO: Created: latency-svc-jpj5b
Feb 27 00:16:19.269: INFO: Got endpoints: latency-svc-vkdzc [712.741059ms]
Feb 27 00:16:19.285: INFO: Created: latency-svc-kjnrp
Feb 27 00:16:19.322: INFO: Got endpoints: latency-svc-khq6d [744.710287ms]
Feb 27 00:16:19.349: INFO: Created: latency-svc-6wshw
Feb 27 00:16:19.365: INFO: Got endpoints: latency-svc-cmw6d [749.511406ms]
Feb 27 00:16:19.379: INFO: Created: latency-svc-8d4f5
Feb 27 00:16:19.415: INFO: Got endpoints: latency-svc-pg7fz [740.023068ms]
Feb 27 00:16:19.430: INFO: Created: latency-svc-xbvbh
Feb 27 00:16:19.467: INFO: Got endpoints: latency-svc-dbq4v [748.787604ms]
Feb 27 00:16:19.480: INFO: Created: latency-svc-vv7n4
Feb 27 00:16:19.520: INFO: Got endpoints: latency-svc-spqwm [746.426895ms]
Feb 27 00:16:19.536: INFO: Created: latency-svc-mndwl
Feb 27 00:16:19.563: INFO: Got endpoints: latency-svc-9r2jq [655.944132ms]
Feb 27 00:16:19.579: INFO: Created: latency-svc-xfcj2
Feb 27 00:16:19.615: INFO: Got endpoints: latency-svc-42lnh [706.833736ms]
Feb 27 00:16:19.637: INFO: Created: latency-svc-8hjm2
Feb 27 00:16:19.666: INFO: Got endpoints: latency-svc-qcdzm [746.170095ms]
Feb 27 00:16:19.685: INFO: Created: latency-svc-4dnhw
Feb 27 00:16:19.717: INFO: Got endpoints: latency-svc-hhbw4 [750.417312ms]
Feb 27 00:16:19.747: INFO: Created: latency-svc-9sd59
Feb 27 00:16:19.765: INFO: Got endpoints: latency-svc-2j4n8 [748.826305ms]
Feb 27 00:16:19.777: INFO: Created: latency-svc-8647c
Feb 27 00:16:19.819: INFO: Got endpoints: latency-svc-zdrgr [740.323771ms]
Feb 27 00:16:19.832: INFO: Created: latency-svc-2bmv2
Feb 27 00:16:19.872: INFO: Got endpoints: latency-svc-85t5m [758.336644ms]
Feb 27 00:16:19.888: INFO: Created: latency-svc-b7zg9
Feb 27 00:16:19.913: INFO: Got endpoints: latency-svc-4s89w [748.891806ms]
Feb 27 00:16:19.925: INFO: Created: latency-svc-4qs7n
Feb 27 00:16:19.971: INFO: Got endpoints: latency-svc-jpj5b [756.805438ms]
Feb 27 00:16:19.984: INFO: Created: latency-svc-mvh7g
Feb 27 00:16:20.016: INFO: Got endpoints: latency-svc-kjnrp [746.916998ms]
Feb 27 00:16:20.028: INFO: Created: latency-svc-rghpj
Feb 27 00:16:20.066: INFO: Got endpoints: latency-svc-6wshw [743.460884ms]
Feb 27 00:16:20.113: INFO: Created: latency-svc-58pl4
Feb 27 00:16:20.116: INFO: Got endpoints: latency-svc-8d4f5 [750.920815ms]
Feb 27 00:16:20.128: INFO: Created: latency-svc-mjn9d
Feb 27 00:16:20.165: INFO: Got endpoints: latency-svc-xbvbh [749.353908ms]
Feb 27 00:16:20.190: INFO: Created: latency-svc-9xtvn
Feb 27 00:16:20.218: INFO: Got endpoints: latency-svc-vv7n4 [750.494913ms]
Feb 27 00:16:20.264: INFO: Created: latency-svc-ddssw
Feb 27 00:16:20.267: INFO: Got endpoints: latency-svc-mndwl [745.982795ms]
Feb 27 00:16:20.282: INFO: Created: latency-svc-ttq9h
Feb 27 00:16:20.315: INFO: Got endpoints: latency-svc-xfcj2 [751.662619ms]
Feb 27 00:16:20.339: INFO: Created: latency-svc-226rn
Feb 27 00:16:20.368: INFO: Got endpoints: latency-svc-8hjm2 [752.565022ms]
Feb 27 00:16:20.382: INFO: Created: latency-svc-h6qdv
Feb 27 00:16:20.417: INFO: Got endpoints: latency-svc-4dnhw [750.961616ms]
Feb 27 00:16:20.436: INFO: Created: latency-svc-psvb9
Feb 27 00:16:20.479: INFO: Got endpoints: latency-svc-9sd59 [761.90166ms]
Feb 27 00:16:20.523: INFO: Created: latency-svc-bsvh9
Feb 27 00:16:20.528: INFO: Got endpoints: latency-svc-8647c [762.924965ms]
Feb 27 00:16:20.544: INFO: Created: latency-svc-28rhc
Feb 27 00:16:20.565: INFO: Got endpoints: latency-svc-2bmv2 [745.548395ms]
Feb 27 00:16:20.580: INFO: Created: latency-svc-mgvs4
Feb 27 00:16:20.616: INFO: Got endpoints: latency-svc-b7zg9 [742.773284ms]
Feb 27 00:16:20.651: INFO: Created: latency-svc-76lhc
Feb 27 00:16:20.664: INFO: Got endpoints: latency-svc-4qs7n [750.965117ms]
Feb 27 00:16:20.678: INFO: Created: latency-svc-555sz
Feb 27 00:16:20.714: INFO: Got endpoints: latency-svc-mvh7g [743.118486ms]
Feb 27 00:16:20.728: INFO: Created: latency-svc-fg5mf
Feb 27 00:16:20.764: INFO: Got endpoints: latency-svc-rghpj [747.962105ms]
Feb 27 00:16:20.778: INFO: Created: latency-svc-2bp9v
Feb 27 00:16:20.815: INFO: Got endpoints: latency-svc-58pl4 [748.321806ms]
Feb 27 00:16:20.827: INFO: Created: latency-svc-fsbz8
Feb 27 00:16:20.864: INFO: Got endpoints: latency-svc-mjn9d [747.719204ms]
Feb 27 00:16:20.885: INFO: Created: latency-svc-5vjth
Feb 27 00:16:20.916: INFO: Got endpoints: latency-svc-9xtvn [751.445419ms]
Feb 27 00:16:20.928: INFO: Created: latency-svc-rpbs4
Feb 27 00:16:20.965: INFO: Got endpoints: latency-svc-ddssw [746.6586ms]
Feb 27 00:16:20.985: INFO: Created: latency-svc-w29c4
Feb 27 00:16:21.013: INFO: Got endpoints: latency-svc-ttq9h [746.6237ms]
Feb 27 00:16:21.028: INFO: Created: latency-svc-mzj8s
Feb 27 00:16:21.066: INFO: Got endpoints: latency-svc-226rn [750.663316ms]
Feb 27 00:16:21.089: INFO: Created: latency-svc-xh4r9
Feb 27 00:16:21.117: INFO: Got endpoints: latency-svc-h6qdv [749.488412ms]
Feb 27 00:16:21.133: INFO: Created: latency-svc-b69ml
Feb 27 00:16:21.163: INFO: Got endpoints: latency-svc-psvb9 [745.774497ms]
Feb 27 00:16:21.198: INFO: Created: latency-svc-zbxm6
Feb 27 00:16:21.219: INFO: Got endpoints: latency-svc-bsvh9 [734.684453ms]
Feb 27 00:16:21.232: INFO: Created: latency-svc-bq7qg
Feb 27 00:16:21.264: INFO: Got endpoints: latency-svc-28rhc [735.556556ms]
Feb 27 00:16:21.279: INFO: Created: latency-svc-hpdwx
Feb 27 00:16:21.313: INFO: Got endpoints: latency-svc-mgvs4 [748.370209ms]
Feb 27 00:16:21.327: INFO: Created: latency-svc-rtdgt
Feb 27 00:16:21.365: INFO: Got endpoints: latency-svc-76lhc [748.73901ms]
Feb 27 00:16:21.377: INFO: Created: latency-svc-rzqwf
Feb 27 00:16:21.417: INFO: Got endpoints: latency-svc-555sz [751.977023ms]
Feb 27 00:16:21.430: INFO: Created: latency-svc-vgkxn
Feb 27 00:16:21.466: INFO: Got endpoints: latency-svc-fg5mf [751.818723ms]
Feb 27 00:16:21.478: INFO: Created: latency-svc-42gmp
Feb 27 00:16:21.517: INFO: Got endpoints: latency-svc-2bp9v [752.448526ms]
Feb 27 00:16:21.536: INFO: Created: latency-svc-6vnpd
Feb 27 00:16:21.564: INFO: Got endpoints: latency-svc-fsbz8 [749.025313ms]
Feb 27 00:16:21.578: INFO: Created: latency-svc-7fp7j
Feb 27 00:16:21.613: INFO: Got endpoints: latency-svc-5vjth [749.068813ms]
Feb 27 00:16:21.629: INFO: Created: latency-svc-lqqxv
Feb 27 00:16:21.665: INFO: Got endpoints: latency-svc-rpbs4 [748.20411ms]
Feb 27 00:16:21.678: INFO: Created: latency-svc-qd5gr
Feb 27 00:16:21.714: INFO: Got endpoints: latency-svc-w29c4 [748.718212ms]
Feb 27 00:16:21.727: INFO: Created: latency-svc-h6jl4
Feb 27 00:16:21.767: INFO: Got endpoints: latency-svc-mzj8s [753.608031ms]
Feb 27 00:16:21.779: INFO: Created: latency-svc-btbdt
Feb 27 00:16:21.815: INFO: Got endpoints: latency-svc-xh4r9 [748.497411ms]
Feb 27 00:16:21.837: INFO: Created: latency-svc-kfl2m
Feb 27 00:16:21.867: INFO: Got endpoints: latency-svc-b69ml [749.241014ms]
Feb 27 00:16:21.883: INFO: Created: latency-svc-czmxs
Feb 27 00:16:21.913: INFO: Got endpoints: latency-svc-zbxm6 [749.455915ms]
Feb 27 00:16:21.931: INFO: Created: latency-svc-8m5nk
Feb 27 00:16:21.965: INFO: Got endpoints: latency-svc-bq7qg [745.560799ms]
Feb 27 00:16:21.997: INFO: Created: latency-svc-t7g2n
Feb 27 00:16:22.016: INFO: Got endpoints: latency-svc-hpdwx [751.515623ms]
Feb 27 00:16:22.028: INFO: Created: latency-svc-mqf24
Feb 27 00:16:22.065: INFO: Got endpoints: latency-svc-rtdgt [751.417223ms]
Feb 27 00:16:22.101: INFO: Created: latency-svc-vs95d
Feb 27 00:16:22.121: INFO: Got endpoints: latency-svc-rzqwf [755.013238ms]
Feb 27 00:16:22.132: INFO: Created: latency-svc-xx9q9
Feb 27 00:16:22.166: INFO: Got endpoints: latency-svc-vgkxn [748.795513ms]
Feb 27 00:16:22.185: INFO: Created: latency-svc-mn2b8
Feb 27 00:16:22.219: INFO: Got endpoints: latency-svc-42gmp [752.057826ms]
Feb 27 00:16:22.237: INFO: Created: latency-svc-6ffh6
Feb 27 00:16:22.263: INFO: Got endpoints: latency-svc-6vnpd [746.604705ms]
Feb 27 00:16:22.278: INFO: Created: latency-svc-2t7dl
Feb 27 00:16:22.316: INFO: Got endpoints: latency-svc-7fp7j [751.787625ms]
Feb 27 00:16:22.331: INFO: Created: latency-svc-4n7hg
Feb 27 00:16:22.366: INFO: Got endpoints: latency-svc-lqqxv [752.702129ms]
Feb 27 00:16:22.381: INFO: Created: latency-svc-rjd6f
Feb 27 00:16:22.417: INFO: Got endpoints: latency-svc-qd5gr [751.990727ms]
Feb 27 00:16:22.452: INFO: Created: latency-svc-7j72b
Feb 27 00:16:22.465: INFO: Got endpoints: latency-svc-h6jl4 [751.427625ms]
Feb 27 00:16:22.477: INFO: Created: latency-svc-tbxb4
Feb 27 00:16:22.519: INFO: Got endpoints: latency-svc-btbdt [751.644526ms]
Feb 27 00:16:22.546: INFO: Created: latency-svc-cf67j
Feb 27 00:16:22.564: INFO: Got endpoints: latency-svc-kfl2m [749.482118ms]
Feb 27 00:16:22.576: INFO: Created: latency-svc-nbb4d
Feb 27 00:16:22.647: INFO: Got endpoints: latency-svc-czmxs [780.08174ms]
Feb 27 00:16:22.671: INFO: Got endpoints: latency-svc-8m5nk [757.929152ms]
Feb 27 00:16:22.678: INFO: Created: latency-svc-vrqwp
Feb 27 00:16:22.688: INFO: Created: latency-svc-pr4nh
Feb 27 00:16:22.716: INFO: Got endpoints: latency-svc-t7g2n [751.604227ms]
Feb 27 00:16:22.730: INFO: Created: latency-svc-9gknt
Feb 27 00:16:22.771: INFO: Got endpoints: latency-svc-mqf24 [754.324438ms]
Feb 27 00:16:22.788: INFO: Created: latency-svc-v965p
Feb 27 00:16:22.816: INFO: Got endpoints: latency-svc-vs95d [751.338526ms]
Feb 27 00:16:22.829: INFO: Created: latency-svc-9fwp5
Feb 27 00:16:22.866: INFO: Got endpoints: latency-svc-xx9q9 [745.353902ms]
Feb 27 00:16:22.891: INFO: Created: latency-svc-g8ncs
Feb 27 00:16:22.915: INFO: Got endpoints: latency-svc-mn2b8 [748.545814ms]
Feb 27 00:16:22.928: INFO: Created: latency-svc-nk2mb
Feb 27 00:16:22.965: INFO: Got endpoints: latency-svc-6ffh6 [746.247106ms]
Feb 27 00:16:22.980: INFO: Created: latency-svc-6djv7
Feb 27 00:16:23.015: INFO: Got endpoints: latency-svc-2t7dl [751.752628ms]
Feb 27 00:16:23.027: INFO: Created: latency-svc-bnj4s
Feb 27 00:16:23.063: INFO: Got endpoints: latency-svc-4n7hg [747.038608ms]
Feb 27 00:16:23.078: INFO: Created: latency-svc-gl6g8
Feb 27 00:16:23.117: INFO: Got endpoints: latency-svc-rjd6f [751.247726ms]
Feb 27 00:16:23.133: INFO: Created: latency-svc-sr4kj
Feb 27 00:16:23.163: INFO: Got endpoints: latency-svc-7j72b [745.364102ms]
Feb 27 00:16:23.195: INFO: Created: latency-svc-c9fhn
Feb 27 00:16:23.214: INFO: Got endpoints: latency-svc-tbxb4 [749.151718ms]
Feb 27 00:16:23.227: INFO: Created: latency-svc-c9ndl
Feb 27 00:16:23.266: INFO: Got endpoints: latency-svc-cf67j [747.394711ms]
Feb 27 00:16:23.278: INFO: Created: latency-svc-8m9v9
Feb 27 00:16:23.325: INFO: Got endpoints: latency-svc-nbb4d [760.859866ms]
Feb 27 00:16:23.344: INFO: Created: latency-svc-9rnwr
Feb 27 00:16:23.364: INFO: Got endpoints: latency-svc-vrqwp [717.36659ms]
Feb 27 00:16:23.376: INFO: Created: latency-svc-bcgkb
Feb 27 00:16:23.415: INFO: Got endpoints: latency-svc-pr4nh [743.622196ms]
Feb 27 00:16:23.447: INFO: Created: latency-svc-jv8kz
Feb 27 00:16:23.465: INFO: Got endpoints: latency-svc-9gknt [748.870717ms]
Feb 27 00:16:23.477: INFO: Created: latency-svc-8xrj6
Feb 27 00:16:23.514: INFO: Got endpoints: latency-svc-v965p [743.315496ms]
Feb 27 00:16:23.527: INFO: Created: latency-svc-2v9w8
Feb 27 00:16:23.567: INFO: Got endpoints: latency-svc-9fwp5 [750.265824ms]
Feb 27 00:16:23.589: INFO: Created: latency-svc-kjqx5
Feb 27 00:16:23.614: INFO: Got endpoints: latency-svc-g8ncs [747.595814ms]
Feb 27 00:16:23.627: INFO: Created: latency-svc-wl2sw
Feb 27 00:16:23.665: INFO: Got endpoints: latency-svc-nk2mb [750.281525ms]
Feb 27 00:16:23.681: INFO: Created: latency-svc-vpdhv
Feb 27 00:16:23.715: INFO: Got endpoints: latency-svc-6djv7 [750.039024ms]
Feb 27 00:16:23.732: INFO: Created: latency-svc-r8pm9
Feb 27 00:16:23.780: INFO: Got endpoints: latency-svc-bnj4s [764.04988ms]
Feb 27 00:16:23.830: INFO: Got endpoints: latency-svc-gl6g8 [766.44939ms]
Feb 27 00:16:23.831: INFO: Created: latency-svc-d496v
Feb 27 00:16:23.847: INFO: Created: latency-svc-8t7qm
Feb 27 00:16:23.863: INFO: Got endpoints: latency-svc-sr4kj [745.646706ms]
Feb 27 00:16:23.877: INFO: Created: latency-svc-mv95w
Feb 27 00:16:23.913: INFO: Got endpoints: latency-svc-c9fhn [750.102425ms]
Feb 27 00:16:23.930: INFO: Created: latency-svc-f2456
Feb 27 00:16:23.966: INFO: Got endpoints: latency-svc-c9ndl [751.141228ms]
Feb 27 00:16:23.979: INFO: Created: latency-svc-wvwgq
Feb 27 00:16:24.016: INFO: Got endpoints: latency-svc-8m9v9 [748.240017ms]
Feb 27 00:16:24.045: INFO: Created: latency-svc-hcqlw
Feb 27 00:16:24.063: INFO: Got endpoints: latency-svc-9rnwr [738.006975ms]
Feb 27 00:16:24.084: INFO: Created: latency-svc-ffrdp
Feb 27 00:16:24.116: INFO: Got endpoints: latency-svc-bcgkb [751.642231ms]
Feb 27 00:16:24.133: INFO: Created: latency-svc-cvv79
Feb 27 00:16:24.165: INFO: Got endpoints: latency-svc-jv8kz [750.046125ms]
Feb 27 00:16:24.186: INFO: Created: latency-svc-mkhg7
Feb 27 00:16:24.228: INFO: Got endpoints: latency-svc-8xrj6 [762.363274ms]
Feb 27 00:16:24.247: INFO: Created: latency-svc-znvgh
Feb 27 00:16:24.265: INFO: Got endpoints: latency-svc-2v9w8 [750.278327ms]
Feb 27 00:16:24.279: INFO: Created: latency-svc-jnmqm
Feb 27 00:16:24.317: INFO: Got endpoints: latency-svc-kjqx5 [749.567424ms]
Feb 27 00:16:24.346: INFO: Created: latency-svc-dgn4r
Feb 27 00:16:24.366: INFO: Got endpoints: latency-svc-wl2sw [752.082233ms]
Feb 27 00:16:24.378: INFO: Created: latency-svc-6rcb2
Feb 27 00:16:24.423: INFO: Got endpoints: latency-svc-vpdhv [757.757057ms]
Feb 27 00:16:24.465: INFO: Got endpoints: latency-svc-r8pm9 [749.338323ms]
Feb 27 00:16:24.466: INFO: Created: latency-svc-nvnxt
Feb 27 00:16:24.480: INFO: Created: latency-svc-vpfk9
Feb 27 00:16:24.518: INFO: Got endpoints: latency-svc-d496v [738.54318ms]
Feb 27 00:16:24.533: INFO: Created: latency-svc-w88xs
Feb 27 00:16:24.565: INFO: Got endpoints: latency-svc-8t7qm [734.870066ms]
Feb 27 00:16:24.580: INFO: Created: latency-svc-94dpz
Feb 27 00:16:24.614: INFO: Got endpoints: latency-svc-mv95w [750.499529ms]
Feb 27 00:16:24.629: INFO: Created: latency-svc-msk28
Feb 27 00:16:24.664: INFO: Got endpoints: latency-svc-f2456 [750.92083ms]
Feb 27 00:16:24.685: INFO: Created: latency-svc-qbkcw
Feb 27 00:16:24.715: INFO: Got endpoints: latency-svc-wvwgq [748.21812ms]
Feb 27 00:16:24.732: INFO: Created: latency-svc-w52b5
Feb 27 00:16:24.767: INFO: Got endpoints: latency-svc-hcqlw [751.082831ms]
Feb 27 00:16:24.795: INFO: Created: latency-svc-zpkxz
Feb 27 00:16:24.820: INFO: Got endpoints: latency-svc-ffrdp [756.528154ms]
Feb 27 00:16:24.832: INFO: Created: latency-svc-5kg5g
Feb 27 00:16:24.865: INFO: Got endpoints: latency-svc-cvv79 [748.736322ms]
Feb 27 00:16:24.878: INFO: Created: latency-svc-f9249
Feb 27 00:16:24.915: INFO: Got endpoints: latency-svc-mkhg7 [749.179524ms]
Feb 27 00:16:24.935: INFO: Created: latency-svc-hf4gn
Feb 27 00:16:24.966: INFO: Got endpoints: latency-svc-znvgh [737.774278ms]
Feb 27 00:16:25.015: INFO: Got endpoints: latency-svc-jnmqm [750.123528ms]
Feb 27 00:16:25.065: INFO: Got endpoints: latency-svc-dgn4r [747.476617ms]
Feb 27 00:16:25.124: INFO: Got endpoints: latency-svc-6rcb2 [757.781559ms]
Feb 27 00:16:25.165: INFO: Got endpoints: latency-svc-nvnxt [741.733495ms]
Feb 27 00:16:25.216: INFO: Got endpoints: latency-svc-vpfk9 [750.71103ms]
Feb 27 00:16:25.268: INFO: Got endpoints: latency-svc-w88xs [749.307826ms]
Feb 27 00:16:25.315: INFO: Got endpoints: latency-svc-94dpz [750.52133ms]
Feb 27 00:16:25.366: INFO: Got endpoints: latency-svc-msk28 [751.812136ms]
Feb 27 00:16:25.416: INFO: Got endpoints: latency-svc-qbkcw [751.706636ms]
Feb 27 00:16:25.464: INFO: Got endpoints: latency-svc-w52b5 [748.851925ms]
Feb 27 00:16:25.515: INFO: Got endpoints: latency-svc-zpkxz [748.800225ms]
Feb 27 00:16:25.567: INFO: Got endpoints: latency-svc-5kg5g [746.439115ms]
Feb 27 00:16:25.615: INFO: Got endpoints: latency-svc-f9249 [748.467724ms]
Feb 27 00:16:25.700: INFO: Got endpoints: latency-svc-hf4gn [784.56127ms]
Feb 27 00:16:25.700: INFO: Latencies: [43.720775ms 51.910508ms 74.362697ms 89.306158ms 101.801707ms 109.74994ms 116.013465ms 133.321533ms 153.156113ms 180.829524ms 185.841544ms 198.093393ms 199.7995ms 201.071605ms 201.592307ms 204.686719ms 205.668924ms 206.804328ms 207.029029ms 207.878733ms 208.920137ms 211.988449ms 212.968752ms 214.525759ms 215.203962ms 215.853064ms 216.335666ms 216.458967ms 219.972781ms 220.408083ms 221.050385ms 221.367787ms 221.481987ms 221.959089ms 222.770092ms 223.247994ms 223.256794ms 224.160897ms 227.970812ms 228.579216ms 232.711431ms 232.999933ms 256.135426ms 303.652716ms 344.051478ms 383.844238ms 389.444859ms 443.099075ms 480.910226ms 518.273376ms 552.009111ms 586.680251ms 622.723195ms 655.944132ms 658.44464ms 678.078317ms 706.833736ms 712.741059ms 716.32217ms 717.36659ms 729.432525ms 734.684453ms 734.870066ms 735.355349ms 735.556556ms 737.082554ms 737.774278ms 738.006975ms 738.54318ms 740.023068ms 740.323771ms 741.733495ms 742.085075ms 742.773284ms 743.118486ms 743.315496ms 743.460884ms 743.622196ms 744.710287ms 745.353902ms 745.364102ms 745.548395ms 745.560799ms 745.646706ms 745.774497ms 745.982795ms 746.170095ms 746.247106ms 746.426895ms 746.439115ms 746.604705ms 746.6237ms 746.6586ms 746.916998ms 747.038608ms 747.044395ms 747.394711ms 747.476617ms 747.595814ms 747.719204ms 747.863898ms 747.962105ms 748.20411ms 748.21812ms 748.240017ms 748.321806ms 748.370209ms 748.467724ms 748.497411ms 748.545814ms 748.718212ms 748.736322ms 748.73901ms 748.787604ms 748.795513ms 748.800225ms 748.826305ms 748.851925ms 748.870717ms 748.891806ms 749.025313ms 749.068813ms 749.151718ms 749.179524ms 749.241014ms 749.307826ms 749.338323ms 749.353908ms 749.455915ms 749.482118ms 749.488412ms 749.511406ms 749.567424ms 750.039024ms 750.046125ms 750.102425ms 750.123528ms 750.265824ms 750.278327ms 750.281525ms 750.417312ms 750.494913ms 750.499529ms 750.52133ms 750.663316ms 750.71103ms 750.920815ms 750.92083ms 750.961616ms 750.965117ms 751.082831ms 751.141228ms 751.247726ms 751.338526ms 751.417223ms 751.427625ms 751.445419ms 751.515623ms 751.604227ms 751.642231ms 751.644526ms 751.662619ms 751.706636ms 751.752628ms 751.787625ms 751.812136ms 751.818723ms 751.977023ms 751.990727ms 752.057826ms 752.082233ms 752.448526ms 752.520117ms 752.565022ms 752.702129ms 753.608031ms 754.324438ms 754.722626ms 755.013238ms 756.213031ms 756.344131ms 756.528154ms 756.805438ms 757.757057ms 757.781559ms 757.929152ms 758.336644ms 760.859866ms 761.135651ms 761.90166ms 762.363274ms 762.924965ms 764.04988ms 766.44939ms 776.07641ms 780.08174ms 784.56127ms 791.484373ms 809.225143ms 837.648858ms]
Feb 27 00:16:25.709: INFO: 50 %ile: 747.863898ms
Feb 27 00:16:25.709: INFO: 90 %ile: 756.344131ms
Feb 27 00:16:25.709: INFO: 99 %ile: 809.225143ms
Feb 27 00:16:25.710: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:16:25.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-ncw5b" for this suite.
Feb 27 00:16:49.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:16:49.779: INFO: namespace: e2e-tests-svc-latency-ncw5b, resource: bindings, ignored listing per whitelist
Feb 27 00:16:49.855: INFO: namespace e2e-tests-svc-latency-ncw5b deletion completed in 24.128042805s

• [SLOW TEST:37.128 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:16:49.856: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rsgsm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-fa175586-3a24-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 00:16:50.110: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-rsgsm" to be "success or failure"
Feb 27 00:16:50.120: INFO: Pod "pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 9.257042ms
Feb 27 00:16:52.123: INFO: Pod "pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012796029s
Feb 27 00:16:54.127: INFO: Pod "pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016522229s
STEP: Saw pod success
Feb 27 00:16:54.127: INFO: Pod "pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:16:54.130: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 00:16:54.157: INFO: Waiting for pod pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:16:54.160: INFO: Pod pod-projected-configmaps-fa183f00-3a24-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:16:54.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rsgsm" for this suite.
Feb 27 00:17:00.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:17:00.203: INFO: namespace: e2e-tests-projected-rsgsm, resource: bindings, ignored listing per whitelist
Feb 27 00:17:00.291: INFO: namespace e2e-tests-projected-rsgsm deletion completed in 6.12640469s

• [SLOW TEST:10.436 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:17:00.292: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-x75vh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0054d812-3a25-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:17:00.545: INFO: Waiting up to 5m0s for pod "pod-secrets-00558033-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-x75vh" to be "success or failure"
Feb 27 00:17:00.550: INFO: Pod "pod-secrets-00558033-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.430831ms
Feb 27 00:17:02.556: INFO: Pod "pod-secrets-00558033-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010876943s
STEP: Saw pod success
Feb 27 00:17:02.556: INFO: Pod "pod-secrets-00558033-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:17:02.561: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-00558033-3a25-11e9-9b83-4a9a78a986da container secret-env-test: <nil>
STEP: delete the pod
Feb 27 00:17:02.588: INFO: Waiting for pod pod-secrets-00558033-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:17:02.597: INFO: Pod pod-secrets-00558033-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:17:02.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x75vh" for this suite.
Feb 27 00:17:08.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:17:08.665: INFO: namespace: e2e-tests-secrets-x75vh, resource: bindings, ignored listing per whitelist
Feb 27 00:17:08.739: INFO: namespace e2e-tests-secrets-x75vh deletion completed in 6.13880867s

• [SLOW TEST:8.447 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:17:08.740: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-pr5bz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 00:17:08.951: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:17:12.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pr5bz" for this suite.
Feb 27 00:17:18.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:17:18.146: INFO: namespace: e2e-tests-init-container-pr5bz, resource: bindings, ignored listing per whitelist
Feb 27 00:17:18.245: INFO: namespace e2e-tests-init-container-pr5bz deletion completed in 6.14003325s

• [SLOW TEST:9.505 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:17:18.245: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-l5nfj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0b048681-3a25-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:17:18.466: INFO: Waiting up to 5m0s for pod "pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-l5nfj" to be "success or failure"
Feb 27 00:17:18.472: INFO: Pod "pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.887522ms
Feb 27 00:17:20.476: INFO: Pod "pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009002544s
Feb 27 00:17:22.479: INFO: Pod "pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012771504s
STEP: Saw pod success
Feb 27 00:17:22.479: INFO: Pod "pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:17:22.484: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:17:22.525: INFO: Waiting for pod pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:17:22.537: INFO: Pod pod-secrets-0b052202-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:17:22.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l5nfj" for this suite.
Feb 27 00:17:28.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:17:28.650: INFO: namespace: e2e-tests-secrets-l5nfj, resource: bindings, ignored listing per whitelist
Feb 27 00:17:28.676: INFO: namespace e2e-tests-secrets-l5nfj deletion completed in 6.133726464s

• [SLOW TEST:10.431 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:17:28.677: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-n4s7t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 27 00:17:28.905: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-167492786 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:17:28.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n4s7t" for this suite.
Feb 27 00:17:35.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:17:35.092: INFO: namespace: e2e-tests-kubectl-n4s7t, resource: bindings, ignored listing per whitelist
Feb 27 00:17:35.132: INFO: namespace e2e-tests-kubectl-n4s7t deletion completed in 6.135397992s

• [SLOW TEST:6.455 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:17:35.132: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-drtsw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-drtsw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-drtsw to expose endpoints map[]
Feb 27 00:17:35.353: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-drtsw exposes endpoints map[] (6.819933ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-drtsw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-drtsw to expose endpoints map[pod1:[80]]
Feb 27 00:17:37.386: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-drtsw exposes endpoints map[pod1:[80]] (2.026534024s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-drtsw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-drtsw to expose endpoints map[pod1:[80] pod2:[80]]
Feb 27 00:17:39.422: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-drtsw exposes endpoints map[pod1:[80] pod2:[80]] (2.029642254s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-drtsw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-drtsw to expose endpoints map[pod2:[80]]
Feb 27 00:17:40.457: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-drtsw exposes endpoints map[pod2:[80]] (1.031512275s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-drtsw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-drtsw to expose endpoints map[]
Feb 27 00:17:41.481: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-drtsw exposes endpoints map[] (1.006206108s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:17:41.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-drtsw" for this suite.
Feb 27 00:18:03.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:18:03.553: INFO: namespace: e2e-tests-services-drtsw, resource: bindings, ignored listing per whitelist
Feb 27 00:18:03.638: INFO: namespace e2e-tests-services-drtsw deletion completed in 22.130246856s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.506 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:18:03.639: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8pr4s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:18:03.836: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:18:07.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8pr4s" for this suite.
Feb 27 00:18:45.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:18:45.964: INFO: namespace: e2e-tests-pods-8pr4s, resource: bindings, ignored listing per whitelist
Feb 27 00:18:46.018: INFO: namespace e2e-tests-pods-8pr4s deletion completed in 38.128109279s

• [SLOW TEST:42.379 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:18:46.019: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gqvfv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:18:46.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-gqvfv" to be "success or failure"
Feb 27 00:18:46.246: INFO: Pod "downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 11.233561ms
Feb 27 00:18:48.249: INFO: Pod "downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015018912s
Feb 27 00:18:50.253: INFO: Pod "downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018521585s
STEP: Saw pod success
Feb 27 00:18:50.253: INFO: Pod "downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:18:50.255: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:18:50.286: INFO: Waiting for pod downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:18:50.299: INFO: Pod downwardapi-volume-3f555760-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:18:50.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gqvfv" for this suite.
Feb 27 00:18:56.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:18:56.407: INFO: namespace: e2e-tests-projected-gqvfv, resource: bindings, ignored listing per whitelist
Feb 27 00:18:56.459: INFO: namespace e2e-tests-projected-gqvfv deletion completed in 6.156539333s

• [SLOW TEST:10.440 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:18:56.460: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5q49l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 27 00:18:56.656: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-167492786 proxy --unix-socket=/tmp/kubectl-proxy-unix860903529/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:18:56.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5q49l" for this suite.
Feb 27 00:19:02.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:19:02.839: INFO: namespace: e2e-tests-kubectl-5q49l, resource: bindings, ignored listing per whitelist
Feb 27 00:19:02.848: INFO: namespace e2e-tests-kubectl-5q49l deletion completed in 6.135112802s

• [SLOW TEST:6.388 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:19:02.848: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ds8hf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:19:03.066: INFO: Waiting up to 5m0s for pod "downwardapi-volume-495da0cb-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-ds8hf" to be "success or failure"
Feb 27 00:19:03.074: INFO: Pod "downwardapi-volume-495da0cb-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.289243ms
Feb 27 00:19:05.089: INFO: Pod "downwardapi-volume-495da0cb-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022459036s
STEP: Saw pod success
Feb 27 00:19:05.089: INFO: Pod "downwardapi-volume-495da0cb-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:19:05.091: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-495da0cb-3a25-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:19:05.109: INFO: Waiting for pod downwardapi-volume-495da0cb-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:19:05.113: INFO: Pod downwardapi-volume-495da0cb-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:19:05.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ds8hf" for this suite.
Feb 27 00:19:11.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:19:11.263: INFO: namespace: e2e-tests-downward-api-ds8hf, resource: bindings, ignored listing per whitelist
Feb 27 00:19:11.284: INFO: namespace e2e-tests-downward-api-ds8hf deletion completed in 6.153450336s

• [SLOW TEST:8.436 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:19:11.286: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-p6s7j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 27 00:19:11.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:12.766: INFO: stderr: ""
Feb 27 00:19:12.766: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 00:19:12.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:12.871: INFO: stderr: ""
Feb 27 00:19:12.871: INFO: stdout: "update-demo-nautilus-bqvvz update-demo-nautilus-j4gxj "
Feb 27 00:19:12.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-bqvvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:12.946: INFO: stderr: ""
Feb 27 00:19:12.946: INFO: stdout: ""
Feb 27 00:19:12.946: INFO: update-demo-nautilus-bqvvz is created but not running
Feb 27 00:19:17.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:18.074: INFO: stderr: ""
Feb 27 00:19:18.074: INFO: stdout: "update-demo-nautilus-bqvvz update-demo-nautilus-j4gxj "
Feb 27 00:19:18.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-bqvvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:18.170: INFO: stderr: ""
Feb 27 00:19:18.170: INFO: stdout: "true"
Feb 27 00:19:18.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-bqvvz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:18.268: INFO: stderr: ""
Feb 27 00:19:18.268: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:19:18.268: INFO: validating pod update-demo-nautilus-bqvvz
Feb 27 00:19:18.274: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:19:18.274: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:19:18.274: INFO: update-demo-nautilus-bqvvz is verified up and running
Feb 27 00:19:18.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-j4gxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:18.358: INFO: stderr: ""
Feb 27 00:19:18.359: INFO: stdout: "true"
Feb 27 00:19:18.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-j4gxj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:18.449: INFO: stderr: ""
Feb 27 00:19:18.449: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:19:18.449: INFO: validating pod update-demo-nautilus-j4gxj
Feb 27 00:19:18.455: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:19:18.455: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:19:18.455: INFO: update-demo-nautilus-j4gxj is verified up and running
STEP: scaling down the replication controller
Feb 27 00:19:18.457: INFO: scanned /root for discovery docs: <nil>
Feb 27 00:19:18.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:19.570: INFO: stderr: ""
Feb 27 00:19:19.570: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 00:19:19.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:19.652: INFO: stderr: ""
Feb 27 00:19:19.652: INFO: stdout: "update-demo-nautilus-bqvvz update-demo-nautilus-j4gxj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 27 00:19:24.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:24.729: INFO: stderr: ""
Feb 27 00:19:24.729: INFO: stdout: "update-demo-nautilus-j4gxj "
Feb 27 00:19:24.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-j4gxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:24.799: INFO: stderr: ""
Feb 27 00:19:24.799: INFO: stdout: "true"
Feb 27 00:19:24.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-j4gxj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:24.867: INFO: stderr: ""
Feb 27 00:19:24.867: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:19:24.867: INFO: validating pod update-demo-nautilus-j4gxj
Feb 27 00:19:24.871: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:19:24.871: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:19:24.871: INFO: update-demo-nautilus-j4gxj is verified up and running
STEP: scaling up the replication controller
Feb 27 00:19:24.873: INFO: scanned /root for discovery docs: <nil>
Feb 27 00:19:24.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:25.985: INFO: stderr: ""
Feb 27 00:19:25.985: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 00:19:25.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:26.167: INFO: stderr: ""
Feb 27 00:19:26.167: INFO: stdout: "update-demo-nautilus-j4gxj update-demo-nautilus-ptc7g "
Feb 27 00:19:26.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-j4gxj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:26.296: INFO: stderr: ""
Feb 27 00:19:26.296: INFO: stdout: "true"
Feb 27 00:19:26.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-j4gxj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:26.377: INFO: stderr: ""
Feb 27 00:19:26.377: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:19:26.377: INFO: validating pod update-demo-nautilus-j4gxj
Feb 27 00:19:26.382: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:19:26.382: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:19:26.382: INFO: update-demo-nautilus-j4gxj is verified up and running
Feb 27 00:19:26.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-ptc7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:26.537: INFO: stderr: ""
Feb 27 00:19:26.538: INFO: stdout: "true"
Feb 27 00:19:26.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-ptc7g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:26.620: INFO: stderr: ""
Feb 27 00:19:26.620: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:19:26.620: INFO: validating pod update-demo-nautilus-ptc7g
Feb 27 00:19:26.625: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:19:26.625: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:19:26.625: INFO: update-demo-nautilus-ptc7g is verified up and running
STEP: using delete to clean up resources
Feb 27 00:19:26.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:26.711: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:19:26.711: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 27 00:19:26.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-p6s7j'
Feb 27 00:19:26.810: INFO: stderr: "No resources found.\n"
Feb 27 00:19:26.810: INFO: stdout: ""
Feb 27 00:19:26.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -l name=update-demo --namespace=e2e-tests-kubectl-p6s7j -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 00:19:26.892: INFO: stderr: ""
Feb 27 00:19:26.892: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:19:26.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p6s7j" for this suite.
Feb 27 00:19:48.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:19:48.935: INFO: namespace: e2e-tests-kubectl-p6s7j, resource: bindings, ignored listing per whitelist
Feb 27 00:19:49.019: INFO: namespace e2e-tests-kubectl-p6s7j deletion completed in 22.122668473s

• [SLOW TEST:37.733 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:19:49.021: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-45fnh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 00:19:49.253: INFO: Waiting up to 5m0s for pod "downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-45fnh" to be "success or failure"
Feb 27 00:19:49.263: INFO: Pod "downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 9.915064ms
Feb 27 00:19:51.267: INFO: Pod "downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013019187s
Feb 27 00:19:53.270: INFO: Pod "downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016527812s
Feb 27 00:19:55.273: INFO: Pod "downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019772332s
STEP: Saw pod success
Feb 27 00:19:55.274: INFO: Pod "downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:19:55.278: INFO: Trying to get logs from node 9cy76-worker-000001 pod downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 00:19:55.301: INFO: Waiting for pod downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:19:55.304: INFO: Pod downward-api-64e3b9eb-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:19:55.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-45fnh" for this suite.
Feb 27 00:20:01.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:20:01.431: INFO: namespace: e2e-tests-downward-api-45fnh, resource: bindings, ignored listing per whitelist
Feb 27 00:20:01.440: INFO: namespace e2e-tests-downward-api-45fnh deletion completed in 6.132022648s

• [SLOW TEST:12.419 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:20:01.445: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cmrwd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6c4bad59-3a25-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:20:01.674: INFO: Waiting up to 5m0s for pod "pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-cmrwd" to be "success or failure"
Feb 27 00:20:01.681: INFO: Pod "pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.583949ms
Feb 27 00:20:03.685: INFO: Pod "pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011224564s
Feb 27 00:20:05.688: INFO: Pod "pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014392275s
STEP: Saw pod success
Feb 27 00:20:05.688: INFO: Pod "pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:20:05.692: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:20:05.716: INFO: Waiting for pod pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:20:05.732: INFO: Pod pod-secrets-6c4c37bb-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:20:05.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cmrwd" for this suite.
Feb 27 00:20:11.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:20:11.845: INFO: namespace: e2e-tests-secrets-cmrwd, resource: bindings, ignored listing per whitelist
Feb 27 00:20:11.887: INFO: namespace e2e-tests-secrets-cmrwd deletion completed in 6.151389425s

• [SLOW TEST:10.442 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:20:11.888: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ltsnf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 27 00:20:16.142: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-7284e8c1-3a25-11e9-9b83-4a9a78a986da", GenerateName:"", Namespace:"e2e-tests-pods-ltsnf", SelfLink:"/api/v1/namespaces/e2e-tests-pods-ltsnf/pods/pod-submit-remove-7284e8c1-3a25-11e9-9b83-4a9a78a986da", UID:"7287835f-3a25-11e9-9b3e-000d3a2390ff", ResourceVersion:"56673", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686823612, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"102477698"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.1.130.73/32", "kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hsl69", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00095eb00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hsl69", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001a62ae8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"9cy76-worker-000000", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0017e1aa0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a62b20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a62b40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001a62b48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001a62b4c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823612, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823614, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823614, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823612, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.1.4", PodIP:"10.1.130.73", StartTime:(*v1.Time)(0xc00161bba0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00161bbc0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://b11b232b4cde64e9fece3b915796927ff27c33fdf3257dbe09847065682bd8c7"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:20:24.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ltsnf" for this suite.
Feb 27 00:20:30.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:20:30.585: INFO: namespace: e2e-tests-pods-ltsnf, resource: bindings, ignored listing per whitelist
Feb 27 00:20:30.585: INFO: namespace e2e-tests-pods-ltsnf deletion completed in 6.115330151s

• [SLOW TEST:18.698 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:20:30.585: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-t9vcm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-wtzkd in namespace e2e-tests-proxy-t9vcm
I0227 00:20:30.805970      17 runners.go:184] Created replication controller with name: proxy-service-wtzkd, namespace: e2e-tests-proxy-t9vcm, replica count: 1
I0227 00:20:31.859767      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 00:20:32.859979      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 00:20:33.860207      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 00:20:34.860637      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 00:20:35.861007      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:36.861243      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:37.861461      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:38.861815      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:39.862071      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:40.862664      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:41.862950      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:42.863142      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 00:20:43.863353      17 runners.go:184] proxy-service-wtzkd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 27 00:20:43.866: INFO: setup took 13.081567627s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 27 00:20:43.884: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 16.535649ms)
Feb 27 00:20:43.884: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 16.877754ms)
Feb 27 00:20:43.884: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 18.039572ms)
Feb 27 00:20:43.884: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 17.476263ms)
Feb 27 00:20:43.890: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 23.585155ms)
Feb 27 00:20:43.890: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 24.093062ms)
Feb 27 00:20:43.891: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 23.644256ms)
Feb 27 00:20:43.891: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 24.264165ms)
Feb 27 00:20:43.892: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 24.656971ms)
Feb 27 00:20:43.899: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 32.766093ms)
Feb 27 00:20:43.899: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 32.626091ms)
Feb 27 00:20:43.900: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 32.974996ms)
Feb 27 00:20:43.903: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 35.448834ms)
Feb 27 00:20:43.904: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 37.049458ms)
Feb 27 00:20:43.904: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 36.956956ms)
Feb 27 00:20:43.906: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 39.227691ms)
Feb 27 00:20:43.913: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 7.045606ms)
Feb 27 00:20:43.914: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 7.462213ms)
Feb 27 00:20:43.915: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 8.115322ms)
Feb 27 00:20:43.917: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 9.94525ms)
Feb 27 00:20:43.918: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 11.208169ms)
Feb 27 00:20:43.918: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 11.768277ms)
Feb 27 00:20:43.918: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 11.660775ms)
Feb 27 00:20:43.918: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 11.756777ms)
Feb 27 00:20:43.920: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 13.472002ms)
Feb 27 00:20:43.923: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 16.201444ms)
Feb 27 00:20:43.924: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 16.674951ms)
Feb 27 00:20:43.924: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 17.452562ms)
Feb 27 00:20:43.925: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 18.018071ms)
Feb 27 00:20:43.925: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 18.481178ms)
Feb 27 00:20:43.926: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 18.939785ms)
Feb 27 00:20:43.926: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 18.884384ms)
Feb 27 00:20:43.935: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 7.35221ms)
Feb 27 00:20:43.939: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 11.108967ms)
Feb 27 00:20:43.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 22.339236ms)
Feb 27 00:20:43.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 20.648111ms)
Feb 27 00:20:43.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 21.800028ms)
Feb 27 00:20:43.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 20.944415ms)
Feb 27 00:20:43.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 22.655641ms)
Feb 27 00:20:43.950: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 21.743528ms)
Feb 27 00:20:43.950: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 21.800228ms)
Feb 27 00:20:43.950: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 22.805844ms)
Feb 27 00:20:43.950: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 23.507454ms)
Feb 27 00:20:43.951: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 22.296335ms)
Feb 27 00:20:43.951: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 22.820343ms)
Feb 27 00:20:43.952: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 24.028061ms)
Feb 27 00:20:43.952: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 23.621856ms)
Feb 27 00:20:43.952: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 25.532784ms)
Feb 27 00:20:43.965: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 12.63449ms)
Feb 27 00:20:43.966: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 13.485103ms)
Feb 27 00:20:43.967: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 14.65082ms)
Feb 27 00:20:43.967: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 14.283315ms)
Feb 27 00:20:43.967: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 14.965426ms)
Feb 27 00:20:43.967: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 14.738322ms)
Feb 27 00:20:43.968: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 15.385631ms)
Feb 27 00:20:43.968: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 15.88434ms)
Feb 27 00:20:43.969: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 16.245144ms)
Feb 27 00:20:43.969: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 16.924255ms)
Feb 27 00:20:43.969: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 16.991956ms)
Feb 27 00:20:43.970: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 16.937355ms)
Feb 27 00:20:43.970: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 17.033756ms)
Feb 27 00:20:43.970: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 17.094258ms)
Feb 27 00:20:43.970: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 17.26406ms)
Feb 27 00:20:43.970: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 17.265759ms)
Feb 27 00:20:43.981: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 10.814563ms)
Feb 27 00:20:43.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 11.513273ms)
Feb 27 00:20:43.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 11.730177ms)
Feb 27 00:20:43.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 11.543374ms)
Feb 27 00:20:43.982: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 12.207284ms)
Feb 27 00:20:43.983: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 12.099382ms)
Feb 27 00:20:43.983: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 13.397202ms)
Feb 27 00:20:43.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 13.430102ms)
Feb 27 00:20:43.984: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 13.553604ms)
Feb 27 00:20:43.985: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 14.191914ms)
Feb 27 00:20:43.985: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 14.138312ms)
Feb 27 00:20:43.987: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 16.084342ms)
Feb 27 00:20:43.987: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 16.197244ms)
Feb 27 00:20:43.990: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 19.161689ms)
Feb 27 00:20:43.991: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 20.436507ms)
Feb 27 00:20:43.991: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 20.540209ms)
Feb 27 00:20:44.006: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 14.216314ms)
Feb 27 00:20:44.008: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 15.568634ms)
Feb 27 00:20:44.008: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 16.00044ms)
Feb 27 00:20:44.008: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 15.89864ms)
Feb 27 00:20:44.008: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 15.98574ms)
Feb 27 00:20:44.009: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 16.972555ms)
Feb 27 00:20:44.009: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 17.343161ms)
Feb 27 00:20:44.009: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 16.978455ms)
Feb 27 00:20:44.010: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 17.809868ms)
Feb 27 00:20:44.010: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 18.422977ms)
Feb 27 00:20:44.010: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 18.119672ms)
Feb 27 00:20:44.011: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 19.630695ms)
Feb 27 00:20:44.011: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 19.28349ms)
Feb 27 00:20:44.011: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 19.460093ms)
Feb 27 00:20:44.012: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 19.667396ms)
Feb 27 00:20:44.012: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 19.514394ms)
Feb 27 00:20:44.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 4.529168ms)
Feb 27 00:20:44.020: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 8.038721ms)
Feb 27 00:20:44.021: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 8.64823ms)
Feb 27 00:20:44.021: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 8.752932ms)
Feb 27 00:20:44.022: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 9.34324ms)
Feb 27 00:20:44.022: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 9.037036ms)
Feb 27 00:20:44.022: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 9.127437ms)
Feb 27 00:20:44.027: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 13.514503ms)
Feb 27 00:20:44.027: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 13.836608ms)
Feb 27 00:20:44.027: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 14.428417ms)
Feb 27 00:20:44.028: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 15.216029ms)
Feb 27 00:20:44.029: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 15.748636ms)
Feb 27 00:20:44.029: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 16.490448ms)
Feb 27 00:20:44.030: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 16.65005ms)
Feb 27 00:20:44.030: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 16.680951ms)
Feb 27 00:20:44.030: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 16.661851ms)
Feb 27 00:20:44.040: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 9.605845ms)
Feb 27 00:20:44.040: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 10.374756ms)
Feb 27 00:20:44.041: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 10.190953ms)
Feb 27 00:20:44.041: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 10.218254ms)
Feb 27 00:20:44.041: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 10.100752ms)
Feb 27 00:20:44.041: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 10.117552ms)
Feb 27 00:20:44.041: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 10.382256ms)
Feb 27 00:20:44.042: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 11.741676ms)
Feb 27 00:20:44.042: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 11.180768ms)
Feb 27 00:20:44.042: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 11.126667ms)
Feb 27 00:20:44.045: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 14.571019ms)
Feb 27 00:20:44.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 15.800637ms)
Feb 27 00:20:44.046: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 15.365331ms)
Feb 27 00:20:44.047: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 16.011541ms)
Feb 27 00:20:44.047: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 15.563334ms)
Feb 27 00:20:44.047: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 16.350646ms)
Feb 27 00:20:44.053: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 5.839987ms)
Feb 27 00:20:44.057: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 10.270954ms)
Feb 27 00:20:44.060: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 12.024781ms)
Feb 27 00:20:44.060: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 13.032096ms)
Feb 27 00:20:44.061: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 13.181898ms)
Feb 27 00:20:44.061: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 13.474203ms)
Feb 27 00:20:44.062: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 14.58392ms)
Feb 27 00:20:44.062: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 14.312215ms)
Feb 27 00:20:44.062: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 14.60122ms)
Feb 27 00:20:44.063: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 15.542034ms)
Feb 27 00:20:44.063: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 14.731321ms)
Feb 27 00:20:44.063: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 16.338245ms)
Feb 27 00:20:44.064: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 16.093142ms)
Feb 27 00:20:44.064: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 16.725752ms)
Feb 27 00:20:44.064: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 16.675251ms)
Feb 27 00:20:44.064: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 16.868954ms)
Feb 27 00:20:44.077: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 11.739076ms)
Feb 27 00:20:44.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 13.688706ms)
Feb 27 00:20:44.079: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 13.579704ms)
Feb 27 00:20:44.079: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 14.64132ms)
Feb 27 00:20:44.079: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 13.896109ms)
Feb 27 00:20:44.079: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 14.101512ms)
Feb 27 00:20:44.083: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 18.315576ms)
Feb 27 00:20:44.083: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 18.787982ms)
Feb 27 00:20:44.083: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 18.883884ms)
Feb 27 00:20:44.083: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 18.151572ms)
Feb 27 00:20:44.083: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 17.94567ms)
Feb 27 00:20:44.084: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 18.806383ms)
Feb 27 00:20:44.084: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 19.579094ms)
Feb 27 00:20:44.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 19.908799ms)
Feb 27 00:20:44.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 20.438607ms)
Feb 27 00:20:44.091: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 25.811888ms)
Feb 27 00:20:44.121: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 29.414442ms)
Feb 27 00:20:44.121: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 29.893249ms)
Feb 27 00:20:44.122: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 29.95555ms)
Feb 27 00:20:44.123: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 31.735877ms)
Feb 27 00:20:44.123: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 31.674076ms)
Feb 27 00:20:44.123: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 32.076483ms)
Feb 27 00:20:44.123: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 31.822079ms)
Feb 27 00:20:44.124: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 32.561789ms)
Feb 27 00:20:44.124: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 32.60369ms)
Feb 27 00:20:44.124: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 32.835794ms)
Feb 27 00:20:44.127: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 35.025527ms)
Feb 27 00:20:44.127: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 35.107828ms)
Feb 27 00:20:44.127: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 35.774738ms)
Feb 27 00:20:44.128: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 36.487149ms)
Feb 27 00:20:44.128: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 36.465248ms)
Feb 27 00:20:44.128: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 36.905654ms)
Feb 27 00:20:44.136: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 7.693315ms)
Feb 27 00:20:44.145: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 15.95844ms)
Feb 27 00:20:44.145: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 16.037941ms)
Feb 27 00:20:44.146: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 16.544748ms)
Feb 27 00:20:44.146: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 16.866153ms)
Feb 27 00:20:44.147: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 17.175658ms)
Feb 27 00:20:44.147: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 18.291675ms)
Feb 27 00:20:44.147: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 19.169088ms)
Feb 27 00:20:44.147: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 18.234374ms)
Feb 27 00:20:44.148: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 18.60308ms)
Feb 27 00:20:44.148: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 19.420492ms)
Feb 27 00:20:44.148: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 19.636995ms)
Feb 27 00:20:44.148: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 18.682681ms)
Feb 27 00:20:44.148: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 18.996386ms)
Feb 27 00:20:44.149: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 19.129988ms)
Feb 27 00:20:44.150: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 21.163918ms)
Feb 27 00:20:44.156: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 5.386081ms)
Feb 27 00:20:44.166: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 14.61682ms)
Feb 27 00:20:44.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 15.412832ms)
Feb 27 00:20:44.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 15.862738ms)
Feb 27 00:20:44.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 15.600635ms)
Feb 27 00:20:44.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 16.938355ms)
Feb 27 00:20:44.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 16.803152ms)
Feb 27 00:20:44.170: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 19.706096ms)
Feb 27 00:20:44.171: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 20.330506ms)
Feb 27 00:20:44.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 21.007016ms)
Feb 27 00:20:44.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 21.123218ms)
Feb 27 00:20:44.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 21.503123ms)
Feb 27 00:20:44.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 24.154863ms)
Feb 27 00:20:44.176: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 24.877774ms)
Feb 27 00:20:44.179: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 27.212609ms)
Feb 27 00:20:44.180: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 28.542629ms)
Feb 27 00:20:44.193: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 12.525288ms)
Feb 27 00:20:44.193: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 12.135082ms)
Feb 27 00:20:44.194: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 13.452202ms)
Feb 27 00:20:44.196: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 15.137327ms)
Feb 27 00:20:44.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 16.760952ms)
Feb 27 00:20:44.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 16.986956ms)
Feb 27 00:20:44.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 17.572764ms)
Feb 27 00:20:44.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 17.807268ms)
Feb 27 00:20:44.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 17.345661ms)
Feb 27 00:20:44.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 17.654765ms)
Feb 27 00:20:44.201: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 20.252105ms)
Feb 27 00:20:44.202: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 21.877129ms)
Feb 27 00:20:44.202: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 21.510824ms)
Feb 27 00:20:44.203: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 22.882344ms)
Feb 27 00:20:44.203: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 22.726841ms)
Feb 27 00:20:44.204: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 24.280565ms)
Feb 27 00:20:44.220: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 14.522418ms)
Feb 27 00:20:44.221: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 15.898339ms)
Feb 27 00:20:44.221: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 16.470447ms)
Feb 27 00:20:44.221: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 15.850538ms)
Feb 27 00:20:44.222: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 17.021156ms)
Feb 27 00:20:44.223: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 17.479063ms)
Feb 27 00:20:44.223: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 17.448162ms)
Feb 27 00:20:44.223: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 17.99317ms)
Feb 27 00:20:44.224: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 18.857583ms)
Feb 27 00:20:44.224: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 18.756882ms)
Feb 27 00:20:44.226: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 20.814313ms)
Feb 27 00:20:44.226: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 20.737412ms)
Feb 27 00:20:44.226: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 20.929714ms)
Feb 27 00:20:44.227: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 22.00263ms)
Feb 27 00:20:44.227: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 22.133133ms)
Feb 27 00:20:44.227: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 22.081532ms)
Feb 27 00:20:44.236: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 8.443827ms)
Feb 27 00:20:44.237: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 8.916734ms)
Feb 27 00:20:44.237: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 9.584144ms)
Feb 27 00:20:44.238: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 9.901649ms)
Feb 27 00:20:44.238: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 10.438357ms)
Feb 27 00:20:44.238: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 10.897764ms)
Feb 27 00:20:44.243: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 14.730221ms)
Feb 27 00:20:44.244: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 16.164443ms)
Feb 27 00:20:44.244: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 16.175543ms)
Feb 27 00:20:44.244: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 17.503563ms)
Feb 27 00:20:44.244: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 16.734452ms)
Feb 27 00:20:44.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 17.319761ms)
Feb 27 00:20:44.247: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 18.662281ms)
Feb 27 00:20:44.248: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 19.389392ms)
Feb 27 00:20:44.248: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 19.774097ms)
Feb 27 00:20:44.248: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 19.488193ms)
Feb 27 00:20:44.281: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 32.704492ms)
Feb 27 00:20:44.284: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 34.658021ms)
Feb 27 00:20:44.288: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 39.8976ms)
Feb 27 00:20:44.292: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 43.086247ms)
Feb 27 00:20:44.294: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 45.815388ms)
Feb 27 00:20:44.294: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 46.088293ms)
Feb 27 00:20:44.295: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 46.146093ms)
Feb 27 00:20:44.295: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 46.372097ms)
Feb 27 00:20:44.296: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 46.467098ms)
Feb 27 00:20:44.296: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 46.737302ms)
Feb 27 00:20:44.296: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 46.697902ms)
Feb 27 00:20:44.301: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 51.633176ms)
Feb 27 00:20:44.301: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 51.959981ms)
Feb 27 00:20:44.302: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 53.672607ms)
Feb 27 00:20:44.302: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 52.57269ms)
Feb 27 00:20:44.303: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 54.617421ms)
Feb 27 00:20:44.318: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 13.818708ms)
Feb 27 00:20:44.332: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 27.190609ms)
Feb 27 00:20:44.334: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 29.432643ms)
Feb 27 00:20:44.336: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 33.022397ms)
Feb 27 00:20:44.341: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 36.426248ms)
Feb 27 00:20:44.341: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 37.344961ms)
Feb 27 00:20:44.342: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 37.581165ms)
Feb 27 00:20:44.345: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 40.797013ms)
Feb 27 00:20:44.346: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 41.397122ms)
Feb 27 00:20:44.347: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 43.588555ms)
Feb 27 00:20:44.348: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 43.101448ms)
Feb 27 00:20:44.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 47.145409ms)
Feb 27 00:20:44.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 46.798403ms)
Feb 27 00:20:44.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 47.138309ms)
Feb 27 00:20:44.351: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 47.670316ms)
Feb 27 00:20:44.352: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 48.642831ms)
Feb 27 00:20:44.370: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 17.088057ms)
Feb 27 00:20:44.373: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 19.835698ms)
Feb 27 00:20:44.373: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 20.221604ms)
Feb 27 00:20:44.373: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 20.539409ms)
Feb 27 00:20:44.387: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 33.179699ms)
Feb 27 00:20:44.389: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 35.521534ms)
Feb 27 00:20:44.389: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 35.27533ms)
Feb 27 00:20:44.389: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 36.400947ms)
Feb 27 00:20:44.389: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 37.180259ms)
Feb 27 00:20:44.390: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 37.573665ms)
Feb 27 00:20:44.390: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 38.058173ms)
Feb 27 00:20:44.390: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 37.481763ms)
Feb 27 00:20:44.392: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 39.9118ms)
Feb 27 00:20:44.395: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 41.582425ms)
Feb 27 00:20:44.395: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 41.322521ms)
Feb 27 00:20:44.396: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 42.908145ms)
Feb 27 00:20:44.416: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 18.912685ms)
Feb 27 00:20:44.430: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:1080/proxy/rewri... (200; 33.381902ms)
Feb 27 00:20:44.430: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:443/proxy/... (200; 33.000197ms)
Feb 27 00:20:44.430: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:462/proxy/: tls qux (200; 33.794908ms)
Feb 27 00:20:44.431: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname2/proxy/: bar (200; 33.479903ms)
Feb 27 00:20:44.431: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname2/proxy/: bar (200; 34.522419ms)
Feb 27 00:20:44.440: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:160/proxy/: foo (200; 43.433353ms)
Feb 27 00:20:44.440: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/https:proxy-service-wtzkd-rhbp5:460/proxy/: tls baz (200; 42.655441ms)
Feb 27 00:20:44.440: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:1080/proxy/... (200; 42.469738ms)
Feb 27 00:20:44.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname1/proxy/: tls baz (200; 44.145264ms)
Feb 27 00:20:44.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 43.873259ms)
Feb 27 00:20:44.441: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/http:proxy-service-wtzkd:portname1/proxy/: foo (200; 44.895575ms)
Feb 27 00:20:44.446: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/https:proxy-service-wtzkd:tlsportname2/proxy/: tls qux (200; 48.574231ms)
Feb 27 00:20:44.446: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/proxy-service-wtzkd-rhbp5/proxy/rewriteme"... (200; 48.927736ms)
Feb 27 00:20:44.448: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/pods/http:proxy-service-wtzkd-rhbp5:162/proxy/: bar (200; 50.595561ms)
Feb 27 00:20:44.448: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t9vcm/services/proxy-service-wtzkd:portname1/proxy/: foo (200; 51.037467ms)
STEP: deleting ReplicationController proxy-service-wtzkd in namespace e2e-tests-proxy-t9vcm, will wait for the garbage collector to delete the pods
Feb 27 00:20:44.511: INFO: Deleting ReplicationController proxy-service-wtzkd took: 8.366226ms
Feb 27 00:20:44.611: INFO: Terminating ReplicationController proxy-service-wtzkd pods took: 100.41921ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:20:54.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-t9vcm" for this suite.
Feb 27 00:21:00.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:21:00.617: INFO: namespace: e2e-tests-proxy-t9vcm, resource: bindings, ignored listing per whitelist
Feb 27 00:21:00.654: INFO: namespace e2e-tests-proxy-t9vcm deletion completed in 6.12846823s

• [SLOW TEST:30.068 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:21:00.654: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5nr4n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 27 00:21:00.864: INFO: Waiting up to 5m0s for pod "pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-5nr4n" to be "success or failure"
Feb 27 00:21:00.878: INFO: Pod "pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 14.060017ms
Feb 27 00:21:02.883: INFO: Pod "pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018326192s
Feb 27 00:21:04.887: INFO: Pod "pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022405237s
STEP: Saw pod success
Feb 27 00:21:04.887: INFO: Pod "pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:21:04.890: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:21:04.919: INFO: Waiting for pod pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:21:04.945: INFO: Pod pod-8f940bf6-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:21:04.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5nr4n" for this suite.
Feb 27 00:21:10.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:21:11.058: INFO: namespace: e2e-tests-emptydir-5nr4n, resource: bindings, ignored listing per whitelist
Feb 27 00:21:11.073: INFO: namespace e2e-tests-emptydir-5nr4n deletion completed in 6.12262095s

• [SLOW TEST:10.419 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:21:11.074: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-v49g4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 27 00:21:11.301: INFO: Waiting up to 5m0s for pod "pod-95cca560-3a25-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-v49g4" to be "success or failure"
Feb 27 00:21:11.311: INFO: Pod "pod-95cca560-3a25-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 9.330736ms
Feb 27 00:21:13.317: INFO: Pod "pod-95cca560-3a25-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015565695s
STEP: Saw pod success
Feb 27 00:21:13.318: INFO: Pod "pod-95cca560-3a25-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:21:13.321: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-95cca560-3a25-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:21:13.344: INFO: Waiting for pod pod-95cca560-3a25-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:21:13.347: INFO: Pod pod-95cca560-3a25-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:21:13.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v49g4" for this suite.
Feb 27 00:21:19.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:21:19.418: INFO: namespace: e2e-tests-emptydir-v49g4, resource: bindings, ignored listing per whitelist
Feb 27 00:21:19.496: INFO: namespace e2e-tests-emptydir-v49g4 deletion completed in 6.142909392s

• [SLOW TEST:8.422 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:21:19.496: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-wmkdh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:21:19.755: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9ad525e6-3a25-11e9-9b3e-000d3a2390ff", Controller:(*bool)(0xc001a62f86), BlockOwnerDeletion:(*bool)(0xc001a62f87)}}
Feb 27 00:21:19.765: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"9ad108f6-3a25-11e9-9b3e-000d3a2390ff", Controller:(*bool)(0xc001ab0aa6), BlockOwnerDeletion:(*bool)(0xc001ab0aa7)}}
Feb 27 00:21:19.770: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"9ad39f6f-3a25-11e9-9b3e-000d3a2390ff", Controller:(*bool)(0xc001a6321e), BlockOwnerDeletion:(*bool)(0xc001a6321f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:21:24.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-wmkdh" for this suite.
Feb 27 00:21:30.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:21:30.821: INFO: namespace: e2e-tests-gc-wmkdh, resource: bindings, ignored listing per whitelist
Feb 27 00:21:30.913: INFO: namespace e2e-tests-gc-wmkdh deletion completed in 6.126379515s

• [SLOW TEST:11.417 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:21:30.914: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-cw7jl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:21:31.123: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 27 00:21:36.128: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 00:21:36.128: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 27 00:21:38.131: INFO: Creating deployment "test-rollover-deployment"
Feb 27 00:21:38.139: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 27 00:21:40.149: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 27 00:21:40.158: INFO: Ensure that both replica sets have 1 created replica
Feb 27 00:21:40.165: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 27 00:21:40.173: INFO: Updating deployment test-rollover-deployment
Feb 27 00:21:40.173: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 27 00:21:42.181: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 27 00:21:42.188: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 27 00:21:42.195: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 00:21:42.195: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823700, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:21:44.205: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 00:21:44.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823702, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:21:46.209: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 00:21:46.209: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823702, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:21:48.204: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 00:21:48.204: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823702, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:21:50.203: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 00:21:50.204: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823702, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:21:52.204: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 00:21:52.204: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823702, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686823698, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:21:54.204: INFO: 
Feb 27 00:21:54.204: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 00:21:54.212: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-cw7jl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cw7jl/deployments/test-rollover-deployment,UID:a5cd37bf-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57068,Generation:2,CreationTimestamp:2019-02-27 00:21:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-27 00:21:38 +0000 UTC 2019-02-27 00:21:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-27 00:21:52 +0000 UTC 2019-02-27 00:21:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 27 00:21:54.216: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-cw7jl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cw7jl/replicasets/test-rollover-deployment-6b7f9d6597,UID:a704f890-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57059,Generation:2,CreationTimestamp:2019-02-27 00:21:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a5cd37bf-3a25-11e9-9b3e-000d3a2390ff 0xc002320cc7 0xc002320cc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 00:21:54.216: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 27 00:21:54.216: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-cw7jl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cw7jl/replicasets/test-rollover-controller,UID:a19eb2e2-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57067,Generation:2,CreationTimestamp:2019-02-27 00:21:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a5cd37bf-3a25-11e9-9b3e-000d3a2390ff 0xc002320ab7 0xc002320ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 00:21:54.216: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-cw7jl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cw7jl/replicasets/test-rollover-deployment-6586df867b,UID:a5d06225-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57024,Generation:2,CreationTimestamp:2019-02-27 00:21:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a5cd37bf-3a25-11e9-9b3e-000d3a2390ff 0xc002320bf7 0xc002320bf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 00:21:54.220: INFO: Pod "test-rollover-deployment-6b7f9d6597-489x4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-489x4,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-cw7jl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cw7jl/pods/test-rollover-deployment-6b7f9d6597-489x4,UID:a70cbbf0-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57040,Generation:0,CreationTimestamp:2019-02-27 00:21:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.79/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 a704f890-3a25-11e9-9b3e-000d3a2390ff 0xc002321cc7 0xc002321cc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdv2d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdv2d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qdv2d true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002321d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002321d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:21:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:21:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:21:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:21:40 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.79,StartTime:2019-02-27 00:21:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-27 00:21:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://992a5c52a5ec20939c9ac2fe87bba5e4deabe28c75a417626f71c5947c12ba35}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:21:54.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cw7jl" for this suite.
Feb 27 00:22:00.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:22:00.315: INFO: namespace: e2e-tests-deployment-cw7jl, resource: bindings, ignored listing per whitelist
Feb 27 00:22:00.356: INFO: namespace e2e-tests-deployment-cw7jl deletion completed in 6.132730363s

• [SLOW TEST:29.443 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:22:00.357: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5vw9c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 27 00:22:00.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 --namespace=e2e-tests-kubectl-5vw9c run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 27 00:22:03.272: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 27 00:22:03.272: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:22:05.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5vw9c" for this suite.
Feb 27 00:22:11.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:22:11.342: INFO: namespace: e2e-tests-kubectl-5vw9c, resource: bindings, ignored listing per whitelist
Feb 27 00:22:11.419: INFO: namespace e2e-tests-kubectl-5vw9c deletion completed in 6.135956132s

• [SLOW TEST:11.063 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:22:11.420: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-bl2bb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:22:11.644: INFO: Creating deployment "nginx-deployment"
Feb 27 00:22:11.650: INFO: Waiting for observed generation 1
Feb 27 00:22:13.658: INFO: Waiting for all required pods to come up
Feb 27 00:22:13.668: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 27 00:22:15.687: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 27 00:22:15.702: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 27 00:22:15.710: INFO: Updating deployment nginx-deployment
Feb 27 00:22:15.710: INFO: Waiting for observed generation 2
Feb 27 00:22:17.720: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 27 00:22:17.722: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 27 00:22:17.727: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 27 00:22:17.757: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 27 00:22:17.757: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 27 00:22:17.761: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 27 00:22:17.769: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 27 00:22:17.769: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 27 00:22:17.781: INFO: Updating deployment nginx-deployment
Feb 27 00:22:17.781: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 27 00:22:17.798: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 27 00:22:17.809: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 00:22:19.857: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bl2bb/deployments/nginx-deployment,UID:b9c6ca71-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57445,Generation:3,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-27 00:22:17 +0000 UTC 2019-02-27 00:22:17 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-27 00:22:18 +0000 UTC 2019-02-27 00:22:11 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 27 00:22:19.866: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bl2bb/replicasets/nginx-deployment-65bbdb5f8,UID:bc33e58f-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57429,Generation:3,CreationTimestamp:2019-02-27 00:22:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b9c6ca71-3a25-11e9-9b3e-000d3a2390ff 0xc001b058e7 0xc001b058e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 00:22:19.866: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 27 00:22:19.866: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bl2bb/replicasets/nginx-deployment-555b55d965,UID:b9c87ad0-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57444,Generation:3,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b9c6ca71-3a25-11e9-9b3e-000d3a2390ff 0xc001b05827 0xc001b05828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 27 00:22:19.885: INFO: Pod "nginx-deployment-555b55d965-6tlfr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6tlfr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-6tlfr,UID:b9ce4f82-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57276,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.129.32/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005fe457 0xc0005fe458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005fe4c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005fe4e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:10.1.129.32,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://7b33b554f70f4b995cdff8507666466e9b679b651f120115c2ab51a36f9611fc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.886: INFO: Pod "nginx-deployment-555b55d965-74tdf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-74tdf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-74tdf,UID:bd75a8c2-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57454,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005fe5a0 0xc0005fe5a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005fe670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005fe690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.886: INFO: Pod "nginx-deployment-555b55d965-7mnpd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7mnpd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-7mnpd,UID:bd83c33e-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57487,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005fe740 0xc0005fe741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005fe7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005fe7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.887: INFO: Pod "nginx-deployment-555b55d965-7pdqw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7pdqw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-7pdqw,UID:bd840163-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57435,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005fe9b0 0xc0005fe9b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005fea10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005fea30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.888: INFO: Pod "nginx-deployment-555b55d965-9sgl2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9sgl2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-9sgl2,UID:b9d3300b-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57304,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.84/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005febf0 0xc0005febf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005fec50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005fec70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.84,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://39680b7726af4b8b1d7dc3fe86565f1f6bc249a2349701791a7842ec5c936110}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.888: INFO: Pod "nginx-deployment-555b55d965-9trs9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9trs9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-9trs9,UID:b9db4359-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57292,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.129.35/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005fed40 0xc0005fed41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005fee80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005feea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:10.1.129.35,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://66b4c6a86f92ec942d093839dd8f7fff28cd53fa2ad116590748a7c29c1c07e4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.889: INFO: Pod "nginx-deployment-555b55d965-9v997" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9v997,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-9v997,UID:b9dc0999-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57298,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.85/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005fef70 0xc0005fef71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ff040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ff060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.85,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://c7b0197161c1f9b81e157284e4ead648b5851f577e3d773f7011a28355d0b41d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.889: INFO: Pod "nginx-deployment-555b55d965-d84z4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d84z4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-d84z4,UID:b9ceb228-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57295,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.82/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ff130 0xc0005ff131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ff190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ff1b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.82,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://e6c7e83382ede5112e7e4be6ec43740023359570b328723a19eb8007607c0696}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.890: INFO: Pod "nginx-deployment-555b55d965-dnlkf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dnlkf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-dnlkf,UID:b9d2fa8b-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57272,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.129.33/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ff310 0xc0005ff311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ff370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ff390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:10.1.129.33,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8c20a0d144d531b1a18cf783b39c057629e57f50bf1121e73846dc10ba7d2672}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.893: INFO: Pod "nginx-deployment-555b55d965-f9rb9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f9rb9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-f9rb9,UID:b9d384f3-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57281,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.83/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ff4d0 0xc0005ff4d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ff530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ff550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.83,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://a65a55316da264e907f122e1d5cbc129b0cdd8eba241dffd842ea5992756ce8c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.894: INFO: Pod "nginx-deployment-555b55d965-gwdg4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gwdg4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-gwdg4,UID:bd7c3048-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57470,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ff680 0xc0005ff681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ff6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ff700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.895: INFO: Pod "nginx-deployment-555b55d965-jsmhp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jsmhp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-jsmhp,UID:bd7cbcce-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57477,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ff7b0 0xc0005ff7b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ff820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ff8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.896: INFO: Pod "nginx-deployment-555b55d965-kqgqq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kqgqq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-kqgqq,UID:bd75512e-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57488,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.89/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ff980 0xc0005ff981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ff9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ffa00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.897: INFO: Pod "nginx-deployment-555b55d965-krdkt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-krdkt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-krdkt,UID:bd7034d5-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57400,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ffb50 0xc0005ffb51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ffbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ffbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.898: INFO: Pod "nginx-deployment-555b55d965-kxpgw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kxpgw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-kxpgw,UID:b9cc3b69-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57301,Generation:0,CreationTimestamp:2019-02-27 00:22:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.81/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ffc90 0xc0005ffc91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ffcf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ffd10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:11 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.81,StartTime:2019-02-27 00:22:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 00:22:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://1f51ba51771a4687ed44ff344991eedf2704c9da79993827067915774d716cbf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.899: INFO: Pod "nginx-deployment-555b55d965-q92ff" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q92ff,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-q92ff,UID:bd8349e5-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57491,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005ffdd0 0xc0005ffdd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ffe30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ffe50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.900: INFO: Pod "nginx-deployment-555b55d965-qbxfs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qbxfs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-qbxfs,UID:bd7bef8e-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57490,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0005fff00 0xc0005fff01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005fff60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005fff80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.901: INFO: Pod "nginx-deployment-555b55d965-rlvcm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rlvcm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-rlvcm,UID:bd838620-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57431,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc002198160 0xc002198161}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021981c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021981e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.901: INFO: Pod "nginx-deployment-555b55d965-schgz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-schgz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-schgz,UID:bd8255cb-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57481,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc0021982f0 0xc0021982f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002198390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002198e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.901: INFO: Pod "nginx-deployment-555b55d965-w7l56" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w7l56,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-555b55d965-w7l56,UID:bd7c64d2-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57486,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9c87ad0-3a25-11e9-9b3e-000d3a2390ff 0xc002199000 0xc002199001}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002199090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002199120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.902: INFO: Pod "nginx-deployment-65bbdb5f8-2zk4j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2zk4j,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-2zk4j,UID:bc34b683-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57362,Generation:0,CreationTimestamp:2019-02-27 00:22:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.86/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc0021993b0 0xc0021993b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002199470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021995c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.902: INFO: Pod "nginx-deployment-65bbdb5f8-4chc2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4chc2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-4chc2,UID:bd723beb-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57437,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc0021996e0 0xc0021996e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002199780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002199870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.902: INFO: Pod "nginx-deployment-65bbdb5f8-7mzs9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7mzs9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-7mzs9,UID:bc42d2f6-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57368,Generation:0,CreationTimestamp:2019-02-27 00:22:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.88/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002199a30 0xc002199a31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002199b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002199b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.904: INFO: Pod "nginx-deployment-65bbdb5f8-cbnmx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cbnmx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-cbnmx,UID:bc36c174-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57364,Generation:0,CreationTimestamp:2019-02-27 00:22:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.129.37/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002199d40 0xc002199d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002199e00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002199ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.904: INFO: Pod "nginx-deployment-65bbdb5f8-g7c49" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-g7c49,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-g7c49,UID:bd7b6b16-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57464,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002120230 0xc002120231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002120610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002120630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.907: INFO: Pod "nginx-deployment-65bbdb5f8-gqv8v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gqv8v,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-gqv8v,UID:bc376cbe-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57365,Generation:0,CreationTimestamp:2019-02-27 00:22:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.87/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002120780 0xc002120781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021207f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002120810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.907: INFO: Pod "nginx-deployment-65bbdb5f8-h7h6d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h7h6d,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-h7h6d,UID:bd7abb14-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57469,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002120a00 0xc002120a01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002120a70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002120a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.912: INFO: Pod "nginx-deployment-65bbdb5f8-k748f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-k748f,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-k748f,UID:bd828810-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57494,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002120b60 0xc002120b61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002120c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002120c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.912: INFO: Pod "nginx-deployment-65bbdb5f8-kg9vw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-kg9vw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-kg9vw,UID:bc3ff1d0-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57482,Generation:0,CreationTimestamp:2019-02-27 00:22:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.129.38/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002120d60 0xc002120d61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002120e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002120e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:15 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.917: INFO: Pod "nginx-deployment-65bbdb5f8-mlzpf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mlzpf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-mlzpf,UID:bd7d3ab0-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57463,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002120f10 0xc002120f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002120f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002120fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.920: INFO: Pod "nginx-deployment-65bbdb5f8-pchsk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pchsk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-pchsk,UID:bd779af0-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57460,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002121060 0xc002121061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000001,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021210d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021210f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.5,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.920: INFO: Pod "nginx-deployment-65bbdb5f8-s5kvp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-s5kvp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-s5kvp,UID:bd7b6f8c-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57461,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc0021211b0 0xc0021211b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002121220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002121240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 00:22:19.921: INFO: Pod "nginx-deployment-65bbdb5f8-t7ktx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-t7ktx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-bl2bb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bl2bb/pods/nginx-deployment-65bbdb5f8-t7ktx,UID:bd76d902-3a25-11e9-9b3e-000d3a2390ff,ResourceVersion:57442,Generation:0,CreationTimestamp:2019-02-27 00:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bc33e58f-3a25-11e9-9b3e-000d3a2390ff 0xc002121300 0xc002121301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8dtk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8dtk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-s8dtk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002121370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002121390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:22:17 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:,StartTime:2019-02-27 00:22:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:22:19.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bl2bb" for this suite.
Feb 27 00:22:27.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:22:28.026: INFO: namespace: e2e-tests-deployment-bl2bb, resource: bindings, ignored listing per whitelist
Feb 27 00:22:28.530: INFO: namespace e2e-tests-deployment-bl2bb deletion completed in 8.592941871s

• [SLOW TEST:17.110 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:22:28.530: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-pb87w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pb87w
Feb 27 00:22:33.196: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pb87w
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 00:22:33.199: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:26:33.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pb87w" for this suite.
Feb 27 00:26:39.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:26:39.917: INFO: namespace: e2e-tests-container-probe-pb87w, resource: bindings, ignored listing per whitelist
Feb 27 00:26:39.920: INFO: namespace e2e-tests-container-probe-pb87w deletion completed in 6.14104165s

• [SLOW TEST:251.390 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:26:39.920: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-xwpbb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-xwpbb.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-xwpbb.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xwpbb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-xwpbb.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-xwpbb.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xwpbb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 27 00:27:06.240: INFO: DNS probes using e2e-tests-dns-xwpbb/dns-test-59ccb7e6-3a26-11e9-9b83-4a9a78a986da succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:27:06.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-xwpbb" for this suite.
Feb 27 00:27:12.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:27:12.450: INFO: namespace: e2e-tests-dns-xwpbb, resource: bindings, ignored listing per whitelist
Feb 27 00:27:12.505: INFO: namespace e2e-tests-dns-xwpbb deletion completed in 6.215349823s

• [SLOW TEST:32.585 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:27:12.508: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-bds29
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 00:27:15.269: INFO: Successfully updated pod "annotationupdate6d3a29dd-3a26-11e9-9b83-4a9a78a986da"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:27:17.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bds29" for this suite.
Feb 27 00:27:39.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:27:39.356: INFO: namespace: e2e-tests-downward-api-bds29, resource: bindings, ignored listing per whitelist
Feb 27 00:27:39.425: INFO: namespace e2e-tests-downward-api-bds29 deletion completed in 22.130015641s

• [SLOW TEST:26.917 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:27:39.425: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-c8xjc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:27:39.641: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d449881-3a26-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-c8xjc" to be "success or failure"
Feb 27 00:27:39.652: INFO: Pod "downwardapi-volume-7d449881-3a26-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 10.162507ms
Feb 27 00:27:41.658: INFO: Pod "downwardapi-volume-7d449881-3a26-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016129773s
STEP: Saw pod success
Feb 27 00:27:41.658: INFO: Pod "downwardapi-volume-7d449881-3a26-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:27:41.662: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-7d449881-3a26-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:27:41.690: INFO: Waiting for pod downwardapi-volume-7d449881-3a26-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:27:41.695: INFO: Pod downwardapi-volume-7d449881-3a26-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:27:41.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c8xjc" for this suite.
Feb 27 00:27:47.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:27:47.748: INFO: namespace: e2e-tests-projected-c8xjc, resource: bindings, ignored listing per whitelist
Feb 27 00:27:47.827: INFO: namespace e2e-tests-projected-c8xjc deletion completed in 6.123772089s

• [SLOW TEST:8.402 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:27:47.827: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-qzhnv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:28:13.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-qzhnv" for this suite.
Feb 27 00:28:19.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:28:19.525: INFO: namespace: e2e-tests-container-runtime-qzhnv, resource: bindings, ignored listing per whitelist
Feb 27 00:28:19.581: INFO: namespace e2e-tests-container-runtime-qzhnv deletion completed in 6.124057946s

• [SLOW TEST:31.754 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:28:19.581: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-tcjgd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 00:28:19.801: INFO: PodSpec: initContainers in spec.initContainers
Feb 27 00:29:08.865: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-9535e4fc-3a26-11e9-9b83-4a9a78a986da", GenerateName:"", Namespace:"e2e-tests-init-container-tcjgd", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-tcjgd/pods/pod-init-9535e4fc-3a26-11e9-9b83-4a9a78a986da", UID:"953730a5-3a26-11e9-9b3e-000d3a2390ff", ResourceVersion:"58625", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686824099, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"801664242"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.1.130.104/32", "kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-ntk5f", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000f119c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ntk5f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ntk5f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ntk5f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001cf1c78), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"9cy76-worker-000000", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0010476e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001cf1d60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001cf1d80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001cf1d88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001cf1d8c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824099, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824099, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824099, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824099, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.1.4", PodIP:"10.1.130.104", StartTime:(*v1.Time)(0xc002039ce0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001977d50)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001977e30)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://1078e89bc47c711846b31b061035a51e53da938a66512e61bc477903a1eac027"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002039d20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002039d00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:29:08.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tcjgd" for this suite.
Feb 27 00:29:30.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:29:31.019: INFO: namespace: e2e-tests-init-container-tcjgd, resource: bindings, ignored listing per whitelist
Feb 27 00:29:31.027: INFO: namespace e2e-tests-init-container-tcjgd deletion completed in 22.154612988s

• [SLOW TEST:71.446 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:29:31.028: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m5h6x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-bfca75ec-3a26-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:29:31.251: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bfcb0854-3a26-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-m5h6x" to be "success or failure"
Feb 27 00:29:31.258: INFO: Pod "pod-projected-secrets-bfcb0854-3a26-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.741362ms
Feb 27 00:29:33.270: INFO: Pod "pod-projected-secrets-bfcb0854-3a26-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018521986s
STEP: Saw pod success
Feb 27 00:29:33.270: INFO: Pod "pod-projected-secrets-bfcb0854-3a26-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:29:33.286: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-secrets-bfcb0854-3a26-11e9-9b83-4a9a78a986da container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:29:33.324: INFO: Waiting for pod pod-projected-secrets-bfcb0854-3a26-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:29:33.337: INFO: Pod pod-projected-secrets-bfcb0854-3a26-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:29:33.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m5h6x" for this suite.
Feb 27 00:29:39.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:29:39.463: INFO: namespace: e2e-tests-projected-m5h6x, resource: bindings, ignored listing per whitelist
Feb 27 00:29:39.477: INFO: namespace e2e-tests-projected-m5h6x deletion completed in 6.135003682s

• [SLOW TEST:8.449 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:29:39.477: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-9mnq9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 27 00:29:40.198: INFO: Waiting up to 5m0s for pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j" in namespace "e2e-tests-svcaccounts-9mnq9" to be "success or failure"
Feb 27 00:29:40.205: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j": Phase="Pending", Reason="", readiness=false. Elapsed: 6.445262ms
Feb 27 00:29:42.210: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011881714s
Feb 27 00:29:44.214: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015885011s
STEP: Saw pod success
Feb 27 00:29:44.214: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j" satisfied condition "success or failure"
Feb 27 00:29:44.217: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j container token-test: <nil>
STEP: delete the pod
Feb 27 00:29:44.254: INFO: Waiting for pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j to disappear
Feb 27 00:29:44.258: INFO: Pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-j8w6j no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 27 00:29:44.263: INFO: Waiting up to 5m0s for pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-cpwsr" in namespace "e2e-tests-svcaccounts-9mnq9" to be "success or failure"
Feb 27 00:29:44.267: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-cpwsr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.889639ms
Feb 27 00:29:46.272: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-cpwsr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008836999s
STEP: Saw pod success
Feb 27 00:29:46.272: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-cpwsr" satisfied condition "success or failure"
Feb 27 00:29:46.274: INFO: Trying to get logs from node 9cy76-worker-000001 pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-cpwsr container root-ca-test: <nil>
STEP: delete the pod
Feb 27 00:29:46.298: INFO: Waiting for pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-cpwsr to disappear
Feb 27 00:29:46.303: INFO: Pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-cpwsr no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 27 00:29:46.308: INFO: Waiting up to 5m0s for pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt" in namespace "e2e-tests-svcaccounts-9mnq9" to be "success or failure"
Feb 27 00:29:46.313: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt": Phase="Pending", Reason="", readiness=false. Elapsed: 5.355653ms
Feb 27 00:29:48.317: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009537579s
Feb 27 00:29:50.321: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013528429s
STEP: Saw pod success
Feb 27 00:29:50.321: INFO: Pod "pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt" satisfied condition "success or failure"
Feb 27 00:29:50.324: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt container namespace-test: <nil>
STEP: delete the pod
Feb 27 00:29:50.348: INFO: Waiting for pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt to disappear
Feb 27 00:29:50.360: INFO: Pod pod-service-account-c5207558-3a26-11e9-9b83-4a9a78a986da-wltdt no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:29:50.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-9mnq9" for this suite.
Feb 27 00:29:56.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:29:56.500: INFO: namespace: e2e-tests-svcaccounts-9mnq9, resource: bindings, ignored listing per whitelist
Feb 27 00:29:56.521: INFO: namespace e2e-tests-svcaccounts-9mnq9 deletion completed in 6.156039049s

• [SLOW TEST:17.044 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:29:56.522: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4mffb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:29:56.756: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-4mffb" to be "success or failure"
Feb 27 00:29:56.761: INFO: Pod "downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.610943ms
Feb 27 00:29:58.766: INFO: Pod "downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00953298s
Feb 27 00:30:00.772: INFO: Pod "downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015366269s
STEP: Saw pod success
Feb 27 00:30:00.772: INFO: Pod "downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:30:00.776: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:30:00.800: INFO: Waiting for pod downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:30:00.821: INFO: Pod downwardapi-volume-cefeb213-3a26-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:30:00.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4mffb" for this suite.
Feb 27 00:30:06.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:30:06.901: INFO: namespace: e2e-tests-downward-api-4mffb, resource: bindings, ignored listing per whitelist
Feb 27 00:30:06.983: INFO: namespace e2e-tests-downward-api-4mffb deletion completed in 6.14478671s

• [SLOW TEST:10.461 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:30:06.983: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-9bnxr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 27 00:30:24.283: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:30:25.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-9bnxr" for this suite.
Feb 27 00:30:47.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:30:47.369: INFO: namespace: e2e-tests-replicaset-9bnxr, resource: bindings, ignored listing per whitelist
Feb 27 00:30:47.441: INFO: namespace e2e-tests-replicaset-9bnxr deletion completed in 22.121368998s

• [SLOW TEST:40.458 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:30:47.441: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bpzkr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 27 00:30:47.660: INFO: Waiting up to 5m0s for pod "pod-ed567e66-3a26-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-bpzkr" to be "success or failure"
Feb 27 00:30:47.668: INFO: Pod "pod-ed567e66-3a26-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.544473ms
Feb 27 00:30:49.673: INFO: Pod "pod-ed567e66-3a26-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012416982s
Feb 27 00:30:51.676: INFO: Pod "pod-ed567e66-3a26-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01600969s
STEP: Saw pod success
Feb 27 00:30:51.676: INFO: Pod "pod-ed567e66-3a26-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:30:51.679: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-ed567e66-3a26-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:30:51.707: INFO: Waiting for pod pod-ed567e66-3a26-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:30:51.715: INFO: Pod pod-ed567e66-3a26-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:30:51.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bpzkr" for this suite.
Feb 27 00:30:57.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:30:57.881: INFO: namespace: e2e-tests-emptydir-bpzkr, resource: bindings, ignored listing per whitelist
Feb 27 00:30:57.883: INFO: namespace e2e-tests-emptydir-bpzkr deletion completed in 6.147634365s

• [SLOW TEST:10.442 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:30:57.883: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-fm9h6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-fm9h6
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-fm9h6
STEP: Deleting pre-stop pod
Feb 27 00:31:13.156: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:31:13.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-fm9h6" for this suite.
Feb 27 00:31:51.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:31:51.296: INFO: namespace: e2e-tests-prestop-fm9h6, resource: bindings, ignored listing per whitelist
Feb 27 00:31:51.317: INFO: namespace e2e-tests-prestop-fm9h6 deletion completed in 38.136153932s

• [SLOW TEST:53.434 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:31:51.321: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d5vcz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 27 00:31:51.535: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 27 00:31:51.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:31:52.893: INFO: stderr: ""
Feb 27 00:31:52.893: INFO: stdout: "service/redis-slave created\n"
Feb 27 00:31:52.893: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 27 00:31:52.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:31:53.267: INFO: stderr: ""
Feb 27 00:31:53.267: INFO: stdout: "service/redis-master created\n"
Feb 27 00:31:53.267: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 27 00:31:53.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:31:53.665: INFO: stderr: ""
Feb 27 00:31:53.665: INFO: stdout: "service/frontend created\n"
Feb 27 00:31:53.665: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 27 00:31:53.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:31:54.005: INFO: stderr: ""
Feb 27 00:31:54.005: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 27 00:31:54.006: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 27 00:31:54.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:31:54.383: INFO: stderr: ""
Feb 27 00:31:54.383: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 27 00:31:54.383: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 27 00:31:54.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:31:54.865: INFO: stderr: ""
Feb 27 00:31:54.865: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 27 00:31:54.865: INFO: Waiting for all frontend pods to be Running.
Feb 27 00:32:39.919: INFO: Waiting for frontend to serve content.
Feb 27 00:32:44.938: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 27 00:32:49.957: INFO: Trying to add a new entry to the guestbook.
Feb 27 00:32:49.971: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 27 00:32:49.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:32:50.087: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:32:50.087: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 00:32:50.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:32:50.254: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:32:50.254: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 00:32:50.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:32:50.382: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:32:50.382: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 00:32:50.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:32:50.515: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:32:50.515: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 00:32:50.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:32:50.671: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:32:50.671: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 00:32:50.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d5vcz'
Feb 27 00:32:50.940: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:32:50.940: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:32:50.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d5vcz" for this suite.
Feb 27 00:33:30.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:33:31.092: INFO: namespace: e2e-tests-kubectl-d5vcz, resource: bindings, ignored listing per whitelist
Feb 27 00:33:31.112: INFO: namespace e2e-tests-kubectl-d5vcz deletion completed in 40.154554273s

• [SLOW TEST:99.791 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:33:31.112: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-w7vvh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4ee37037-3a27-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 00:33:31.332: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ee40c4a-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-w7vvh" to be "success or failure"
Feb 27 00:33:31.341: INFO: Pod "pod-configmaps-4ee40c4a-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.861074ms
Feb 27 00:33:33.348: INFO: Pod "pod-configmaps-4ee40c4a-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016030116s
STEP: Saw pod success
Feb 27 00:33:33.349: INFO: Pod "pod-configmaps-4ee40c4a-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:33:33.351: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-4ee40c4a-3a27-11e9-9b83-4a9a78a986da container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 00:33:33.384: INFO: Waiting for pod pod-configmaps-4ee40c4a-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:33:33.386: INFO: Pod pod-configmaps-4ee40c4a-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:33:33.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w7vvh" for this suite.
Feb 27 00:33:39.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:33:39.426: INFO: namespace: e2e-tests-configmap-w7vvh, resource: bindings, ignored listing per whitelist
Feb 27 00:33:39.556: INFO: namespace e2e-tests-configmap-w7vvh deletion completed in 6.164407713s

• [SLOW TEST:8.444 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:33:39.557: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5c7d2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-53ec015f-3a27-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:33:39.773: INFO: Waiting up to 5m0s for pod "pod-secrets-53ecac38-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-5c7d2" to be "success or failure"
Feb 27 00:33:39.782: INFO: Pod "pod-secrets-53ecac38-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.591173ms
Feb 27 00:33:41.786: INFO: Pod "pod-secrets-53ecac38-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013034776s
STEP: Saw pod success
Feb 27 00:33:41.786: INFO: Pod "pod-secrets-53ecac38-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:33:41.789: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-53ecac38-3a27-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:33:41.814: INFO: Waiting for pod pod-secrets-53ecac38-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:33:41.816: INFO: Pod pod-secrets-53ecac38-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:33:41.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5c7d2" for this suite.
Feb 27 00:33:47.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:33:47.939: INFO: namespace: e2e-tests-secrets-5c7d2, resource: bindings, ignored listing per whitelist
Feb 27 00:33:47.967: INFO: namespace e2e-tests-secrets-5c7d2 deletion completed in 6.134647848s

• [SLOW TEST:8.411 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:33:47.967: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-bb8lb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 27 00:33:50.735: INFO: Successfully updated pod "pod-update-58f33006-3a27-11e9-9b83-4a9a78a986da"
STEP: verifying the updated pod is in kubernetes
Feb 27 00:33:50.744: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:33:50.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bb8lb" for this suite.
Feb 27 00:34:12.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:34:12.784: INFO: namespace: e2e-tests-pods-bb8lb, resource: bindings, ignored listing per whitelist
Feb 27 00:34:12.874: INFO: namespace e2e-tests-pods-bb8lb deletion completed in 22.125126528s

• [SLOW TEST:24.907 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:34:12.875: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-5dwxs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:34:13.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5dwxs" for this suite.
Feb 27 00:34:19.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:34:19.121: INFO: namespace: e2e-tests-services-5dwxs, resource: bindings, ignored listing per whitelist
Feb 27 00:34:19.228: INFO: namespace e2e-tests-services-5dwxs deletion completed in 6.136675329s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.353 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:34:19.228: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-qhx2s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-2mpb
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 00:34:19.503: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2mpb" in namespace "e2e-tests-subpath-qhx2s" to be "success or failure"
Feb 27 00:34:19.512: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.840573ms
Feb 27 00:34:21.515: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012198353s
Feb 27 00:34:23.519: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 4.016067162s
Feb 27 00:34:25.523: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 6.019541098s
Feb 27 00:34:27.526: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 8.023411233s
Feb 27 00:34:29.531: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 10.027821667s
Feb 27 00:34:31.536: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 12.033431705s
Feb 27 00:34:33.540: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 14.036994724s
Feb 27 00:34:35.544: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 16.04082704s
Feb 27 00:34:37.549: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 18.046460964s
Feb 27 00:34:39.553: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 20.05021127s
Feb 27 00:34:41.557: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Running", Reason="", readiness=false. Elapsed: 22.05360707s
Feb 27 00:34:43.560: INFO: Pod "pod-subpath-test-configmap-2mpb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.056785463s
STEP: Saw pod success
Feb 27 00:34:43.560: INFO: Pod "pod-subpath-test-configmap-2mpb" satisfied condition "success or failure"
Feb 27 00:34:43.563: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-subpath-test-configmap-2mpb container test-container-subpath-configmap-2mpb: <nil>
STEP: delete the pod
Feb 27 00:34:43.583: INFO: Waiting for pod pod-subpath-test-configmap-2mpb to disappear
Feb 27 00:34:43.598: INFO: Pod pod-subpath-test-configmap-2mpb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2mpb
Feb 27 00:34:43.598: INFO: Deleting pod "pod-subpath-test-configmap-2mpb" in namespace "e2e-tests-subpath-qhx2s"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:34:43.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qhx2s" for this suite.
Feb 27 00:34:49.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:34:49.685: INFO: namespace: e2e-tests-subpath-qhx2s, resource: bindings, ignored listing per whitelist
Feb 27 00:34:49.726: INFO: namespace e2e-tests-subpath-qhx2s deletion completed in 6.11877853s

• [SLOW TEST:30.498 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:34:49.727: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fsww6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:34:49.947: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7dc0513e-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-fsww6" to be "success or failure"
Feb 27 00:34:49.951: INFO: Pod "downwardapi-volume-7dc0513e-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.117625ms
Feb 27 00:34:51.954: INFO: Pod "downwardapi-volume-7dc0513e-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006546776s
STEP: Saw pod success
Feb 27 00:34:51.954: INFO: Pod "downwardapi-volume-7dc0513e-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:34:51.957: INFO: Trying to get logs from node 9cy76-worker-000001 pod downwardapi-volume-7dc0513e-3a27-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:34:51.981: INFO: Waiting for pod downwardapi-volume-7dc0513e-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:34:51.984: INFO: Pod downwardapi-volume-7dc0513e-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:34:51.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsww6" for this suite.
Feb 27 00:34:58.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:34:58.150: INFO: namespace: e2e-tests-projected-fsww6, resource: bindings, ignored listing per whitelist
Feb 27 00:34:58.181: INFO: namespace e2e-tests-projected-fsww6 deletion completed in 6.193137134s

• [SLOW TEST:8.454 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:34:58.181: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-6bqqw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:34:58.376: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 27 00:34:58.387: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 27 00:35:03.391: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 00:35:03.391: INFO: Creating deployment "test-rolling-update-deployment"
Feb 27 00:35:03.399: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 27 00:35:03.406: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 27 00:35:05.413: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 27 00:35:05.416: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824503, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824503, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824503, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824503, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:35:07.419: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 00:35:07.428: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-6bqqw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6bqqw/deployments/test-rolling-update-deployment,UID:85c5a976-3a27-11e9-9b3e-000d3a2390ff,ResourceVersion:59891,Generation:1,CreationTimestamp:2019-02-27 00:35:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-27 00:35:03 +0000 UTC 2019-02-27 00:35:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-27 00:35:05 +0000 UTC 2019-02-27 00:35:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 27 00:35:07.433: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-6bqqw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6bqqw/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:85c89da8-3a27-11e9-9b3e-000d3a2390ff,ResourceVersion:59882,Generation:1,CreationTimestamp:2019-02-27 00:35:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 85c5a976-3a27-11e9-9b3e-000d3a2390ff 0xc0014b0e87 0xc0014b0e88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 00:35:07.433: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 27 00:35:07.433: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-6bqqw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6bqqw/replicasets/test-rolling-update-controller,UID:82c871a1-3a27-11e9-9b3e-000d3a2390ff,ResourceVersion:59890,Generation:2,CreationTimestamp:2019-02-27 00:34:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 85c5a976-3a27-11e9-9b3e-000d3a2390ff 0xc0014b0dc7 0xc0014b0dc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 00:35:07.437: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-ztm86" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-ztm86,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-6bqqw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6bqqw/pods/test-rolling-update-deployment-68b55d7bc6-ztm86,UID:85cc44e8-3a27-11e9-9b3e-000d3a2390ff,ResourceVersion:59880,Generation:0,CreationTimestamp:2019-02-27 00:35:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.123/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 85c89da8-3a27-11e9-9b3e-000d3a2390ff 0xc0022e6b27 0xc0022e6b28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nzm6w {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nzm6w,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nzm6w true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e6b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e6bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:35:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:35:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:35:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:35:03 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.123,StartTime:2019-02-27 00:35:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-27 00:35:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b3237afdc0fdd7a187be3bb6c5facded898615956c6956add30f9c6847bfea59}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:35:07.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6bqqw" for this suite.
Feb 27 00:35:13.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:35:13.523: INFO: namespace: e2e-tests-deployment-6bqqw, resource: bindings, ignored listing per whitelist
Feb 27 00:35:13.575: INFO: namespace e2e-tests-deployment-6bqqw deletion completed in 6.134061567s

• [SLOW TEST:15.394 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:35:13.575: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-v6s4j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 27 00:35:13.786: INFO: Waiting up to 5m0s for pod "pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-v6s4j" to be "success or failure"
Feb 27 00:35:13.790: INFO: Pod "pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402536ms
Feb 27 00:35:15.794: INFO: Pod "pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008043729s
Feb 27 00:35:17.797: INFO: Pod "pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011455607s
STEP: Saw pod success
Feb 27 00:35:17.797: INFO: Pod "pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:35:17.800: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:35:17.823: INFO: Waiting for pod pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:35:17.832: INFO: Pod pod-8bf5907d-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:35:17.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v6s4j" for this suite.
Feb 27 00:35:23.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:35:23.920: INFO: namespace: e2e-tests-emptydir-v6s4j, resource: bindings, ignored listing per whitelist
Feb 27 00:35:23.976: INFO: namespace e2e-tests-emptydir-v6s4j deletion completed in 6.13797067s

• [SLOW TEST:10.401 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:35:23.977: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-m5nfh
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 27 00:35:24.200: INFO: Waiting up to 5m0s for pod "pod-922af544-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-m5nfh" to be "success or failure"
Feb 27 00:35:24.207: INFO: Pod "pod-922af544-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.820753ms
Feb 27 00:35:26.211: INFO: Pod "pod-922af544-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010435355s
Feb 27 00:35:28.214: INFO: Pod "pod-922af544-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014044577s
STEP: Saw pod success
Feb 27 00:35:28.214: INFO: Pod "pod-922af544-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:35:28.217: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-922af544-3a27-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:35:28.246: INFO: Waiting for pod pod-922af544-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:35:28.251: INFO: Pod pod-922af544-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:35:28.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m5nfh" for this suite.
Feb 27 00:35:34.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:35:34.367: INFO: namespace: e2e-tests-emptydir-m5nfh, resource: bindings, ignored listing per whitelist
Feb 27 00:35:34.403: INFO: namespace e2e-tests-emptydir-m5nfh deletion completed in 6.142636433s

• [SLOW TEST:10.426 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:35:34.403: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-q44pw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:35:36.693: INFO: Waiting up to 5m0s for pod "client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-pods-q44pw" to be "success or failure"
Feb 27 00:35:36.711: INFO: Pod "client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.128649ms
Feb 27 00:35:38.715: INFO: Pod "client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009839121s
Feb 27 00:35:40.719: INFO: Pod "client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013898511s
STEP: Saw pod success
Feb 27 00:35:40.719: INFO: Pod "client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:35:40.721: INFO: Trying to get logs from node 9cy76-worker-000000 pod client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da container env3cont: <nil>
STEP: delete the pod
Feb 27 00:35:40.741: INFO: Waiting for pod client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:35:40.760: INFO: Pod client-envvars-999b1c13-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:35:40.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-q44pw" for this suite.
Feb 27 00:36:26.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:36:26.902: INFO: namespace: e2e-tests-pods-q44pw, resource: bindings, ignored listing per whitelist
Feb 27 00:36:26.905: INFO: namespace e2e-tests-pods-q44pw deletion completed in 46.138733632s

• [SLOW TEST:52.501 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:36:26.905: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hcxdx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:36:27.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-hcxdx" to be "success or failure"
Feb 27 00:36:27.117: INFO: Pod "downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.322135ms
Feb 27 00:36:29.121: INFO: Pod "downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008039927s
Feb 27 00:36:31.125: INFO: Pod "downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01190893s
STEP: Saw pod success
Feb 27 00:36:31.125: INFO: Pod "downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:36:31.128: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:36:31.151: INFO: Waiting for pod downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:36:31.155: INFO: Pod downwardapi-volume-b7aa91d3-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:36:31.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hcxdx" for this suite.
Feb 27 00:36:37.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:36:37.321: INFO: namespace: e2e-tests-downward-api-hcxdx, resource: bindings, ignored listing per whitelist
Feb 27 00:36:37.324: INFO: namespace e2e-tests-downward-api-hcxdx deletion completed in 6.164380913s

• [SLOW TEST:10.419 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:36:37.325: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-thp94
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-bde66156-3a27-11e9-9b83-4a9a78a986da
STEP: Creating configMap with name cm-test-opt-upd-bde66191-3a27-11e9-9b83-4a9a78a986da
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bde66156-3a27-11e9-9b83-4a9a78a986da
STEP: Updating configmap cm-test-opt-upd-bde66191-3a27-11e9-9b83-4a9a78a986da
STEP: Creating configMap with name cm-test-opt-create-bde661a5-3a27-11e9-9b83-4a9a78a986da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:38:06.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-thp94" for this suite.
Feb 27 00:38:28.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:38:28.210: INFO: namespace: e2e-tests-projected-thp94, resource: bindings, ignored listing per whitelist
Feb 27 00:38:28.215: INFO: namespace e2e-tests-projected-thp94 deletion completed in 22.155372519s

• [SLOW TEST:110.890 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:38:28.215: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6fm2b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fff8f326-3a27-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 00:38:28.427: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-6fm2b" to be "success or failure"
Feb 27 00:38:28.437: INFO: Pod "pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 10.025878ms
Feb 27 00:38:30.442: INFO: Pod "pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014684478s
Feb 27 00:38:32.446: INFO: Pod "pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018429496s
STEP: Saw pod success
Feb 27 00:38:32.446: INFO: Pod "pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:38:32.449: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 00:38:32.479: INFO: Waiting for pod pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:38:32.493: INFO: Pod pod-projected-configmaps-fff978ae-3a27-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:38:32.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6fm2b" for this suite.
Feb 27 00:38:38.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:38:38.618: INFO: namespace: e2e-tests-projected-6fm2b, resource: bindings, ignored listing per whitelist
Feb 27 00:38:38.652: INFO: namespace e2e-tests-projected-6fm2b deletion completed in 6.149132357s

• [SLOW TEST:10.437 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:38:38.652: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-86d4x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 27 00:38:38.858: INFO: Waiting up to 5m0s for pod "client-containers-06315303-3a28-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-containers-86d4x" to be "success or failure"
Feb 27 00:38:38.874: INFO: Pod "client-containers-06315303-3a28-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 15.94281ms
Feb 27 00:38:40.877: INFO: Pod "client-containers-06315303-3a28-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019259484s
Feb 27 00:38:42.881: INFO: Pod "client-containers-06315303-3a28-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023118508s
STEP: Saw pod success
Feb 27 00:38:42.881: INFO: Pod "client-containers-06315303-3a28-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:38:42.884: INFO: Trying to get logs from node 9cy76-worker-000000 pod client-containers-06315303-3a28-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:38:42.903: INFO: Waiting for pod client-containers-06315303-3a28-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:38:42.922: INFO: Pod client-containers-06315303-3a28-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:38:42.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-86d4x" for this suite.
Feb 27 00:38:48.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:38:49.025: INFO: namespace: e2e-tests-containers-86d4x, resource: bindings, ignored listing per whitelist
Feb 27 00:38:49.053: INFO: namespace e2e-tests-containers-86d4x deletion completed in 6.123217032s

• [SLOW TEST:10.401 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:38:49.054: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mzwg2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 27 00:38:49.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-mzwg2'
Feb 27 00:38:49.762: INFO: stderr: ""
Feb 27 00:38:49.762: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 27 00:38:50.766: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:38:50.766: INFO: Found 0 / 1
Feb 27 00:38:51.773: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:38:51.773: INFO: Found 0 / 1
Feb 27 00:38:52.766: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:38:52.767: INFO: Found 1 / 1
Feb 27 00:38:52.767: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 00:38:52.770: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 00:38:52.770: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 27 00:38:52.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 logs redis-master-49m87 redis-master --namespace=e2e-tests-kubectl-mzwg2'
Feb 27 00:38:52.861: INFO: stderr: ""
Feb 27 00:38:52.861: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 00:38:51.784 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 00:38:51.784 # Server started, Redis version 3.2.12\n1:M 27 Feb 00:38:51.785 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 00:38:51.785 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 27 00:38:52.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 log redis-master-49m87 redis-master --namespace=e2e-tests-kubectl-mzwg2 --tail=1'
Feb 27 00:38:52.957: INFO: stderr: ""
Feb 27 00:38:52.957: INFO: stdout: "1:M 27 Feb 00:38:51.785 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 27 00:38:52.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 log redis-master-49m87 redis-master --namespace=e2e-tests-kubectl-mzwg2 --limit-bytes=1'
Feb 27 00:38:53.052: INFO: stderr: ""
Feb 27 00:38:53.052: INFO: stdout: " "
STEP: exposing timestamps
Feb 27 00:38:53.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 log redis-master-49m87 redis-master --namespace=e2e-tests-kubectl-mzwg2 --tail=1 --timestamps'
Feb 27 00:38:53.145: INFO: stderr: ""
Feb 27 00:38:53.146: INFO: stdout: "2019-02-27T00:38:51.785401204Z 1:M 27 Feb 00:38:51.785 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 27 00:38:55.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 log redis-master-49m87 redis-master --namespace=e2e-tests-kubectl-mzwg2 --since=1s'
Feb 27 00:38:55.739: INFO: stderr: ""
Feb 27 00:38:55.739: INFO: stdout: ""
Feb 27 00:38:55.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 log redis-master-49m87 redis-master --namespace=e2e-tests-kubectl-mzwg2 --since=24h'
Feb 27 00:38:55.827: INFO: stderr: ""
Feb 27 00:38:55.827: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 00:38:51.784 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 00:38:51.784 # Server started, Redis version 3.2.12\n1:M 27 Feb 00:38:51.785 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 00:38:51.785 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 27 00:38:55.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mzwg2'
Feb 27 00:38:55.913: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 00:38:55.913: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 27 00:38:55.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-mzwg2'
Feb 27 00:38:56.009: INFO: stderr: "No resources found.\n"
Feb 27 00:38:56.009: INFO: stdout: ""
Feb 27 00:38:56.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -l name=nginx --namespace=e2e-tests-kubectl-mzwg2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 00:38:56.144: INFO: stderr: ""
Feb 27 00:38:56.144: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:38:56.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mzwg2" for this suite.
Feb 27 00:39:16.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:39:16.239: INFO: namespace: e2e-tests-kubectl-mzwg2, resource: bindings, ignored listing per whitelist
Feb 27 00:39:16.277: INFO: namespace e2e-tests-kubectl-mzwg2 deletion completed in 20.127993272s

• [SLOW TEST:27.223 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:39:16.277: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8fgcd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1ca2671a-3a28-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:39:16.516: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ca34264-3a28-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-8fgcd" to be "success or failure"
Feb 27 00:39:16.521: INFO: Pod "pod-projected-secrets-1ca34264-3a28-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075431ms
Feb 27 00:39:18.525: INFO: Pod "pod-projected-secrets-1ca34264-3a28-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008466407s
STEP: Saw pod success
Feb 27 00:39:18.525: INFO: Pod "pod-projected-secrets-1ca34264-3a28-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:39:18.529: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-secrets-1ca34264-3a28-11e9-9b83-4a9a78a986da container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:39:18.558: INFO: Waiting for pod pod-projected-secrets-1ca34264-3a28-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:39:18.565: INFO: Pod pod-projected-secrets-1ca34264-3a28-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:39:18.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8fgcd" for this suite.
Feb 27 00:39:24.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:39:24.651: INFO: namespace: e2e-tests-projected-8fgcd, resource: bindings, ignored listing per whitelist
Feb 27 00:39:24.718: INFO: namespace e2e-tests-projected-8fgcd deletion completed in 6.140431778s

• [SLOW TEST:8.440 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:39:24.718: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-x759l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:39:24.931: INFO: Creating deployment "test-recreate-deployment"
Feb 27 00:39:24.935: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 27 00:39:24.941: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 27 00:39:26.948: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 27 00:39:26.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824764, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824764, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824765, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686824764, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 00:39:28.955: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 27 00:39:28.971: INFO: Updating deployment test-recreate-deployment
Feb 27 00:39:28.971: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 00:39:29.073: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-x759l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x759l/deployments/test-recreate-deployment,UID:21a93c15-3a28-11e9-9b3e-000d3a2390ff,ResourceVersion:60671,Generation:2,CreationTimestamp:2019-02-27 00:39:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-27 00:39:29 +0000 UTC 2019-02-27 00:39:29 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-27 00:39:29 +0000 UTC 2019-02-27 00:39:24 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 27 00:39:29.082: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-x759l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x759l/replicasets/test-recreate-deployment-697fbf54bf,UID:2418661a-3a28-11e9-9b3e-000d3a2390ff,ResourceVersion:60668,Generation:1,CreationTimestamp:2019-02-27 00:39:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 21a93c15-3a28-11e9-9b3e-000d3a2390ff 0xc00131bee7 0xc00131bee8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 00:39:29.082: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 27 00:39:29.082: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-x759l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x759l/replicasets/test-recreate-deployment-5dfdcc846d,UID:21aad7bc-3a28-11e9-9b3e-000d3a2390ff,ResourceVersion:60660,Generation:2,CreationTimestamp:2019-02-27 00:39:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 21a93c15-3a28-11e9-9b3e-000d3a2390ff 0xc00131be27 0xc00131be28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 00:39:29.087: INFO: Pod "test-recreate-deployment-697fbf54bf-bp7ng" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-bp7ng,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-x759l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-x759l/pods/test-recreate-deployment-697fbf54bf-bp7ng,UID:2419a8a3-3a28-11e9-9b3e-000d3a2390ff,ResourceVersion:60665,Generation:0,CreationTimestamp:2019-02-27 00:39:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 2418661a-3a28-11e9-9b3e-000d3a2390ff 0xc001cf0de7 0xc001cf0de8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lbgtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lbgtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lbgtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cf0e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cf0e70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:39:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:39:29.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-x759l" for this suite.
Feb 27 00:39:35.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:39:35.141: INFO: namespace: e2e-tests-deployment-x759l, resource: bindings, ignored listing per whitelist
Feb 27 00:39:35.293: INFO: namespace e2e-tests-deployment-x759l deletion completed in 6.191038386s

• [SLOW TEST:10.575 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:39:35.294: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-95r2v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0227 00:39:45.572533      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 00:39:45.572: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:39:45.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-95r2v" for this suite.
Feb 27 00:39:51.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:39:51.658: INFO: namespace: e2e-tests-gc-95r2v, resource: bindings, ignored listing per whitelist
Feb 27 00:39:51.707: INFO: namespace e2e-tests-gc-95r2v deletion completed in 6.130459407s

• [SLOW TEST:16.413 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:39:51.708: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r4gzv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 00:39:51.921: INFO: Waiting up to 5m0s for pod "downward-api-31bd84a6-3a28-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-r4gzv" to be "success or failure"
Feb 27 00:39:51.928: INFO: Pod "downward-api-31bd84a6-3a28-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.19605ms
Feb 27 00:39:53.932: INFO: Pod "downward-api-31bd84a6-3a28-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010951102s
STEP: Saw pod success
Feb 27 00:39:53.932: INFO: Pod "downward-api-31bd84a6-3a28-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:39:53.934: INFO: Trying to get logs from node 9cy76-worker-000000 pod downward-api-31bd84a6-3a28-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 00:39:53.973: INFO: Waiting for pod downward-api-31bd84a6-3a28-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:39:53.976: INFO: Pod downward-api-31bd84a6-3a28-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:39:53.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r4gzv" for this suite.
Feb 27 00:40:00.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:40:00.098: INFO: namespace: e2e-tests-downward-api-r4gzv, resource: bindings, ignored listing per whitelist
Feb 27 00:40:00.149: INFO: namespace e2e-tests-downward-api-r4gzv deletion completed in 6.165097213s

• [SLOW TEST:8.441 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:40:00.150: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-dxp5n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 00:40:00.457: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:40:00.463: INFO: Number of nodes with available pods: 0
Feb 27 00:40:00.463: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:40:01.468: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:40:01.471: INFO: Number of nodes with available pods: 0
Feb 27 00:40:01.471: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:40:02.467: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:40:02.470: INFO: Number of nodes with available pods: 2
Feb 27 00:40:02.470: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 27 00:40:02.496: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:40:02.506: INFO: Number of nodes with available pods: 1
Feb 27 00:40:02.506: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:40:03.515: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:40:03.519: INFO: Number of nodes with available pods: 1
Feb 27 00:40:03.519: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:40:04.511: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:40:04.515: INFO: Number of nodes with available pods: 1
Feb 27 00:40:04.516: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 00:40:05.511: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 00:40:05.514: INFO: Number of nodes with available pods: 2
Feb 27 00:40:05.514: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-dxp5n, will wait for the garbage collector to delete the pods
Feb 27 00:40:05.578: INFO: Deleting DaemonSet.extensions daemon-set took: 5.941844ms
Feb 27 00:40:05.679: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.380243ms
Feb 27 00:40:38.683: INFO: Number of nodes with available pods: 0
Feb 27 00:40:38.683: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 00:40:38.686: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dxp5n/daemonsets","resourceVersion":"60952"},"items":null}

Feb 27 00:40:38.694: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dxp5n/pods","resourceVersion":"60952"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:40:38.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dxp5n" for this suite.
Feb 27 00:40:44.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:40:44.802: INFO: namespace: e2e-tests-daemonsets-dxp5n, resource: bindings, ignored listing per whitelist
Feb 27 00:40:44.832: INFO: namespace e2e-tests-daemonsets-dxp5n deletion completed in 6.125028284s

• [SLOW TEST:44.682 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:40:44.832: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-2nr5c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 27 00:40:45.047: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 27 00:40:50.050: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:40:51.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2nr5c" for this suite.
Feb 27 00:40:57.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:40:57.166: INFO: namespace: e2e-tests-replication-controller-2nr5c, resource: bindings, ignored listing per whitelist
Feb 27 00:40:57.223: INFO: namespace e2e-tests-replication-controller-2nr5c deletion completed in 6.143053763s

• [SLOW TEST:12.391 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:40:57.224: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zzr58
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 00:40:57.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zzr58'
Feb 27 00:40:57.552: INFO: stderr: ""
Feb 27 00:40:57.552: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 27 00:40:57.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-zzr58'
Feb 27 00:41:02.754: INFO: stderr: ""
Feb 27 00:41:02.754: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:41:02.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zzr58" for this suite.
Feb 27 00:41:08.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:41:08.885: INFO: namespace: e2e-tests-kubectl-zzr58, resource: bindings, ignored listing per whitelist
Feb 27 00:41:08.906: INFO: namespace e2e-tests-kubectl-zzr58 deletion completed in 6.138792667s

• [SLOW TEST:11.683 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:41:08.907: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-dcgwh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-dcgwh
Feb 27 00:41:13.133: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-dcgwh
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 00:41:13.136: INFO: Initial restart count of pod liveness-http is 0
Feb 27 00:41:27.168: INFO: Restart count of pod e2e-tests-container-probe-dcgwh/liveness-http is now 1 (14.031421319s elapsed)
Feb 27 00:41:47.213: INFO: Restart count of pod e2e-tests-container-probe-dcgwh/liveness-http is now 2 (34.076942699s elapsed)
Feb 27 00:42:07.253: INFO: Restart count of pod e2e-tests-container-probe-dcgwh/liveness-http is now 3 (54.116849196s elapsed)
Feb 27 00:42:27.290: INFO: Restart count of pod e2e-tests-container-probe-dcgwh/liveness-http is now 4 (1m14.153746925s elapsed)
Feb 27 00:43:31.426: INFO: Restart count of pod e2e-tests-container-probe-dcgwh/liveness-http is now 5 (2m18.289602988s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:43:31.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dcgwh" for this suite.
Feb 27 00:43:37.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:43:37.564: INFO: namespace: e2e-tests-container-probe-dcgwh, resource: bindings, ignored listing per whitelist
Feb 27 00:43:37.599: INFO: namespace e2e-tests-container-probe-dcgwh deletion completed in 6.137649036s

• [SLOW TEST:148.692 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:43:37.600: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d8fqd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 27 00:43:37.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 api-versions'
Feb 27 00:43:38.143: INFO: stderr: ""
Feb 27 00:43:38.143: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napplication.giantswarm.io/v1alpha1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncore.giantswarm.io/v1alpha1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:43:38.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d8fqd" for this suite.
Feb 27 00:43:44.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:43:44.178: INFO: namespace: e2e-tests-kubectl-d8fqd, resource: bindings, ignored listing per whitelist
Feb 27 00:43:44.288: INFO: namespace e2e-tests-kubectl-d8fqd deletion completed in 6.140104455s

• [SLOW TEST:6.688 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:43:44.289: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jftgw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 27 00:43:44.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:46.760: INFO: stderr: ""
Feb 27 00:43:46.760: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 00:43:46.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:46.872: INFO: stderr: ""
Feb 27 00:43:46.872: INFO: stdout: "update-demo-nautilus-dg8l5 update-demo-nautilus-ksl4f "
Feb 27 00:43:46.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-dg8l5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:46.947: INFO: stderr: ""
Feb 27 00:43:46.947: INFO: stdout: ""
Feb 27 00:43:46.947: INFO: update-demo-nautilus-dg8l5 is created but not running
Feb 27 00:43:51.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:52.027: INFO: stderr: ""
Feb 27 00:43:52.027: INFO: stdout: "update-demo-nautilus-dg8l5 update-demo-nautilus-ksl4f "
Feb 27 00:43:52.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-dg8l5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:52.102: INFO: stderr: ""
Feb 27 00:43:52.102: INFO: stdout: "true"
Feb 27 00:43:52.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-dg8l5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:52.179: INFO: stderr: ""
Feb 27 00:43:52.179: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:43:52.179: INFO: validating pod update-demo-nautilus-dg8l5
Feb 27 00:43:52.194: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:43:52.194: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:43:52.194: INFO: update-demo-nautilus-dg8l5 is verified up and running
Feb 27 00:43:52.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-ksl4f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:52.276: INFO: stderr: ""
Feb 27 00:43:52.276: INFO: stdout: "true"
Feb 27 00:43:52.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-nautilus-ksl4f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:43:52.350: INFO: stderr: ""
Feb 27 00:43:52.350: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 00:43:52.350: INFO: validating pod update-demo-nautilus-ksl4f
Feb 27 00:43:52.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 00:43:52.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 00:43:52.356: INFO: update-demo-nautilus-ksl4f is verified up and running
STEP: rolling-update to new replication controller
Feb 27 00:43:52.361: INFO: scanned /root for discovery docs: <nil>
Feb 27 00:43:52.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:44:15.045: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 27 00:44:15.045: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 00:44:15.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:44:15.161: INFO: stderr: ""
Feb 27 00:44:15.161: INFO: stdout: "update-demo-kitten-5d5wf update-demo-kitten-v9rmf "
Feb 27 00:44:15.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-kitten-5d5wf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:44:15.253: INFO: stderr: ""
Feb 27 00:44:15.253: INFO: stdout: "true"
Feb 27 00:44:15.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-kitten-5d5wf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:44:15.348: INFO: stderr: ""
Feb 27 00:44:15.348: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 27 00:44:15.348: INFO: validating pod update-demo-kitten-5d5wf
Feb 27 00:44:15.356: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 27 00:44:15.356: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 27 00:44:15.357: INFO: update-demo-kitten-5d5wf is verified up and running
Feb 27 00:44:15.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-kitten-v9rmf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:44:15.433: INFO: stderr: ""
Feb 27 00:44:15.433: INFO: stdout: "true"
Feb 27 00:44:15.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods update-demo-kitten-v9rmf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jftgw'
Feb 27 00:44:15.515: INFO: stderr: ""
Feb 27 00:44:15.515: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 27 00:44:15.515: INFO: validating pod update-demo-kitten-v9rmf
Feb 27 00:44:15.521: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 27 00:44:15.521: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 27 00:44:15.522: INFO: update-demo-kitten-v9rmf is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:44:15.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jftgw" for this suite.
Feb 27 00:44:37.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:44:37.564: INFO: namespace: e2e-tests-kubectl-jftgw, resource: bindings, ignored listing per whitelist
Feb 27 00:44:37.656: INFO: namespace e2e-tests-kubectl-jftgw deletion completed in 22.129987551s

• [SLOW TEST:53.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:44:37.657: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-dfnht
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 27 00:44:39.889: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-dc2d81f8-3a28-11e9-9b83-4a9a78a986da,GenerateName:,Namespace:e2e-tests-events-dfnht,SelfLink:/api/v1/namespaces/e2e-tests-events-dfnht/pods/send-events-dc2d81f8-3a28-11e9-9b83-4a9a78a986da,UID:dc2e3032-3a28-11e9-9b3e-000d3a2390ff,ResourceVersion:61649,Generation:0,CreationTimestamp:2019-02-27 00:44:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 858396079,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.145/32,kubernetes.io/psp: cert-exporter-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vk9df {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vk9df,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-vk9df true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001855b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001855bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:44:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:44:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:44:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 00:44:37 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.145,StartTime:2019-02-27 00:44:37 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-27 00:44:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://b60e8428f58a669ebf2f6cf09f0aa9ec291de9f1d50bff565ff7ecf6541a4d1f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 27 00:44:41.893: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 27 00:44:43.898: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:44:43.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-dfnht" for this suite.
Feb 27 00:45:25.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:45:25.975: INFO: namespace: e2e-tests-events-dfnht, resource: bindings, ignored listing per whitelist
Feb 27 00:45:26.063: INFO: namespace e2e-tests-events-dfnht deletion completed in 42.143015741s

• [SLOW TEST:48.407 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:45:26.064: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-p7qtl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 27 00:45:26.295: INFO: Waiting up to 5m0s for pod "pod-f90b2b41-3a28-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-p7qtl" to be "success or failure"
Feb 27 00:45:26.301: INFO: Pod "pod-f90b2b41-3a28-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.641741ms
Feb 27 00:45:28.305: INFO: Pod "pod-f90b2b41-3a28-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009996717s
STEP: Saw pod success
Feb 27 00:45:28.305: INFO: Pod "pod-f90b2b41-3a28-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:45:28.311: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-f90b2b41-3a28-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:45:28.350: INFO: Waiting for pod pod-f90b2b41-3a28-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:45:28.357: INFO: Pod pod-f90b2b41-3a28-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:45:28.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p7qtl" for this suite.
Feb 27 00:45:34.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:45:34.471: INFO: namespace: e2e-tests-emptydir-p7qtl, resource: bindings, ignored listing per whitelist
Feb 27 00:45:34.503: INFO: namespace e2e-tests-emptydir-p7qtl deletion completed in 6.143095016s

• [SLOW TEST:8.440 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:45:34.505: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-86x29
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:45:34.716: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-86x29" to be "success or failure"
Feb 27 00:45:34.722: INFO: Pod "downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.500145ms
Feb 27 00:45:36.726: INFO: Pod "downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01010978s
Feb 27 00:45:38.730: INFO: Pod "downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014397445s
STEP: Saw pod success
Feb 27 00:45:38.730: INFO: Pod "downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:45:38.733: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:45:38.762: INFO: Waiting for pod downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:45:38.764: INFO: Pod downwardapi-volume-fe1039d6-3a28-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:45:38.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-86x29" for this suite.
Feb 27 00:45:44.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:45:44.875: INFO: namespace: e2e-tests-projected-86x29, resource: bindings, ignored listing per whitelist
Feb 27 00:45:44.902: INFO: namespace e2e-tests-projected-86x29 deletion completed in 6.13321442s

• [SLOW TEST:10.397 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:45:44.902: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-j4l2h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:45:45.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-j4l2h" for this suite.
Feb 27 00:45:51.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:45:51.199: INFO: namespace: e2e-tests-kubelet-test-j4l2h, resource: bindings, ignored listing per whitelist
Feb 27 00:45:51.281: INFO: namespace e2e-tests-kubelet-test-j4l2h deletion completed in 6.124480659s

• [SLOW TEST:6.379 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:45:51.282: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-f2xv4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:45:51.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-080fa8fd-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-f2xv4" to be "success or failure"
Feb 27 00:45:51.493: INFO: Pod "downwardapi-volume-080fa8fd-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068728ms
Feb 27 00:45:53.497: INFO: Pod "downwardapi-volume-080fa8fd-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00829791s
STEP: Saw pod success
Feb 27 00:45:53.497: INFO: Pod "downwardapi-volume-080fa8fd-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:45:53.500: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-080fa8fd-3a29-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:45:53.523: INFO: Waiting for pod downwardapi-volume-080fa8fd-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:45:53.531: INFO: Pod downwardapi-volume-080fa8fd-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:45:53.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f2xv4" for this suite.
Feb 27 00:45:59.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:45:59.597: INFO: namespace: e2e-tests-downward-api-f2xv4, resource: bindings, ignored listing per whitelist
Feb 27 00:45:59.654: INFO: namespace e2e-tests-downward-api-f2xv4 deletion completed in 6.11579905s

• [SLOW TEST:8.373 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:45:59.655: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-bwgkw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 27 00:45:59.873: INFO: Waiting up to 5m0s for pod "var-expansion-0d0e7cf8-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-var-expansion-bwgkw" to be "success or failure"
Feb 27 00:45:59.880: INFO: Pod "var-expansion-0d0e7cf8-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.469243ms
Feb 27 00:46:01.883: INFO: Pod "var-expansion-0d0e7cf8-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01023761s
STEP: Saw pod success
Feb 27 00:46:01.883: INFO: Pod "var-expansion-0d0e7cf8-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:46:01.888: INFO: Trying to get logs from node 9cy76-worker-000000 pod var-expansion-0d0e7cf8-3a29-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 00:46:01.907: INFO: Waiting for pod var-expansion-0d0e7cf8-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:46:01.915: INFO: Pod var-expansion-0d0e7cf8-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:46:01.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bwgkw" for this suite.
Feb 27 00:46:07.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:46:08.080: INFO: namespace: e2e-tests-var-expansion-bwgkw, resource: bindings, ignored listing per whitelist
Feb 27 00:46:08.112: INFO: namespace e2e-tests-var-expansion-bwgkw deletion completed in 6.174518063s

• [SLOW TEST:8.457 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:46:08.113: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hpzld
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:46:08.382: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 27 00:46:08.388: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hpzld/daemonsets","resourceVersion":"61931"},"items":null}

Feb 27 00:46:08.391: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hpzld/pods","resourceVersion":"61931"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:46:08.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hpzld" for this suite.
Feb 27 00:46:14.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:46:14.474: INFO: namespace: e2e-tests-daemonsets-hpzld, resource: bindings, ignored listing per whitelist
Feb 27 00:46:14.547: INFO: namespace e2e-tests-daemonsets-hpzld deletion completed in 6.136471497s

S [SKIPPING] [6.434 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 27 00:46:08.382: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:46:14.551: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mn44j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-15efcb94-3a29-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 00:46:14.773: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-mn44j" to be "success or failure"
Feb 27 00:46:14.779: INFO: Pod "pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.506041ms
Feb 27 00:46:16.783: INFO: Pod "pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009783281s
Feb 27 00:46:18.789: INFO: Pod "pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01654346s
STEP: Saw pod success
Feb 27 00:46:18.789: INFO: Pod "pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:46:18.792: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 00:46:18.824: INFO: Waiting for pod pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:46:18.833: INFO: Pod pod-projected-configmaps-15f04b24-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:46:18.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mn44j" for this suite.
Feb 27 00:46:24.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:46:24.944: INFO: namespace: e2e-tests-projected-mn44j, resource: bindings, ignored listing per whitelist
Feb 27 00:46:24.994: INFO: namespace e2e-tests-projected-mn44j deletion completed in 6.156432424s

• [SLOW TEST:10.443 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:46:24.994: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-87gs7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 00:46:25.204: INFO: Creating ReplicaSet my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da
Feb 27 00:46:25.212: INFO: Pod name my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da: Found 0 pods out of 1
Feb 27 00:46:30.215: INFO: Pod name my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da: Found 1 pods out of 1
Feb 27 00:46:30.216: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da" is running
Feb 27 00:46:30.218: INFO: Pod "my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da-jjktj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 00:46:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 00:46:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 00:46:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 00:46:25 +0000 UTC Reason: Message:}])
Feb 27 00:46:30.218: INFO: Trying to dial the pod
Feb 27 00:46:35.231: INFO: Controller my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da: Got expected result from replica 1 [my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da-jjktj]: "my-hostname-basic-1c293a17-3a29-11e9-9b83-4a9a78a986da-jjktj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:46:35.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-87gs7" for this suite.
Feb 27 00:46:41.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:46:41.331: INFO: namespace: e2e-tests-replicaset-87gs7, resource: bindings, ignored listing per whitelist
Feb 27 00:46:41.369: INFO: namespace e2e-tests-replicaset-87gs7 deletion completed in 6.133627226s

• [SLOW TEST:16.375 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:46:41.370: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-g749h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-g749h
Feb 27 00:46:45.596: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-g749h
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 00:46:45.599: INFO: Initial restart count of pod liveness-http is 0
Feb 27 00:47:03.636: INFO: Restart count of pod e2e-tests-container-probe-g749h/liveness-http is now 1 (18.036831567s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:47:03.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-g749h" for this suite.
Feb 27 00:47:09.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:47:09.775: INFO: namespace: e2e-tests-container-probe-g749h, resource: bindings, ignored listing per whitelist
Feb 27 00:47:09.811: INFO: namespace e2e-tests-container-probe-g749h deletion completed in 6.141668075s

• [SLOW TEST:28.441 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:47:09.812: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gvblc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-36de30eb-3a29-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 00:47:10.022: INFO: Waiting up to 5m0s for pod "pod-configmaps-36dec70b-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-gvblc" to be "success or failure"
Feb 27 00:47:10.034: INFO: Pod "pod-configmaps-36dec70b-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 11.921273ms
Feb 27 00:47:12.038: INFO: Pod "pod-configmaps-36dec70b-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015700386s
STEP: Saw pod success
Feb 27 00:47:12.038: INFO: Pod "pod-configmaps-36dec70b-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:47:12.041: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-36dec70b-3a29-11e9-9b83-4a9a78a986da container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 00:47:12.068: INFO: Waiting for pod pod-configmaps-36dec70b-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:47:12.071: INFO: Pod pod-configmaps-36dec70b-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:47:12.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gvblc" for this suite.
Feb 27 00:47:18.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:47:18.149: INFO: namespace: e2e-tests-configmap-gvblc, resource: bindings, ignored listing per whitelist
Feb 27 00:47:18.239: INFO: namespace e2e-tests-configmap-gvblc deletion completed in 6.155158578s

• [SLOW TEST:8.428 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:47:18.240: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7jtrp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:47:18.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3be52e80-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-7jtrp" to be "success or failure"
Feb 27 00:47:18.459: INFO: Pod "downwardapi-volume-3be52e80-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.225142ms
Feb 27 00:47:20.463: INFO: Pod "downwardapi-volume-3be52e80-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009795796s
STEP: Saw pod success
Feb 27 00:47:20.463: INFO: Pod "downwardapi-volume-3be52e80-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:47:20.465: INFO: Trying to get logs from node 9cy76-worker-000001 pod downwardapi-volume-3be52e80-3a29-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:47:20.492: INFO: Waiting for pod downwardapi-volume-3be52e80-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:47:20.495: INFO: Pod downwardapi-volume-3be52e80-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:47:20.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7jtrp" for this suite.
Feb 27 00:47:26.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:47:26.563: INFO: namespace: e2e-tests-projected-7jtrp, resource: bindings, ignored listing per whitelist
Feb 27 00:47:26.636: INFO: namespace e2e-tests-projected-7jtrp deletion completed in 6.136948113s

• [SLOW TEST:8.397 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:47:26.637: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-j44l7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 00:47:26.865: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:47:32.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-j44l7" for this suite.
Feb 27 00:47:54.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:47:54.540: INFO: namespace: e2e-tests-init-container-j44l7, resource: bindings, ignored listing per whitelist
Feb 27 00:47:54.595: INFO: namespace e2e-tests-init-container-j44l7 deletion completed in 22.145922781s

• [SLOW TEST:27.958 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:47:54.595: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-w7jzp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-518f25f7-3a29-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 00:47:54.802: INFO: Waiting up to 5m0s for pod "pod-secrets-518f9515-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-w7jzp" to be "success or failure"
Feb 27 00:47:54.808: INFO: Pod "pod-secrets-518f9515-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.097639ms
Feb 27 00:47:56.820: INFO: Pod "pod-secrets-518f9515-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017873862s
STEP: Saw pod success
Feb 27 00:47:56.828: INFO: Pod "pod-secrets-518f9515-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:47:56.831: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-518f9515-3a29-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 00:47:56.853: INFO: Waiting for pod pod-secrets-518f9515-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:47:56.857: INFO: Pod pod-secrets-518f9515-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:47:56.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w7jzp" for this suite.
Feb 27 00:48:02.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:48:02.985: INFO: namespace: e2e-tests-secrets-w7jzp, resource: bindings, ignored listing per whitelist
Feb 27 00:48:03.002: INFO: namespace e2e-tests-secrets-w7jzp deletion completed in 6.140375246s

• [SLOW TEST:8.406 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:48:03.002: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-hfb5q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 27 00:48:07.295: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:07.300: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:09.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:09.305: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:11.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:11.303: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:13.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:13.304: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:15.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:15.304: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:17.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:17.308: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:19.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:19.305: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:21.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:21.304: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:23.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:23.306: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:25.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:25.304: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 00:48:27.300: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 00:48:27.303: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:48:27.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hfb5q" for this suite.
Feb 27 00:48:49.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:48:49.402: INFO: namespace: e2e-tests-container-lifecycle-hook-hfb5q, resource: bindings, ignored listing per whitelist
Feb 27 00:48:49.497: INFO: namespace e2e-tests-container-lifecycle-hook-hfb5q deletion completed in 22.188515432s

• [SLOW TEST:46.495 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:48:49.497: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-bxjfq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:48:53.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-bxjfq" for this suite.
Feb 27 00:49:35.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:49:35.869: INFO: namespace: e2e-tests-kubelet-test-bxjfq, resource: bindings, ignored listing per whitelist
Feb 27 00:49:35.915: INFO: namespace e2e-tests-kubelet-test-bxjfq deletion completed in 42.137031336s

• [SLOW TEST:46.417 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:49:35.915: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-t8lcb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-t8lcb
Feb 27 00:49:40.136: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-t8lcb
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 00:49:40.139: INFO: Initial restart count of pod liveness-exec is 0
Feb 27 00:50:28.234: INFO: Restart count of pod e2e-tests-container-probe-t8lcb/liveness-exec is now 1 (48.094197806s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:50:28.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-t8lcb" for this suite.
Feb 27 00:50:34.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:50:34.316: INFO: namespace: e2e-tests-container-probe-t8lcb, resource: bindings, ignored listing per whitelist
Feb 27 00:50:34.402: INFO: namespace e2e-tests-container-probe-t8lcb deletion completed in 6.136955134s

• [SLOW TEST:58.487 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:50:34.402: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6sclw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b0d3137a-3a29-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 00:50:34.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-6sclw" to be "success or failure"
Feb 27 00:50:34.637: INFO: Pod "pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.87164ms
Feb 27 00:50:36.641: INFO: Pod "pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010013418s
Feb 27 00:50:38.644: INFO: Pod "pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013368604s
STEP: Saw pod success
Feb 27 00:50:38.644: INFO: Pod "pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:50:38.646: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 00:50:38.674: INFO: Waiting for pod pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:50:38.676: INFO: Pod pod-configmaps-b0d3c12f-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:50:38.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6sclw" for this suite.
Feb 27 00:50:44.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:50:44.809: INFO: namespace: e2e-tests-configmap-6sclw, resource: bindings, ignored listing per whitelist
Feb 27 00:50:44.811: INFO: namespace e2e-tests-configmap-6sclw deletion completed in 6.125675666s

• [SLOW TEST:10.409 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:50:44.812: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-m9p78
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 27 00:50:45.024: INFO: Waiting up to 5m0s for pod "pod-b7052b86-3a29-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-m9p78" to be "success or failure"
Feb 27 00:50:45.027: INFO: Pod "pod-b7052b86-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.937418ms
Feb 27 00:50:47.032: INFO: Pod "pod-b7052b86-3a29-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007392297s
Feb 27 00:50:49.036: INFO: Pod "pod-b7052b86-3a29-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011257387s
STEP: Saw pod success
Feb 27 00:50:49.036: INFO: Pod "pod-b7052b86-3a29-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:50:49.039: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-b7052b86-3a29-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 00:50:49.062: INFO: Waiting for pod pod-b7052b86-3a29-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:50:49.077: INFO: Pod pod-b7052b86-3a29-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:50:49.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m9p78" for this suite.
Feb 27 00:50:55.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:50:55.201: INFO: namespace: e2e-tests-emptydir-m9p78, resource: bindings, ignored listing per whitelist
Feb 27 00:50:55.243: INFO: namespace e2e-tests-emptydir-m9p78 deletion completed in 6.160610177s

• [SLOW TEST:10.431 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:50:55.244: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zgggl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 00:50:55.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zgggl'
Feb 27 00:50:55.547: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 00:50:55.547: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 27 00:50:55.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-zgggl'
Feb 27 00:50:55.659: INFO: stderr: ""
Feb 27 00:50:55.659: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:50:55.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zgggl" for this suite.
Feb 27 00:51:01.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:51:01.805: INFO: namespace: e2e-tests-kubectl-zgggl, resource: bindings, ignored listing per whitelist
Feb 27 00:51:01.820: INFO: namespace e2e-tests-kubectl-zgggl deletion completed in 6.154460463s

• [SLOW TEST:6.576 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:51:01.820: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fxtb2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0227 00:51:08.108861      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 00:51:08.108: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:51:08.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fxtb2" for this suite.
Feb 27 00:51:14.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:51:14.172: INFO: namespace: e2e-tests-gc-fxtb2, resource: bindings, ignored listing per whitelist
Feb 27 00:51:14.283: INFO: namespace e2e-tests-gc-fxtb2 deletion completed in 6.168333418s

• [SLOW TEST:12.463 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:51:14.284: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5z5rz
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c8981477-3a29-11e9-9b83-4a9a78a986da
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c8981477-3a29-11e9-9b83-4a9a78a986da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:52:32.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5z5rz" for this suite.
Feb 27 00:52:54.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:52:55.051: INFO: namespace: e2e-tests-projected-5z5rz, resource: bindings, ignored listing per whitelist
Feb 27 00:52:55.059: INFO: namespace e2e-tests-projected-5z5rz deletion completed in 22.129817408s

• [SLOW TEST:100.776 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:52:55.060: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-djch2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 00:52:55.272: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 00:52:55.280: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 00:52:55.283: INFO: 
Logging pods the kubelet thinks is on node 9cy76-worker-000000 before test
Feb 27 00:52:55.293: INFO: kube-proxy-kbpzq from kube-system started at 2019-02-26 14:59:45 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.293: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 00:52:55.293: INFO: external-dns-7f6b74c57f-rhd2v from kube-system started at 2019-02-26 15:03:10 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.293: INFO: 	Container external-dns ready: true, restart count 0
Feb 27 00:52:55.293: INFO: cert-exporter-5hgps from kube-system started at 2019-02-26 15:02:08 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.293: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 00:52:55.293: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-26 23:53:44 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.293: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 00:52:55.293: INFO: nginx-ingress-controller-5fd6d9c498-mm48v from kube-system started at 2019-02-26 15:02:48 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.293: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 00:52:55.293: INFO: default-http-backend-6c5fdb64cc-v88ph from kube-system started at 2019-02-26 15:02:48 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.293: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 00:52:55.293: INFO: calico-node-qd6l7 from kube-system started at 2019-02-26 14:59:18 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.293: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 00:52:55.293: INFO: coredns-7fb74c7cfc-mlmrb from kube-system started at 2019-02-26 15:02:05 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.294: INFO: 	Container coredns ready: true, restart count 0
Feb 27 00:52:55.294: INFO: sonobuoy-systemd-logs-daemon-set-d15354df4d564054-2fdhp from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 00:52:55.294: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 27 00:52:55.294: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 00:52:55.294: INFO: sonobuoy-e2e-job-82313ed720c94b11 from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 00:52:55.294: INFO: 	Container e2e ready: true, restart count 0
Feb 27 00:52:55.294: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 00:52:55.294: INFO: net-exporter-9p5kx from kube-system started at 2019-02-26 15:02:45 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.294: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 00:52:55.294: INFO: node-exporter-zzsmv from kube-system started at 2019-02-26 15:03:04 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.294: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 00:52:55.294: INFO: 
Logging pods the kubelet thinks is on node 9cy76-worker-000001 before test
Feb 27 00:52:55.302: INFO: calico-node-7gd69 from kube-system started at 2019-02-26 14:59:18 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 00:52:55.302: INFO: cert-exporter-94f46 from kube-system started at 2019-02-26 15:02:08 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 00:52:55.302: INFO: sonobuoy-systemd-logs-daemon-set-d15354df4d564054-6h2mv from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb 27 00:52:55.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 00:52:55.302: INFO: default-http-backend-6c5fdb64cc-gq6kw from kube-system started at 2019-02-26 15:02:47 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 00:52:55.302: INFO: node-exporter-s9wzl from kube-system started at 2019-02-26 15:03:05 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 00:52:55.302: INFO: net-exporter-5fhjf from kube-system started at 2019-02-26 15:02:44 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 00:52:55.302: INFO: tiller-deploy-7d54987577-vw7wm from giantswarm started at 2019-02-26 15:00:37 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container tiller ready: true, restart count 0
Feb 27 00:52:55.302: INFO: kube-proxy-hz4l8 from kube-system started at 2019-02-26 14:59:43 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 00:52:55.302: INFO: metrics-server-7fc59d6b67-2lrrx from kube-system started at 2019-02-26 15:02:40 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container metrics-server ready: true, restart count 0
Feb 27 00:52:55.302: INFO: nginx-ingress-controller-5fd6d9c498-9ccm2 from kube-system started at 2019-02-26 15:02:47 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 00:52:55.302: INFO: coredns-7fb74c7cfc-bhhcg from kube-system started at 2019-02-26 15:02:05 +0000 UTC (1 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container coredns ready: true, restart count 0
Feb 27 00:52:55.302: INFO: kube-state-metrics-68f7795bbd-glc6h from kube-system started at 2019-02-26 15:02:48 +0000 UTC (2 container statuses recorded)
Feb 27 00:52:55.302: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 27 00:52:55.302: INFO: 	Container kube-state-metrics ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 9cy76-worker-000000
STEP: verifying the node has the label node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod tiller-deploy-7d54987577-vw7wm requesting resource cpu=0m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod sonobuoy requesting resource cpu=0m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod sonobuoy-e2e-job-82313ed720c94b11 requesting resource cpu=0m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod sonobuoy-systemd-logs-daemon-set-d15354df4d564054-2fdhp requesting resource cpu=0m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod sonobuoy-systemd-logs-daemon-set-d15354df4d564054-6h2mv requesting resource cpu=0m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod calico-node-7gd69 requesting resource cpu=250m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod calico-node-qd6l7 requesting resource cpu=250m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod cert-exporter-5hgps requesting resource cpu=50m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod cert-exporter-94f46 requesting resource cpu=50m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod coredns-7fb74c7cfc-bhhcg requesting resource cpu=250m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod coredns-7fb74c7cfc-mlmrb requesting resource cpu=250m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod default-http-backend-6c5fdb64cc-gq6kw requesting resource cpu=10m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod default-http-backend-6c5fdb64cc-v88ph requesting resource cpu=10m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod external-dns-7f6b74c57f-rhd2v requesting resource cpu=50m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod kube-proxy-hz4l8 requesting resource cpu=75m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod kube-proxy-kbpzq requesting resource cpu=75m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod kube-state-metrics-68f7795bbd-glc6h requesting resource cpu=353m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod metrics-server-7fc59d6b67-2lrrx requesting resource cpu=0m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod net-exporter-5fhjf requesting resource cpu=50m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod net-exporter-9p5kx requesting resource cpu=50m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod nginx-ingress-controller-5fd6d9c498-9ccm2 requesting resource cpu=500m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod nginx-ingress-controller-5fd6d9c498-mm48v requesting resource cpu=500m on Node 9cy76-worker-000000
Feb 27 00:52:55.353: INFO: Pod node-exporter-s9wzl requesting resource cpu=55m on Node 9cy76-worker-000001
Feb 27 00:52:55.353: INFO: Pod node-exporter-zzsmv requesting resource cpu=55m on Node 9cy76-worker-000000
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b546a4-3a2a-11e9-9b83-4a9a78a986da.1587125a39812d0c], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-djch2/filler-pod-04b546a4-3a2a-11e9-9b83-4a9a78a986da to 9cy76-worker-000000]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b546a4-3a2a-11e9-9b83-4a9a78a986da.1587125a75f71ff1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b546a4-3a2a-11e9-9b83-4a9a78a986da.1587125a91490a9f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b546a4-3a2a-11e9-9b83-4a9a78a986da.1587125ab4c729d7], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b66943-3a2a-11e9-9b83-4a9a78a986da.1587125a39dedfb4], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-djch2/filler-pod-04b66943-3a2a-11e9-9b83-4a9a78a986da to 9cy76-worker-000001]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b66943-3a2a-11e9-9b83-4a9a78a986da.1587125a71f6de03], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b66943-3a2a-11e9-9b83-4a9a78a986da.1587125a786a4d82], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-04b66943-3a2a-11e9-9b83-4a9a78a986da.1587125a8626b797], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1587125b2952a98a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 9cy76-worker-000000
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 9cy76-worker-000001
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:53:00.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-djch2" for this suite.
Feb 27 00:53:06.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:53:06.513: INFO: namespace: e2e-tests-sched-pred-djch2, resource: bindings, ignored listing per whitelist
Feb 27 00:53:06.604: INFO: namespace e2e-tests-sched-pred-djch2 deletion completed in 6.132970694s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.544 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:53:06.605: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vglfv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 00:53:06.849: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-vglfv" to be "success or failure"
Feb 27 00:53:06.855: INFO: Pod "downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.159737ms
Feb 27 00:53:08.860: INFO: Pod "downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010298016s
Feb 27 00:53:10.863: INFO: Pod "downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013756494s
STEP: Saw pod success
Feb 27 00:53:10.863: INFO: Pod "downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:53:10.866: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 00:53:10.890: INFO: Waiting for pod downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:53:10.896: INFO: Pod downwardapi-volume-0b8deadb-3a2a-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:53:10.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vglfv" for this suite.
Feb 27 00:53:16.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:53:17.000: INFO: namespace: e2e-tests-projected-vglfv, resource: bindings, ignored listing per whitelist
Feb 27 00:53:17.056: INFO: namespace e2e-tests-projected-vglfv deletion completed in 6.13343809s

• [SLOW TEST:10.451 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:53:17.056: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ddb5w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-24l9
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 00:53:17.277: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-24l9" in namespace "e2e-tests-subpath-ddb5w" to be "success or failure"
Feb 27 00:53:17.288: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.695267ms
Feb 27 00:53:19.294: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016927632s
Feb 27 00:53:21.297: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 4.02004054s
Feb 27 00:53:23.301: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 6.023723319s
Feb 27 00:53:25.305: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 8.028134805s
Feb 27 00:53:27.309: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 10.031971891s
Feb 27 00:53:29.313: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 12.03590078s
Feb 27 00:53:31.319: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 14.041403182s
Feb 27 00:53:33.323: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 16.045462578s
Feb 27 00:53:35.327: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 18.049747278s
Feb 27 00:53:37.333: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 20.055432989s
Feb 27 00:53:39.336: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 22.058812889s
Feb 27 00:53:41.340: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Running", Reason="", readiness=false. Elapsed: 24.062991697s
Feb 27 00:53:43.345: INFO: Pod "pod-subpath-test-configmap-24l9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.067436912s
STEP: Saw pod success
Feb 27 00:53:43.345: INFO: Pod "pod-subpath-test-configmap-24l9" satisfied condition "success or failure"
Feb 27 00:53:43.348: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-subpath-test-configmap-24l9 container test-container-subpath-configmap-24l9: <nil>
STEP: delete the pod
Feb 27 00:53:43.372: INFO: Waiting for pod pod-subpath-test-configmap-24l9 to disappear
Feb 27 00:53:43.383: INFO: Pod pod-subpath-test-configmap-24l9 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-24l9
Feb 27 00:53:43.385: INFO: Deleting pod "pod-subpath-test-configmap-24l9" in namespace "e2e-tests-subpath-ddb5w"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:53:43.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ddb5w" for this suite.
Feb 27 00:53:49.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:53:49.565: INFO: namespace: e2e-tests-subpath-ddb5w, resource: bindings, ignored listing per whitelist
Feb 27 00:53:49.570: INFO: namespace e2e-tests-subpath-ddb5w deletion completed in 6.163468603s

• [SLOW TEST:32.514 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:53:49.571: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fsjqg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-25272be0-3a2a-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 00:53:49.800: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2527c575-3a2a-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-fsjqg" to be "success or failure"
Feb 27 00:53:49.820: INFO: Pod "pod-projected-configmaps-2527c575-3a2a-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 19.740031ms
Feb 27 00:53:51.824: INFO: Pod "pod-projected-configmaps-2527c575-3a2a-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024300335s
STEP: Saw pod success
Feb 27 00:53:51.832: INFO: Pod "pod-projected-configmaps-2527c575-3a2a-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:53:51.852: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-configmaps-2527c575-3a2a-11e9-9b83-4a9a78a986da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 00:53:51.891: INFO: Waiting for pod pod-projected-configmaps-2527c575-3a2a-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:53:51.920: INFO: Pod pod-projected-configmaps-2527c575-3a2a-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:53:51.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsjqg" for this suite.
Feb 27 00:53:57.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:53:58.027: INFO: namespace: e2e-tests-projected-fsjqg, resource: bindings, ignored listing per whitelist
Feb 27 00:53:58.095: INFO: namespace e2e-tests-projected-fsjqg deletion completed in 6.160199953s

• [SLOW TEST:8.525 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:53:58.097: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-vklbb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 27 00:53:58.522: INFO: Pod name wrapped-volume-race-2a59fc1b-3a2a-11e9-9b83-4a9a78a986da: Found 0 pods out of 5
Feb 27 00:54:03.530: INFO: Pod name wrapped-volume-race-2a59fc1b-3a2a-11e9-9b83-4a9a78a986da: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2a59fc1b-3a2a-11e9-9b83-4a9a78a986da in namespace e2e-tests-emptydir-wrapper-vklbb, will wait for the garbage collector to delete the pods
Feb 27 00:54:15.616: INFO: Deleting ReplicationController wrapped-volume-race-2a59fc1b-3a2a-11e9-9b83-4a9a78a986da took: 9.431561ms
Feb 27 00:54:15.718: INFO: Terminating ReplicationController wrapped-volume-race-2a59fc1b-3a2a-11e9-9b83-4a9a78a986da pods took: 101.507058ms
STEP: Creating RC which spawns configmap-volume pods
Feb 27 00:54:54.948: INFO: Pod name wrapped-volume-race-4bfa08d9-3a2a-11e9-9b83-4a9a78a986da: Found 0 pods out of 5
Feb 27 00:54:59.955: INFO: Pod name wrapped-volume-race-4bfa08d9-3a2a-11e9-9b83-4a9a78a986da: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4bfa08d9-3a2a-11e9-9b83-4a9a78a986da in namespace e2e-tests-emptydir-wrapper-vklbb, will wait for the garbage collector to delete the pods
Feb 27 00:55:12.070: INFO: Deleting ReplicationController wrapped-volume-race-4bfa08d9-3a2a-11e9-9b83-4a9a78a986da took: 19.755018ms
Feb 27 00:55:12.238: INFO: Terminating ReplicationController wrapped-volume-race-4bfa08d9-3a2a-11e9-9b83-4a9a78a986da pods took: 168.703801ms
STEP: Creating RC which spawns configmap-volume pods
Feb 27 00:55:55.482: INFO: Pod name wrapped-volume-race-700c2119-3a2a-11e9-9b83-4a9a78a986da: Found 0 pods out of 5
Feb 27 00:56:00.488: INFO: Pod name wrapped-volume-race-700c2119-3a2a-11e9-9b83-4a9a78a986da: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-700c2119-3a2a-11e9-9b83-4a9a78a986da in namespace e2e-tests-emptydir-wrapper-vklbb, will wait for the garbage collector to delete the pods
Feb 27 00:56:12.569: INFO: Deleting ReplicationController wrapped-volume-race-700c2119-3a2a-11e9-9b83-4a9a78a986da took: 6.293137ms
Feb 27 00:56:12.769: INFO: Terminating ReplicationController wrapped-volume-race-700c2119-3a2a-11e9-9b83-4a9a78a986da pods took: 200.214785ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:56:55.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-vklbb" for this suite.
Feb 27 00:57:03.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:57:03.921: INFO: namespace: e2e-tests-emptydir-wrapper-vklbb, resource: bindings, ignored listing per whitelist
Feb 27 00:57:03.927: INFO: namespace e2e-tests-emptydir-wrapper-vklbb deletion completed in 8.146539763s

• [SLOW TEST:185.830 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:57:03.928: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-464zs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 00:57:04.139: INFO: Waiting up to 5m0s for pod "downward-api-98fded15-3a2a-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-464zs" to be "success or failure"
Feb 27 00:57:04.143: INFO: Pod "downward-api-98fded15-3a2a-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.254521ms
Feb 27 00:57:06.147: INFO: Pod "downward-api-98fded15-3a2a-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007016537s
STEP: Saw pod success
Feb 27 00:57:06.147: INFO: Pod "downward-api-98fded15-3a2a-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:57:06.149: INFO: Trying to get logs from node 9cy76-worker-000001 pod downward-api-98fded15-3a2a-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 00:57:06.175: INFO: Waiting for pod downward-api-98fded15-3a2a-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:57:06.178: INFO: Pod downward-api-98fded15-3a2a-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:57:06.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-464zs" for this suite.
Feb 27 00:57:12.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:57:12.251: INFO: namespace: e2e-tests-downward-api-464zs, resource: bindings, ignored listing per whitelist
Feb 27 00:57:12.297: INFO: namespace e2e-tests-downward-api-464zs deletion completed in 6.115008524s

• [SLOW TEST:8.370 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:57:12.298: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-qq55r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-qq55r
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 00:57:12.503: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 00:57:32.614: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.130.189:8080/dial?request=hostName&protocol=udp&host=10.1.130.188&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-qq55r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 00:57:32.614: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 00:57:32.737: INFO: Waiting for endpoints: map[]
Feb 27 00:57:32.741: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.130.189:8080/dial?request=hostName&protocol=udp&host=10.1.129.68&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-qq55r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 00:57:32.741: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 00:57:32.858: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:57:32.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-qq55r" for this suite.
Feb 27 00:57:54.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:57:54.951: INFO: namespace: e2e-tests-pod-network-test-qq55r, resource: bindings, ignored listing per whitelist
Feb 27 00:57:55.046: INFO: namespace e2e-tests-pod-network-test-qq55r deletion completed in 22.183782261s

• [SLOW TEST:42.748 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:57:55.046: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-bdzpq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bdzpq
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-bdzpq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-bdzpq
Feb 27 00:57:55.284: INFO: Found 0 stateful pods, waiting for 1
Feb 27 00:58:05.288: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 27 00:58:05.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 00:58:05.523: INFO: stderr: ""
Feb 27 00:58:05.523: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 00:58:05.523: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 00:58:05.530: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 27 00:58:15.535: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 00:58:15.535: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 00:58:15.561: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.9999998s
Feb 27 00:58:16.565: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.987049781s
Feb 27 00:58:17.569: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982860713s
Feb 27 00:58:18.574: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.978961946s
Feb 27 00:58:19.578: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.973972171s
Feb 27 00:58:20.583: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.969574398s
Feb 27 00:58:21.587: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.965345825s
Feb 27 00:58:22.593: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96099405s
Feb 27 00:58:23.598: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.955300765s
Feb 27 00:58:24.603: INFO: Verifying statefulset ss doesn't scale past 1 for another 949.998982ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-bdzpq
Feb 27 00:58:25.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 00:58:25.791: INFO: stderr: ""
Feb 27 00:58:25.791: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 00:58:25.791: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 00:58:25.802: INFO: Found 1 stateful pods, waiting for 3
Feb 27 00:58:35.806: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 00:58:35.806: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 00:58:35.806: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 27 00:58:35.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 00:58:36.024: INFO: stderr: ""
Feb 27 00:58:36.024: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 00:58:36.024: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 00:58:36.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 00:58:36.228: INFO: stderr: ""
Feb 27 00:58:36.228: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 00:58:36.228: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 00:58:36.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 00:58:36.439: INFO: stderr: ""
Feb 27 00:58:36.440: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 00:58:36.440: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 00:58:36.440: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 00:58:36.443: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 27 00:58:46.450: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 00:58:46.450: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 00:58:46.450: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 00:58:46.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999998s
Feb 27 00:58:47.466: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995551572s
Feb 27 00:58:48.470: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990643442s
Feb 27 00:58:49.475: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986651421s
Feb 27 00:58:50.480: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982317597s
Feb 27 00:58:51.484: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976954867s
Feb 27 00:58:52.489: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972448145s
Feb 27 00:58:53.493: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968133025s
Feb 27 00:58:54.499: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963604105s
Feb 27 00:58:55.504: INFO: Verifying statefulset ss doesn't scale past 3 for another 958.30628ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-bdzpq
Feb 27 00:58:56.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 00:58:56.713: INFO: stderr: ""
Feb 27 00:58:56.713: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 00:58:56.713: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 00:58:56.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 00:58:56.944: INFO: stderr: ""
Feb 27 00:58:56.944: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 00:58:56.944: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 00:58:56.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-bdzpq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 00:58:57.124: INFO: stderr: ""
Feb 27 00:58:57.124: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 00:58:57.124: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 00:58:57.124: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 00:59:17.142: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bdzpq
Feb 27 00:59:17.144: INFO: Scaling statefulset ss to 0
Feb 27 00:59:17.153: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 00:59:17.156: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:59:17.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bdzpq" for this suite.
Feb 27 00:59:23.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:59:23.259: INFO: namespace: e2e-tests-statefulset-bdzpq, resource: bindings, ignored listing per whitelist
Feb 27 00:59:23.302: INFO: namespace e2e-tests-statefulset-bdzpq deletion completed in 6.126904532s

• [SLOW TEST:88.256 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:59:23.303: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4bzj6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 00:59:23.520: INFO: Waiting up to 5m0s for pod "downward-api-ec10e162-3a2a-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-4bzj6" to be "success or failure"
Feb 27 00:59:23.525: INFO: Pod "downward-api-ec10e162-3a2a-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.602829ms
Feb 27 00:59:25.529: INFO: Pod "downward-api-ec10e162-3a2a-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008474499s
STEP: Saw pod success
Feb 27 00:59:25.529: INFO: Pod "downward-api-ec10e162-3a2a-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 00:59:25.532: INFO: Trying to get logs from node 9cy76-worker-000001 pod downward-api-ec10e162-3a2a-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 00:59:25.554: INFO: Waiting for pod downward-api-ec10e162-3a2a-11e9-9b83-4a9a78a986da to disappear
Feb 27 00:59:25.558: INFO: Pod downward-api-ec10e162-3a2a-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:59:25.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4bzj6" for this suite.
Feb 27 00:59:31.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 00:59:31.627: INFO: namespace: e2e-tests-downward-api-4bzj6, resource: bindings, ignored listing per whitelist
Feb 27 00:59:31.693: INFO: namespace e2e-tests-downward-api-4bzj6 deletion completed in 6.131682694s

• [SLOW TEST:8.391 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 00:59:31.694: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-pz7g6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-zwh6
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 00:59:31.909: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zwh6" in namespace "e2e-tests-subpath-pz7g6" to be "success or failure"
Feb 27 00:59:31.916: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.016845ms
Feb 27 00:59:33.922: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013646297s
Feb 27 00:59:35.934: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 4.024989649s
Feb 27 00:59:37.937: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 6.028343303s
Feb 27 00:59:39.941: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 8.032570966s
Feb 27 00:59:41.945: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 10.036467829s
Feb 27 00:59:43.949: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 12.040212194s
Feb 27 00:59:45.953: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 14.044096763s
Feb 27 00:59:47.958: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 16.049443244s
Feb 27 00:59:49.962: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 18.05352872s
Feb 27 00:59:51.966: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 20.057607699s
Feb 27 00:59:53.971: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Running", Reason="", readiness=false. Elapsed: 22.061867181s
Feb 27 00:59:55.975: INFO: Pod "pod-subpath-test-projected-zwh6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.066614269s
STEP: Saw pod success
Feb 27 00:59:55.975: INFO: Pod "pod-subpath-test-projected-zwh6" satisfied condition "success or failure"
Feb 27 00:59:55.980: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-subpath-test-projected-zwh6 container test-container-subpath-projected-zwh6: <nil>
STEP: delete the pod
Feb 27 00:59:56.008: INFO: Waiting for pod pod-subpath-test-projected-zwh6 to disappear
Feb 27 00:59:56.011: INFO: Pod pod-subpath-test-projected-zwh6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-zwh6
Feb 27 00:59:56.011: INFO: Deleting pod "pod-subpath-test-projected-zwh6" in namespace "e2e-tests-subpath-pz7g6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 00:59:56.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-pz7g6" for this suite.
Feb 27 01:00:02.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:00:02.123: INFO: namespace: e2e-tests-subpath-pz7g6, resource: bindings, ignored listing per whitelist
Feb 27 01:00:02.167: INFO: namespace e2e-tests-subpath-pz7g6 deletion completed in 6.138904391s

• [SLOW TEST:30.474 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:00:02.168: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-v9ptw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-033b7f2d-3a2b-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:00:02.390: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-v9ptw" to be "success or failure"
Feb 27 01:00:02.394: INFO: Pod "pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.431826ms
Feb 27 01:00:04.397: INFO: Pod "pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007588422s
Feb 27 01:00:06.402: INFO: Pod "pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012713763s
STEP: Saw pod success
Feb 27 01:00:06.402: INFO: Pod "pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:00:06.406: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:00:06.472: INFO: Waiting for pod pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:00:06.475: INFO: Pod pod-projected-configmaps-033cf3c3-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:00:06.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v9ptw" for this suite.
Feb 27 01:00:12.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:00:12.565: INFO: namespace: e2e-tests-projected-v9ptw, resource: bindings, ignored listing per whitelist
Feb 27 01:00:12.611: INFO: namespace e2e-tests-projected-v9ptw deletion completed in 6.128422584s

• [SLOW TEST:10.443 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:00:12.612: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fsr2j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 27 01:00:15.376: INFO: Successfully updated pod "pod-update-activedeadlineseconds-0977d946-3a2b-11e9-9b83-4a9a78a986da"
Feb 27 01:00:15.376: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-0977d946-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-pods-fsr2j" to be "terminated due to deadline exceeded"
Feb 27 01:00:15.380: INFO: Pod "pod-update-activedeadlineseconds-0977d946-3a2b-11e9-9b83-4a9a78a986da": Phase="Running", Reason="", readiness=true. Elapsed: 4.198626ms
Feb 27 01:00:17.384: INFO: Pod "pod-update-activedeadlineseconds-0977d946-3a2b-11e9-9b83-4a9a78a986da": Phase="Running", Reason="", readiness=true. Elapsed: 2.008075849s
Feb 27 01:00:19.388: INFO: Pod "pod-update-activedeadlineseconds-0977d946-3a2b-11e9-9b83-4a9a78a986da": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.011441448s
Feb 27 01:00:19.388: INFO: Pod "pod-update-activedeadlineseconds-0977d946-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:00:19.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fsr2j" for this suite.
Feb 27 01:00:25.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:00:25.457: INFO: namespace: e2e-tests-pods-fsr2j, resource: bindings, ignored listing per whitelist
Feb 27 01:00:25.517: INFO: namespace e2e-tests-pods-fsr2j deletion completed in 6.12486806s

• [SLOW TEST:12.905 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:00:25.517: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-sdpvf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1124dc10-3a2b-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:00:25.724: INFO: Waiting up to 5m0s for pod "pod-configmaps-11256797-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-sdpvf" to be "success or failure"
Feb 27 01:00:25.734: INFO: Pod "pod-configmaps-11256797-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 10.182866ms
Feb 27 01:00:27.738: INFO: Pod "pod-configmaps-11256797-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01388602s
STEP: Saw pod success
Feb 27 01:00:27.738: INFO: Pod "pod-configmaps-11256797-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:00:27.740: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-11256797-3a2b-11e9-9b83-4a9a78a986da container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:00:27.759: INFO: Waiting for pod pod-configmaps-11256797-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:00:27.762: INFO: Pod pod-configmaps-11256797-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:00:27.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sdpvf" for this suite.
Feb 27 01:00:33.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:00:33.902: INFO: namespace: e2e-tests-configmap-sdpvf, resource: bindings, ignored listing per whitelist
Feb 27 01:00:33.915: INFO: namespace e2e-tests-configmap-sdpvf deletion completed in 6.146598633s

• [SLOW TEST:8.397 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:00:33.915: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-s8pnr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 27 01:00:34.149: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-s8pnr,SelfLink:/api/v1/namespaces/e2e-tests-watch-s8pnr/configmaps/e2e-watch-test-watch-closed,UID:162a588d-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:65454,Generation:0,CreationTimestamp:2019-02-27 01:00:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 01:00:34.150: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-s8pnr,SelfLink:/api/v1/namespaces/e2e-tests-watch-s8pnr/configmaps/e2e-watch-test-watch-closed,UID:162a588d-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:65455,Generation:0,CreationTimestamp:2019-02-27 01:00:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 27 01:00:34.163: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-s8pnr,SelfLink:/api/v1/namespaces/e2e-tests-watch-s8pnr/configmaps/e2e-watch-test-watch-closed,UID:162a588d-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:65456,Generation:0,CreationTimestamp:2019-02-27 01:00:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 01:00:34.163: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-s8pnr,SelfLink:/api/v1/namespaces/e2e-tests-watch-s8pnr/configmaps/e2e-watch-test-watch-closed,UID:162a588d-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:65457,Generation:0,CreationTimestamp:2019-02-27 01:00:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:00:34.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-s8pnr" for this suite.
Feb 27 01:00:40.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:00:40.266: INFO: namespace: e2e-tests-watch-s8pnr, resource: bindings, ignored listing per whitelist
Feb 27 01:00:40.301: INFO: namespace e2e-tests-watch-s8pnr deletion completed in 6.132120078s

• [SLOW TEST:6.386 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:00:40.301: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-f4zq4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:00:42.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-f4zq4" for this suite.
Feb 27 01:01:26.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:01:26.651: INFO: namespace: e2e-tests-kubelet-test-f4zq4, resource: bindings, ignored listing per whitelist
Feb 27 01:01:26.710: INFO: namespace e2e-tests-kubelet-test-f4zq4 deletion completed in 44.140282208s

• [SLOW TEST:46.409 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:01:26.710: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pmnwl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-35a00ebd-3a2b-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:01:26.931: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35a096d0-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-pmnwl" to be "success or failure"
Feb 27 01:01:26.937: INFO: Pod "pod-projected-configmaps-35a096d0-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.985637ms
Feb 27 01:01:28.942: INFO: Pod "pod-projected-configmaps-35a096d0-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010562937s
STEP: Saw pod success
Feb 27 01:01:28.942: INFO: Pod "pod-projected-configmaps-35a096d0-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:01:28.945: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-configmaps-35a096d0-3a2b-11e9-9b83-4a9a78a986da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:01:28.974: INFO: Waiting for pod pod-projected-configmaps-35a096d0-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:01:28.981: INFO: Pod pod-projected-configmaps-35a096d0-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:01:28.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pmnwl" for this suite.
Feb 27 01:01:34.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:01:35.053: INFO: namespace: e2e-tests-projected-pmnwl, resource: bindings, ignored listing per whitelist
Feb 27 01:01:35.128: INFO: namespace e2e-tests-projected-pmnwl deletion completed in 6.142864874s

• [SLOW TEST:8.418 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:01:35.129: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ckn25
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 01:01:35.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ckn25'
Feb 27 01:01:36.301: INFO: stderr: ""
Feb 27 01:01:36.301: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 27 01:01:41.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ckn25 -o json'
Feb 27 01:01:41.428: INFO: stderr: ""
Feb 27 01:01:41.428: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.1.130.198/32\",\n            \"kubernetes.io/psp\": \"cert-exporter-psp\"\n        },\n        \"creationTimestamp\": \"2019-02-27T01:01:36Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-ckn25\",\n        \"resourceVersion\": \"65633\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-ckn25/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3b34d78a-3a2b-11e9-9b3e-000d3a2390ff\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-rm799\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"9cy76-worker-000000\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-rm799\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-rm799\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:01:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:01:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:01:38Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T01:01:36Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://6f1bd380acd0c12447cf37e4d2b34ac9f515cd53754daeb05bfe519f1852e38e\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-27T01:01:37Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.1.1.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.130.198\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-27T01:01:36Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 27 01:01:41.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 replace -f - --namespace=e2e-tests-kubectl-ckn25'
Feb 27 01:01:41.726: INFO: stderr: ""
Feb 27 01:01:41.726: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 27 01:01:41.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ckn25'
Feb 27 01:01:54.456: INFO: stderr: ""
Feb 27 01:01:54.456: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:01:54.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ckn25" for this suite.
Feb 27 01:02:00.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:02:00.499: INFO: namespace: e2e-tests-kubectl-ckn25, resource: bindings, ignored listing per whitelist
Feb 27 01:02:00.595: INFO: namespace e2e-tests-kubectl-ckn25 deletion completed in 6.135692331s

• [SLOW TEST:25.467 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:02:00.596: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rfq4r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0227 01:02:01.852789      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 01:02:01.853: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:02:01.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rfq4r" for this suite.
Feb 27 01:02:07.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:02:07.952: INFO: namespace: e2e-tests-gc-rfq4r, resource: bindings, ignored listing per whitelist
Feb 27 01:02:07.991: INFO: namespace e2e-tests-gc-rfq4r deletion completed in 6.134470849s

• [SLOW TEST:7.395 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:02:07.992: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-z97jf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-4e41cf8d-3a2b-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:02:08.259: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e4260ec-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-z97jf" to be "success or failure"
Feb 27 01:02:08.263: INFO: Pod "pod-configmaps-4e4260ec-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.246821ms
Feb 27 01:02:10.274: INFO: Pod "pod-configmaps-4e4260ec-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014874295s
STEP: Saw pod success
Feb 27 01:02:10.274: INFO: Pod "pod-configmaps-4e4260ec-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:02:10.286: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-4e4260ec-3a2b-11e9-9b83-4a9a78a986da container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:02:10.321: INFO: Waiting for pod pod-configmaps-4e4260ec-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:02:10.325: INFO: Pod pod-configmaps-4e4260ec-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:02:10.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z97jf" for this suite.
Feb 27 01:02:16.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:02:16.414: INFO: namespace: e2e-tests-configmap-z97jf, resource: bindings, ignored listing per whitelist
Feb 27 01:02:16.524: INFO: namespace e2e-tests-configmap-z97jf deletion completed in 6.17539232s

• [SLOW TEST:8.532 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:02:16.524: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-j48cp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 27 01:02:16.768: INFO: Waiting up to 5m0s for pod "pod-5354a115-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-j48cp" to be "success or failure"
Feb 27 01:02:16.778: INFO: Pod "pod-5354a115-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 9.907359ms
Feb 27 01:02:18.782: INFO: Pod "pod-5354a115-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01393322s
STEP: Saw pod success
Feb 27 01:02:18.782: INFO: Pod "pod-5354a115-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:02:18.790: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-5354a115-3a2b-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:02:18.807: INFO: Waiting for pod pod-5354a115-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:02:18.812: INFO: Pod pod-5354a115-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:02:18.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j48cp" for this suite.
Feb 27 01:02:24.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:02:24.914: INFO: namespace: e2e-tests-emptydir-j48cp, resource: bindings, ignored listing per whitelist
Feb 27 01:02:24.961: INFO: namespace e2e-tests-emptydir-j48cp deletion completed in 6.143977068s

• [SLOW TEST:8.437 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:02:24.962: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-4d48d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-rqbk6
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 27 01:02:29.456: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-qgg2l
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:02:53.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-4d48d" for this suite.
Feb 27 01:02:59.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:02:59.708: INFO: namespace: e2e-tests-namespaces-4d48d, resource: bindings, ignored listing per whitelist
Feb 27 01:02:59.759: INFO: namespace e2e-tests-namespaces-4d48d deletion completed in 6.14448172s
STEP: Destroying namespace "e2e-tests-nsdeletetest-rqbk6" for this suite.
Feb 27 01:02:59.763: INFO: Namespace e2e-tests-nsdeletetest-rqbk6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-qgg2l" for this suite.
Feb 27 01:03:05.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:03:05.819: INFO: namespace: e2e-tests-nsdeletetest-qgg2l, resource: bindings, ignored listing per whitelist
Feb 27 01:03:05.908: INFO: namespace e2e-tests-nsdeletetest-qgg2l deletion completed in 6.144868794s

• [SLOW TEST:40.947 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:03:05.909: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fbrrg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 01:03:06.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-fbrrg'
Feb 27 01:03:06.205: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 01:03:06.205: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 27 01:03:06.229: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 27 01:03:06.242: INFO: scanned /root for discovery docs: <nil>
Feb 27 01:03:06.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-fbrrg'
Feb 27 01:03:22.335: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 27 01:03:22.335: INFO: stdout: "Created e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f\nScaling up e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 27 01:03:22.335: INFO: stdout: "Created e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f\nScaling up e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 27 01:03:22.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fbrrg'
Feb 27 01:03:22.436: INFO: stderr: ""
Feb 27 01:03:22.436: INFO: stdout: "e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f-g8g97 "
Feb 27 01:03:22.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f-g8g97 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fbrrg'
Feb 27 01:03:22.517: INFO: stderr: ""
Feb 27 01:03:22.517: INFO: stdout: "true"
Feb 27 01:03:22.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 get pods e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f-g8g97 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fbrrg'
Feb 27 01:03:22.591: INFO: stderr: ""
Feb 27 01:03:22.591: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 27 01:03:22.591: INFO: e2e-test-nginx-rc-ada6d971a47fd7bbea61b8828200378f-g8g97 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 27 01:03:22.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fbrrg'
Feb 27 01:03:22.673: INFO: stderr: ""
Feb 27 01:03:22.673: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:03:22.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fbrrg" for this suite.
Feb 27 01:03:28.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:03:28.763: INFO: namespace: e2e-tests-kubectl-fbrrg, resource: bindings, ignored listing per whitelist
Feb 27 01:03:28.814: INFO: namespace e2e-tests-kubectl-fbrrg deletion completed in 6.133867892s

• [SLOW TEST:22.906 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:03:28.815: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vh2x5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 27 01:03:29.026: INFO: Waiting up to 5m0s for pod "pod-7e670b14-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-vh2x5" to be "success or failure"
Feb 27 01:03:29.032: INFO: Pod "pod-7e670b14-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.747034ms
Feb 27 01:03:31.036: INFO: Pod "pod-7e670b14-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010502431s
STEP: Saw pod success
Feb 27 01:03:31.036: INFO: Pod "pod-7e670b14-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:03:31.040: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-7e670b14-3a2b-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:03:31.088: INFO: Waiting for pod pod-7e670b14-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:03:31.095: INFO: Pod pod-7e670b14-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:03:31.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vh2x5" for this suite.
Feb 27 01:03:37.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:03:37.217: INFO: namespace: e2e-tests-emptydir-vh2x5, resource: bindings, ignored listing per whitelist
Feb 27 01:03:37.278: INFO: namespace e2e-tests-emptydir-vh2x5 deletion completed in 6.150976905s

• [SLOW TEST:8.464 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:03:37.279: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2drn9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 27 01:03:37.489: INFO: Waiting up to 5m0s for pod "pod-83727009-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-2drn9" to be "success or failure"
Feb 27 01:03:37.493: INFO: Pod "pod-83727009-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.853617ms
Feb 27 01:03:39.496: INFO: Pod "pod-83727009-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006775576s
STEP: Saw pod success
Feb 27 01:03:39.497: INFO: Pod "pod-83727009-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:03:39.502: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-83727009-3a2b-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:03:39.531: INFO: Waiting for pod pod-83727009-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:03:39.540: INFO: Pod pod-83727009-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:03:39.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2drn9" for this suite.
Feb 27 01:03:45.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:03:45.663: INFO: namespace: e2e-tests-emptydir-2drn9, resource: bindings, ignored listing per whitelist
Feb 27 01:03:45.695: INFO: namespace e2e-tests-emptydir-2drn9 deletion completed in 6.146345567s

• [SLOW TEST:8.416 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:03:45.695: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-jjdj4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 27 01:03:50.000: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:03:50.012: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:03:52.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:03:52.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:03:54.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:03:54.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:03:56.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:03:56.019: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:03:58.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:03:58.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:00.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:00.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:02.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:02.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:04.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:04.020: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:06.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:06.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:08.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:08.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:10.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:10.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:12.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:12.016: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:14.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:14.017: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:04:16.013: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:04:16.017: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:04:16.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jjdj4" for this suite.
Feb 27 01:04:38.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:04:38.203: INFO: namespace: e2e-tests-container-lifecycle-hook-jjdj4, resource: bindings, ignored listing per whitelist
Feb 27 01:04:38.208: INFO: namespace e2e-tests-container-lifecycle-hook-jjdj4 deletion completed in 22.176697266s

• [SLOW TEST:52.513 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:04:38.209: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-dgrjf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 27 01:04:38.434: INFO: Waiting up to 5m0s for pod "client-containers-a7c50b9c-3a2b-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-containers-dgrjf" to be "success or failure"
Feb 27 01:04:38.443: INFO: Pod "client-containers-a7c50b9c-3a2b-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.987356ms
Feb 27 01:04:40.447: INFO: Pod "client-containers-a7c50b9c-3a2b-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013565852s
STEP: Saw pod success
Feb 27 01:04:40.447: INFO: Pod "client-containers-a7c50b9c-3a2b-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:04:40.451: INFO: Trying to get logs from node 9cy76-worker-000000 pod client-containers-a7c50b9c-3a2b-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:04:40.499: INFO: Waiting for pod client-containers-a7c50b9c-3a2b-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:04:40.503: INFO: Pod client-containers-a7c50b9c-3a2b-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:04:40.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-dgrjf" for this suite.
Feb 27 01:04:46.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:04:46.646: INFO: namespace: e2e-tests-containers-dgrjf, resource: bindings, ignored listing per whitelist
Feb 27 01:04:46.694: INFO: namespace e2e-tests-containers-dgrjf deletion completed in 6.18507156s

• [SLOW TEST:8.484 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:04:46.694: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wvvlb
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-acd1e0bc-3a2b-11e9-9b83-4a9a78a986da
STEP: Creating secret with name s-test-opt-upd-acd1e137-3a2b-11e9-9b83-4a9a78a986da
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-acd1e0bc-3a2b-11e9-9b83-4a9a78a986da
STEP: Updating secret s-test-opt-upd-acd1e137-3a2b-11e9-9b83-4a9a78a986da
STEP: Creating secret with name s-test-opt-create-acd1e153-3a2b-11e9-9b83-4a9a78a986da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:04:51.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wvvlb" for this suite.
Feb 27 01:05:13.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:05:13.100: INFO: namespace: e2e-tests-secrets-wvvlb, resource: bindings, ignored listing per whitelist
Feb 27 01:05:13.134: INFO: namespace e2e-tests-secrets-wvvlb deletion completed in 22.128316866s

• [SLOW TEST:26.440 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:05:13.135: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-gf9qq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:05:13.341: INFO: (0) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.515326ms)
Feb 27 01:05:13.344: INFO: (1) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.301319ms)
Feb 27 01:05:13.348: INFO: (2) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.732822ms)
Feb 27 01:05:13.351: INFO: (3) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.188119ms)
Feb 27 01:05:13.355: INFO: (4) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.734722ms)
Feb 27 01:05:13.360: INFO: (5) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.475227ms)
Feb 27 01:05:13.363: INFO: (6) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.35942ms)
Feb 27 01:05:13.367: INFO: (7) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.820823ms)
Feb 27 01:05:13.370: INFO: (8) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.528821ms)
Feb 27 01:05:13.375: INFO: (9) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.998723ms)
Feb 27 01:05:13.378: INFO: (10) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.765923ms)
Feb 27 01:05:13.384: INFO: (11) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.608733ms)
Feb 27 01:05:13.389: INFO: (12) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.671628ms)
Feb 27 01:05:13.395: INFO: (13) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.558539ms)
Feb 27 01:05:13.402: INFO: (14) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.994742ms)
Feb 27 01:05:13.414: INFO: (15) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 11.389667ms)
Feb 27 01:05:13.419: INFO: (16) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.130031ms)
Feb 27 01:05:13.423: INFO: (17) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.418126ms)
Feb 27 01:05:13.430: INFO: (18) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 6.324138ms)
Feb 27 01:05:13.434: INFO: (19) /api/v1/nodes/9cy76-worker-000000/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.966824ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:05:13.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gf9qq" for this suite.
Feb 27 01:05:19.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:05:19.475: INFO: namespace: e2e-tests-proxy-gf9qq, resource: bindings, ignored listing per whitelist
Feb 27 01:05:19.566: INFO: namespace e2e-tests-proxy-gf9qq deletion completed in 6.127408691s

• [SLOW TEST:6.431 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:05:19.567: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-lrxjt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:05:21.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-lrxjt" for this suite.
Feb 27 01:05:27.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:05:27.968: INFO: namespace: e2e-tests-emptydir-wrapper-lrxjt, resource: bindings, ignored listing per whitelist
Feb 27 01:05:28.000: INFO: namespace e2e-tests-emptydir-wrapper-lrxjt deletion completed in 6.150412021s

• [SLOW TEST:8.434 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:05:28.001: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-45h7c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:05:35.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-45h7c" for this suite.
Feb 27 01:05:57.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:05:57.397: INFO: namespace: e2e-tests-replication-controller-45h7c, resource: bindings, ignored listing per whitelist
Feb 27 01:05:57.448: INFO: namespace e2e-tests-replication-controller-45h7c deletion completed in 22.131075759s

• [SLOW TEST:29.447 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:05:57.448: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-56wkv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 27 01:05:57.660: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66563,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 01:05:57.661: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66563,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 27 01:06:07.668: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66579,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 27 01:06:07.668: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66579,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 27 01:06:17.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66596,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 01:06:17.677: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66596,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 27 01:06:27.683: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66611,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 01:06:27.683: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-a,UID:d6fedf50-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66611,Generation:0,CreationTimestamp:2019-02-27 01:05:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 27 01:06:37.694: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-b,UID:eedaee53-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66627,Generation:0,CreationTimestamp:2019-02-27 01:06:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 01:06:37.694: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-b,UID:eedaee53-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66627,Generation:0,CreationTimestamp:2019-02-27 01:06:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 27 01:06:47.701: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-b,UID:eedaee53-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66644,Generation:0,CreationTimestamp:2019-02-27 01:06:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 01:06:47.701: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-56wkv,SelfLink:/api/v1/namespaces/e2e-tests-watch-56wkv/configmaps/e2e-watch-test-configmap-b,UID:eedaee53-3a2b-11e9-9b3e-000d3a2390ff,ResourceVersion:66644,Generation:0,CreationTimestamp:2019-02-27 01:06:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:06:57.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-56wkv" for this suite.
Feb 27 01:07:03.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:07:03.813: INFO: namespace: e2e-tests-watch-56wkv, resource: bindings, ignored listing per whitelist
Feb 27 01:07:03.838: INFO: namespace e2e-tests-watch-56wkv deletion completed in 6.130774472s

• [SLOW TEST:66.390 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:07:03.839: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-msrwd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0227 01:07:44.108808      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 01:07:44.108: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:07:44.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-msrwd" for this suite.
Feb 27 01:07:50.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:07:50.252: INFO: namespace: e2e-tests-gc-msrwd, resource: bindings, ignored listing per whitelist
Feb 27 01:07:50.354: INFO: namespace e2e-tests-gc-msrwd deletion completed in 6.239948648s

• [SLOW TEST:46.516 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:07:50.360: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-dcfjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:07:50.659: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:07:51.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-dcfjl" for this suite.
Feb 27 01:07:57.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:07:57.833: INFO: namespace: e2e-tests-custom-resource-definition-dcfjl, resource: bindings, ignored listing per whitelist
Feb 27 01:07:57.860: INFO: namespace e2e-tests-custom-resource-definition-dcfjl deletion completed in 6.125098228s

• [SLOW TEST:7.500 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:07:57.861: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4qxzg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:08:18.082: INFO: Container started at 2019-02-27 01:07:59 +0000 UTC, pod became ready at 2019-02-27 01:08:16 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:08:18.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4qxzg" for this suite.
Feb 27 01:08:40.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:08:40.199: INFO: namespace: e2e-tests-container-probe-4qxzg, resource: bindings, ignored listing per whitelist
Feb 27 01:08:40.238: INFO: namespace e2e-tests-container-probe-4qxzg deletion completed in 22.140037171s

• [SLOW TEST:42.378 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:08:40.239: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2swrn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-2swrn/secret-test-38083e2f-3a2c-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 01:08:40.464: INFO: Waiting up to 5m0s for pod "pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-2swrn" to be "success or failure"
Feb 27 01:08:40.471: INFO: Pod "pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.959039ms
Feb 27 01:08:42.475: INFO: Pod "pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011207957s
Feb 27 01:08:44.479: INFO: Pod "pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015150651s
STEP: Saw pod success
Feb 27 01:08:44.479: INFO: Pod "pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:08:44.482: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da container env-test: <nil>
STEP: delete the pod
Feb 27 01:08:44.504: INFO: Waiting for pod pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:08:44.511: INFO: Pod pod-configmaps-3808b35b-3a2c-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:08:44.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2swrn" for this suite.
Feb 27 01:08:50.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:08:50.635: INFO: namespace: e2e-tests-secrets-2swrn, resource: bindings, ignored listing per whitelist
Feb 27 01:08:50.666: INFO: namespace e2e-tests-secrets-2swrn deletion completed in 6.149763386s

• [SLOW TEST:10.427 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:08:50.667: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-nvtbs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 27 01:08:50.899: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-nvtbs" to be "success or failure"
Feb 27 01:08:50.909: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.474666ms
Feb 27 01:08:52.913: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014306013s
Feb 27 01:08:54.918: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019252321s
STEP: Saw pod success
Feb 27 01:08:54.918: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 27 01:08:54.921: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 27 01:08:54.947: INFO: Waiting for pod pod-host-path-test to disappear
Feb 27 01:08:54.958: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:08:54.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-nvtbs" for this suite.
Feb 27 01:09:00.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:09:01.054: INFO: namespace: e2e-tests-hostpath-nvtbs, resource: bindings, ignored listing per whitelist
Feb 27 01:09:01.098: INFO: namespace e2e-tests-hostpath-nvtbs deletion completed in 6.127908065s

• [SLOW TEST:10.432 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:09:01.101: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-mdkh6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 27 01:09:07.368: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 01:09:07.373: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 01:09:09.374: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 01:09:09.378: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 01:09:11.373: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 01:09:11.376: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 01:09:13.373: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 01:09:13.379: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 01:09:15.373: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 01:09:15.380: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:09:15.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mdkh6" for this suite.
Feb 27 01:09:37.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:09:37.506: INFO: namespace: e2e-tests-container-lifecycle-hook-mdkh6, resource: bindings, ignored listing per whitelist
Feb 27 01:09:37.525: INFO: namespace e2e-tests-container-lifecycle-hook-mdkh6 deletion completed in 22.131556417s

• [SLOW TEST:36.424 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:09:37.526: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-nrlbd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-jtwrm
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-mddw4
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:09:44.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-nrlbd" for this suite.
Feb 27 01:09:50.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:09:50.182: INFO: namespace: e2e-tests-namespaces-nrlbd, resource: bindings, ignored listing per whitelist
Feb 27 01:09:50.201: INFO: namespace e2e-tests-namespaces-nrlbd deletion completed in 6.146147388s
STEP: Destroying namespace "e2e-tests-nsdeletetest-jtwrm" for this suite.
Feb 27 01:09:50.205: INFO: Namespace e2e-tests-nsdeletetest-jtwrm was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mddw4" for this suite.
Feb 27 01:09:56.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:09:56.341: INFO: namespace: e2e-tests-nsdeletetest-mddw4, resource: bindings, ignored listing per whitelist
Feb 27 01:09:56.341: INFO: namespace e2e-tests-nsdeletetest-mddw4 deletion completed in 6.13655315s

• [SLOW TEST:18.816 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:09:56.341: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qhc2h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-656650dc-3a2c-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:09:56.581: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6566ee79-3a2c-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-qhc2h" to be "success or failure"
Feb 27 01:09:56.584: INFO: Pod "pod-projected-configmaps-6566ee79-3a2c-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.289221ms
Feb 27 01:09:58.589: INFO: Pod "pod-projected-configmaps-6566ee79-3a2c-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008606024s
STEP: Saw pod success
Feb 27 01:09:58.589: INFO: Pod "pod-projected-configmaps-6566ee79-3a2c-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:09:58.593: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-configmaps-6566ee79-3a2c-11e9-9b83-4a9a78a986da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:09:58.615: INFO: Waiting for pod pod-projected-configmaps-6566ee79-3a2c-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:09:58.619: INFO: Pod pod-projected-configmaps-6566ee79-3a2c-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:09:58.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qhc2h" for this suite.
Feb 27 01:10:04.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:10:04.715: INFO: namespace: e2e-tests-projected-qhc2h, resource: bindings, ignored listing per whitelist
Feb 27 01:10:04.802: INFO: namespace e2e-tests-projected-qhc2h deletion completed in 6.14777242s

• [SLOW TEST:8.461 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:10:04.803: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-b4zqr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 01:10:05.028: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:05.032: INFO: Number of nodes with available pods: 0
Feb 27 01:10:05.032: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:06.038: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:06.043: INFO: Number of nodes with available pods: 0
Feb 27 01:10:06.043: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:07.037: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:07.040: INFO: Number of nodes with available pods: 2
Feb 27 01:10:07.040: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 27 01:10:07.064: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:07.067: INFO: Number of nodes with available pods: 1
Feb 27 01:10:07.067: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:08.074: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:08.078: INFO: Number of nodes with available pods: 1
Feb 27 01:10:08.078: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:09.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:09.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:09.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:10.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:10.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:10.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:11.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:11.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:11.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:12.075: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:12.079: INFO: Number of nodes with available pods: 1
Feb 27 01:10:12.079: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:13.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:13.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:13.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:14.075: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:14.080: INFO: Number of nodes with available pods: 1
Feb 27 01:10:14.080: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:15.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:15.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:15.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:16.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:16.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:16.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:17.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:17.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:17.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:18.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:18.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:18.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:19.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:19.077: INFO: Number of nodes with available pods: 1
Feb 27 01:10:19.077: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:20.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:20.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:20.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:21.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:21.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:21.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:22.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:22.077: INFO: Number of nodes with available pods: 1
Feb 27 01:10:22.083: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:23.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:23.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:23.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:24.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:24.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:24.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:25.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:25.077: INFO: Number of nodes with available pods: 1
Feb 27 01:10:25.077: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:26.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:26.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:26.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:27.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:27.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:27.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:28.076: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:28.080: INFO: Number of nodes with available pods: 1
Feb 27 01:10:28.080: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:29.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:29.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:29.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:30.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:30.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:30.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:31.076: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:31.080: INFO: Number of nodes with available pods: 1
Feb 27 01:10:31.080: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:32.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:32.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:32.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:33.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:33.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:33.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:34.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:34.076: INFO: Number of nodes with available pods: 1
Feb 27 01:10:34.076: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:35.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:35.078: INFO: Number of nodes with available pods: 1
Feb 27 01:10:35.078: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:36.074: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:36.078: INFO: Number of nodes with available pods: 1
Feb 27 01:10:36.078: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:37.074: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:37.078: INFO: Number of nodes with available pods: 1
Feb 27 01:10:37.078: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:38.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:38.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:38.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:39.075: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:39.080: INFO: Number of nodes with available pods: 1
Feb 27 01:10:39.080: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:40.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:40.077: INFO: Number of nodes with available pods: 1
Feb 27 01:10:40.077: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:41.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:41.087: INFO: Number of nodes with available pods: 1
Feb 27 01:10:41.087: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:42.072: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:42.075: INFO: Number of nodes with available pods: 1
Feb 27 01:10:42.075: INFO: Node 9cy76-worker-000000 is running more than one daemon pod
Feb 27 01:10:43.073: INFO: DaemonSet pods can't tolerate node 9cy76-master-000000 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 01:10:43.077: INFO: Number of nodes with available pods: 2
Feb 27 01:10:43.077: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-b4zqr, will wait for the garbage collector to delete the pods
Feb 27 01:10:43.144: INFO: Deleting DaemonSet.extensions daemon-set took: 10.62857ms
Feb 27 01:10:43.244: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.144159ms
Feb 27 01:11:24.454: INFO: Number of nodes with available pods: 0
Feb 27 01:11:24.454: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 01:11:24.457: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-b4zqr/daemonsets","resourceVersion":"67575"},"items":null}

Feb 27 01:11:24.459: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-b4zqr/pods","resourceVersion":"67575"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:11:24.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-b4zqr" for this suite.
Feb 27 01:11:30.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:11:30.552: INFO: namespace: e2e-tests-daemonsets-b4zqr, resource: bindings, ignored listing per whitelist
Feb 27 01:11:30.625: INFO: namespace e2e-tests-daemonsets-b4zqr deletion completed in 6.153982193s

• [SLOW TEST:85.823 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:11:30.625: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-hmwmd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:11:30.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hmwmd" for this suite.
Feb 27 01:11:52.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:11:52.959: INFO: namespace: e2e-tests-pods-hmwmd, resource: bindings, ignored listing per whitelist
Feb 27 01:11:52.998: INFO: namespace e2e-tests-pods-hmwmd deletion completed in 22.137441925s

• [SLOW TEST:22.373 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:11:52.998: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8ds9r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 01:11:53.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-8ds9r'
Feb 27 01:11:54.166: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 01:11:54.166: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 27 01:11:58.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-8ds9r'
Feb 27 01:11:58.348: INFO: stderr: ""
Feb 27 01:11:58.348: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:11:58.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8ds9r" for this suite.
Feb 27 01:12:20.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:12:20.508: INFO: namespace: e2e-tests-kubectl-8ds9r, resource: bindings, ignored listing per whitelist
Feb 27 01:12:20.508: INFO: namespace e2e-tests-kubectl-8ds9r deletion completed in 22.156054189s

• [SLOW TEST:27.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:12:20.508: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rctcb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:12:20.719: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-rctcb" to be "success or failure"
Feb 27 01:12:20.726: INFO: Pod "downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.016046ms
Feb 27 01:12:22.730: INFO: Pod "downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010592148s
Feb 27 01:12:24.734: INFO: Pod "downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014844455s
STEP: Saw pod success
Feb 27 01:12:24.734: INFO: Pod "downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:12:24.737: INFO: Trying to get logs from node 9cy76-worker-000001 pod downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 01:12:24.764: INFO: Waiting for pod downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:12:24.767: INFO: Pod downwardapi-volume-bb50eaef-3a2c-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:12:24.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rctcb" for this suite.
Feb 27 01:12:30.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:12:30.902: INFO: namespace: e2e-tests-downward-api-rctcb, resource: bindings, ignored listing per whitelist
Feb 27 01:12:30.905: INFO: namespace e2e-tests-downward-api-rctcb deletion completed in 6.133180219s

• [SLOW TEST:10.396 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:12:30.906: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7nw78
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c1831451-3a2c-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:12:31.119: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1837ba1-3a2c-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-7nw78" to be "success or failure"
Feb 27 01:12:31.140: INFO: Pod "pod-configmaps-c1837ba1-3a2c-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 20.612636ms
Feb 27 01:12:33.144: INFO: Pod "pod-configmaps-c1837ba1-3a2c-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02418318s
STEP: Saw pod success
Feb 27 01:12:33.144: INFO: Pod "pod-configmaps-c1837ba1-3a2c-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:12:33.147: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-c1837ba1-3a2c-11e9-9b83-4a9a78a986da container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:12:33.166: INFO: Waiting for pod pod-configmaps-c1837ba1-3a2c-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:12:33.180: INFO: Pod pod-configmaps-c1837ba1-3a2c-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:12:33.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7nw78" for this suite.
Feb 27 01:12:39.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:12:39.269: INFO: namespace: e2e-tests-configmap-7nw78, resource: bindings, ignored listing per whitelist
Feb 27 01:12:39.326: INFO: namespace e2e-tests-configmap-7nw78 deletion completed in 6.127360253s

• [SLOW TEST:8.420 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:12:39.326: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-l2xcz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da
Feb 27 01:12:39.545: INFO: Pod name my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da: Found 0 pods out of 1
Feb 27 01:12:44.549: INFO: Pod name my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da: Found 1 pods out of 1
Feb 27 01:12:44.549: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da" are running
Feb 27 01:12:44.553: INFO: Pod "my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da-l8hns" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:12:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:12:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:12:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:12:39 +0000 UTC Reason: Message:}])
Feb 27 01:12:44.553: INFO: Trying to dial the pod
Feb 27 01:12:49.565: INFO: Controller my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da: Got expected result from replica 1 [my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da-l8hns]: "my-hostname-basic-c6893000-3a2c-11e9-9b83-4a9a78a986da-l8hns", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:12:49.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-l2xcz" for this suite.
Feb 27 01:12:55.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:12:55.634: INFO: namespace: e2e-tests-replication-controller-l2xcz, resource: bindings, ignored listing per whitelist
Feb 27 01:12:55.720: INFO: namespace e2e-tests-replication-controller-l2xcz deletion completed in 6.150609434s

• [SLOW TEST:16.393 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:12:55.720: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-jjqfl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jjqfl
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jjqfl
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jjqfl
Feb 27 01:12:55.972: INFO: Found 0 stateful pods, waiting for 1
Feb 27 01:13:05.977: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 27 01:13:05.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-jjqfl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:13:06.172: INFO: stderr: ""
Feb 27 01:13:06.172: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:13:06.172: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:13:06.176: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 27 01:13:16.179: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:13:16.179: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:13:16.207: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:16.207: INFO: ss-0  9cy76-worker-000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:16.207: INFO: 
Feb 27 01:13:16.207: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 27 01:13:17.210: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.982679785s
Feb 27 01:13:18.217: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979108034s
Feb 27 01:13:19.222: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.971391007s
Feb 27 01:13:20.227: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966982492s
Feb 27 01:13:21.231: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962663477s
Feb 27 01:13:22.235: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.95828056s
Feb 27 01:13:23.239: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954357045s
Feb 27 01:13:24.244: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949959625s
Feb 27 01:13:25.248: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.418204ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jjqfl
Feb 27 01:13:26.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-jjqfl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:13:26.481: INFO: stderr: ""
Feb 27 01:13:26.481: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:13:26.481: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:13:26.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-jjqfl ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:13:26.688: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 27 01:13:26.688: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:13:26.688: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:13:26.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-jjqfl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:13:26.899: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 27 01:13:26.899: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:13:26.899: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:13:26.903: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb 27 01:13:36.907: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:13:36.907: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:13:36.907: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 27 01:13:36.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-jjqfl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:13:37.114: INFO: stderr: ""
Feb 27 01:13:37.114: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:13:37.114: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:13:37.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-jjqfl ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:13:37.418: INFO: stderr: ""
Feb 27 01:13:37.418: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:13:37.418: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:13:37.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-jjqfl ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:13:37.809: INFO: stderr: ""
Feb 27 01:13:37.809: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:13:37.809: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:13:37.809: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:13:37.813: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 27 01:13:47.819: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:13:47.819: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:13:47.819: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:13:47.832: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:47.832: INFO: ss-0  9cy76-worker-000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:47.832: INFO: ss-1  9cy76-worker-000001  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  }]
Feb 27 01:13:47.832: INFO: ss-2  9cy76-worker-000000  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  }]
Feb 27 01:13:47.832: INFO: 
Feb 27 01:13:47.832: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 27 01:13:48.837: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:48.837: INFO: ss-0  9cy76-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:48.838: INFO: ss-1  9cy76-worker-000001  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  }]
Feb 27 01:13:48.838: INFO: ss-2  9cy76-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  }]
Feb 27 01:13:48.838: INFO: 
Feb 27 01:13:48.838: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 27 01:13:50.038: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:50.038: INFO: ss-0  9cy76-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:50.038: INFO: ss-2  9cy76-worker-000000  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:16 +0000 UTC  }]
Feb 27 01:13:50.038: INFO: 
Feb 27 01:13:50.038: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 27 01:13:51.042: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:51.042: INFO: ss-0  9cy76-worker-000000  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:51.042: INFO: 
Feb 27 01:13:51.042: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 01:13:52.047: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:52.047: INFO: ss-0  9cy76-worker-000000  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:52.047: INFO: 
Feb 27 01:13:52.047: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 01:13:53.053: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:53.053: INFO: ss-0  9cy76-worker-000000  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:53.053: INFO: 
Feb 27 01:13:53.053: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 01:13:54.057: INFO: POD   NODE                 PHASE    GRACE  CONDITIONS
Feb 27 01:13:54.057: INFO: ss-0  9cy76-worker-000000  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:13:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:12:55 +0000 UTC  }]
Feb 27 01:13:54.058: INFO: 
Feb 27 01:13:54.058: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 27 01:13:55.067: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.769289244s
Feb 27 01:13:56.086: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.746427499s
Feb 27 01:13:57.089: INFO: Verifying statefulset ss doesn't scale past 0 for another 741.596272ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jjqfl
Feb 27 01:13:58.094: INFO: Scaling statefulset ss to 0
Feb 27 01:13:58.112: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 01:13:58.115: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jjqfl
Feb 27 01:13:58.118: INFO: Scaling statefulset ss to 0
Feb 27 01:13:58.129: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:13:58.133: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:13:58.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jjqfl" for this suite.
Feb 27 01:14:04.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:14:04.296: INFO: namespace: e2e-tests-statefulset-jjqfl, resource: bindings, ignored listing per whitelist
Feb 27 01:14:04.307: INFO: namespace e2e-tests-statefulset-jjqfl deletion completed in 6.120405668s

• [SLOW TEST:68.586 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:14:04.307: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-bvrj4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:14:04.513: INFO: (0) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.851025ms)
Feb 27 01:14:04.517: INFO: (1) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.419422ms)
Feb 27 01:14:04.521: INFO: (2) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.190028ms)
Feb 27 01:14:04.524: INFO: (3) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.271222ms)
Feb 27 01:14:04.528: INFO: (4) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.697125ms)
Feb 27 01:14:04.531: INFO: (5) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.235821ms)
Feb 27 01:14:04.535: INFO: (6) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.143628ms)
Feb 27 01:14:04.540: INFO: (7) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.002833ms)
Feb 27 01:14:04.545: INFO: (8) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.057834ms)
Feb 27 01:14:04.550: INFO: (9) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.266328ms)
Feb 27 01:14:04.555: INFO: (10) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.439135ms)
Feb 27 01:14:04.559: INFO: (11) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.055926ms)
Feb 27 01:14:04.563: INFO: (12) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.698624ms)
Feb 27 01:14:04.567: INFO: (13) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.802525ms)
Feb 27 01:14:04.571: INFO: (14) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.915226ms)
Feb 27 01:14:04.575: INFO: (15) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 3.826425ms)
Feb 27 01:14:04.579: INFO: (16) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.074727ms)
Feb 27 01:14:04.583: INFO: (17) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 4.377929ms)
Feb 27 01:14:04.591: INFO: (18) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 7.861051ms)
Feb 27 01:14:04.596: INFO: (19) /api/v1/nodes/9cy76-worker-000000:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 5.268134ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:14:04.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bvrj4" for this suite.
Feb 27 01:14:10.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:14:10.653: INFO: namespace: e2e-tests-proxy-bvrj4, resource: bindings, ignored listing per whitelist
Feb 27 01:14:10.749: INFO: namespace e2e-tests-proxy-bvrj4 deletion completed in 6.147704157s

• [SLOW TEST:6.442 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:14:10.750: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-5d9nq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-5d9nq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5d9nq to expose endpoints map[]
Feb 27 01:14:11.003: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5d9nq exposes endpoints map[] (6.451142ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5d9nq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5d9nq to expose endpoints map[pod1:[100]]
Feb 27 01:14:13.047: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5d9nq exposes endpoints map[pod1:[100]] (2.032518896s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5d9nq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5d9nq to expose endpoints map[pod1:[100] pod2:[101]]
Feb 27 01:14:15.118: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5d9nq exposes endpoints map[pod1:[100] pod2:[101]] (2.061359155s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5d9nq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5d9nq to expose endpoints map[pod2:[101]]
Feb 27 01:14:15.144: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5d9nq exposes endpoints map[pod2:[101]] (15.176491ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5d9nq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-5d9nq to expose endpoints map[]
Feb 27 01:14:16.184: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-5d9nq exposes endpoints map[] (1.025105702s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:14:16.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5d9nq" for this suite.
Feb 27 01:14:38.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:14:38.293: INFO: namespace: e2e-tests-services-5d9nq, resource: bindings, ignored listing per whitelist
Feb 27 01:14:38.344: INFO: namespace e2e-tests-services-5d9nq deletion completed in 22.132387559s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.595 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:14:38.345: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-gv5t6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:14:38.575: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 27 01:14:43.579: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 01:14:43.580: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 01:14:43.618: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-gv5t6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gv5t6/deployments/test-cleanup-deployment,UID:1079948b-3a2d-11e9-9b3e-000d3a2390ff,ResourceVersion:68326,Generation:1,CreationTimestamp:2019-02-27 01:14:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 27 01:14:43.628: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-gv5t6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gv5t6/replicasets/test-cleanup-deployment-7dbbfcf846,UID:107e0588-3a2d-11e9-9b3e-000d3a2390ff,ResourceVersion:68328,Generation:1,CreationTimestamp:2019-02-27 01:14:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 1079948b-3a2d-11e9-9b3e-000d3a2390ff 0xc001bd3947 0xc001bd3948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 01:14:43.628: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 27 01:14:43.628: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-gv5t6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gv5t6/replicasets/test-cleanup-controller,UID:0d7b42fd-3a2d-11e9-9b3e-000d3a2390ff,ResourceVersion:68327,Generation:1,CreationTimestamp:2019-02-27 01:14:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 1079948b-3a2d-11e9-9b3e-000d3a2390ff 0xc001bd35c7 0xc001bd35c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 01:14:43.648: INFO: Pod "test-cleanup-controller-jxgkd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-jxgkd,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-gv5t6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gv5t6/pods/test-cleanup-controller-jxgkd,UID:0d7d815a-3a2d-11e9-9b3e-000d3a2390ff,ResourceVersion:68321,Generation:0,CreationTimestamp:2019-02-27 01:14:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.1.130.233/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 0d7b42fd-3a2d-11e9-9b3e-000d3a2390ff 0xc0018ae457 0xc0018ae458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lthk5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lthk5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lthk5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ae520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ae540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:14:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:14:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:14:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:14:38 +0000 UTC  }],Message:,Reason:,HostIP:10.1.1.4,PodIP:10.1.130.233,StartTime:2019-02-27 01:14:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 01:14:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://081a98f4f5279dd899b0093b860aa840922f052b5fe6ddbd4e5e8f390f46af37}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 01:14:43.649: INFO: Pod "test-cleanup-deployment-7dbbfcf846-k6r9k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-k6r9k,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-gv5t6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gv5t6/pods/test-cleanup-deployment-7dbbfcf846-k6r9k,UID:107f1f49-3a2d-11e9-9b3e-000d3a2390ff,ResourceVersion:68332,Generation:0,CreationTimestamp:2019-02-27 01:14:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 107e0588-3a2d-11e9-9b3e-000d3a2390ff 0xc0018ae667 0xc0018ae668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lthk5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lthk5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lthk5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9cy76-worker-000000,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ae6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ae8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:14:43 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:14:43.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gv5t6" for this suite.
Feb 27 01:14:49.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:14:49.785: INFO: namespace: e2e-tests-deployment-gv5t6, resource: bindings, ignored listing per whitelist
Feb 27 01:14:49.795: INFO: namespace e2e-tests-deployment-gv5t6 deletion completed in 6.135491941s

• [SLOW TEST:11.451 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:14:49.801: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ffj5r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:14:50.038: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1450e8eb-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-ffj5r" to be "success or failure"
Feb 27 01:14:50.050: INFO: Pod "downwardapi-volume-1450e8eb-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 11.186169ms
Feb 27 01:14:52.053: INFO: Pod "downwardapi-volume-1450e8eb-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014203619s
STEP: Saw pod success
Feb 27 01:14:52.053: INFO: Pod "downwardapi-volume-1450e8eb-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:14:52.055: INFO: Trying to get logs from node 9cy76-worker-000001 pod downwardapi-volume-1450e8eb-3a2d-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 01:14:52.074: INFO: Waiting for pod downwardapi-volume-1450e8eb-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:14:52.092: INFO: Pod downwardapi-volume-1450e8eb-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:14:52.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ffj5r" for this suite.
Feb 27 01:14:58.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:14:58.176: INFO: namespace: e2e-tests-projected-ffj5r, resource: bindings, ignored listing per whitelist
Feb 27 01:14:58.244: INFO: namespace e2e-tests-projected-ffj5r deletion completed in 6.147567326s

• [SLOW TEST:8.444 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:14:58.245: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-6x6kc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 27 01:14:58.464: INFO: Waiting up to 5m0s for pod "var-expansion-19561014-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-var-expansion-6x6kc" to be "success or failure"
Feb 27 01:14:58.472: INFO: Pod "var-expansion-19561014-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.971536ms
Feb 27 01:15:00.477: INFO: Pod "var-expansion-19561014-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011217809s
STEP: Saw pod success
Feb 27 01:15:00.479: INFO: Pod "var-expansion-19561014-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:15:00.484: INFO: Trying to get logs from node 9cy76-worker-000000 pod var-expansion-19561014-3a2d-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 01:15:00.519: INFO: Waiting for pod var-expansion-19561014-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:15:00.534: INFO: Pod var-expansion-19561014-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:15:00.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6x6kc" for this suite.
Feb 27 01:15:06.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:15:06.670: INFO: namespace: e2e-tests-var-expansion-6x6kc, resource: bindings, ignored listing per whitelist
Feb 27 01:15:06.685: INFO: namespace e2e-tests-var-expansion-6x6kc deletion completed in 6.143331629s

• [SLOW TEST:8.440 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:15:06.686: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dqpsp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 27 01:15:06.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-dqpsp'
Feb 27 01:15:07.254: INFO: stderr: ""
Feb 27 01:15:07.254: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 01:15:08.260: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:15:08.260: INFO: Found 0 / 1
Feb 27 01:15:09.259: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:15:09.259: INFO: Found 0 / 1
Feb 27 01:15:10.259: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:15:10.259: INFO: Found 1 / 1
Feb 27 01:15:10.259: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 27 01:15:10.262: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:15:10.263: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 01:15:10.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 patch pod redis-master-pldzc --namespace=e2e-tests-kubectl-dqpsp -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 27 01:15:10.360: INFO: stderr: ""
Feb 27 01:15:10.360: INFO: stdout: "pod/redis-master-pldzc patched\n"
STEP: checking annotations
Feb 27 01:15:10.364: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:15:10.364: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:15:10.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dqpsp" for this suite.
Feb 27 01:15:32.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:15:32.419: INFO: namespace: e2e-tests-kubectl-dqpsp, resource: bindings, ignored listing per whitelist
Feb 27 01:15:32.516: INFO: namespace e2e-tests-kubectl-dqpsp deletion completed in 22.141644762s

• [SLOW TEST:25.831 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:15:32.517: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gw4v5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2dc55c3e-3a2d-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:15:32.748: INFO: Waiting up to 5m0s for pod "pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-gw4v5" to be "success or failure"
Feb 27 01:15:32.752: INFO: Pod "pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.987426ms
Feb 27 01:15:34.756: INFO: Pod "pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008497233s
Feb 27 01:15:36.761: INFO: Pod "pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01309629s
STEP: Saw pod success
Feb 27 01:15:36.761: INFO: Pod "pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:15:36.769: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:15:36.794: INFO: Waiting for pod pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:15:36.801: INFO: Pod pod-configmaps-2dc5ee38-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:15:36.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gw4v5" for this suite.
Feb 27 01:15:42.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:15:42.873: INFO: namespace: e2e-tests-configmap-gw4v5, resource: bindings, ignored listing per whitelist
Feb 27 01:15:42.953: INFO: namespace e2e-tests-configmap-gw4v5 deletion completed in 6.147581447s

• [SLOW TEST:10.436 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:15:42.953: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-kp49f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 01:15:43.166: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 01:15:43.174: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 01:15:43.176: INFO: 
Logging pods the kubelet thinks is on node 9cy76-worker-000000 before test
Feb 27 01:15:43.185: INFO: kube-proxy-kbpzq from kube-system started at 2019-02-26 14:59:45 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.185: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 01:15:43.185: INFO: external-dns-7f6b74c57f-rhd2v from kube-system started at 2019-02-26 15:03:10 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.185: INFO: 	Container external-dns ready: true, restart count 0
Feb 27 01:15:43.185: INFO: nginx-ingress-controller-5fd6d9c498-mm48v from kube-system started at 2019-02-26 15:02:48 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.185: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 01:15:43.185: INFO: default-http-backend-6c5fdb64cc-v88ph from kube-system started at 2019-02-26 15:02:48 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.185: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 01:15:43.185: INFO: cert-exporter-5hgps from kube-system started at 2019-02-26 15:02:08 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.185: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 01:15:43.185: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-26 23:53:44 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.185: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 01:15:43.185: INFO: calico-node-qd6l7 from kube-system started at 2019-02-26 14:59:18 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.186: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 01:15:43.186: INFO: coredns-7fb74c7cfc-mlmrb from kube-system started at 2019-02-26 15:02:05 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.186: INFO: 	Container coredns ready: true, restart count 0
Feb 27 01:15:43.186: INFO: sonobuoy-systemd-logs-daemon-set-d15354df4d564054-2fdhp from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 01:15:43.186: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 01:15:43.186: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 01:15:43.186: INFO: sonobuoy-e2e-job-82313ed720c94b11 from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 01:15:43.186: INFO: 	Container e2e ready: true, restart count 0
Feb 27 01:15:43.186: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 01:15:43.186: INFO: net-exporter-9p5kx from kube-system started at 2019-02-26 15:02:45 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.186: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 01:15:43.186: INFO: node-exporter-zzsmv from kube-system started at 2019-02-26 15:03:04 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.186: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 01:15:43.186: INFO: 
Logging pods the kubelet thinks is on node 9cy76-worker-000001 before test
Feb 27 01:15:43.195: INFO: default-http-backend-6c5fdb64cc-gq6kw from kube-system started at 2019-02-26 15:02:47 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 01:15:43.195: INFO: node-exporter-s9wzl from kube-system started at 2019-02-26 15:03:05 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 01:15:43.195: INFO: net-exporter-5fhjf from kube-system started at 2019-02-26 15:02:44 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 01:15:43.195: INFO: tiller-deploy-7d54987577-vw7wm from giantswarm started at 2019-02-26 15:00:37 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container tiller ready: true, restart count 0
Feb 27 01:15:43.195: INFO: nginx-ingress-controller-5fd6d9c498-9ccm2 from kube-system started at 2019-02-26 15:02:47 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 01:15:43.195: INFO: kube-proxy-hz4l8 from kube-system started at 2019-02-26 14:59:43 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 01:15:43.195: INFO: metrics-server-7fc59d6b67-2lrrx from kube-system started at 2019-02-26 15:02:40 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container metrics-server ready: true, restart count 0
Feb 27 01:15:43.195: INFO: coredns-7fb74c7cfc-bhhcg from kube-system started at 2019-02-26 15:02:05 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container coredns ready: true, restart count 0
Feb 27 01:15:43.195: INFO: kube-state-metrics-68f7795bbd-glc6h from kube-system started at 2019-02-26 15:02:48 +0000 UTC (2 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 27 01:15:43.195: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 27 01:15:43.195: INFO: sonobuoy-systemd-logs-daemon-set-d15354df4d564054-6h2mv from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 01:15:43.195: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 01:15:43.195: INFO: calico-node-7gd69 from kube-system started at 2019-02-26 14:59:18 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 01:15:43.195: INFO: cert-exporter-94f46 from kube-system started at 2019-02-26 15:02:08 +0000 UTC (1 container statuses recorded)
Feb 27 01:15:43.195: INFO: 	Container cert-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15871398b3cd25aa], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:15:44.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kp49f" for this suite.
Feb 27 01:15:50.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:15:50.278: INFO: namespace: e2e-tests-sched-pred-kp49f, resource: bindings, ignored listing per whitelist
Feb 27 01:15:50.370: INFO: namespace e2e-tests-sched-pred-kp49f deletion completed in 6.136690251s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.417 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:15:50.372: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-sst58
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-dxz4m
STEP: Creating secret with name secret-test-3868fd00-3a2d-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 01:15:50.745: INFO: Waiting up to 5m0s for pod "pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-sst58" to be "success or failure"
Feb 27 01:15:50.753: INFO: Pod "pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.480944ms
Feb 27 01:15:52.757: INFO: Pod "pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011294711s
Feb 27 01:15:54.762: INFO: Pod "pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017199423s
STEP: Saw pod success
Feb 27 01:15:54.763: INFO: Pod "pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:15:54.766: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:15:54.799: INFO: Waiting for pod pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:15:54.805: INFO: Pod pod-secrets-38806776-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:15:54.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sst58" for this suite.
Feb 27 01:16:00.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:16:00.899: INFO: namespace: e2e-tests-secrets-sst58, resource: bindings, ignored listing per whitelist
Feb 27 01:16:00.973: INFO: namespace e2e-tests-secrets-sst58 deletion completed in 6.15389176s
STEP: Destroying namespace "e2e-tests-secret-namespace-dxz4m" for this suite.
Feb 27 01:16:06.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:16:07.028: INFO: namespace: e2e-tests-secret-namespace-dxz4m, resource: bindings, ignored listing per whitelist
Feb 27 01:16:07.121: INFO: namespace e2e-tests-secret-namespace-dxz4m deletion completed in 6.148493403s

• [SLOW TEST:16.749 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:16:07.121: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-4tq5k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 27 01:16:07.371: INFO: Waiting up to 5m0s for pod "var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-var-expansion-4tq5k" to be "success or failure"
Feb 27 01:16:07.377: INFO: Pod "var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 5.795633ms
Feb 27 01:16:09.381: INFO: Pod "var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010601447s
Feb 27 01:16:11.385: INFO: Pod "var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014449142s
STEP: Saw pod success
Feb 27 01:16:11.385: INFO: Pod "var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:16:11.390: INFO: Trying to get logs from node 9cy76-worker-000000 pod var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da container dapi-container: <nil>
STEP: delete the pod
Feb 27 01:16:11.414: INFO: Waiting for pod var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:16:11.424: INFO: Pod var-expansion-42691044-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:16:11.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4tq5k" for this suite.
Feb 27 01:16:17.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:16:17.493: INFO: namespace: e2e-tests-var-expansion-4tq5k, resource: bindings, ignored listing per whitelist
Feb 27 01:16:17.571: INFO: namespace e2e-tests-var-expansion-4tq5k deletion completed in 6.142361623s

• [SLOW TEST:10.450 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:16:17.572: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sc2dw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 27 01:16:17.782: INFO: namespace e2e-tests-kubectl-sc2dw
Feb 27 01:16:17.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 create -f - --namespace=e2e-tests-kubectl-sc2dw'
Feb 27 01:16:18.108: INFO: stderr: ""
Feb 27 01:16:18.108: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 01:16:19.113: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:16:19.113: INFO: Found 0 / 1
Feb 27 01:16:20.125: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:16:20.125: INFO: Found 1 / 1
Feb 27 01:16:20.125: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 01:16:20.129: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 01:16:20.129: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 01:16:20.129: INFO: wait on redis-master startup in e2e-tests-kubectl-sc2dw 
Feb 27 01:16:20.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 logs redis-master-l9c5b redis-master --namespace=e2e-tests-kubectl-sc2dw'
Feb 27 01:16:20.223: INFO: stderr: ""
Feb 27 01:16:20.223: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 01:16:19.407 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 01:16:19.407 # Server started, Redis version 3.2.12\n1:M 27 Feb 01:16:19.407 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 01:16:19.407 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 27 01:16:20.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-sc2dw'
Feb 27 01:16:20.339: INFO: stderr: ""
Feb 27 01:16:20.339: INFO: stdout: "service/rm2 exposed\n"
Feb 27 01:16:20.346: INFO: Service rm2 in namespace e2e-tests-kubectl-sc2dw found.
STEP: exposing service
Feb 27 01:16:22.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-sc2dw'
Feb 27 01:16:22.485: INFO: stderr: ""
Feb 27 01:16:22.485: INFO: stdout: "service/rm3 exposed\n"
Feb 27 01:16:22.489: INFO: Service rm3 in namespace e2e-tests-kubectl-sc2dw found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:16:24.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sc2dw" for this suite.
Feb 27 01:16:46.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:16:46.568: INFO: namespace: e2e-tests-kubectl-sc2dw, resource: bindings, ignored listing per whitelist
Feb 27 01:16:46.698: INFO: namespace e2e-tests-kubectl-sc2dw deletion completed in 22.198790608s

• [SLOW TEST:29.126 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:16:46.699: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kj7sk
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-5a066f29-3a2d-11e9-9b83-4a9a78a986da
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:16:49.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kj7sk" for this suite.
Feb 27 01:17:11.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:17:11.150: INFO: namespace: e2e-tests-configmap-kj7sk, resource: bindings, ignored listing per whitelist
Feb 27 01:17:11.159: INFO: namespace e2e-tests-configmap-kj7sk deletion completed in 22.129323089s

• [SLOW TEST:24.460 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:17:11.159: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-g8rv5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 27 01:17:11.375: INFO: Waiting up to 5m0s for pod "client-containers-688f143f-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-containers-g8rv5" to be "success or failure"
Feb 27 01:17:11.380: INFO: Pod "client-containers-688f143f-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.880431ms
Feb 27 01:17:13.385: INFO: Pod "client-containers-688f143f-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009506135s
STEP: Saw pod success
Feb 27 01:17:13.385: INFO: Pod "client-containers-688f143f-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:17:13.390: INFO: Trying to get logs from node 9cy76-worker-000000 pod client-containers-688f143f-3a2d-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:17:13.437: INFO: Waiting for pod client-containers-688f143f-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:17:13.442: INFO: Pod client-containers-688f143f-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:17:13.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-g8rv5" for this suite.
Feb 27 01:17:19.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:17:19.537: INFO: namespace: e2e-tests-containers-g8rv5, resource: bindings, ignored listing per whitelist
Feb 27 01:17:19.597: INFO: namespace e2e-tests-containers-g8rv5 deletion completed in 6.147414378s

• [SLOW TEST:8.438 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:17:19.597: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ljcq7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 27 01:17:19.805: INFO: Waiting up to 5m0s for pod "pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-ljcq7" to be "success or failure"
Feb 27 01:17:19.810: INFO: Pod "pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.915532ms
Feb 27 01:17:21.814: INFO: Pod "pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008854986s
Feb 27 01:17:23.817: INFO: Pod "pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012285831s
STEP: Saw pod success
Feb 27 01:17:23.817: INFO: Pod "pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:17:23.820: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:17:23.842: INFO: Waiting for pod pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:17:23.845: INFO: Pod pod-6d9550d0-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:17:23.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ljcq7" for this suite.
Feb 27 01:17:29.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:17:29.931: INFO: namespace: e2e-tests-emptydir-ljcq7, resource: bindings, ignored listing per whitelist
Feb 27 01:17:30.023: INFO: namespace e2e-tests-emptydir-ljcq7 deletion completed in 6.168985284s

• [SLOW TEST:10.425 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:17:30.023: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2blrk
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-73d4bd7c-3a2d-11e9-9b83-4a9a78a986da
STEP: Creating configMap with name cm-test-opt-upd-73d4bdac-3a2d-11e9-9b83-4a9a78a986da
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-73d4bd7c-3a2d-11e9-9b83-4a9a78a986da
STEP: Updating configmap cm-test-opt-upd-73d4bdac-3a2d-11e9-9b83-4a9a78a986da
STEP: Creating configMap with name cm-test-opt-create-73d4bdbc-3a2d-11e9-9b83-4a9a78a986da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:18:46.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2blrk" for this suite.
Feb 27 01:19:08.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:19:08.833: INFO: namespace: e2e-tests-configmap-2blrk, resource: bindings, ignored listing per whitelist
Feb 27 01:19:08.914: INFO: namespace e2e-tests-configmap-2blrk deletion completed in 22.142970079s

• [SLOW TEST:98.891 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:19:08.914: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7lvfm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-aebeb1a0-3a2d-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 01:19:09.132: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-7lvfm" to be "success or failure"
Feb 27 01:19:09.136: INFO: Pod "pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.256222ms
Feb 27 01:19:11.139: INFO: Pod "pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006456861s
Feb 27 01:19:13.143: INFO: Pod "pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010349552s
STEP: Saw pod success
Feb 27 01:19:13.143: INFO: Pod "pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:19:13.146: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:19:13.170: INFO: Waiting for pod pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:19:13.176: INFO: Pod pod-projected-secrets-aebf2d47-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:19:13.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7lvfm" for this suite.
Feb 27 01:19:19.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:19:19.248: INFO: namespace: e2e-tests-projected-7lvfm, resource: bindings, ignored listing per whitelist
Feb 27 01:19:19.351: INFO: namespace e2e-tests-projected-7lvfm deletion completed in 6.166162443s

• [SLOW TEST:10.437 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:19:19.352: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-wlmjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 27 01:19:19.575: INFO: Waiting up to 5m0s for pod "client-containers-b4f96f33-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-containers-wlmjl" to be "success or failure"
Feb 27 01:19:19.583: INFO: Pod "client-containers-b4f96f33-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.073752ms
Feb 27 01:19:21.589: INFO: Pod "client-containers-b4f96f33-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014133213s
STEP: Saw pod success
Feb 27 01:19:21.589: INFO: Pod "client-containers-b4f96f33-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:19:21.592: INFO: Trying to get logs from node 9cy76-worker-000000 pod client-containers-b4f96f33-3a2d-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:19:21.631: INFO: Waiting for pod client-containers-b4f96f33-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:19:21.640: INFO: Pod client-containers-b4f96f33-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:19:21.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wlmjl" for this suite.
Feb 27 01:19:27.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:19:27.745: INFO: namespace: e2e-tests-containers-wlmjl, resource: bindings, ignored listing per whitelist
Feb 27 01:19:27.787: INFO: namespace e2e-tests-containers-wlmjl deletion completed in 6.132730511s

• [SLOW TEST:8.436 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:19:27.788: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dnzv7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 27 01:19:27.996: INFO: Waiting up to 5m0s for pod "pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-emptydir-dnzv7" to be "success or failure"
Feb 27 01:19:28.005: INFO: Pod "pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 8.73516ms
Feb 27 01:19:30.011: INFO: Pod "pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014348567s
Feb 27 01:19:32.016: INFO: Pod "pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019853582s
STEP: Saw pod success
Feb 27 01:19:32.016: INFO: Pod "pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:19:32.019: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da container test-container: <nil>
STEP: delete the pod
Feb 27 01:19:32.042: INFO: Waiting for pod pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:19:32.053: INFO: Pod pod-b9fe5a5f-3a2d-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:19:32.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dnzv7" for this suite.
Feb 27 01:19:38.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:19:38.100: INFO: namespace: e2e-tests-emptydir-dnzv7, resource: bindings, ignored listing per whitelist
Feb 27 01:19:38.220: INFO: namespace e2e-tests-emptydir-dnzv7 deletion completed in 6.153419204s

• [SLOW TEST:10.432 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:19:38.221: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7fs4s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 01:19:38.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7fs4s'
Feb 27 01:19:38.517: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 01:19:38.517: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 27 01:19:40.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-7fs4s'
Feb 27 01:19:40.621: INFO: stderr: ""
Feb 27 01:19:40.621: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:19:40.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7fs4s" for this suite.
Feb 27 01:19:46.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:19:46.675: INFO: namespace: e2e-tests-kubectl-7fs4s, resource: bindings, ignored listing per whitelist
Feb 27 01:19:46.749: INFO: namespace e2e-tests-kubectl-7fs4s deletion completed in 6.123650402s

• [SLOW TEST:8.528 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:19:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-7m86r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7m86r
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 27 01:19:46.963: INFO: Found 0 stateful pods, waiting for 3
Feb 27 01:19:56.968: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:19:56.968: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:19:56.968: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:19:56.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-7m86r ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:19:57.173: INFO: stderr: ""
Feb 27 01:19:57.173: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:19:57.173: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 27 01:20:07.214: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 27 01:20:17.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-7m86r ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:20:17.420: INFO: stderr: ""
Feb 27 01:20:17.421: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:20:17.421: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:20:27.439: INFO: Waiting for StatefulSet e2e-tests-statefulset-7m86r/ss2 to complete update
Feb 27 01:20:27.439: INFO: Waiting for Pod e2e-tests-statefulset-7m86r/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 27 01:20:27.439: INFO: Waiting for Pod e2e-tests-statefulset-7m86r/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 27 01:20:37.446: INFO: Waiting for StatefulSet e2e-tests-statefulset-7m86r/ss2 to complete update
Feb 27 01:20:37.446: INFO: Waiting for Pod e2e-tests-statefulset-7m86r/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 27 01:20:47.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-7m86r ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:20:47.631: INFO: stderr: ""
Feb 27 01:20:47.631: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:20:47.631: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:20:57.663: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 27 01:21:07.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-167492786 exec --namespace=e2e-tests-statefulset-7m86r ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:21:07.876: INFO: stderr: ""
Feb 27 01:21:07.876: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:21:07.876: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 01:21:27.897: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7m86r
Feb 27 01:21:27.900: INFO: Scaling statefulset ss2 to 0
Feb 27 01:21:57.951: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:21:57.954: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:21:57.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7m86r" for this suite.
Feb 27 01:22:03.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:22:04.080: INFO: namespace: e2e-tests-statefulset-7m86r, resource: bindings, ignored listing per whitelist
Feb 27 01:22:04.135: INFO: namespace e2e-tests-statefulset-7m86r deletion completed in 6.157601467s

• [SLOW TEST:137.385 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:22:04.136: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-549kt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-549kt/configmap-test-172eda4f-3a2e-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:22:04.360: INFO: Waiting up to 5m0s for pod "pod-configmaps-172f6c82-3a2e-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-549kt" to be "success or failure"
Feb 27 01:22:04.371: INFO: Pod "pod-configmaps-172f6c82-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 11.635576ms
Feb 27 01:22:06.376: INFO: Pod "pod-configmaps-172f6c82-3a2e-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016011619s
STEP: Saw pod success
Feb 27 01:22:06.376: INFO: Pod "pod-configmaps-172f6c82-3a2e-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:22:06.379: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-172f6c82-3a2e-11e9-9b83-4a9a78a986da container env-test: <nil>
STEP: delete the pod
Feb 27 01:22:06.409: INFO: Waiting for pod pod-configmaps-172f6c82-3a2e-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:22:06.416: INFO: Pod pod-configmaps-172f6c82-3a2e-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:22:06.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-549kt" for this suite.
Feb 27 01:22:12.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:22:12.535: INFO: namespace: e2e-tests-configmap-549kt, resource: bindings, ignored listing per whitelist
Feb 27 01:22:12.558: INFO: namespace e2e-tests-configmap-549kt deletion completed in 6.131265042s

• [SLOW TEST:8.422 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:22:12.559: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mghzk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 01:22:17.314: INFO: Successfully updated pod "annotationupdate1c33c751-3a2e-11e9-9b83-4a9a78a986da"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:22:19.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mghzk" for this suite.
Feb 27 01:22:41.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:22:41.456: INFO: namespace: e2e-tests-projected-mghzk, resource: bindings, ignored listing per whitelist
Feb 27 01:22:41.496: INFO: namespace e2e-tests-projected-mghzk deletion completed in 22.151228621s

• [SLOW TEST:28.937 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:22:41.497: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-x8cqs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-x8cqs
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-x8cqs
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-x8cqs
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-x8cqs
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-x8cqs
Feb 27 01:22:45.756: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-x8cqs, name: ss-0, uid: 2fc146a6-3a2e-11e9-9b3e-000d3a2390ff, status phase: Pending. Waiting for statefulset controller to delete.
Feb 27 01:22:46.139: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-x8cqs, name: ss-0, uid: 2fc146a6-3a2e-11e9-9b3e-000d3a2390ff, status phase: Failed. Waiting for statefulset controller to delete.
Feb 27 01:22:46.148: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-x8cqs, name: ss-0, uid: 2fc146a6-3a2e-11e9-9b3e-000d3a2390ff, status phase: Failed. Waiting for statefulset controller to delete.
Feb 27 01:22:46.156: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-x8cqs
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-x8cqs
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-x8cqs and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 01:22:48.192: INFO: Deleting all statefulset in ns e2e-tests-statefulset-x8cqs
Feb 27 01:22:48.194: INFO: Scaling statefulset ss to 0
Feb 27 01:22:58.214: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:22:58.217: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:22:58.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-x8cqs" for this suite.
Feb 27 01:23:04.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:23:04.292: INFO: namespace: e2e-tests-statefulset-x8cqs, resource: bindings, ignored listing per whitelist
Feb 27 01:23:04.365: INFO: namespace e2e-tests-statefulset-x8cqs deletion completed in 6.129553612s

• [SLOW TEST:22.868 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:23:04.365: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-knxvg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3b192b6c-3a2e-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 01:23:04.604: INFO: Waiting up to 5m0s for pod "pod-secrets-3b19db0f-3a2e-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-secrets-knxvg" to be "success or failure"
Feb 27 01:23:04.607: INFO: Pod "pod-secrets-3b19db0f-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.919419ms
Feb 27 01:23:06.612: INFO: Pod "pod-secrets-3b19db0f-3a2e-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007653286s
STEP: Saw pod success
Feb 27 01:23:06.612: INFO: Pod "pod-secrets-3b19db0f-3a2e-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:23:06.617: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-secrets-3b19db0f-3a2e-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:23:06.654: INFO: Waiting for pod pod-secrets-3b19db0f-3a2e-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:23:06.674: INFO: Pod pod-secrets-3b19db0f-3a2e-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:23:06.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-knxvg" for this suite.
Feb 27 01:23:12.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:23:12.786: INFO: namespace: e2e-tests-secrets-knxvg, resource: bindings, ignored listing per whitelist
Feb 27 01:23:12.829: INFO: namespace e2e-tests-secrets-knxvg deletion completed in 6.139447868s

• [SLOW TEST:8.464 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:23:12.830: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-w568t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 27 01:23:21.080: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.081: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:21.210: INFO: Exec stderr: ""
Feb 27 01:23:21.211: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.211: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:21.355: INFO: Exec stderr: ""
Feb 27 01:23:21.355: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.356: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:21.464: INFO: Exec stderr: ""
Feb 27 01:23:21.464: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.464: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:21.598: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 27 01:23:21.598: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.598: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:21.712: INFO: Exec stderr: ""
Feb 27 01:23:21.712: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.712: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:21.833: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 27 01:23:21.834: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.834: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:21.937: INFO: Exec stderr: ""
Feb 27 01:23:21.938: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:21.938: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:22.054: INFO: Exec stderr: ""
Feb 27 01:23:22.055: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:22.055: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:22.162: INFO: Exec stderr: ""
Feb 27 01:23:22.162: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-w568t PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:23:22.162: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:23:22.255: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:23:22.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-w568t" for this suite.
Feb 27 01:24:06.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:24:06.337: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-w568t, resource: bindings, ignored listing per whitelist
Feb 27 01:24:06.393: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-w568t deletion completed in 44.133859899s

• [SLOW TEST:53.564 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:24:06.394: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rlv7n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-6011952b-3a2e-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume secrets
Feb 27 01:24:06.638: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-projected-rlv7n" to be "success or failure"
Feb 27 01:24:06.642: INFO: Pod "pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.370921ms
Feb 27 01:24:08.646: INFO: Pod "pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008166294s
Feb 27 01:24:10.655: INFO: Pod "pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017285253s
STEP: Saw pod success
Feb 27 01:24:10.656: INFO: Pod "pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:24:10.660: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:24:10.688: INFO: Waiting for pod pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:24:10.692: INFO: Pod pod-projected-secrets-60129bbd-3a2e-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:24:10.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rlv7n" for this suite.
Feb 27 01:24:16.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:24:16.872: INFO: namespace: e2e-tests-projected-rlv7n, resource: bindings, ignored listing per whitelist
Feb 27 01:24:16.912: INFO: namespace e2e-tests-projected-rlv7n deletion completed in 6.214102195s

• [SLOW TEST:10.518 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:24:16.912: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-8jc5q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 27 01:24:25.211: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 01:24:25.220: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 01:24:27.220: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 01:24:27.224: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 01:24:29.220: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 01:24:29.225: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 01:24:31.220: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 01:24:31.224: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 01:24:33.220: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 01:24:33.226: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 01:24:35.220: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 01:24:35.224: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:24:35.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8jc5q" for this suite.
Feb 27 01:24:57.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:24:57.303: INFO: namespace: e2e-tests-container-lifecycle-hook-8jc5q, resource: bindings, ignored listing per whitelist
Feb 27 01:24:57.373: INFO: namespace e2e-tests-container-lifecycle-hook-8jc5q deletion completed in 22.144016074s

• [SLOW TEST:40.461 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:24:57.373: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cbd6z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:24:57.584: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-cbd6z" to be "success or failure"
Feb 27 01:24:57.587: INFO: Pod "downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.688616ms
Feb 27 01:24:59.592: INFO: Pod "downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008139934s
Feb 27 01:25:01.597: INFO: Pod "downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012451678s
STEP: Saw pod success
Feb 27 01:25:01.597: INFO: Pod "downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:25:01.599: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 01:25:01.625: INFO: Waiting for pod downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:25:01.638: INFO: Pod downwardapi-volume-7e71576d-3a2e-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:25:01.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cbd6z" for this suite.
Feb 27 01:25:07.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:25:07.763: INFO: namespace: e2e-tests-downward-api-cbd6z, resource: bindings, ignored listing per whitelist
Feb 27 01:25:07.772: INFO: namespace e2e-tests-downward-api-cbd6z deletion completed in 6.130515398s

• [SLOW TEST:10.399 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:25:07.773: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-f2ww9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:25:07.985: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:25:12.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f2ww9" for this suite.
Feb 27 01:25:50.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:25:50.180: INFO: namespace: e2e-tests-pods-f2ww9, resource: bindings, ignored listing per whitelist
Feb 27 01:25:50.265: INFO: namespace e2e-tests-pods-f2ww9 deletion completed in 38.133029968s

• [SLOW TEST:42.493 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:25:50.266: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-cbj2z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-cbj2z/configmap-test-9df9546d-3a2e-11e9-9b83-4a9a78a986da
STEP: Creating a pod to test consume configMaps
Feb 27 01:25:50.488: INFO: Waiting up to 5m0s for pod "pod-configmaps-9dfa1599-3a2e-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-configmap-cbj2z" to be "success or failure"
Feb 27 01:25:50.495: INFO: Pod "pod-configmaps-9dfa1599-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.319039ms
Feb 27 01:25:52.498: INFO: Pod "pod-configmaps-9dfa1599-3a2e-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009647573s
STEP: Saw pod success
Feb 27 01:25:52.498: INFO: Pod "pod-configmaps-9dfa1599-3a2e-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:25:52.501: INFO: Trying to get logs from node 9cy76-worker-000000 pod pod-configmaps-9dfa1599-3a2e-11e9-9b83-4a9a78a986da container env-test: <nil>
STEP: delete the pod
Feb 27 01:25:52.520: INFO: Waiting for pod pod-configmaps-9dfa1599-3a2e-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:25:52.526: INFO: Pod pod-configmaps-9dfa1599-3a2e-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:25:52.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cbj2z" for this suite.
Feb 27 01:25:58.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:25:58.607: INFO: namespace: e2e-tests-configmap-cbj2z, resource: bindings, ignored listing per whitelist
Feb 27 01:25:58.675: INFO: namespace e2e-tests-configmap-cbj2z deletion completed in 6.142752328s

• [SLOW TEST:8.409 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:25:58.676: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-bg9mp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:25:58.960: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da" in namespace "e2e-tests-downward-api-bg9mp" to be "success or failure"
Feb 27 01:25:58.967: INFO: Pod "downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 7.66915ms
Feb 27 01:26:00.971: INFO: Pod "downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011391158s
Feb 27 01:26:02.975: INFO: Pod "downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015568116s
STEP: Saw pod success
Feb 27 01:26:02.975: INFO: Pod "downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da" satisfied condition "success or failure"
Feb 27 01:26:02.979: INFO: Trying to get logs from node 9cy76-worker-000000 pod downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da container client-container: <nil>
STEP: delete the pod
Feb 27 01:26:03.005: INFO: Waiting for pod downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da to disappear
Feb 27 01:26:03.008: INFO: Pod downwardapi-volume-a306028d-3a2e-11e9-9b83-4a9a78a986da no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:26:03.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bg9mp" for this suite.
Feb 27 01:26:09.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:26:09.071: INFO: namespace: e2e-tests-downward-api-bg9mp, resource: bindings, ignored listing per whitelist
Feb 27 01:26:09.156: INFO: namespace e2e-tests-downward-api-bg9mp deletion completed in 6.135143798s

• [SLOW TEST:10.480 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:26:09.156: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-pjt4s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-pjt4s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 01:26:09.365: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 01:26:29.458: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.130.23:8080/dial?request=hostName&protocol=http&host=10.1.129.84&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-pjt4s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:26:29.458: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:26:29.585: INFO: Waiting for endpoints: map[]
Feb 27 01:26:29.588: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.130.23:8080/dial?request=hostName&protocol=http&host=10.1.130.22&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-pjt4s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:26:29.588: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
Feb 27 01:26:29.713: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:26:29.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-pjt4s" for this suite.
Feb 27 01:26:51.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:26:51.821: INFO: namespace: e2e-tests-pod-network-test-pjt4s, resource: bindings, ignored listing per whitelist
Feb 27 01:26:51.881: INFO: namespace e2e-tests-pod-network-test-pjt4s deletion completed in 22.156092549s

• [SLOW TEST:42.725 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:26:51.882: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-sdwml
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0227 01:27:22.642439      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 01:27:22.642: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:27:22.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sdwml" for this suite.
Feb 27 01:27:28.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:27:28.701: INFO: namespace: e2e-tests-gc-sdwml, resource: bindings, ignored listing per whitelist
Feb 27 01:27:28.835: INFO: namespace e2e-tests-gc-sdwml deletion completed in 6.188178008s

• [SLOW TEST:36.953 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:27:28.836: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-6zzww
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 01:27:29.146: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 01:27:29.153: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 01:27:29.155: INFO: 
Logging pods the kubelet thinks is on node 9cy76-worker-000000 before test
Feb 27 01:27:29.164: INFO: calico-node-qd6l7 from kube-system started at 2019-02-26 14:59:18 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.164: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 01:27:29.164: INFO: coredns-7fb74c7cfc-mlmrb from kube-system started at 2019-02-26 15:02:05 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.164: INFO: 	Container coredns ready: true, restart count 0
Feb 27 01:27:29.164: INFO: sonobuoy-systemd-logs-daemon-set-d15354df4d564054-2fdhp from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 01:27:29.164: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 01:27:29.165: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 01:27:29.165: INFO: sonobuoy-e2e-job-82313ed720c94b11 from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 01:27:29.165: INFO: 	Container e2e ready: true, restart count 0
Feb 27 01:27:29.165: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 01:27:29.165: INFO: net-exporter-9p5kx from kube-system started at 2019-02-26 15:02:45 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.166: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 01:27:29.166: INFO: node-exporter-zzsmv from kube-system started at 2019-02-26 15:03:04 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.166: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 01:27:29.167: INFO: kube-proxy-kbpzq from kube-system started at 2019-02-26 14:59:45 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.167: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 01:27:29.167: INFO: external-dns-7f6b74c57f-rhd2v from kube-system started at 2019-02-26 15:03:10 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.167: INFO: 	Container external-dns ready: true, restart count 0
Feb 27 01:27:29.167: INFO: cert-exporter-5hgps from kube-system started at 2019-02-26 15:02:08 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.168: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 01:27:29.168: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-26 23:53:44 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.168: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 01:27:29.168: INFO: nginx-ingress-controller-5fd6d9c498-mm48v from kube-system started at 2019-02-26 15:02:48 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.168: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 01:27:29.169: INFO: default-http-backend-6c5fdb64cc-v88ph from kube-system started at 2019-02-26 15:02:48 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.169: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 01:27:29.169: INFO: 
Logging pods the kubelet thinks is on node 9cy76-worker-000001 before test
Feb 27 01:27:29.233: INFO: coredns-7fb74c7cfc-bhhcg from kube-system started at 2019-02-26 15:02:05 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.234: INFO: 	Container coredns ready: true, restart count 0
Feb 27 01:27:29.234: INFO: kube-state-metrics-68f7795bbd-glc6h from kube-system started at 2019-02-26 15:02:48 +0000 UTC (2 container statuses recorded)
Feb 27 01:27:29.234: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 27 01:27:29.235: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 27 01:27:29.236: INFO: calico-node-7gd69 from kube-system started at 2019-02-26 14:59:18 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.236: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 01:27:29.236: INFO: cert-exporter-94f46 from kube-system started at 2019-02-26 15:02:08 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.237: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 01:27:29.237: INFO: sonobuoy-systemd-logs-daemon-set-d15354df4d564054-6h2mv from heptio-sonobuoy started at 2019-02-26 23:53:51 +0000 UTC (2 container statuses recorded)
Feb 27 01:27:29.238: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 01:27:29.238: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 01:27:29.238: INFO: default-http-backend-6c5fdb64cc-gq6kw from kube-system started at 2019-02-26 15:02:47 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.238: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 01:27:29.239: INFO: node-exporter-s9wzl from kube-system started at 2019-02-26 15:03:05 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.239: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 01:27:29.240: INFO: net-exporter-5fhjf from kube-system started at 2019-02-26 15:02:44 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.240: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 01:27:29.240: INFO: tiller-deploy-7d54987577-vw7wm from giantswarm started at 2019-02-26 15:00:37 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.241: INFO: 	Container tiller ready: true, restart count 0
Feb 27 01:27:29.241: INFO: kube-proxy-hz4l8 from kube-system started at 2019-02-26 14:59:43 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.241: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 01:27:29.244: INFO: metrics-server-7fc59d6b67-2lrrx from kube-system started at 2019-02-26 15:02:40 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.244: INFO: 	Container metrics-server ready: true, restart count 0
Feb 27 01:27:29.244: INFO: nginx-ingress-controller-5fd6d9c498-9ccm2 from kube-system started at 2019-02-26 15:02:47 +0000 UTC (1 container statuses recorded)
Feb 27 01:27:29.244: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-da121419-3a2e-11e9-9b83-4a9a78a986da 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-da121419-3a2e-11e9-9b83-4a9a78a986da off the node 9cy76-worker-000000
STEP: verifying the node doesn't have the label kubernetes.io/e2e-da121419-3a2e-11e9-9b83-4a9a78a986da
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:27:35.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6zzww" for this suite.
Feb 27 01:27:43.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:27:43.473: INFO: namespace: e2e-tests-sched-pred-6zzww, resource: bindings, ignored listing per whitelist
Feb 27 01:27:43.515: INFO: namespace e2e-tests-sched-pred-6zzww deletion completed in 8.147377043s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.680 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:27:43.516: INFO: >>> kubeConfig: /tmp/kubeconfig-167492786
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-kptzn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 27 01:27:45.755: INFO: Pod pod-hostip-e17b3f42-3a2e-11e9-9b83-4a9a78a986da has hostIP: 10.1.1.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:27:45.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kptzn" for this suite.
Feb 27 01:28:07.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:28:07.856: INFO: namespace: e2e-tests-pods-kptzn, resource: bindings, ignored listing per whitelist
Feb 27 01:28:07.903: INFO: namespace e2e-tests-pods-kptzn deletion completed in 22.145280686s

• [SLOW TEST:24.388 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSFeb 27 01:28:07.904: INFO: Running AfterSuite actions on all nodes
Feb 27 01:28:07.904: INFO: Running AfterSuite actions on node 1
Feb 27 01:28:07.904: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5584.038 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h33m4.941652428s
Test Suite Passed
