I0227 01:40:37.076613      19 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-766965386
I0227 01:40:37.076685      19 e2e.go:224] Starting e2e run "ae26e338-3a30-11e9-853a-328ab8481bb7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551231636 - Will randomize all specs
Will run 201 of 1946 specs

Feb 27 01:40:37.220: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:40:37.223: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 27 01:40:37.233: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 27 01:40:37.283: INFO: 28 / 28 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 27 01:40:37.283: INFO: expected 10 pod replicas in namespace 'kube-system', 10 are Running and Ready.
Feb 27 01:40:37.283: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 27 01:40:37.297: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 27 01:40:37.297: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cert-exporter' (0 seconds elapsed)
Feb 27 01:40:37.297: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 27 01:40:37.297: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'net-exporter' (0 seconds elapsed)
Feb 27 01:40:37.297: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Feb 27 01:40:37.297: INFO: e2e test version: v1.13.0
Feb 27 01:40:37.298: INFO: kube-apiserver version: v1.13.3
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:40:37.302: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
Feb 27 01:40:37.394: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 27 01:40:37.405: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-77684
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 01:40:42.064: INFO: Successfully updated pod "labelsupdateaeb20cad-3a30-11e9-853a-328ab8481bb7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:40:44.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-77684" for this suite.
Feb 27 01:41:06.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:41:06.123: INFO: namespace: e2e-tests-downward-api-77684, resource: bindings, ignored listing per whitelist
Feb 27 01:41:06.166: INFO: namespace e2e-tests-downward-api-77684 deletion completed in 22.080318268s

• [SLOW TEST:28.864 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:41:06.168: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-crq59
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 27 01:41:06.367: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-crq59,SelfLink:/api/v1/namespaces/e2e-tests-watch-crq59/configmaps/e2e-watch-test-resource-version,UID:bfe2d00c-3a30-11e9-bb22-deadbe9ffdf9,ResourceVersion:11117,Generation:0,CreationTimestamp:2019-02-27 01:41:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 01:41:06.368: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-crq59,SelfLink:/api/v1/namespaces/e2e-tests-watch-crq59/configmaps/e2e-watch-test-resource-version,UID:bfe2d00c-3a30-11e9-bb22-deadbe9ffdf9,ResourceVersion:11118,Generation:0,CreationTimestamp:2019-02-27 01:41:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:41:06.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-crq59" for this suite.
Feb 27 01:41:12.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:41:12.448: INFO: namespace: e2e-tests-watch-crq59, resource: bindings, ignored listing per whitelist
Feb 27 01:41:12.452: INFO: namespace e2e-tests-watch-crq59 deletion completed in 6.081068043s

• [SLOW TEST:6.284 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:41:12.452: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-wkjcx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 01:41:12.617: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:41:18.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wkjcx" for this suite.
Feb 27 01:41:24.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:41:24.880: INFO: namespace: e2e-tests-init-container-wkjcx, resource: bindings, ignored listing per whitelist
Feb 27 01:41:24.898: INFO: namespace e2e-tests-init-container-wkjcx deletion completed in 6.093979422s

• [SLOW TEST:12.446 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:41:24.900: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-t7r96
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb 27 01:41:25.078: INFO: Waiting up to 5m0s for pod "var-expansion-cb0942e1-3a30-11e9-853a-328ab8481bb7" in namespace "e2e-tests-var-expansion-t7r96" to be "success or failure"
Feb 27 01:41:25.080: INFO: Pod "var-expansion-cb0942e1-3a30-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.164993ms
Feb 27 01:41:27.084: INFO: Pod "var-expansion-cb0942e1-3a30-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006497771s
STEP: Saw pod success
Feb 27 01:41:27.085: INFO: Pod "var-expansion-cb0942e1-3a30-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:41:27.089: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod var-expansion-cb0942e1-3a30-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 01:41:27.104: INFO: Waiting for pod var-expansion-cb0942e1-3a30-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:41:27.109: INFO: Pod var-expansion-cb0942e1-3a30-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:41:27.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-t7r96" for this suite.
Feb 27 01:41:33.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:41:33.177: INFO: namespace: e2e-tests-var-expansion-t7r96, resource: bindings, ignored listing per whitelist
Feb 27 01:41:33.194: INFO: namespace e2e-tests-var-expansion-t7r96 deletion completed in 6.083327708s

• [SLOW TEST:8.295 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:41:33.195: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bvd8t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-cffa76a5-3a30-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 01:41:33.374: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cffaee5c-3a30-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-bvd8t" to be "success or failure"
Feb 27 01:41:33.376: INFO: Pod "pod-projected-configmaps-cffaee5c-3a30-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.406196ms
Feb 27 01:41:35.379: INFO: Pod "pod-projected-configmaps-cffaee5c-3a30-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005262225s
STEP: Saw pod success
Feb 27 01:41:35.379: INFO: Pod "pod-projected-configmaps-cffaee5c-3a30-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:41:35.381: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-configmaps-cffaee5c-3a30-11e9-853a-328ab8481bb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:41:35.394: INFO: Waiting for pod pod-projected-configmaps-cffaee5c-3a30-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:41:35.396: INFO: Pod pod-projected-configmaps-cffaee5c-3a30-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:41:35.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bvd8t" for this suite.
Feb 27 01:41:41.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:41:41.426: INFO: namespace: e2e-tests-projected-bvd8t, resource: bindings, ignored listing per whitelist
Feb 27 01:41:41.502: INFO: namespace e2e-tests-projected-bvd8t deletion completed in 6.103888675s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:41:41.502: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9px6x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d4ee4038-3a30-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 01:41:41.681: INFO: Waiting up to 5m0s for pod "pod-configmaps-d4eece24-3a30-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-9px6x" to be "success or failure"
Feb 27 01:41:41.684: INFO: Pod "pod-configmaps-d4eece24-3a30-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.664701ms
Feb 27 01:41:43.687: INFO: Pod "pod-configmaps-d4eece24-3a30-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005502648s
STEP: Saw pod success
Feb 27 01:41:43.687: INFO: Pod "pod-configmaps-d4eece24-3a30-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:41:43.689: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-d4eece24-3a30-11e9-853a-328ab8481bb7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:41:43.704: INFO: Waiting for pod pod-configmaps-d4eece24-3a30-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:41:43.706: INFO: Pod pod-configmaps-d4eece24-3a30-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:41:43.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9px6x" for this suite.
Feb 27 01:41:49.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:41:49.770: INFO: namespace: e2e-tests-configmap-9px6x, resource: bindings, ignored listing per whitelist
Feb 27 01:41:49.793: INFO: namespace e2e-tests-configmap-9px6x deletion completed in 6.084906265s

• [SLOW TEST:8.290 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:41:49.793: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-px6f6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:41:49.964: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 27 01:41:49.970: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 27 01:41:54.975: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 01:41:54.975: INFO: Creating deployment "test-rolling-update-deployment"
Feb 27 01:41:54.978: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 27 01:41:54.983: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 27 01:41:56.989: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 27 01:41:56.991: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686828515, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686828515, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686828515, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686828515, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 01:41:58.995: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 01:41:59.004: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-px6f6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-px6f6/deployments/test-rolling-update-deployment,UID:dcdea63a-3a30-11e9-bb22-deadbe9ffdf9,ResourceVersion:11414,Generation:1,CreationTimestamp:2019-02-27 01:41:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-27 01:41:55 +0000 UTC 2019-02-27 01:41:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-27 01:41:57 +0000 UTC 2019-02-27 01:41:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 27 01:41:59.006: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-px6f6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-px6f6/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:dce1178a-3a30-11e9-bb22-deadbe9ffdf9,ResourceVersion:11405,Generation:1,CreationTimestamp:2019-02-27 01:41:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment dcdea63a-3a30-11e9-bb22-deadbe9ffdf9 0xc001bb3c07 0xc001bb3c08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 01:41:59.006: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 27 01:41:59.006: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-px6f6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-px6f6/replicasets/test-rolling-update-controller,UID:d9e21eda-3a30-11e9-bb22-deadbe9ffdf9,ResourceVersion:11413,Generation:2,CreationTimestamp:2019-02-27 01:41:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment dcdea63a-3a30-11e9-bb22-deadbe9ffdf9 0xc001bb3b47 0xc001bb3b48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 01:41:59.009: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-5t9jd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-5t9jd,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-px6f6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-px6f6/pods/test-rolling-update-deployment-68b55d7bc6-5t9jd,UID:dce1a349-3a30-11e9-bb22-deadbe9ffdf9,ResourceVersion:11404,Generation:0,CreationTimestamp:2019-02-27 01:41:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 dce1178a-3a30-11e9-bb22-deadbe9ffdf9 0xc001d784e7 0xc001d784e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nzbjn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nzbjn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nzbjn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d78550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d78570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:41:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:41:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:41:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 01:41:55 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:192.168.45.73,StartTime:2019-02-27 01:41:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-27 01:41:57 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://ad314bf3c1ba804852a0aa97bbaadc01854463897008755144f33c4b1fc3b3fb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:41:59.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-px6f6" for this suite.
Feb 27 01:42:05.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:42:05.066: INFO: namespace: e2e-tests-deployment-px6f6, resource: bindings, ignored listing per whitelist
Feb 27 01:42:05.102: INFO: namespace e2e-tests-deployment-px6f6 deletion completed in 6.09039569s

• [SLOW TEST:15.309 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:42:05.104: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hj98r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:42:05.281: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2ffafe8-3a30-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-hj98r" to be "success or failure"
Feb 27 01:42:05.284: INFO: Pod "downwardapi-volume-e2ffafe8-3a30-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.466304ms
Feb 27 01:42:07.291: INFO: Pod "downwardapi-volume-e2ffafe8-3a30-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009954329s
STEP: Saw pod success
Feb 27 01:42:07.291: INFO: Pod "downwardapi-volume-e2ffafe8-3a30-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:42:07.293: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-e2ffafe8-3a30-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 01:42:07.315: INFO: Waiting for pod downwardapi-volume-e2ffafe8-3a30-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:42:07.323: INFO: Pod downwardapi-volume-e2ffafe8-3a30-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:42:07.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hj98r" for this suite.
Feb 27 01:42:13.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:42:13.365: INFO: namespace: e2e-tests-downward-api-hj98r, resource: bindings, ignored listing per whitelist
Feb 27 01:42:13.434: INFO: namespace e2e-tests-downward-api-hj98r deletion completed in 6.099001994s

• [SLOW TEST:8.330 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:42:13.434: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bd67c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e7f69567-3a30-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 01:42:13.615: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e7f71765-3a30-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-bd67c" to be "success or failure"
Feb 27 01:42:13.620: INFO: Pod "pod-projected-secrets-e7f71765-3a30-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.517774ms
Feb 27 01:42:15.623: INFO: Pod "pod-projected-secrets-e7f71765-3a30-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008705374s
STEP: Saw pod success
Feb 27 01:42:15.624: INFO: Pod "pod-projected-secrets-e7f71765-3a30-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:42:15.626: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-secrets-e7f71765-3a30-11e9-853a-328ab8481bb7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:42:15.639: INFO: Waiting for pod pod-projected-secrets-e7f71765-3a30-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:42:15.641: INFO: Pod pod-projected-secrets-e7f71765-3a30-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:42:15.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bd67c" for this suite.
Feb 27 01:42:21.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:42:21.693: INFO: namespace: e2e-tests-projected-bd67c, resource: bindings, ignored listing per whitelist
Feb 27 01:42:21.743: INFO: namespace e2e-tests-projected-bd67c deletion completed in 6.098981474s

• [SLOW TEST:8.309 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:42:21.743: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nxncv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 01:42:21.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nxncv'
Feb 27 01:42:22.104: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 01:42:22.104: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 27 01:42:22.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-nxncv'
Feb 27 01:42:22.199: INFO: stderr: ""
Feb 27 01:42:22.199: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:42:22.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nxncv" for this suite.
Feb 27 01:42:44.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:42:44.298: INFO: namespace: e2e-tests-kubectl-nxncv, resource: bindings, ignored listing per whitelist
Feb 27 01:42:44.302: INFO: namespace e2e-tests-kubectl-nxncv deletion completed in 22.097438848s

• [SLOW TEST:22.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:42:44.304: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-bfrzl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:42:53.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bfrzl" for this suite.
Feb 27 01:43:15.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:43:15.557: INFO: namespace: e2e-tests-replication-controller-bfrzl, resource: bindings, ignored listing per whitelist
Feb 27 01:43:15.596: INFO: namespace e2e-tests-replication-controller-bfrzl deletion completed in 22.09548266s

• [SLOW TEST:31.292 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:43:15.597: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2sd5d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-0d041ae9-3a31-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 01:43:15.776: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0d0473b6-3a31-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-2sd5d" to be "success or failure"
Feb 27 01:43:15.778: INFO: Pod "pod-projected-secrets-0d0473b6-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004685ms
Feb 27 01:43:17.782: INFO: Pod "pod-projected-secrets-0d0473b6-3a31-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005468901s
STEP: Saw pod success
Feb 27 01:43:17.782: INFO: Pod "pod-projected-secrets-0d0473b6-3a31-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:43:17.784: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-secrets-0d0473b6-3a31-11e9-853a-328ab8481bb7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:43:17.799: INFO: Waiting for pod pod-projected-secrets-0d0473b6-3a31-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:43:17.802: INFO: Pod pod-projected-secrets-0d0473b6-3a31-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:43:17.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2sd5d" for this suite.
Feb 27 01:43:23.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:43:23.856: INFO: namespace: e2e-tests-projected-2sd5d, resource: bindings, ignored listing per whitelist
Feb 27 01:43:23.886: INFO: namespace e2e-tests-projected-2sd5d deletion completed in 6.07982817s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:43:23.887: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-fxfxb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 27 01:43:24.059: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 27 01:43:29.062: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:43:30.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-fxfxb" for this suite.
Feb 27 01:43:36.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:43:36.150: INFO: namespace: e2e-tests-replication-controller-fxfxb, resource: bindings, ignored listing per whitelist
Feb 27 01:43:36.155: INFO: namespace e2e-tests-replication-controller-fxfxb deletion completed in 6.079045663s

• [SLOW TEST:12.268 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:43:36.155: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-6gpql
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:43:36.346: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 27 01:43:36.352: INFO: Number of nodes with available pods: 0
Feb 27 01:43:36.352: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 27 01:43:36.374: INFO: Number of nodes with available pods: 0
Feb 27 01:43:36.374: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:37.378: INFO: Number of nodes with available pods: 0
Feb 27 01:43:37.378: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:38.377: INFO: Number of nodes with available pods: 0
Feb 27 01:43:38.377: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:39.378: INFO: Number of nodes with available pods: 1
Feb 27 01:43:39.378: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 27 01:43:39.389: INFO: Number of nodes with available pods: 1
Feb 27 01:43:39.389: INFO: Number of running nodes: 0, number of available pods: 1
Feb 27 01:43:40.392: INFO: Number of nodes with available pods: 0
Feb 27 01:43:40.392: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 27 01:43:40.400: INFO: Number of nodes with available pods: 0
Feb 27 01:43:40.400: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:41.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:41.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:42.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:42.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:43.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:43.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:44.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:44.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:45.403: INFO: Number of nodes with available pods: 0
Feb 27 01:43:45.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:46.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:46.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:47.403: INFO: Number of nodes with available pods: 0
Feb 27 01:43:47.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:48.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:48.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:49.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:49.405: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:50.403: INFO: Number of nodes with available pods: 0
Feb 27 01:43:50.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:51.407: INFO: Number of nodes with available pods: 0
Feb 27 01:43:51.407: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:52.403: INFO: Number of nodes with available pods: 0
Feb 27 01:43:52.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:53.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:53.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:54.403: INFO: Number of nodes with available pods: 0
Feb 27 01:43:54.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:55.403: INFO: Number of nodes with available pods: 0
Feb 27 01:43:55.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:56.405: INFO: Number of nodes with available pods: 0
Feb 27 01:43:56.405: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:57.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:57.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:58.405: INFO: Number of nodes with available pods: 0
Feb 27 01:43:58.405: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:43:59.404: INFO: Number of nodes with available pods: 0
Feb 27 01:43:59.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:00.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:00.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:01.403: INFO: Number of nodes with available pods: 0
Feb 27 01:44:01.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:02.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:02.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:03.403: INFO: Number of nodes with available pods: 0
Feb 27 01:44:03.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:04.403: INFO: Number of nodes with available pods: 0
Feb 27 01:44:04.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:05.403: INFO: Number of nodes with available pods: 0
Feb 27 01:44:05.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:06.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:06.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:07.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:07.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:08.403: INFO: Number of nodes with available pods: 0
Feb 27 01:44:08.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:09.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:09.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:10.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:10.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:11.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:11.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:12.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:12.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:13.403: INFO: Number of nodes with available pods: 0
Feb 27 01:44:13.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:14.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:14.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:15.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:15.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:16.405: INFO: Number of nodes with available pods: 0
Feb 27 01:44:16.405: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:17.404: INFO: Number of nodes with available pods: 0
Feb 27 01:44:17.404: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:18.403: INFO: Number of nodes with available pods: 0
Feb 27 01:44:18.403: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 01:44:19.404: INFO: Number of nodes with available pods: 1
Feb 27 01:44:19.404: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-6gpql, will wait for the garbage collector to delete the pods
Feb 27 01:44:19.465: INFO: Deleting DaemonSet.extensions daemon-set took: 4.140291ms
Feb 27 01:44:19.566: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.272763ms
Feb 27 01:44:53.768: INFO: Number of nodes with available pods: 0
Feb 27 01:44:53.768: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 01:44:53.771: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6gpql/daemonsets","resourceVersion":"12029"},"items":null}

Feb 27 01:44:53.773: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6gpql/pods","resourceVersion":"12029"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:44:53.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6gpql" for this suite.
Feb 27 01:44:59.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:44:59.880: INFO: namespace: e2e-tests-daemonsets-6gpql, resource: bindings, ignored listing per whitelist
Feb 27 01:44:59.896: INFO: namespace e2e-tests-daemonsets-6gpql deletion completed in 6.109711733s

• [SLOW TEST:83.741 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:44:59.897: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-242hz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-4b2fd0df-3a31-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 01:45:00.082: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4b30282a-3a31-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-242hz" to be "success or failure"
Feb 27 01:45:00.088: INFO: Pod "pod-projected-secrets-4b30282a-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.120884ms
Feb 27 01:45:02.091: INFO: Pod "pod-projected-secrets-4b30282a-3a31-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009012521s
STEP: Saw pod success
Feb 27 01:45:02.091: INFO: Pod "pod-projected-secrets-4b30282a-3a31-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:45:02.094: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-secrets-4b30282a-3a31-11e9-853a-328ab8481bb7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:45:02.110: INFO: Waiting for pod pod-projected-secrets-4b30282a-3a31-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:45:02.114: INFO: Pod pod-projected-secrets-4b30282a-3a31-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:45:02.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-242hz" for this suite.
Feb 27 01:45:08.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:45:08.206: INFO: namespace: e2e-tests-projected-242hz, resource: bindings, ignored listing per whitelist
Feb 27 01:45:08.225: INFO: namespace e2e-tests-projected-242hz deletion completed in 6.108044099s

• [SLOW TEST:8.328 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:45:08.226: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-n7lt4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5026164b-3a31-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 01:45:08.408: INFO: Waiting up to 5m0s for pod "pod-secrets-502687cb-3a31-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-n7lt4" to be "success or failure"
Feb 27 01:45:08.418: INFO: Pod "pod-secrets-502687cb-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.031418ms
Feb 27 01:45:10.422: INFO: Pod "pod-secrets-502687cb-3a31-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013548346s
STEP: Saw pod success
Feb 27 01:45:10.422: INFO: Pod "pod-secrets-502687cb-3a31-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:45:10.426: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-502687cb-3a31-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:45:10.439: INFO: Waiting for pod pod-secrets-502687cb-3a31-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:45:10.442: INFO: Pod pod-secrets-502687cb-3a31-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:45:10.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n7lt4" for this suite.
Feb 27 01:45:16.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:45:16.472: INFO: namespace: e2e-tests-secrets-n7lt4, resource: bindings, ignored listing per whitelist
Feb 27 01:45:16.532: INFO: namespace e2e-tests-secrets-n7lt4 deletion completed in 6.087783865s

• [SLOW TEST:8.307 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:45:16.533: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-5z787
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:45:20.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-5z787" for this suite.
Feb 27 01:45:26.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:45:26.811: INFO: namespace: e2e-tests-emptydir-wrapper-5z787, resource: bindings, ignored listing per whitelist
Feb 27 01:45:26.845: INFO: namespace e2e-tests-emptydir-wrapper-5z787 deletion completed in 6.078395819s

• [SLOW TEST:10.312 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:45:26.845: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-srh9t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:45:27.027: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b3f2a1f-3a31-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-srh9t" to be "success or failure"
Feb 27 01:45:27.035: INFO: Pod "downwardapi-volume-5b3f2a1f-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.212592ms
Feb 27 01:45:29.038: INFO: Pod "downwardapi-volume-5b3f2a1f-3a31-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011835979s
STEP: Saw pod success
Feb 27 01:45:29.039: INFO: Pod "downwardapi-volume-5b3f2a1f-3a31-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:45:29.041: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-5b3f2a1f-3a31-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 01:45:29.055: INFO: Waiting for pod downwardapi-volume-5b3f2a1f-3a31-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:45:29.058: INFO: Pod downwardapi-volume-5b3f2a1f-3a31-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:45:29.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-srh9t" for this suite.
Feb 27 01:45:35.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:45:35.129: INFO: namespace: e2e-tests-projected-srh9t, resource: bindings, ignored listing per whitelist
Feb 27 01:45:35.152: INFO: namespace e2e-tests-projected-srh9t deletion completed in 6.091926862s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:45:35.153: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-hpnsd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-hpnsd
I0227 01:45:35.333985      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-hpnsd, replica count: 1
I0227 01:45:36.384594      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 01:45:37.384833      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 27 01:45:37.494: INFO: Created: latency-svc-mcnv2
Feb 27 01:45:37.505: INFO: Got endpoints: latency-svc-mcnv2 [20.936675ms]
Feb 27 01:45:37.520: INFO: Created: latency-svc-ddbll
Feb 27 01:45:37.520: INFO: Created: latency-svc-xg5wd
Feb 27 01:45:37.525: INFO: Got endpoints: latency-svc-xg5wd [18.967028ms]
Feb 27 01:45:37.529: INFO: Created: latency-svc-7b6dx
Feb 27 01:45:37.532: INFO: Got endpoints: latency-svc-ddbll [26.800931ms]
Feb 27 01:45:37.533: INFO: Got endpoints: latency-svc-7b6dx [26.769812ms]
Feb 27 01:45:37.538: INFO: Created: latency-svc-r5pjq
Feb 27 01:45:37.540: INFO: Got endpoints: latency-svc-r5pjq [34.253041ms]
Feb 27 01:45:37.556: INFO: Created: latency-svc-9c4v8
Feb 27 01:45:37.558: INFO: Got endpoints: latency-svc-9c4v8 [52.231378ms]
Feb 27 01:45:37.564: INFO: Created: latency-svc-s6x7v
Feb 27 01:45:37.571: INFO: Got endpoints: latency-svc-s6x7v [64.315512ms]
Feb 27 01:45:37.571: INFO: Created: latency-svc-h6hr5
Feb 27 01:45:37.578: INFO: Got endpoints: latency-svc-h6hr5 [71.825309ms]
Feb 27 01:45:37.579: INFO: Created: latency-svc-5mnwv
Feb 27 01:45:37.585: INFO: Got endpoints: latency-svc-5mnwv [78.65517ms]
Feb 27 01:45:37.585: INFO: Created: latency-svc-j5j2k
Feb 27 01:45:37.590: INFO: Got endpoints: latency-svc-j5j2k [83.565494ms]
Feb 27 01:45:37.591: INFO: Created: latency-svc-gpjst
Feb 27 01:45:37.596: INFO: Got endpoints: latency-svc-gpjst [89.937424ms]
Feb 27 01:45:37.597: INFO: Created: latency-svc-hwwzf
Feb 27 01:45:37.602: INFO: Created: latency-svc-lwhmd
Feb 27 01:45:37.608: INFO: Got endpoints: latency-svc-hwwzf [101.334381ms]
Feb 27 01:45:37.611: INFO: Created: latency-svc-mdnvz
Feb 27 01:45:37.612: INFO: Got endpoints: latency-svc-lwhmd [105.200519ms]
Feb 27 01:45:37.616: INFO: Got endpoints: latency-svc-mdnvz [109.969432ms]
Feb 27 01:45:37.617: INFO: Created: latency-svc-hk5dp
Feb 27 01:45:37.621: INFO: Created: latency-svc-rh77v
Feb 27 01:45:37.622: INFO: Got endpoints: latency-svc-hk5dp [115.477356ms]
Feb 27 01:45:37.626: INFO: Created: latency-svc-2gj44
Feb 27 01:45:37.627: INFO: Got endpoints: latency-svc-rh77v [120.474922ms]
Feb 27 01:45:37.629: INFO: Created: latency-svc-vpgqt
Feb 27 01:45:37.644: INFO: Got endpoints: latency-svc-vpgqt [111.179938ms]
Feb 27 01:45:37.644: INFO: Got endpoints: latency-svc-2gj44 [119.325166ms]
Feb 27 01:45:37.647: INFO: Created: latency-svc-vqvfr
Feb 27 01:45:37.653: INFO: Got endpoints: latency-svc-vqvfr [119.524499ms]
Feb 27 01:45:37.663: INFO: Created: latency-svc-sq82s
Feb 27 01:45:37.663: INFO: Created: latency-svc-nlfsw
Feb 27 01:45:37.663: INFO: Got endpoints: latency-svc-nlfsw [104.765306ms]
Feb 27 01:45:37.663: INFO: Got endpoints: latency-svc-sq82s [123.15904ms]
Feb 27 01:45:37.667: INFO: Created: latency-svc-srkwt
Feb 27 01:45:37.668: INFO: Created: latency-svc-hhg4q
Feb 27 01:45:37.673: INFO: Got endpoints: latency-svc-srkwt [102.405228ms]
Feb 27 01:45:37.673: INFO: Got endpoints: latency-svc-hhg4q [95.245536ms]
Feb 27 01:45:37.676: INFO: Created: latency-svc-s7b69
Feb 27 01:45:37.679: INFO: Got endpoints: latency-svc-s7b69 [94.067446ms]
Feb 27 01:45:37.682: INFO: Created: latency-svc-4b9wx
Feb 27 01:45:37.688: INFO: Got endpoints: latency-svc-4b9wx [98.005203ms]
Feb 27 01:45:37.688: INFO: Created: latency-svc-6hc2w
Feb 27 01:45:37.692: INFO: Got endpoints: latency-svc-6hc2w [95.741452ms]
Feb 27 01:45:37.693: INFO: Created: latency-svc-5d9zj
Feb 27 01:45:37.710: INFO: Created: latency-svc-w6qpp
Feb 27 01:45:37.712: INFO: Got endpoints: latency-svc-5d9zj [104.074342ms]
Feb 27 01:45:37.717: INFO: Got endpoints: latency-svc-w6qpp [105.202617ms]
Feb 27 01:45:37.720: INFO: Created: latency-svc-wxw7k
Feb 27 01:45:37.726: INFO: Got endpoints: latency-svc-wxw7k [109.460534ms]
Feb 27 01:45:37.730: INFO: Created: latency-svc-j8pdh
Feb 27 01:45:37.732: INFO: Created: latency-svc-7bznd
Feb 27 01:45:37.734: INFO: Got endpoints: latency-svc-j8pdh [111.721488ms]
Feb 27 01:45:37.741: INFO: Created: latency-svc-lqcv8
Feb 27 01:45:37.756: INFO: Got endpoints: latency-svc-7bznd [129.317097ms]
Feb 27 01:45:37.757: INFO: Got endpoints: latency-svc-lqcv8 [112.996231ms]
Feb 27 01:45:37.765: INFO: Created: latency-svc-cct79
Feb 27 01:45:37.770: INFO: Created: latency-svc-lgw9t
Feb 27 01:45:37.771: INFO: Got endpoints: latency-svc-cct79 [126.841595ms]
Feb 27 01:45:37.777: INFO: Got endpoints: latency-svc-lgw9t [124.25998ms]
Feb 27 01:45:37.781: INFO: Created: latency-svc-q7f4t
Feb 27 01:45:37.786: INFO: Created: latency-svc-hp7g9
Feb 27 01:45:37.787: INFO: Got endpoints: latency-svc-q7f4t [123.957019ms]
Feb 27 01:45:37.789: INFO: Created: latency-svc-v8295
Feb 27 01:45:37.793: INFO: Created: latency-svc-4wngv
Feb 27 01:45:37.807: INFO: Got endpoints: latency-svc-hp7g9 [139.539876ms]
Feb 27 01:45:37.810: INFO: Created: latency-svc-r4422
Feb 27 01:45:37.817: INFO: Created: latency-svc-5j55n
Feb 27 01:45:37.821: INFO: Created: latency-svc-98n7w
Feb 27 01:45:37.829: INFO: Created: latency-svc-9pjbt
Feb 27 01:45:37.832: INFO: Created: latency-svc-lbbtm
Feb 27 01:45:37.838: INFO: Created: latency-svc-dfbhh
Feb 27 01:45:37.842: INFO: Created: latency-svc-9ntzp
Feb 27 01:45:37.847: INFO: Got endpoints: latency-svc-v8295 [174.082334ms]
Feb 27 01:45:37.849: INFO: Created: latency-svc-jmd5b
Feb 27 01:45:37.852: INFO: Created: latency-svc-7r69r
Feb 27 01:45:37.870: INFO: Created: latency-svc-mkxlp
Feb 27 01:45:37.873: INFO: Created: latency-svc-5m526
Feb 27 01:45:37.878: INFO: Created: latency-svc-dpgq5
Feb 27 01:45:37.884: INFO: Created: latency-svc-2csn9
Feb 27 01:45:37.893: INFO: Created: latency-svc-7pxlq
Feb 27 01:45:37.895: INFO: Got endpoints: latency-svc-4wngv [221.375799ms]
Feb 27 01:45:37.913: INFO: Created: latency-svc-49d8v
Feb 27 01:45:37.946: INFO: Got endpoints: latency-svc-r4422 [266.448669ms]
Feb 27 01:45:37.957: INFO: Created: latency-svc-f4m88
Feb 27 01:45:37.997: INFO: Got endpoints: latency-svc-5j55n [309.152001ms]
Feb 27 01:45:38.007: INFO: Created: latency-svc-dm4zv
Feb 27 01:45:38.053: INFO: Got endpoints: latency-svc-98n7w [360.329923ms]
Feb 27 01:45:38.065: INFO: Created: latency-svc-v7lqr
Feb 27 01:45:38.107: INFO: Got endpoints: latency-svc-9pjbt [395.353925ms]
Feb 27 01:45:38.130: INFO: Created: latency-svc-4mg5w
Feb 27 01:45:38.145: INFO: Got endpoints: latency-svc-lbbtm [427.585652ms]
Feb 27 01:45:38.153: INFO: Created: latency-svc-xgqpt
Feb 27 01:45:38.199: INFO: Got endpoints: latency-svc-dfbhh [473.368796ms]
Feb 27 01:45:38.210: INFO: Created: latency-svc-j8gfn
Feb 27 01:45:38.245: INFO: Got endpoints: latency-svc-9ntzp [511.749552ms]
Feb 27 01:45:38.252: INFO: Created: latency-svc-w6zmd
Feb 27 01:45:38.300: INFO: Got endpoints: latency-svc-jmd5b [543.287404ms]
Feb 27 01:45:38.311: INFO: Created: latency-svc-nrdlx
Feb 27 01:45:38.346: INFO: Got endpoints: latency-svc-7r69r [589.05659ms]
Feb 27 01:45:38.355: INFO: Created: latency-svc-5grzd
Feb 27 01:45:38.395: INFO: Got endpoints: latency-svc-mkxlp [547.496161ms]
Feb 27 01:45:38.403: INFO: Created: latency-svc-xnzsf
Feb 27 01:45:38.454: INFO: Got endpoints: latency-svc-5m526 [683.147621ms]
Feb 27 01:45:38.462: INFO: Created: latency-svc-xkkrj
Feb 27 01:45:38.495: INFO: Got endpoints: latency-svc-dpgq5 [717.97201ms]
Feb 27 01:45:38.503: INFO: Created: latency-svc-42hj4
Feb 27 01:45:38.548: INFO: Got endpoints: latency-svc-2csn9 [760.590907ms]
Feb 27 01:45:38.560: INFO: Created: latency-svc-9ckh4
Feb 27 01:45:38.597: INFO: Got endpoints: latency-svc-7pxlq [789.616919ms]
Feb 27 01:45:38.607: INFO: Created: latency-svc-mmlpm
Feb 27 01:45:38.647: INFO: Got endpoints: latency-svc-49d8v [752.066745ms]
Feb 27 01:45:38.654: INFO: Created: latency-svc-4zwnh
Feb 27 01:45:38.694: INFO: Got endpoints: latency-svc-f4m88 [748.156563ms]
Feb 27 01:45:38.702: INFO: Created: latency-svc-xvx4h
Feb 27 01:45:38.745: INFO: Got endpoints: latency-svc-dm4zv [747.420814ms]
Feb 27 01:45:38.756: INFO: Created: latency-svc-x4p26
Feb 27 01:45:38.794: INFO: Got endpoints: latency-svc-v7lqr [741.706662ms]
Feb 27 01:45:38.802: INFO: Created: latency-svc-ctd2l
Feb 27 01:45:38.845: INFO: Got endpoints: latency-svc-4mg5w [737.882117ms]
Feb 27 01:45:38.852: INFO: Created: latency-svc-msnmj
Feb 27 01:45:38.904: INFO: Got endpoints: latency-svc-xgqpt [759.042094ms]
Feb 27 01:45:38.912: INFO: Created: latency-svc-nq4mh
Feb 27 01:45:38.946: INFO: Got endpoints: latency-svc-j8gfn [746.245938ms]
Feb 27 01:45:38.952: INFO: Created: latency-svc-b7hjf
Feb 27 01:45:38.996: INFO: Got endpoints: latency-svc-w6zmd [750.532761ms]
Feb 27 01:45:39.005: INFO: Created: latency-svc-cdx2x
Feb 27 01:45:39.045: INFO: Got endpoints: latency-svc-nrdlx [745.571779ms]
Feb 27 01:45:39.058: INFO: Created: latency-svc-5w5qt
Feb 27 01:45:39.095: INFO: Got endpoints: latency-svc-5grzd [748.585504ms]
Feb 27 01:45:39.102: INFO: Created: latency-svc-fph8f
Feb 27 01:45:39.146: INFO: Got endpoints: latency-svc-xnzsf [751.247082ms]
Feb 27 01:45:39.154: INFO: Created: latency-svc-t666q
Feb 27 01:45:39.195: INFO: Got endpoints: latency-svc-xkkrj [740.631833ms]
Feb 27 01:45:39.203: INFO: Created: latency-svc-95h49
Feb 27 01:45:39.254: INFO: Got endpoints: latency-svc-42hj4 [758.929411ms]
Feb 27 01:45:39.265: INFO: Created: latency-svc-h58qh
Feb 27 01:45:39.301: INFO: Got endpoints: latency-svc-9ckh4 [752.46299ms]
Feb 27 01:45:39.309: INFO: Created: latency-svc-8lrsl
Feb 27 01:45:39.344: INFO: Got endpoints: latency-svc-mmlpm [747.703616ms]
Feb 27 01:45:39.355: INFO: Created: latency-svc-hrhwr
Feb 27 01:45:39.395: INFO: Got endpoints: latency-svc-4zwnh [747.849287ms]
Feb 27 01:45:39.406: INFO: Created: latency-svc-cjmvc
Feb 27 01:45:39.445: INFO: Got endpoints: latency-svc-xvx4h [751.398773ms]
Feb 27 01:45:39.456: INFO: Created: latency-svc-bc9s5
Feb 27 01:45:39.496: INFO: Got endpoints: latency-svc-x4p26 [751.625611ms]
Feb 27 01:45:39.507: INFO: Created: latency-svc-mq2fl
Feb 27 01:45:39.549: INFO: Got endpoints: latency-svc-ctd2l [755.010088ms]
Feb 27 01:45:39.577: INFO: Created: latency-svc-9sglm
Feb 27 01:45:39.596: INFO: Got endpoints: latency-svc-msnmj [751.389541ms]
Feb 27 01:45:39.606: INFO: Created: latency-svc-pmzwp
Feb 27 01:45:39.647: INFO: Got endpoints: latency-svc-nq4mh [742.589584ms]
Feb 27 01:45:39.658: INFO: Created: latency-svc-jkfrk
Feb 27 01:45:39.696: INFO: Got endpoints: latency-svc-b7hjf [750.58961ms]
Feb 27 01:45:39.706: INFO: Created: latency-svc-l8wng
Feb 27 01:45:39.745: INFO: Got endpoints: latency-svc-cdx2x [749.14856ms]
Feb 27 01:45:39.755: INFO: Created: latency-svc-fk4dk
Feb 27 01:45:39.800: INFO: Got endpoints: latency-svc-5w5qt [754.979562ms]
Feb 27 01:45:39.815: INFO: Created: latency-svc-jrhjj
Feb 27 01:45:39.845: INFO: Got endpoints: latency-svc-fph8f [750.5656ms]
Feb 27 01:45:39.854: INFO: Created: latency-svc-m5wvq
Feb 27 01:45:39.897: INFO: Got endpoints: latency-svc-t666q [751.007183ms]
Feb 27 01:45:39.906: INFO: Created: latency-svc-llwzp
Feb 27 01:45:39.944: INFO: Got endpoints: latency-svc-95h49 [749.408683ms]
Feb 27 01:45:39.953: INFO: Created: latency-svc-g86xb
Feb 27 01:45:40.003: INFO: Got endpoints: latency-svc-h58qh [748.62815ms]
Feb 27 01:45:40.015: INFO: Created: latency-svc-4hsf8
Feb 27 01:45:40.044: INFO: Got endpoints: latency-svc-8lrsl [743.514863ms]
Feb 27 01:45:40.052: INFO: Created: latency-svc-9qr8p
Feb 27 01:45:40.096: INFO: Got endpoints: latency-svc-hrhwr [751.367451ms]
Feb 27 01:45:40.109: INFO: Created: latency-svc-m87wh
Feb 27 01:45:40.146: INFO: Got endpoints: latency-svc-cjmvc [750.824479ms]
Feb 27 01:45:40.152: INFO: Created: latency-svc-k4555
Feb 27 01:45:40.195: INFO: Got endpoints: latency-svc-bc9s5 [749.844031ms]
Feb 27 01:45:40.203: INFO: Created: latency-svc-x6xdw
Feb 27 01:45:40.244: INFO: Got endpoints: latency-svc-mq2fl [747.58953ms]
Feb 27 01:45:40.251: INFO: Created: latency-svc-92sr5
Feb 27 01:45:40.294: INFO: Got endpoints: latency-svc-9sglm [744.846203ms]
Feb 27 01:45:40.303: INFO: Created: latency-svc-hkvdv
Feb 27 01:45:40.345: INFO: Got endpoints: latency-svc-pmzwp [748.492772ms]
Feb 27 01:45:40.351: INFO: Created: latency-svc-w9lb5
Feb 27 01:45:40.394: INFO: Got endpoints: latency-svc-jkfrk [747.765642ms]
Feb 27 01:45:40.401: INFO: Created: latency-svc-4j4fh
Feb 27 01:45:40.445: INFO: Got endpoints: latency-svc-l8wng [748.962592ms]
Feb 27 01:45:40.453: INFO: Created: latency-svc-p2h46
Feb 27 01:45:40.495: INFO: Got endpoints: latency-svc-fk4dk [749.762529ms]
Feb 27 01:45:40.503: INFO: Created: latency-svc-w77k4
Feb 27 01:45:40.545: INFO: Got endpoints: latency-svc-jrhjj [745.015532ms]
Feb 27 01:45:40.554: INFO: Created: latency-svc-bm5js
Feb 27 01:45:40.594: INFO: Got endpoints: latency-svc-m5wvq [748.659059ms]
Feb 27 01:45:40.609: INFO: Created: latency-svc-x5xk8
Feb 27 01:45:40.645: INFO: Got endpoints: latency-svc-llwzp [747.2982ms]
Feb 27 01:45:40.652: INFO: Created: latency-svc-gnwfs
Feb 27 01:45:40.695: INFO: Got endpoints: latency-svc-g86xb [750.221148ms]
Feb 27 01:45:40.701: INFO: Created: latency-svc-kprt4
Feb 27 01:45:40.746: INFO: Got endpoints: latency-svc-4hsf8 [743.266866ms]
Feb 27 01:45:40.759: INFO: Created: latency-svc-rn224
Feb 27 01:45:40.796: INFO: Got endpoints: latency-svc-9qr8p [752.240834ms]
Feb 27 01:45:40.804: INFO: Created: latency-svc-glkr2
Feb 27 01:45:40.850: INFO: Got endpoints: latency-svc-m87wh [753.71503ms]
Feb 27 01:45:40.858: INFO: Created: latency-svc-wmvvr
Feb 27 01:45:40.895: INFO: Got endpoints: latency-svc-k4555 [749.671078ms]
Feb 27 01:45:40.904: INFO: Created: latency-svc-j8z24
Feb 27 01:45:40.952: INFO: Got endpoints: latency-svc-x6xdw [756.656059ms]
Feb 27 01:45:40.961: INFO: Created: latency-svc-bhzmd
Feb 27 01:45:40.994: INFO: Got endpoints: latency-svc-92sr5 [749.654396ms]
Feb 27 01:45:41.004: INFO: Created: latency-svc-pl78x
Feb 27 01:45:41.047: INFO: Got endpoints: latency-svc-hkvdv [752.450817ms]
Feb 27 01:45:41.062: INFO: Created: latency-svc-j5xsj
Feb 27 01:45:41.096: INFO: Got endpoints: latency-svc-w9lb5 [751.122318ms]
Feb 27 01:45:41.108: INFO: Created: latency-svc-grvcx
Feb 27 01:45:41.146: INFO: Got endpoints: latency-svc-4j4fh [751.036475ms]
Feb 27 01:45:41.153: INFO: Created: latency-svc-f8d5h
Feb 27 01:45:41.197: INFO: Got endpoints: latency-svc-p2h46 [751.425477ms]
Feb 27 01:45:41.210: INFO: Created: latency-svc-xr96d
Feb 27 01:45:41.257: INFO: Got endpoints: latency-svc-w77k4 [762.065131ms]
Feb 27 01:45:41.272: INFO: Created: latency-svc-28fxj
Feb 27 01:45:41.295: INFO: Got endpoints: latency-svc-bm5js [749.137879ms]
Feb 27 01:45:41.304: INFO: Created: latency-svc-mzfjd
Feb 27 01:45:41.347: INFO: Got endpoints: latency-svc-x5xk8 [753.097612ms]
Feb 27 01:45:41.361: INFO: Created: latency-svc-wp944
Feb 27 01:45:41.397: INFO: Got endpoints: latency-svc-gnwfs [752.093836ms]
Feb 27 01:45:41.409: INFO: Created: latency-svc-ctxn9
Feb 27 01:45:41.445: INFO: Got endpoints: latency-svc-kprt4 [749.970269ms]
Feb 27 01:45:41.459: INFO: Created: latency-svc-mmfjz
Feb 27 01:45:41.498: INFO: Got endpoints: latency-svc-rn224 [751.596169ms]
Feb 27 01:45:41.506: INFO: Created: latency-svc-kz9mw
Feb 27 01:45:41.545: INFO: Got endpoints: latency-svc-glkr2 [748.300644ms]
Feb 27 01:45:41.553: INFO: Created: latency-svc-d7w88
Feb 27 01:45:41.596: INFO: Got endpoints: latency-svc-wmvvr [746.120593ms]
Feb 27 01:45:41.605: INFO: Created: latency-svc-qdzwp
Feb 27 01:45:41.648: INFO: Got endpoints: latency-svc-j8z24 [752.708985ms]
Feb 27 01:45:41.655: INFO: Created: latency-svc-m69kf
Feb 27 01:45:41.696: INFO: Got endpoints: latency-svc-bhzmd [742.874055ms]
Feb 27 01:45:41.708: INFO: Created: latency-svc-dz6cb
Feb 27 01:45:41.745: INFO: Got endpoints: latency-svc-pl78x [750.740531ms]
Feb 27 01:45:41.753: INFO: Created: latency-svc-j6f24
Feb 27 01:45:41.798: INFO: Got endpoints: latency-svc-j5xsj [750.727275ms]
Feb 27 01:45:41.811: INFO: Created: latency-svc-vn8fg
Feb 27 01:45:41.846: INFO: Got endpoints: latency-svc-grvcx [749.403083ms]
Feb 27 01:45:41.852: INFO: Created: latency-svc-288d8
Feb 27 01:45:41.899: INFO: Got endpoints: latency-svc-f8d5h [753.341546ms]
Feb 27 01:45:41.908: INFO: Created: latency-svc-bn8ff
Feb 27 01:45:41.945: INFO: Got endpoints: latency-svc-xr96d [747.885361ms]
Feb 27 01:45:41.952: INFO: Created: latency-svc-f494t
Feb 27 01:45:41.995: INFO: Got endpoints: latency-svc-28fxj [737.261464ms]
Feb 27 01:45:42.020: INFO: Created: latency-svc-dwl2h
Feb 27 01:45:42.051: INFO: Got endpoints: latency-svc-mzfjd [755.846633ms]
Feb 27 01:45:42.060: INFO: Created: latency-svc-fwtdt
Feb 27 01:45:42.096: INFO: Got endpoints: latency-svc-wp944 [748.261676ms]
Feb 27 01:45:42.111: INFO: Created: latency-svc-5f5n2
Feb 27 01:45:42.157: INFO: Got endpoints: latency-svc-ctxn9 [760.117361ms]
Feb 27 01:45:42.190: INFO: Created: latency-svc-rgn4m
Feb 27 01:45:42.200: INFO: Got endpoints: latency-svc-mmfjz [755.13458ms]
Feb 27 01:45:42.209: INFO: Created: latency-svc-c7dr7
Feb 27 01:45:42.245: INFO: Got endpoints: latency-svc-kz9mw [747.202453ms]
Feb 27 01:45:42.252: INFO: Created: latency-svc-7zbv8
Feb 27 01:45:42.294: INFO: Got endpoints: latency-svc-d7w88 [748.88556ms]
Feb 27 01:45:42.302: INFO: Created: latency-svc-xc85r
Feb 27 01:45:42.346: INFO: Got endpoints: latency-svc-qdzwp [750.492064ms]
Feb 27 01:45:42.353: INFO: Created: latency-svc-n8jld
Feb 27 01:45:42.395: INFO: Got endpoints: latency-svc-m69kf [746.655495ms]
Feb 27 01:45:42.410: INFO: Created: latency-svc-wwckr
Feb 27 01:45:42.447: INFO: Got endpoints: latency-svc-dz6cb [750.945012ms]
Feb 27 01:45:42.454: INFO: Created: latency-svc-rwgj8
Feb 27 01:45:42.495: INFO: Got endpoints: latency-svc-j6f24 [749.819498ms]
Feb 27 01:45:42.501: INFO: Created: latency-svc-jz66g
Feb 27 01:45:42.548: INFO: Got endpoints: latency-svc-vn8fg [749.479209ms]
Feb 27 01:45:42.555: INFO: Created: latency-svc-g4fhn
Feb 27 01:45:42.597: INFO: Got endpoints: latency-svc-288d8 [751.26801ms]
Feb 27 01:45:42.606: INFO: Created: latency-svc-2h2gf
Feb 27 01:45:42.645: INFO: Got endpoints: latency-svc-bn8ff [745.993472ms]
Feb 27 01:45:42.655: INFO: Created: latency-svc-lf477
Feb 27 01:45:42.697: INFO: Got endpoints: latency-svc-f494t [752.060449ms]
Feb 27 01:45:42.711: INFO: Created: latency-svc-f6s6s
Feb 27 01:45:42.746: INFO: Got endpoints: latency-svc-dwl2h [751.051264ms]
Feb 27 01:45:42.753: INFO: Created: latency-svc-lhjjr
Feb 27 01:45:42.795: INFO: Got endpoints: latency-svc-fwtdt [744.593433ms]
Feb 27 01:45:42.803: INFO: Created: latency-svc-2cmq9
Feb 27 01:45:42.848: INFO: Got endpoints: latency-svc-5f5n2 [752.442719ms]
Feb 27 01:45:42.859: INFO: Created: latency-svc-6jjjr
Feb 27 01:45:42.895: INFO: Got endpoints: latency-svc-rgn4m [738.434655ms]
Feb 27 01:45:42.904: INFO: Created: latency-svc-7mx96
Feb 27 01:45:42.944: INFO: Got endpoints: latency-svc-c7dr7 [744.678411ms]
Feb 27 01:45:42.957: INFO: Created: latency-svc-sj6w6
Feb 27 01:45:42.995: INFO: Got endpoints: latency-svc-7zbv8 [750.054644ms]
Feb 27 01:45:43.005: INFO: Created: latency-svc-mhxj8
Feb 27 01:45:43.051: INFO: Got endpoints: latency-svc-xc85r [757.216557ms]
Feb 27 01:45:43.063: INFO: Created: latency-svc-8rptt
Feb 27 01:45:43.094: INFO: Got endpoints: latency-svc-n8jld [748.124371ms]
Feb 27 01:45:43.106: INFO: Created: latency-svc-74vq7
Feb 27 01:45:43.144: INFO: Got endpoints: latency-svc-wwckr [749.548683ms]
Feb 27 01:45:43.157: INFO: Created: latency-svc-jmlrx
Feb 27 01:45:43.199: INFO: Got endpoints: latency-svc-rwgj8 [751.956557ms]
Feb 27 01:45:43.207: INFO: Created: latency-svc-dzpvk
Feb 27 01:45:43.246: INFO: Got endpoints: latency-svc-jz66g [750.92129ms]
Feb 27 01:45:43.253: INFO: Created: latency-svc-9g42s
Feb 27 01:45:43.296: INFO: Got endpoints: latency-svc-g4fhn [748.112613ms]
Feb 27 01:45:43.303: INFO: Created: latency-svc-jtmcj
Feb 27 01:45:43.344: INFO: Got endpoints: latency-svc-2h2gf [747.414275ms]
Feb 27 01:45:43.352: INFO: Created: latency-svc-9bvht
Feb 27 01:45:43.395: INFO: Got endpoints: latency-svc-lf477 [749.889799ms]
Feb 27 01:45:43.405: INFO: Created: latency-svc-g4nzw
Feb 27 01:45:43.445: INFO: Got endpoints: latency-svc-f6s6s [745.545047ms]
Feb 27 01:45:43.453: INFO: Created: latency-svc-msgh2
Feb 27 01:45:43.502: INFO: Got endpoints: latency-svc-lhjjr [756.687492ms]
Feb 27 01:45:43.524: INFO: Created: latency-svc-4qqdr
Feb 27 01:45:43.547: INFO: Got endpoints: latency-svc-2cmq9 [751.875253ms]
Feb 27 01:45:43.557: INFO: Created: latency-svc-9vzhn
Feb 27 01:45:43.595: INFO: Got endpoints: latency-svc-6jjjr [746.421627ms]
Feb 27 01:45:43.605: INFO: Created: latency-svc-49khb
Feb 27 01:45:43.645: INFO: Got endpoints: latency-svc-7mx96 [749.48382ms]
Feb 27 01:45:43.653: INFO: Created: latency-svc-bgjcv
Feb 27 01:45:43.695: INFO: Got endpoints: latency-svc-sj6w6 [750.574746ms]
Feb 27 01:45:43.702: INFO: Created: latency-svc-rsspk
Feb 27 01:45:43.746: INFO: Got endpoints: latency-svc-mhxj8 [751.215434ms]
Feb 27 01:45:43.758: INFO: Created: latency-svc-snl59
Feb 27 01:45:43.795: INFO: Got endpoints: latency-svc-8rptt [744.123841ms]
Feb 27 01:45:43.804: INFO: Created: latency-svc-8hqrz
Feb 27 01:45:43.844: INFO: Got endpoints: latency-svc-74vq7 [749.75373ms]
Feb 27 01:45:43.854: INFO: Created: latency-svc-2q5mj
Feb 27 01:45:43.895: INFO: Got endpoints: latency-svc-jmlrx [750.094061ms]
Feb 27 01:45:43.906: INFO: Created: latency-svc-j4v5x
Feb 27 01:45:43.944: INFO: Got endpoints: latency-svc-dzpvk [744.947846ms]
Feb 27 01:45:43.957: INFO: Created: latency-svc-ds2ng
Feb 27 01:45:43.999: INFO: Got endpoints: latency-svc-9g42s [753.775693ms]
Feb 27 01:45:44.011: INFO: Created: latency-svc-kkljl
Feb 27 01:45:44.046: INFO: Got endpoints: latency-svc-jtmcj [749.552824ms]
Feb 27 01:45:44.065: INFO: Created: latency-svc-2svkp
Feb 27 01:45:44.096: INFO: Got endpoints: latency-svc-9bvht [751.911465ms]
Feb 27 01:45:44.103: INFO: Created: latency-svc-g5jnj
Feb 27 01:45:44.147: INFO: Got endpoints: latency-svc-g4nzw [751.397108ms]
Feb 27 01:45:44.155: INFO: Created: latency-svc-npmr9
Feb 27 01:45:44.194: INFO: Got endpoints: latency-svc-msgh2 [749.842785ms]
Feb 27 01:45:44.205: INFO: Created: latency-svc-8n277
Feb 27 01:45:44.245: INFO: Got endpoints: latency-svc-4qqdr [742.088183ms]
Feb 27 01:45:44.255: INFO: Created: latency-svc-l5cnn
Feb 27 01:45:44.300: INFO: Got endpoints: latency-svc-9vzhn [753.150407ms]
Feb 27 01:45:44.310: INFO: Created: latency-svc-qpx67
Feb 27 01:45:44.346: INFO: Got endpoints: latency-svc-49khb [751.401378ms]
Feb 27 01:45:44.356: INFO: Created: latency-svc-84prx
Feb 27 01:45:44.395: INFO: Got endpoints: latency-svc-bgjcv [749.530994ms]
Feb 27 01:45:44.402: INFO: Created: latency-svc-sgtz7
Feb 27 01:45:44.446: INFO: Got endpoints: latency-svc-rsspk [750.833673ms]
Feb 27 01:45:44.455: INFO: Created: latency-svc-vdxvb
Feb 27 01:45:44.495: INFO: Got endpoints: latency-svc-snl59 [748.415799ms]
Feb 27 01:45:44.504: INFO: Created: latency-svc-qjppg
Feb 27 01:45:44.545: INFO: Got endpoints: latency-svc-8hqrz [749.386345ms]
Feb 27 01:45:44.555: INFO: Created: latency-svc-29x6c
Feb 27 01:45:44.600: INFO: Got endpoints: latency-svc-2q5mj [755.592483ms]
Feb 27 01:45:44.612: INFO: Created: latency-svc-swssr
Feb 27 01:45:44.647: INFO: Got endpoints: latency-svc-j4v5x [752.376838ms]
Feb 27 01:45:44.660: INFO: Created: latency-svc-lq8pk
Feb 27 01:45:44.696: INFO: Got endpoints: latency-svc-ds2ng [751.811096ms]
Feb 27 01:45:44.705: INFO: Created: latency-svc-br8pq
Feb 27 01:45:44.745: INFO: Got endpoints: latency-svc-kkljl [745.940956ms]
Feb 27 01:45:44.752: INFO: Created: latency-svc-qp2dj
Feb 27 01:45:44.797: INFO: Got endpoints: latency-svc-2svkp [750.737969ms]
Feb 27 01:45:44.803: INFO: Created: latency-svc-n22gg
Feb 27 01:45:44.850: INFO: Got endpoints: latency-svc-g5jnj [753.829494ms]
Feb 27 01:45:44.857: INFO: Created: latency-svc-fh4z6
Feb 27 01:45:44.895: INFO: Got endpoints: latency-svc-npmr9 [747.867752ms]
Feb 27 01:45:44.903: INFO: Created: latency-svc-2pqmh
Feb 27 01:45:44.945: INFO: Got endpoints: latency-svc-8n277 [750.188142ms]
Feb 27 01:45:44.956: INFO: Created: latency-svc-bpjpz
Feb 27 01:45:44.995: INFO: Got endpoints: latency-svc-l5cnn [750.511006ms]
Feb 27 01:45:45.004: INFO: Created: latency-svc-d8zd9
Feb 27 01:45:45.044: INFO: Got endpoints: latency-svc-qpx67 [743.765122ms]
Feb 27 01:45:45.052: INFO: Created: latency-svc-jpc6m
Feb 27 01:45:45.097: INFO: Got endpoints: latency-svc-84prx [750.263877ms]
Feb 27 01:45:45.103: INFO: Created: latency-svc-n952d
Feb 27 01:45:45.146: INFO: Got endpoints: latency-svc-sgtz7 [751.239338ms]
Feb 27 01:45:45.155: INFO: Created: latency-svc-ffzdn
Feb 27 01:45:45.196: INFO: Got endpoints: latency-svc-vdxvb [750.366561ms]
Feb 27 01:45:45.204: INFO: Created: latency-svc-4528g
Feb 27 01:45:45.248: INFO: Got endpoints: latency-svc-qjppg [752.908504ms]
Feb 27 01:45:45.257: INFO: Created: latency-svc-ljvl2
Feb 27 01:45:45.297: INFO: Got endpoints: latency-svc-29x6c [751.791105ms]
Feb 27 01:45:45.314: INFO: Created: latency-svc-mhp77
Feb 27 01:45:45.345: INFO: Got endpoints: latency-svc-swssr [745.274286ms]
Feb 27 01:45:45.395: INFO: Got endpoints: latency-svc-lq8pk [747.79343ms]
Feb 27 01:45:45.445: INFO: Got endpoints: latency-svc-br8pq [748.773474ms]
Feb 27 01:45:45.496: INFO: Got endpoints: latency-svc-qp2dj [750.515693ms]
Feb 27 01:45:45.546: INFO: Got endpoints: latency-svc-n22gg [749.468599ms]
Feb 27 01:45:45.595: INFO: Got endpoints: latency-svc-fh4z6 [745.05967ms]
Feb 27 01:45:45.646: INFO: Got endpoints: latency-svc-2pqmh [751.549113ms]
Feb 27 01:45:45.696: INFO: Got endpoints: latency-svc-bpjpz [750.809595ms]
Feb 27 01:45:45.749: INFO: Got endpoints: latency-svc-d8zd9 [753.976294ms]
Feb 27 01:45:45.798: INFO: Got endpoints: latency-svc-jpc6m [753.896899ms]
Feb 27 01:45:45.845: INFO: Got endpoints: latency-svc-n952d [748.544018ms]
Feb 27 01:45:45.900: INFO: Got endpoints: latency-svc-ffzdn [754.269902ms]
Feb 27 01:45:45.951: INFO: Got endpoints: latency-svc-4528g [754.629687ms]
Feb 27 01:45:45.995: INFO: Got endpoints: latency-svc-ljvl2 [746.476196ms]
Feb 27 01:45:46.051: INFO: Got endpoints: latency-svc-mhp77 [753.398357ms]
Feb 27 01:45:46.051: INFO: Latencies: [18.967028ms 26.769812ms 26.800931ms 34.253041ms 52.231378ms 64.315512ms 71.825309ms 78.65517ms 83.565494ms 89.937424ms 94.067446ms 95.245536ms 95.741452ms 98.005203ms 101.334381ms 102.405228ms 104.074342ms 104.765306ms 105.200519ms 105.202617ms 109.460534ms 109.969432ms 111.179938ms 111.721488ms 112.996231ms 115.477356ms 119.325166ms 119.524499ms 120.474922ms 123.15904ms 123.957019ms 124.25998ms 126.841595ms 129.317097ms 139.539876ms 174.082334ms 221.375799ms 266.448669ms 309.152001ms 360.329923ms 395.353925ms 427.585652ms 473.368796ms 511.749552ms 543.287404ms 547.496161ms 589.05659ms 683.147621ms 717.97201ms 737.261464ms 737.882117ms 738.434655ms 740.631833ms 741.706662ms 742.088183ms 742.589584ms 742.874055ms 743.266866ms 743.514863ms 743.765122ms 744.123841ms 744.593433ms 744.678411ms 744.846203ms 744.947846ms 745.015532ms 745.05967ms 745.274286ms 745.545047ms 745.571779ms 745.940956ms 745.993472ms 746.120593ms 746.245938ms 746.421627ms 746.476196ms 746.655495ms 747.202453ms 747.2982ms 747.414275ms 747.420814ms 747.58953ms 747.703616ms 747.765642ms 747.79343ms 747.849287ms 747.867752ms 747.885361ms 748.112613ms 748.124371ms 748.156563ms 748.261676ms 748.300644ms 748.415799ms 748.492772ms 748.544018ms 748.585504ms 748.62815ms 748.659059ms 748.773474ms 748.88556ms 748.962592ms 749.137879ms 749.14856ms 749.386345ms 749.403083ms 749.408683ms 749.468599ms 749.479209ms 749.48382ms 749.530994ms 749.548683ms 749.552824ms 749.654396ms 749.671078ms 749.75373ms 749.762529ms 749.819498ms 749.842785ms 749.844031ms 749.889799ms 749.970269ms 750.054644ms 750.094061ms 750.188142ms 750.221148ms 750.263877ms 750.366561ms 750.492064ms 750.511006ms 750.515693ms 750.532761ms 750.5656ms 750.574746ms 750.58961ms 750.727275ms 750.737969ms 750.740531ms 750.809595ms 750.824479ms 750.833673ms 750.92129ms 750.945012ms 751.007183ms 751.036475ms 751.051264ms 751.122318ms 751.215434ms 751.239338ms 751.247082ms 751.26801ms 751.367451ms 751.389541ms 751.397108ms 751.398773ms 751.401378ms 751.425477ms 751.549113ms 751.596169ms 751.625611ms 751.791105ms 751.811096ms 751.875253ms 751.911465ms 751.956557ms 752.060449ms 752.066745ms 752.093836ms 752.240834ms 752.376838ms 752.442719ms 752.450817ms 752.46299ms 752.708985ms 752.908504ms 753.097612ms 753.150407ms 753.341546ms 753.398357ms 753.71503ms 753.775693ms 753.829494ms 753.896899ms 753.976294ms 754.269902ms 754.629687ms 754.979562ms 755.010088ms 755.13458ms 755.592483ms 755.846633ms 756.656059ms 756.687492ms 757.216557ms 758.929411ms 759.042094ms 760.117361ms 760.590907ms 762.065131ms 789.616919ms]
Feb 27 01:45:46.051: INFO: 50 %ile: 748.88556ms
Feb 27 01:45:46.051: INFO: 90 %ile: 753.775693ms
Feb 27 01:45:46.051: INFO: 99 %ile: 762.065131ms
Feb 27 01:45:46.051: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:45:46.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-hpnsd" for this suite.
Feb 27 01:46:00.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:46:00.081: INFO: namespace: e2e-tests-svc-latency-hpnsd, resource: bindings, ignored listing per whitelist
Feb 27 01:46:00.144: INFO: namespace e2e-tests-svc-latency-hpnsd deletion completed in 14.089673661s

• [SLOW TEST:24.991 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:46:00.146: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-pfbtv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb 27 01:46:00.389: INFO: Waiting up to 5m0s for pod "client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7" in namespace "e2e-tests-containers-pfbtv" to be "success or failure"
Feb 27 01:46:00.393: INFO: Pod "client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.73964ms
Feb 27 01:46:02.396: INFO: Pod "client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006435889s
Feb 27 01:46:04.399: INFO: Pod "client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00925639s
STEP: Saw pod success
Feb 27 01:46:04.399: INFO: Pod "client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:46:04.401: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 01:46:04.416: INFO: Waiting for pod client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:46:04.417: INFO: Pod client-containers-6f2202e9-3a31-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:46:04.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-pfbtv" for this suite.
Feb 27 01:46:10.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:46:10.450: INFO: namespace: e2e-tests-containers-pfbtv, resource: bindings, ignored listing per whitelist
Feb 27 01:46:10.513: INFO: namespace e2e-tests-containers-pfbtv deletion completed in 6.092861582s

• [SLOW TEST:10.366 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:46:10.513: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-sfb6j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sfb6j
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-sfb6j
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-sfb6j
Feb 27 01:46:10.703: INFO: Found 0 stateful pods, waiting for 1
Feb 27 01:46:20.707: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 27 01:46:20.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:46:20.862: INFO: stderr: ""
Feb 27 01:46:20.862: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:46:20.862: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:46:20.864: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 27 01:46:30.868: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:46:30.868: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:46:30.883: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999754s
Feb 27 01:46:31.887: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993182632s
Feb 27 01:46:32.890: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98918438s
Feb 27 01:46:33.893: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985976885s
Feb 27 01:46:34.898: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982953335s
Feb 27 01:46:35.901: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978433428s
Feb 27 01:46:36.905: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97481809s
Feb 27 01:46:37.908: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.971440481s
Feb 27 01:46:38.912: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.968115025s
Feb 27 01:46:39.915: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.594259ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-sfb6j
Feb 27 01:46:40.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:46:41.063: INFO: stderr: ""
Feb 27 01:46:41.063: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:46:41.063: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:46:41.066: INFO: Found 1 stateful pods, waiting for 3
Feb 27 01:46:51.069: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:46:51.069: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:46:51.069: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 27 01:46:51.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:46:51.230: INFO: stderr: ""
Feb 27 01:46:51.230: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:46:51.230: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:46:51.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:46:51.390: INFO: stderr: ""
Feb 27 01:46:51.390: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:46:51.390: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:46:51.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:46:51.553: INFO: stderr: ""
Feb 27 01:46:51.553: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:46:51.553: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:46:51.553: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:46:51.556: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 27 01:47:01.561: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:47:01.561: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:47:01.561: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 01:47:01.573: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999729s
Feb 27 01:47:02.576: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99495891s
Feb 27 01:47:03.580: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991250476s
Feb 27 01:47:04.585: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987587763s
Feb 27 01:47:05.588: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98233702s
Feb 27 01:47:06.592: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979614369s
Feb 27 01:47:07.596: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975322846s
Feb 27 01:47:08.600: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972021083s
Feb 27 01:47:09.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967683305s
Feb 27 01:47:10.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 962.152587ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-sfb6j
Feb 27 01:47:11.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:47:11.762: INFO: stderr: ""
Feb 27 01:47:11.762: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:47:11.762: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:47:11.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:47:11.924: INFO: stderr: ""
Feb 27 01:47:11.924: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:47:11.924: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:47:11.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-sfb6j ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:47:12.071: INFO: stderr: ""
Feb 27 01:47:12.071: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:47:12.071: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:47:12.071: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 01:47:22.085: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sfb6j
Feb 27 01:47:22.087: INFO: Scaling statefulset ss to 0
Feb 27 01:47:22.093: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:47:22.095: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:47:22.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sfb6j" for this suite.
Feb 27 01:47:28.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:47:28.144: INFO: namespace: e2e-tests-statefulset-sfb6j, resource: bindings, ignored listing per whitelist
Feb 27 01:47:28.196: INFO: namespace e2e-tests-statefulset-sfb6j deletion completed in 6.089040481s

• [SLOW TEST:77.684 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:47:28.197: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-77ttm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:47:28.374: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-77ttm" to be "success or failure"
Feb 27 01:47:28.375: INFO: Pod "downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.725057ms
Feb 27 01:47:30.383: INFO: Pod "downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.009127154s
Feb 27 01:47:32.386: INFO: Pod "downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01245511s
STEP: Saw pod success
Feb 27 01:47:32.386: INFO: Pod "downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:47:32.389: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 01:47:32.408: INFO: Waiting for pod downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:47:32.412: INFO: Pod downwardapi-volume-a393bf2c-3a31-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:47:32.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-77ttm" for this suite.
Feb 27 01:47:38.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:47:38.452: INFO: namespace: e2e-tests-downward-api-77ttm, resource: bindings, ignored listing per whitelist
Feb 27 01:47:38.544: INFO: namespace e2e-tests-downward-api-77ttm deletion completed in 6.124079361s

• [SLOW TEST:10.347 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:47:38.548: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-4qkwq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7
Feb 27 01:47:38.737: INFO: Pod name my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7: Found 0 pods out of 1
Feb 27 01:47:43.740: INFO: Pod name my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7: Found 1 pods out of 1
Feb 27 01:47:43.740: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7" are running
Feb 27 01:47:43.743: INFO: Pod "my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7-m8mnd" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:47:38 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:47:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:47:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 01:47:38 +0000 UTC Reason: Message:}])
Feb 27 01:47:43.743: INFO: Trying to dial the pod
Feb 27 01:47:48.752: INFO: Controller my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7: Got expected result from replica 1 [my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7-m8mnd]: "my-hostname-basic-a9c0abd2-3a31-11e9-853a-328ab8481bb7-m8mnd", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:47:48.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-4qkwq" for this suite.
Feb 27 01:47:54.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:47:54.822: INFO: namespace: e2e-tests-replication-controller-4qkwq, resource: bindings, ignored listing per whitelist
Feb 27 01:47:54.843: INFO: namespace e2e-tests-replication-controller-4qkwq deletion completed in 6.087948034s

• [SLOW TEST:16.295 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:47:54.845: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2knxd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb 27 01:47:55.023: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 27 01:47:55.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:47:55.202: INFO: stderr: ""
Feb 27 01:47:55.202: INFO: stdout: "service/redis-slave created\n"
Feb 27 01:47:55.202: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 27 01:47:55.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:47:55.364: INFO: stderr: ""
Feb 27 01:47:55.364: INFO: stdout: "service/redis-master created\n"
Feb 27 01:47:55.364: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 27 01:47:55.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:47:55.515: INFO: stderr: ""
Feb 27 01:47:55.515: INFO: stdout: "service/frontend created\n"
Feb 27 01:47:55.515: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 27 01:47:55.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:47:55.669: INFO: stderr: ""
Feb 27 01:47:55.669: INFO: stdout: "deployment.extensions/frontend created\n"
Feb 27 01:47:55.669: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 27 01:47:55.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:47:55.837: INFO: stderr: ""
Feb 27 01:47:55.837: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb 27 01:47:55.837: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 27 01:47:55.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:47:56.081: INFO: stderr: ""
Feb 27 01:47:56.081: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb 27 01:47:56.081: INFO: Waiting for all frontend pods to be Running.
Feb 27 01:48:11.131: INFO: Waiting for frontend to serve content.
Feb 27 01:48:16.149: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 27 01:48:21.163: INFO: Trying to add a new entry to the guestbook.
Feb 27 01:48:21.179: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 27 01:48:21.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:48:21.274: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 01:48:21.274: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 01:48:21.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:48:21.406: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 01:48:21.406: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 01:48:21.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:48:21.501: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 01:48:21.501: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 01:48:21.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:48:21.583: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 01:48:21.583: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 01:48:21.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:48:21.694: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 01:48:21.694: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 27 01:48:21.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2knxd'
Feb 27 01:48:21.846: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 01:48:21.846: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:48:21.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2knxd" for this suite.
Feb 27 01:48:59.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:48:59.901: INFO: namespace: e2e-tests-kubectl-2knxd, resource: bindings, ignored listing per whitelist
Feb 27 01:48:59.955: INFO: namespace e2e-tests-kubectl-2knxd deletion completed in 38.098657494s

• [SLOW TEST:65.111 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:48:59.955: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-mqbpg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mqbpg
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-mqbpg
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-mqbpg
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-mqbpg
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-mqbpg
Feb 27 01:49:02.164: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-mqbpg, name: ss-0, uid: db220907-3a31-11e9-bb22-deadbe9ffdf9, status phase: Pending. Waiting for statefulset controller to delete.
Feb 27 01:49:02.552: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-mqbpg, name: ss-0, uid: db220907-3a31-11e9-bb22-deadbe9ffdf9, status phase: Failed. Waiting for statefulset controller to delete.
Feb 27 01:49:02.556: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-mqbpg, name: ss-0, uid: db220907-3a31-11e9-bb22-deadbe9ffdf9, status phase: Failed. Waiting for statefulset controller to delete.
Feb 27 01:49:02.562: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-mqbpg
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-mqbpg
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-mqbpg and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 01:49:04.577: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mqbpg
Feb 27 01:49:04.583: INFO: Scaling statefulset ss to 0
Feb 27 01:49:14.602: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:49:14.605: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:49:14.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mqbpg" for this suite.
Feb 27 01:49:20.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:49:20.680: INFO: namespace: e2e-tests-statefulset-mqbpg, resource: bindings, ignored listing per whitelist
Feb 27 01:49:20.709: INFO: namespace e2e-tests-statefulset-mqbpg deletion completed in 6.089916923s

• [SLOW TEST:20.753 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:49:20.709: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-vwvl4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-2fn8
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 01:49:20.901: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2fn8" in namespace "e2e-tests-subpath-vwvl4" to be "success or failure"
Feb 27 01:49:20.904: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.851375ms
Feb 27 01:49:22.907: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005545067s
Feb 27 01:49:24.910: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008902426s
Feb 27 01:49:26.914: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 6.01263809s
Feb 27 01:49:28.918: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 8.016602696s
Feb 27 01:49:30.921: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 10.020297722s
Feb 27 01:49:32.926: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 12.02522162s
Feb 27 01:49:34.932: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 14.031224542s
Feb 27 01:49:36.935: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 16.03433849s
Feb 27 01:49:38.939: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 18.037448618s
Feb 27 01:49:40.943: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 20.041681244s
Feb 27 01:49:42.946: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 22.044564689s
Feb 27 01:49:44.954: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 24.052805658s
Feb 27 01:49:46.958: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Running", Reason="", readiness=false. Elapsed: 26.057020183s
Feb 27 01:49:48.962: INFO: Pod "pod-subpath-test-configmap-2fn8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.060733309s
STEP: Saw pod success
Feb 27 01:49:48.962: INFO: Pod "pod-subpath-test-configmap-2fn8" satisfied condition "success or failure"
Feb 27 01:49:48.964: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod pod-subpath-test-configmap-2fn8 container test-container-subpath-configmap-2fn8: <nil>
STEP: delete the pod
Feb 27 01:49:48.977: INFO: Waiting for pod pod-subpath-test-configmap-2fn8 to disappear
Feb 27 01:49:48.980: INFO: Pod pod-subpath-test-configmap-2fn8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2fn8
Feb 27 01:49:48.980: INFO: Deleting pod "pod-subpath-test-configmap-2fn8" in namespace "e2e-tests-subpath-vwvl4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:49:48.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vwvl4" for this suite.
Feb 27 01:49:54.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:49:55.077: INFO: namespace: e2e-tests-subpath-vwvl4, resource: bindings, ignored listing per whitelist
Feb 27 01:49:55.099: INFO: namespace e2e-tests-subpath-vwvl4 deletion completed in 6.111380747s

• [SLOW TEST:34.390 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:49:55.101: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-g2l9b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 27 01:49:55.285: INFO: Waiting up to 5m0s for pod "pod-fb23d186-3a31-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-g2l9b" to be "success or failure"
Feb 27 01:49:55.298: INFO: Pod "pod-fb23d186-3a31-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.290165ms
Feb 27 01:49:57.301: INFO: Pod "pod-fb23d186-3a31-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015685453s
STEP: Saw pod success
Feb 27 01:49:57.301: INFO: Pod "pod-fb23d186-3a31-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:49:57.303: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-fb23d186-3a31-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 01:49:57.336: INFO: Waiting for pod pod-fb23d186-3a31-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:49:57.338: INFO: Pod pod-fb23d186-3a31-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:49:57.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-g2l9b" for this suite.
Feb 27 01:50:03.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:50:03.413: INFO: namespace: e2e-tests-emptydir-g2l9b, resource: bindings, ignored listing per whitelist
Feb 27 01:50:03.424: INFO: namespace e2e-tests-emptydir-g2l9b deletion completed in 6.083450523s

• [SLOW TEST:8.324 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:50:03.426: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-5mbj9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb 27 01:50:03.600: INFO: Waiting up to 5m0s for pod "client-containers-0019732b-3a32-11e9-853a-328ab8481bb7" in namespace "e2e-tests-containers-5mbj9" to be "success or failure"
Feb 27 01:50:03.602: INFO: Pod "client-containers-0019732b-3a32-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.867632ms
Feb 27 01:50:05.606: INFO: Pod "client-containers-0019732b-3a32-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006456289s
STEP: Saw pod success
Feb 27 01:50:05.606: INFO: Pod "client-containers-0019732b-3a32-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:50:05.608: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod client-containers-0019732b-3a32-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 01:50:05.622: INFO: Waiting for pod client-containers-0019732b-3a32-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:50:05.628: INFO: Pod client-containers-0019732b-3a32-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:50:05.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5mbj9" for this suite.
Feb 27 01:50:11.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:50:11.714: INFO: namespace: e2e-tests-containers-5mbj9, resource: bindings, ignored listing per whitelist
Feb 27 01:50:11.756: INFO: namespace e2e-tests-containers-5mbj9 deletion completed in 6.124709794s

• [SLOW TEST:8.330 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:50:11.756: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2m44j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2m44j
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb 27 01:50:11.943: INFO: Found 0 stateful pods, waiting for 3
Feb 27 01:50:21.947: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:50:21.947: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:50:21.947: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 01:50:21.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-2m44j ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:50:22.111: INFO: stderr: ""
Feb 27 01:50:22.111: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:50:22.111: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 27 01:50:32.137: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 27 01:50:42.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-2m44j ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:50:42.300: INFO: stderr: ""
Feb 27 01:50:42.300: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:50:42.300: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:51:02.317: INFO: Waiting for StatefulSet e2e-tests-statefulset-2m44j/ss2 to complete update
Feb 27 01:51:02.317: INFO: Waiting for Pod e2e-tests-statefulset-2m44j/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb 27 01:51:12.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-2m44j ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 01:51:12.468: INFO: stderr: ""
Feb 27 01:51:12.468: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 01:51:12.468: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 01:51:22.496: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 27 01:51:32.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-2m44j ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 01:51:32.659: INFO: stderr: ""
Feb 27 01:51:32.659: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 01:51:32.659: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 01:51:52.678: INFO: Waiting for StatefulSet e2e-tests-statefulset-2m44j/ss2 to complete update
Feb 27 01:51:52.678: INFO: Waiting for Pod e2e-tests-statefulset-2m44j/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 01:52:02.684: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2m44j
Feb 27 01:52:02.686: INFO: Scaling statefulset ss2 to 0
Feb 27 01:52:32.696: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 01:52:32.699: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:52:32.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2m44j" for this suite.
Feb 27 01:52:38.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:52:38.794: INFO: namespace: e2e-tests-statefulset-2m44j, resource: bindings, ignored listing per whitelist
Feb 27 01:52:38.803: INFO: namespace e2e-tests-statefulset-2m44j deletion completed in 6.087776075s

• [SLOW TEST:147.047 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:52:38.805: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-hnzwn
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 01:52:38.990: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:52:40.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-hnzwn" for this suite.
Feb 27 01:52:46.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:52:46.107: INFO: namespace: e2e-tests-custom-resource-definition-hnzwn, resource: bindings, ignored listing per whitelist
Feb 27 01:52:46.125: INFO: namespace e2e-tests-custom-resource-definition-hnzwn deletion completed in 6.095702035s

• [SLOW TEST:7.320 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:52:46.126: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xb8p8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6114a4ff-3a32-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 01:52:46.316: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6115349c-3a32-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-xb8p8" to be "success or failure"
Feb 27 01:52:46.323: INFO: Pod "pod-projected-configmaps-6115349c-3a32-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.294008ms
Feb 27 01:52:48.326: INFO: Pod "pod-projected-configmaps-6115349c-3a32-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010493703s
STEP: Saw pod success
Feb 27 01:52:48.327: INFO: Pod "pod-projected-configmaps-6115349c-3a32-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:52:48.329: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-configmaps-6115349c-3a32-11e9-853a-328ab8481bb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 01:52:48.344: INFO: Waiting for pod pod-projected-configmaps-6115349c-3a32-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:52:48.346: INFO: Pod pod-projected-configmaps-6115349c-3a32-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:52:48.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xb8p8" for this suite.
Feb 27 01:52:54.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:52:54.386: INFO: namespace: e2e-tests-projected-xb8p8, resource: bindings, ignored listing per whitelist
Feb 27 01:52:54.429: INFO: namespace e2e-tests-projected-xb8p8 deletion completed in 6.080516616s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:52:54.429: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-29wgw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-29wgw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-29wgw to expose endpoints map[]
Feb 27 01:52:54.619: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-29wgw exposes endpoints map[] (2.257182ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-29wgw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-29wgw to expose endpoints map[pod1:[100]]
Feb 27 01:52:56.646: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-29wgw exposes endpoints map[pod1:[100]] (2.0215011s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-29wgw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-29wgw to expose endpoints map[pod1:[100] pod2:[101]]
Feb 27 01:52:58.673: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-29wgw exposes endpoints map[pod1:[100] pod2:[101]] (2.022317652s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-29wgw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-29wgw to expose endpoints map[pod2:[101]]
Feb 27 01:52:59.693: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-29wgw exposes endpoints map[pod2:[101]] (1.016256778s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-29wgw
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-29wgw to expose endpoints map[]
Feb 27 01:53:00.701: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-29wgw exposes endpoints map[] (1.004591223s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:53:00.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-29wgw" for this suite.
Feb 27 01:53:22.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:53:22.752: INFO: namespace: e2e-tests-services-29wgw, resource: bindings, ignored listing per whitelist
Feb 27 01:53:22.816: INFO: namespace e2e-tests-services-29wgw deletion completed in 22.094873761s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.387 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:53:22.816: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-dg4fk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 27 01:53:31.044: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:31.047: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:33.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:33.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:35.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:35.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:37.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:37.052: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:39.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:39.049: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:41.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:41.051: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:43.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:43.049: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:45.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:45.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:47.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:47.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:49.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:49.055: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:51.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:51.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:53.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:53.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:55.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:55.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:57.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:57.050: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 27 01:53:59.047: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 27 01:53:59.050: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:53:59.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dg4fk" for this suite.
Feb 27 01:54:21.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:54:21.078: INFO: namespace: e2e-tests-container-lifecycle-hook-dg4fk, resource: bindings, ignored listing per whitelist
Feb 27 01:54:21.138: INFO: namespace e2e-tests-container-lifecycle-hook-dg4fk deletion completed in 22.078415404s

• [SLOW TEST:58.322 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:54:21.140: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4n2fh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 01:54:21.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99b929de-3a32-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-4n2fh" to be "success or failure"
Feb 27 01:54:21.350: INFO: Pod "downwardapi-volume-99b929de-3a32-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.197274ms
Feb 27 01:54:23.353: INFO: Pod "downwardapi-volume-99b929de-3a32-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012592726s
STEP: Saw pod success
Feb 27 01:54:23.353: INFO: Pod "downwardapi-volume-99b929de-3a32-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:54:23.355: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-99b929de-3a32-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 01:54:23.371: INFO: Waiting for pod downwardapi-volume-99b929de-3a32-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:54:23.373: INFO: Pod downwardapi-volume-99b929de-3a32-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:54:23.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4n2fh" for this suite.
Feb 27 01:54:29.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:54:29.445: INFO: namespace: e2e-tests-projected-4n2fh, resource: bindings, ignored listing per whitelist
Feb 27 01:54:29.472: INFO: namespace e2e-tests-projected-4n2fh deletion completed in 6.096510776s

• [SLOW TEST:8.332 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:54:29.472: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-nzbkq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 27 01:54:29.855: INFO: Pod name wrapped-volume-race-9ec55275-3a32-11e9-853a-328ab8481bb7: Found 3 pods out of 5
Feb 27 01:54:34.866: INFO: Pod name wrapped-volume-race-9ec55275-3a32-11e9-853a-328ab8481bb7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9ec55275-3a32-11e9-853a-328ab8481bb7 in namespace e2e-tests-emptydir-wrapper-nzbkq, will wait for the garbage collector to delete the pods
Feb 27 01:54:44.941: INFO: Deleting ReplicationController wrapped-volume-race-9ec55275-3a32-11e9-853a-328ab8481bb7 took: 6.863291ms
Feb 27 01:54:45.141: INFO: Terminating ReplicationController wrapped-volume-race-9ec55275-3a32-11e9-853a-328ab8481bb7 pods took: 200.157497ms
STEP: Creating RC which spawns configmap-volume pods
Feb 27 01:55:28.754: INFO: Pod name wrapped-volume-race-c1e6e229-3a32-11e9-853a-328ab8481bb7: Found 0 pods out of 5
Feb 27 01:55:33.760: INFO: Pod name wrapped-volume-race-c1e6e229-3a32-11e9-853a-328ab8481bb7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c1e6e229-3a32-11e9-853a-328ab8481bb7 in namespace e2e-tests-emptydir-wrapper-nzbkq, will wait for the garbage collector to delete the pods
Feb 27 01:55:43.832: INFO: Deleting ReplicationController wrapped-volume-race-c1e6e229-3a32-11e9-853a-328ab8481bb7 took: 5.096956ms
Feb 27 01:55:43.933: INFO: Terminating ReplicationController wrapped-volume-race-c1e6e229-3a32-11e9-853a-328ab8481bb7 pods took: 100.875223ms
STEP: Creating RC which spawns configmap-volume pods
Feb 27 01:56:28.752: INFO: Pod name wrapped-volume-race-e5a8d4a0-3a32-11e9-853a-328ab8481bb7: Found 0 pods out of 5
Feb 27 01:56:33.760: INFO: Pod name wrapped-volume-race-e5a8d4a0-3a32-11e9-853a-328ab8481bb7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e5a8d4a0-3a32-11e9-853a-328ab8481bb7 in namespace e2e-tests-emptydir-wrapper-nzbkq, will wait for the garbage collector to delete the pods
Feb 27 01:56:43.841: INFO: Deleting ReplicationController wrapped-volume-race-e5a8d4a0-3a32-11e9-853a-328ab8481bb7 took: 8.451222ms
Feb 27 01:56:43.941: INFO: Terminating ReplicationController wrapped-volume-race-e5a8d4a0-3a32-11e9-853a-328ab8481bb7 pods took: 100.183861ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:57:28.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-nzbkq" for this suite.
Feb 27 01:57:34.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:57:34.428: INFO: namespace: e2e-tests-emptydir-wrapper-nzbkq, resource: bindings, ignored listing per whitelist
Feb 27 01:57:34.465: INFO: namespace e2e-tests-emptydir-wrapper-nzbkq deletion completed in 6.095207662s

• [SLOW TEST:184.993 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:57:34.467: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-x95gb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 27 01:57:40.669: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:40.670: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:40.750: INFO: Exec stderr: ""
Feb 27 01:57:40.750: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:40.750: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:40.823: INFO: Exec stderr: ""
Feb 27 01:57:40.823: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:40.823: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:40.895: INFO: Exec stderr: ""
Feb 27 01:57:40.895: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:40.895: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:40.971: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 27 01:57:40.971: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:40.971: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:41.058: INFO: Exec stderr: ""
Feb 27 01:57:41.058: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:41.058: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:41.162: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 27 01:57:41.162: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:41.162: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:41.248: INFO: Exec stderr: ""
Feb 27 01:57:41.248: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:41.248: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:41.329: INFO: Exec stderr: ""
Feb 27 01:57:41.329: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:41.329: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:41.403: INFO: Exec stderr: ""
Feb 27 01:57:41.403: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-x95gb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 01:57:41.403: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 01:57:41.475: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:57:41.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-x95gb" for this suite.
Feb 27 01:58:33.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:58:33.506: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-x95gb, resource: bindings, ignored listing per whitelist
Feb 27 01:58:33.579: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-x95gb deletion completed in 52.101105421s

• [SLOW TEST:59.113 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:58:33.579: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4khcd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb 27 01:58:33.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-4khcd'
Feb 27 01:58:34.615: INFO: stderr: ""
Feb 27 01:58:34.615: INFO: stdout: "pod/pause created\n"
Feb 27 01:58:34.615: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 27 01:58:34.615: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-4khcd" to be "running and ready"
Feb 27 01:58:34.620: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.88361ms
Feb 27 01:58:36.625: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009363854s
Feb 27 01:58:36.625: INFO: Pod "pause" satisfied condition "running and ready"
Feb 27 01:58:36.625: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 27 01:58:36.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-4khcd'
Feb 27 01:58:36.717: INFO: stderr: ""
Feb 27 01:58:36.717: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 27 01:58:36.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4khcd'
Feb 27 01:58:36.792: INFO: stderr: ""
Feb 27 01:58:36.792: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 27 01:58:36.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 label pods pause testing-label- --namespace=e2e-tests-kubectl-4khcd'
Feb 27 01:58:36.863: INFO: stderr: ""
Feb 27 01:58:36.863: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 27 01:58:36.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pod pause -L testing-label --namespace=e2e-tests-kubectl-4khcd'
Feb 27 01:58:36.929: INFO: stderr: ""
Feb 27 01:58:36.929: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb 27 01:58:36.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4khcd'
Feb 27 01:58:37.011: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 01:58:37.011: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 27 01:58:37.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-4khcd'
Feb 27 01:58:37.137: INFO: stderr: "No resources found.\n"
Feb 27 01:58:37.137: INFO: stdout: ""
Feb 27 01:58:37.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -l name=pause --namespace=e2e-tests-kubectl-4khcd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 01:58:37.238: INFO: stderr: ""
Feb 27 01:58:37.238: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:58:37.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4khcd" for this suite.
Feb 27 01:58:43.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:58:43.337: INFO: namespace: e2e-tests-kubectl-4khcd, resource: bindings, ignored listing per whitelist
Feb 27 01:58:43.342: INFO: namespace e2e-tests-kubectl-4khcd deletion completed in 6.10202775s

• [SLOW TEST:9.763 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:58:43.343: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-lfckh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-jrd6k
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb 27 01:58:45.679: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-v5qjr
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:59:09.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-lfckh" for this suite.
Feb 27 01:59:15.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:59:15.875: INFO: namespace: e2e-tests-namespaces-lfckh, resource: bindings, ignored listing per whitelist
Feb 27 01:59:15.915: INFO: namespace e2e-tests-namespaces-lfckh deletion completed in 6.088139849s
STEP: Destroying namespace "e2e-tests-nsdeletetest-jrd6k" for this suite.
Feb 27 01:59:15.917: INFO: Namespace e2e-tests-nsdeletetest-jrd6k was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-v5qjr" for this suite.
Feb 27 01:59:21.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:59:21.938: INFO: namespace: e2e-tests-nsdeletetest-v5qjr, resource: bindings, ignored listing per whitelist
Feb 27 01:59:22.004: INFO: namespace e2e-tests-nsdeletetest-v5qjr deletion completed in 6.086510518s

• [SLOW TEST:38.661 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:59:22.004: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nbgd9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 01:59:22.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-nbgd9'
Feb 27 01:59:22.259: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 01:59:22.259: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb 27 01:59:24.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-nbgd9'
Feb 27 01:59:24.346: INFO: stderr: ""
Feb 27 01:59:24.346: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:59:24.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nbgd9" for this suite.
Feb 27 01:59:46.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:59:46.419: INFO: namespace: e2e-tests-kubectl-nbgd9, resource: bindings, ignored listing per whitelist
Feb 27 01:59:46.438: INFO: namespace e2e-tests-kubectl-nbgd9 deletion completed in 22.08855258s

• [SLOW TEST:24.434 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:59:46.438: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cblpp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5b99f3f9-3a33-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 01:59:46.615: INFO: Waiting up to 5m0s for pod "pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-cblpp" to be "success or failure"
Feb 27 01:59:46.618: INFO: Pod "pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.457661ms
Feb 27 01:59:48.621: INFO: Pod "pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.006304708s
Feb 27 01:59:50.625: INFO: Pod "pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010379036s
STEP: Saw pod success
Feb 27 01:59:50.626: INFO: Pod "pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:59:50.627: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 01:59:50.640: INFO: Waiting for pod pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:59:50.642: INFO: Pod pod-secrets-5b9a74ec-3a33-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:59:50.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cblpp" for this suite.
Feb 27 01:59:56.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 01:59:56.687: INFO: namespace: e2e-tests-secrets-cblpp, resource: bindings, ignored listing per whitelist
Feb 27 01:59:56.732: INFO: namespace e2e-tests-secrets-cblpp deletion completed in 6.086800968s

• [SLOW TEST:10.294 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 01:59:56.732: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-82c46
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 01:59:56.928: INFO: Waiting up to 5m0s for pod "downward-api-61bf78fe-3a33-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-82c46" to be "success or failure"
Feb 27 01:59:56.931: INFO: Pod "downward-api-61bf78fe-3a33-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217387ms
Feb 27 01:59:58.935: INFO: Pod "downward-api-61bf78fe-3a33-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006814772s
STEP: Saw pod success
Feb 27 01:59:58.935: INFO: Pod "downward-api-61bf78fe-3a33-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 01:59:58.937: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod downward-api-61bf78fe-3a33-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 01:59:58.955: INFO: Waiting for pod downward-api-61bf78fe-3a33-11e9-853a-328ab8481bb7 to disappear
Feb 27 01:59:58.959: INFO: Pod downward-api-61bf78fe-3a33-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 01:59:58.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-82c46" for this suite.
Feb 27 02:00:04.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:00:05.030: INFO: namespace: e2e-tests-downward-api-82c46, resource: bindings, ignored listing per whitelist
Feb 27 02:00:05.061: INFO: namespace e2e-tests-downward-api-82c46 deletion completed in 6.096628654s

• [SLOW TEST:8.329 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:00:05.062: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-b25xv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-b25xv
Feb 27 02:00:07.244: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-b25xv
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:00:07.246: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:04:07.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-b25xv" for this suite.
Feb 27 02:04:13.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:04:13.792: INFO: namespace: e2e-tests-container-probe-b25xv, resource: bindings, ignored listing per whitelist
Feb 27 02:04:13.843: INFO: namespace e2e-tests-container-probe-b25xv deletion completed in 6.121561288s

• [SLOW TEST:248.781 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:04:13.844: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-n7r4d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:04:32.038: INFO: Container started at 2019-02-27 02:04:14 +0000 UTC, pod became ready at 2019-02-27 02:04:30 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:04:32.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-n7r4d" for this suite.
Feb 27 02:04:54.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:04:54.093: INFO: namespace: e2e-tests-container-probe-n7r4d, resource: bindings, ignored listing per whitelist
Feb 27 02:04:54.128: INFO: namespace e2e-tests-container-probe-n7r4d deletion completed in 22.087627892s

• [SLOW TEST:40.285 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:04:54.129: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-56hcf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0227 02:05:04.349258      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 02:05:04.349: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:05:04.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-56hcf" for this suite.
Feb 27 02:05:10.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:05:10.399: INFO: namespace: e2e-tests-gc-56hcf, resource: bindings, ignored listing per whitelist
Feb 27 02:05:10.434: INFO: namespace e2e-tests-gc-56hcf deletion completed in 6.08163269s

• [SLOW TEST:16.305 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:05:10.434: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-w6n44
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-w6n44/secret-test-1cb76378-3a34-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:05:10.608: INFO: Waiting up to 5m0s for pod "pod-configmaps-1cb7d8f0-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-w6n44" to be "success or failure"
Feb 27 02:05:10.611: INFO: Pod "pod-configmaps-1cb7d8f0-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.593454ms
Feb 27 02:05:12.614: INFO: Pod "pod-configmaps-1cb7d8f0-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006445714s
STEP: Saw pod success
Feb 27 02:05:12.614: INFO: Pod "pod-configmaps-1cb7d8f0-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:05:12.616: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-1cb7d8f0-3a34-11e9-853a-328ab8481bb7 container env-test: <nil>
STEP: delete the pod
Feb 27 02:05:12.629: INFO: Waiting for pod pod-configmaps-1cb7d8f0-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:05:12.641: INFO: Pod pod-configmaps-1cb7d8f0-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:05:12.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w6n44" for this suite.
Feb 27 02:05:18.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:05:18.668: INFO: namespace: e2e-tests-secrets-w6n44, resource: bindings, ignored listing per whitelist
Feb 27 02:05:18.721: INFO: namespace e2e-tests-secrets-w6n44 deletion completed in 6.077457916s

• [SLOW TEST:8.287 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:05:18.721: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-pn7pw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0227 02:05:49.409320      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 02:05:49.409: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:05:49.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pn7pw" for this suite.
Feb 27 02:05:55.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:05:55.473: INFO: namespace: e2e-tests-gc-pn7pw, resource: bindings, ignored listing per whitelist
Feb 27 02:05:55.496: INFO: namespace e2e-tests-gc-pn7pw deletion completed in 6.085222482s

• [SLOW TEST:36.775 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:05:55.498: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-nmldx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-hgbjq
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-kxr5l
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:01.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-nmldx" for this suite.
Feb 27 02:06:07.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:08.019: INFO: namespace: e2e-tests-namespaces-nmldx, resource: bindings, ignored listing per whitelist
Feb 27 02:06:08.064: INFO: namespace e2e-tests-namespaces-nmldx deletion completed in 6.083397695s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hgbjq" for this suite.
Feb 27 02:06:08.066: INFO: Namespace e2e-tests-nsdeletetest-hgbjq was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-kxr5l" for this suite.
Feb 27 02:06:14.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:14.132: INFO: namespace: e2e-tests-nsdeletetest-kxr5l, resource: bindings, ignored listing per whitelist
Feb 27 02:06:14.145: INFO: namespace e2e-tests-nsdeletetest-kxr5l deletion completed in 6.078811227s

• [SLOW TEST:18.646 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:06:14.147: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nlssd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-42b14cd1-3a34-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:06:14.322: INFO: Waiting up to 5m0s for pod "pod-configmaps-42b1c8a1-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-nlssd" to be "success or failure"
Feb 27 02:06:14.324: INFO: Pod "pod-configmaps-42b1c8a1-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087189ms
Feb 27 02:06:16.328: INFO: Pod "pod-configmaps-42b1c8a1-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006009556s
STEP: Saw pod success
Feb 27 02:06:16.328: INFO: Pod "pod-configmaps-42b1c8a1-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:06:16.332: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-42b1c8a1-3a34-11e9-853a-328ab8481bb7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:06:16.364: INFO: Waiting for pod pod-configmaps-42b1c8a1-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:06:16.366: INFO: Pod pod-configmaps-42b1c8a1-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:16.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nlssd" for this suite.
Feb 27 02:06:22.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:22.400: INFO: namespace: e2e-tests-configmap-nlssd, resource: bindings, ignored listing per whitelist
Feb 27 02:06:22.461: INFO: namespace e2e-tests-configmap-nlssd deletion completed in 6.091061506s

• [SLOW TEST:8.315 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:06:22.462: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-c92bb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 27 02:06:27.673: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:27.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-c92bb" for this suite.
Feb 27 02:06:49.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:49.791: INFO: namespace: e2e-tests-replicaset-c92bb, resource: bindings, ignored listing per whitelist
Feb 27 02:06:49.804: INFO: namespace e2e-tests-replicaset-c92bb deletion completed in 22.105896285s

• [SLOW TEST:27.342 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:06:49.805: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-lgx4p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:06:50.004: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb 27 02:06:50.008: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lgx4p/daemonsets","resourceVersion":"18884"},"items":null}

Feb 27 02:06:50.010: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lgx4p/pods","resourceVersion":"18884"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:50.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lgx4p" for this suite.
Feb 27 02:06:56.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:06:56.044: INFO: namespace: e2e-tests-daemonsets-lgx4p, resource: bindings, ignored listing per whitelist
Feb 27 02:06:56.107: INFO: namespace e2e-tests-daemonsets-lgx4p deletion completed in 6.08278804s

S [SKIPPING] [6.302 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb 27 02:06:50.004: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:06:56.107: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h76fp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:06:56.297: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5bb55856-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-h76fp" to be "success or failure"
Feb 27 02:06:56.300: INFO: Pod "downwardapi-volume-5bb55856-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.258954ms
Feb 27 02:06:58.304: INFO: Pod "downwardapi-volume-5bb55856-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006590515s
STEP: Saw pod success
Feb 27 02:06:58.304: INFO: Pod "downwardapi-volume-5bb55856-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:06:58.306: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-5bb55856-3a34-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:06:58.324: INFO: Waiting for pod downwardapi-volume-5bb55856-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:06:58.326: INFO: Pod downwardapi-volume-5bb55856-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:06:58.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h76fp" for this suite.
Feb 27 02:07:04.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:07:04.357: INFO: namespace: e2e-tests-projected-h76fp, resource: bindings, ignored listing per whitelist
Feb 27 02:07:04.413: INFO: namespace e2e-tests-projected-h76fp deletion completed in 6.084699418s

• [SLOW TEST:8.305 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:07:04.413: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5vdwt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:07:04.588: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60a7e69c-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-5vdwt" to be "success or failure"
Feb 27 02:07:04.590: INFO: Pod "downwardapi-volume-60a7e69c-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.95635ms
Feb 27 02:07:06.597: INFO: Pod "downwardapi-volume-60a7e69c-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00889363s
STEP: Saw pod success
Feb 27 02:07:06.597: INFO: Pod "downwardapi-volume-60a7e69c-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:07:06.599: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-60a7e69c-3a34-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:07:06.627: INFO: Waiting for pod downwardapi-volume-60a7e69c-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:07:06.630: INFO: Pod downwardapi-volume-60a7e69c-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:07:06.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vdwt" for this suite.
Feb 27 02:07:12.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:07:12.720: INFO: namespace: e2e-tests-projected-5vdwt, resource: bindings, ignored listing per whitelist
Feb 27 02:07:12.730: INFO: namespace e2e-tests-projected-5vdwt deletion completed in 6.097152164s

• [SLOW TEST:8.317 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:07:12.730: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tgwgf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 27 02:07:12.921: INFO: Waiting up to 5m0s for pod "pod-659f5b7f-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-tgwgf" to be "success or failure"
Feb 27 02:07:12.927: INFO: Pod "pod-659f5b7f-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.846547ms
Feb 27 02:07:14.932: INFO: Pod "pod-659f5b7f-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011584701s
STEP: Saw pod success
Feb 27 02:07:14.932: INFO: Pod "pod-659f5b7f-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:07:14.934: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-659f5b7f-3a34-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:07:14.950: INFO: Waiting for pod pod-659f5b7f-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:07:14.952: INFO: Pod pod-659f5b7f-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:07:14.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tgwgf" for this suite.
Feb 27 02:07:20.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:07:21.056: INFO: namespace: e2e-tests-emptydir-tgwgf, resource: bindings, ignored listing per whitelist
Feb 27 02:07:21.081: INFO: namespace e2e-tests-emptydir-tgwgf deletion completed in 6.125668937s

• [SLOW TEST:8.351 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:07:21.081: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-n2q4g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-6a97a028-3a34-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:07:21.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-6a982af4-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-n2q4g" to be "success or failure"
Feb 27 02:07:21.265: INFO: Pod "pod-configmaps-6a982af4-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258967ms
Feb 27 02:07:23.268: INFO: Pod "pod-configmaps-6a982af4-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005073509s
STEP: Saw pod success
Feb 27 02:07:23.268: INFO: Pod "pod-configmaps-6a982af4-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:07:23.270: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-6a982af4-3a34-11e9-853a-328ab8481bb7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:07:23.299: INFO: Waiting for pod pod-configmaps-6a982af4-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:07:23.301: INFO: Pod pod-configmaps-6a982af4-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:07:23.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n2q4g" for this suite.
Feb 27 02:07:29.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:07:29.330: INFO: namespace: e2e-tests-configmap-n2q4g, resource: bindings, ignored listing per whitelist
Feb 27 02:07:29.399: INFO: namespace e2e-tests-configmap-n2q4g deletion completed in 6.094697414s

• [SLOW TEST:8.318 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:07:29.401: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-v6dkd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-6f8c4cf4-3a34-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:07:29.578: INFO: Waiting up to 5m0s for pod "pod-secrets-6f8cd4fb-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-v6dkd" to be "success or failure"
Feb 27 02:07:29.580: INFO: Pod "pod-secrets-6f8cd4fb-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.684332ms
Feb 27 02:07:31.584: INFO: Pod "pod-secrets-6f8cd4fb-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006870309s
STEP: Saw pod success
Feb 27 02:07:31.585: INFO: Pod "pod-secrets-6f8cd4fb-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:07:31.587: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-6f8cd4fb-3a34-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:07:31.601: INFO: Waiting for pod pod-secrets-6f8cd4fb-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:07:31.602: INFO: Pod pod-secrets-6f8cd4fb-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:07:31.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v6dkd" for this suite.
Feb 27 02:07:37.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:07:37.694: INFO: namespace: e2e-tests-secrets-v6dkd, resource: bindings, ignored listing per whitelist
Feb 27 02:07:37.715: INFO: namespace e2e-tests-secrets-v6dkd deletion completed in 6.110172351s

• [SLOW TEST:8.315 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:07:37.716: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5z86c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:07:37.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74811ecd-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-5z86c" to be "success or failure"
Feb 27 02:07:37.895: INFO: Pod "downwardapi-volume-74811ecd-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.986396ms
Feb 27 02:07:39.898: INFO: Pod "downwardapi-volume-74811ecd-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007178099s
STEP: Saw pod success
Feb 27 02:07:39.898: INFO: Pod "downwardapi-volume-74811ecd-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:07:39.900: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod downwardapi-volume-74811ecd-3a34-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:07:39.913: INFO: Waiting for pod downwardapi-volume-74811ecd-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:07:39.916: INFO: Pod downwardapi-volume-74811ecd-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:07:39.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5z86c" for this suite.
Feb 27 02:07:45.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:07:45.986: INFO: namespace: e2e-tests-projected-5z86c, resource: bindings, ignored listing per whitelist
Feb 27 02:07:46.018: INFO: namespace e2e-tests-projected-5z86c deletion completed in 6.086228863s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:07:46.019: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-9cnwr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-9cnwr.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-9cnwr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9cnwr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-9cnwr.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-9cnwr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9cnwr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 27 02:07:58.263: INFO: DNS probes using e2e-tests-dns-9cnwr/dns-test-7974f0d3-3a34-11e9-853a-328ab8481bb7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:07:58.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-9cnwr" for this suite.
Feb 27 02:08:04.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:08:04.315: INFO: namespace: e2e-tests-dns-9cnwr, resource: bindings, ignored listing per whitelist
Feb 27 02:08:04.365: INFO: namespace e2e-tests-dns-9cnwr deletion completed in 6.08961126s

• [SLOW TEST:18.346 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:08:04.365: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-w4npm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 02:08:04.543: INFO: Waiting up to 5m0s for pod "downward-api-8463f405-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-w4npm" to be "success or failure"
Feb 27 02:08:04.548: INFO: Pod "downward-api-8463f405-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.515475ms
Feb 27 02:08:06.550: INFO: Pod "downward-api-8463f405-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007148933s
STEP: Saw pod success
Feb 27 02:08:06.550: INFO: Pod "downward-api-8463f405-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:08:06.553: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod downward-api-8463f405-3a34-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:08:06.574: INFO: Waiting for pod downward-api-8463f405-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:08:06.576: INFO: Pod downward-api-8463f405-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:08:06.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w4npm" for this suite.
Feb 27 02:08:12.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:08:12.633: INFO: namespace: e2e-tests-downward-api-w4npm, resource: bindings, ignored listing per whitelist
Feb 27 02:08:12.687: INFO: namespace e2e-tests-downward-api-w4npm deletion completed in 6.107146709s

• [SLOW TEST:8.322 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:08:12.689: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-xsmn9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0227 02:08:52.916471      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 02:08:52.916: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:08:52.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xsmn9" for this suite.
Feb 27 02:08:58.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:08:58.947: INFO: namespace: e2e-tests-gc-xsmn9, resource: bindings, ignored listing per whitelist
Feb 27 02:08:59.004: INFO: namespace e2e-tests-gc-xsmn9 deletion completed in 6.085020925s

• [SLOW TEST:46.316 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:08:59.005: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tcjqz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tcjqz
Feb 27 02:09:03.187: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tcjqz
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:09:03.189: INFO: Initial restart count of pod liveness-exec is 0
Feb 27 02:09:47.268: INFO: Restart count of pod e2e-tests-container-probe-tcjqz/liveness-exec is now 1 (44.07932342s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:09:47.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tcjqz" for this suite.
Feb 27 02:09:53.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:09:53.354: INFO: namespace: e2e-tests-container-probe-tcjqz, resource: bindings, ignored listing per whitelist
Feb 27 02:09:53.413: INFO: namespace e2e-tests-container-probe-tcjqz deletion completed in 6.132442817s

• [SLOW TEST:54.408 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:09:53.414: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tvz4v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c5655f93-3a34-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:09:53.608: INFO: Waiting up to 5m0s for pod "pod-configmaps-c565d215-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-tvz4v" to be "success or failure"
Feb 27 02:09:53.611: INFO: Pod "pod-configmaps-c565d215-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.395692ms
Feb 27 02:09:55.623: INFO: Pod "pod-configmaps-c565d215-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015493972s
STEP: Saw pod success
Feb 27 02:09:55.623: INFO: Pod "pod-configmaps-c565d215-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:09:55.626: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-c565d215-3a34-11e9-853a-328ab8481bb7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:09:55.641: INFO: Waiting for pod pod-configmaps-c565d215-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:09:55.650: INFO: Pod pod-configmaps-c565d215-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:09:55.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tvz4v" for this suite.
Feb 27 02:10:01.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:01.715: INFO: namespace: e2e-tests-configmap-tvz4v, resource: bindings, ignored listing per whitelist
Feb 27 02:10:01.751: INFO: namespace e2e-tests-configmap-tvz4v deletion completed in 6.09077129s

• [SLOW TEST:8.337 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:01.752: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-99mlt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb 27 02:10:01.950: INFO: Waiting up to 5m0s for pod "client-containers-ca5e7042-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-containers-99mlt" to be "success or failure"
Feb 27 02:10:01.953: INFO: Pod "client-containers-ca5e7042-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.637799ms
Feb 27 02:10:03.957: INFO: Pod "client-containers-ca5e7042-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006386271s
STEP: Saw pod success
Feb 27 02:10:03.957: INFO: Pod "client-containers-ca5e7042-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:10:03.960: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod client-containers-ca5e7042-3a34-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:10:03.975: INFO: Waiting for pod client-containers-ca5e7042-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:10:03.977: INFO: Pod client-containers-ca5e7042-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:10:03.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-99mlt" for this suite.
Feb 27 02:10:09.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:10.035: INFO: namespace: e2e-tests-containers-99mlt, resource: bindings, ignored listing per whitelist
Feb 27 02:10:10.059: INFO: namespace e2e-tests-containers-99mlt deletion completed in 6.079145676s

• [SLOW TEST:8.308 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:10.060: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-h5qdw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:10:10.225: INFO: Creating ReplicaSet my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7
Feb 27 02:10:10.231: INFO: Pod name my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7: Found 0 pods out of 1
Feb 27 02:10:15.234: INFO: Pod name my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7: Found 1 pods out of 1
Feb 27 02:10:15.234: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7" is running
Feb 27 02:10:15.236: INFO: Pod "my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7-79cm4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 02:10:10 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 02:10:11 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 02:10:11 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-27 02:10:10 +0000 UTC Reason: Message:}])
Feb 27 02:10:15.236: INFO: Trying to dial the pod
Feb 27 02:10:20.245: INFO: Controller my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7: Got expected result from replica 1 [my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7-79cm4]: "my-hostname-basic-cf4e8373-3a34-11e9-853a-328ab8481bb7-79cm4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:10:20.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-h5qdw" for this suite.
Feb 27 02:10:26.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:26.287: INFO: namespace: e2e-tests-replicaset-h5qdw, resource: bindings, ignored listing per whitelist
Feb 27 02:10:26.331: INFO: namespace e2e-tests-replicaset-h5qdw deletion completed in 6.08294576s

• [SLOW TEST:16.272 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:26.331: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-df6ln
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb 27 02:10:26.512: INFO: Waiting up to 5m0s for pod "client-containers-d9030a75-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-containers-df6ln" to be "success or failure"
Feb 27 02:10:26.516: INFO: Pod "client-containers-d9030a75-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.737301ms
Feb 27 02:10:28.520: INFO: Pod "client-containers-d9030a75-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007440659s
STEP: Saw pod success
Feb 27 02:10:28.520: INFO: Pod "client-containers-d9030a75-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:10:28.522: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod client-containers-d9030a75-3a34-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:10:28.536: INFO: Waiting for pod client-containers-d9030a75-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:10:28.538: INFO: Pod client-containers-d9030a75-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:10:28.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-df6ln" for this suite.
Feb 27 02:10:34.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:34.613: INFO: namespace: e2e-tests-containers-df6ln, resource: bindings, ignored listing per whitelist
Feb 27 02:10:34.628: INFO: namespace e2e-tests-containers-df6ln deletion completed in 6.086935037s

• [SLOW TEST:8.297 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:34.630: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-947xh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 27 02:10:34.821: INFO: Waiting up to 5m0s for pod "pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-947xh" to be "success or failure"
Feb 27 02:10:34.823: INFO: Pod "pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.301456ms
Feb 27 02:10:36.827: INFO: Pod "pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005815822s
Feb 27 02:10:38.830: INFO: Pod "pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008725645s
STEP: Saw pod success
Feb 27 02:10:38.830: INFO: Pod "pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:10:38.831: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:10:38.843: INFO: Waiting for pod pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:10:38.846: INFO: Pod pod-ddf5e5dd-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:10:38.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-947xh" for this suite.
Feb 27 02:10:44.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:44.915: INFO: namespace: e2e-tests-emptydir-947xh, resource: bindings, ignored listing per whitelist
Feb 27 02:10:44.926: INFO: namespace e2e-tests-emptydir-947xh deletion completed in 6.077274019s

• [SLOW TEST:10.296 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:44.929: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f68jv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:10:45.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e4206278-3a34-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-f68jv" to be "success or failure"
Feb 27 02:10:45.167: INFO: Pod "downwardapi-volume-e4206278-3a34-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.353382ms
Feb 27 02:10:47.171: INFO: Pod "downwardapi-volume-e4206278-3a34-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00932128s
STEP: Saw pod success
Feb 27 02:10:47.171: INFO: Pod "downwardapi-volume-e4206278-3a34-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:10:47.173: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-e4206278-3a34-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:10:47.188: INFO: Waiting for pod downwardapi-volume-e4206278-3a34-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:10:47.189: INFO: Pod downwardapi-volume-e4206278-3a34-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:10:47.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f68jv" for this suite.
Feb 27 02:10:53.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:10:53.216: INFO: namespace: e2e-tests-projected-f68jv, resource: bindings, ignored listing per whitelist
Feb 27 02:10:53.284: INFO: namespace e2e-tests-projected-f68jv deletion completed in 6.091762547s

• [SLOW TEST:8.355 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:10:53.284: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-hrlkd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-hrlkd
Feb 27 02:10:55.488: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-hrlkd
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:10:55.490: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:14:55.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hrlkd" for this suite.
Feb 27 02:15:01.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:15:01.937: INFO: namespace: e2e-tests-container-probe-hrlkd, resource: bindings, ignored listing per whitelist
Feb 27 02:15:01.990: INFO: namespace e2e-tests-container-probe-hrlkd deletion completed in 6.0752546s

• [SLOW TEST:248.706 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:15:01.991: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b5z8s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:15:02.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 version'
Feb 27 02:15:02.205: INFO: stderr: ""
Feb 27 02:15:02.205: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:15:02.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b5z8s" for this suite.
Feb 27 02:15:08.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:15:08.281: INFO: namespace: e2e-tests-kubectl-b5z8s, resource: bindings, ignored listing per whitelist
Feb 27 02:15:08.285: INFO: namespace e2e-tests-kubectl-b5z8s deletion completed in 6.076673793s

• [SLOW TEST:6.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:15:08.285: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-6czn5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:15:08.450: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:15:10.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6czn5" for this suite.
Feb 27 02:16:02.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:16:02.628: INFO: namespace: e2e-tests-pods-6czn5, resource: bindings, ignored listing per whitelist
Feb 27 02:16:02.661: INFO: namespace e2e-tests-pods-6czn5 deletion completed in 52.088232659s

• [SLOW TEST:54.376 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:16:02.662: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-sm82n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:16:02.863: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 27 02:16:07.868: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 02:16:07.868: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:16:07.887: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-sm82n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-sm82n/deployments/test-cleanup-deployment,UID:a47c583c-3a35-11e9-bb22-deadbe9ffdf9,ResourceVersion:20660,Generation:1,CreationTimestamp:2019-02-27 02:16:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb 27 02:16:07.889: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:16:07.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-sm82n" for this suite.
Feb 27 02:16:13.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:16:13.948: INFO: namespace: e2e-tests-deployment-sm82n, resource: bindings, ignored listing per whitelist
Feb 27 02:16:14.006: INFO: namespace e2e-tests-deployment-sm82n deletion completed in 6.090087699s

• [SLOW TEST:11.345 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:16:14.008: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-dxblx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:17:14.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dxblx" for this suite.
Feb 27 02:17:36.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:17:36.255: INFO: namespace: e2e-tests-container-probe-dxblx, resource: bindings, ignored listing per whitelist
Feb 27 02:17:36.289: INFO: namespace e2e-tests-container-probe-dxblx deletion completed in 22.096614628s

• [SLOW TEST:82.281 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:17:36.289: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-fr894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-fr894;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-fr894;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-fr894.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-fr894.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fr894.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 192.139.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.139.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.139.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.139.192_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-fr894;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-fr894;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fr894.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-fr894.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fr894.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-fr894.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fr894.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 192.139.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.139.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.139.31.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.31.139.192_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 27 02:17:48.526: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.529: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.531: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-fr894 from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.534: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-fr894 from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.536: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.539: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.541: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.544: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.563: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.566: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.569: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fr894 from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.572: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fr894 from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.574: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.578: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.580: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.583: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc from pod e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7: the server could not find the requested resource (get pods dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7)
Feb 27 02:17:48.600: INFO: Lookups using e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-fr894 wheezy_tcp@dns-test-service.e2e-tests-dns-fr894 wheezy_udp@dns-test-service.e2e-tests-dns-fr894.svc wheezy_tcp@dns-test-service.e2e-tests-dns-fr894.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-fr894 jessie_tcp@dns-test-service.e2e-tests-dns-fr894 jessie_udp@dns-test-service.e2e-tests-dns-fr894.svc jessie_tcp@dns-test-service.e2e-tests-dns-fr894.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fr894.svc]

Feb 27 02:17:53.693: INFO: DNS probes using e2e-tests-dns-fr894/dns-test-d94e1f1d-3a35-11e9-853a-328ab8481bb7 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:17:53.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-fr894" for this suite.
Feb 27 02:17:59.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:17:59.776: INFO: namespace: e2e-tests-dns-fr894, resource: bindings, ignored listing per whitelist
Feb 27 02:17:59.829: INFO: namespace e2e-tests-dns-fr894 deletion completed in 6.081228863s

• [SLOW TEST:23.539 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:17:59.829: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lgw22
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:18:00.021: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e752c31c-3a35-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-lgw22" to be "success or failure"
Feb 27 02:18:00.026: INFO: Pod "downwardapi-volume-e752c31c-3a35-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.836492ms
Feb 27 02:18:02.031: INFO: Pod "downwardapi-volume-e752c31c-3a35-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009073131s
STEP: Saw pod success
Feb 27 02:18:02.031: INFO: Pod "downwardapi-volume-e752c31c-3a35-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:18:02.033: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-e752c31c-3a35-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:18:02.047: INFO: Waiting for pod downwardapi-volume-e752c31c-3a35-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:18:02.050: INFO: Pod downwardapi-volume-e752c31c-3a35-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:18:02.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lgw22" for this suite.
Feb 27 02:18:08.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:18:08.104: INFO: namespace: e2e-tests-downward-api-lgw22, resource: bindings, ignored listing per whitelist
Feb 27 02:18:08.130: INFO: namespace e2e-tests-downward-api-lgw22 deletion completed in 6.076890655s

• [SLOW TEST:8.301 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:18:08.130: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-c7g58
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:18:10.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-c7g58" for this suite.
Feb 27 02:19:00.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:19:00.363: INFO: namespace: e2e-tests-kubelet-test-c7g58, resource: bindings, ignored listing per whitelist
Feb 27 02:19:00.401: INFO: namespace e2e-tests-kubelet-test-c7g58 deletion completed in 50.080377506s

• [SLOW TEST:52.271 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:19:00.401: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4s987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 27 02:19:00.584: INFO: Waiting up to 5m0s for pod "pod-0b6be8e5-3a36-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-4s987" to be "success or failure"
Feb 27 02:19:00.589: INFO: Pod "pod-0b6be8e5-3a36-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.758864ms
Feb 27 02:19:02.593: INFO: Pod "pod-0b6be8e5-3a36-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007957575s
STEP: Saw pod success
Feb 27 02:19:02.593: INFO: Pod "pod-0b6be8e5-3a36-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:19:02.595: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-0b6be8e5-3a36-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:19:02.609: INFO: Waiting for pod pod-0b6be8e5-3a36-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:19:02.612: INFO: Pod pod-0b6be8e5-3a36-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:19:02.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4s987" for this suite.
Feb 27 02:19:08.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:19:08.634: INFO: namespace: e2e-tests-emptydir-4s987, resource: bindings, ignored listing per whitelist
Feb 27 02:19:08.698: INFO: namespace e2e-tests-emptydir-4s987 deletion completed in 6.082429049s

• [SLOW TEST:8.297 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:19:08.700: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-q4zmv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 27 02:19:08.875: INFO: Waiting up to 5m0s for pod "pod-105d277c-3a36-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-q4zmv" to be "success or failure"
Feb 27 02:19:08.877: INFO: Pod "pod-105d277c-3a36-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.314721ms
Feb 27 02:19:10.882: INFO: Pod "pod-105d277c-3a36-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006783677s
STEP: Saw pod success
Feb 27 02:19:10.882: INFO: Pod "pod-105d277c-3a36-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:19:10.884: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-105d277c-3a36-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:19:10.899: INFO: Waiting for pod pod-105d277c-3a36-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:19:10.913: INFO: Pod pod-105d277c-3a36-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:19:10.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q4zmv" for this suite.
Feb 27 02:19:16.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:19:17.004: INFO: namespace: e2e-tests-emptydir-q4zmv, resource: bindings, ignored listing per whitelist
Feb 27 02:19:17.006: INFO: namespace e2e-tests-emptydir-q4zmv deletion completed in 6.090068039s

• [SLOW TEST:8.306 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:19:17.007: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-kfg97
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 27 02:19:19.698: INFO: Successfully updated pod "pod-update-155082c8-3a36-11e9-853a-328ab8481bb7"
STEP: verifying the updated pod is in kubernetes
Feb 27 02:19:19.714: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:19:19.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kfg97" for this suite.
Feb 27 02:19:41.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:19:41.810: INFO: namespace: e2e-tests-pods-kfg97, resource: bindings, ignored listing per whitelist
Feb 27 02:19:41.814: INFO: namespace e2e-tests-pods-kfg97 deletion completed in 22.09017637s

• [SLOW TEST:24.807 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:19:41.815: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-clz2g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 27 02:19:42.001: INFO: Waiting up to 5m0s for pod "pod-241b5d42-3a36-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-clz2g" to be "success or failure"
Feb 27 02:19:42.005: INFO: Pod "pod-241b5d42-3a36-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.194718ms
Feb 27 02:19:44.009: INFO: Pod "pod-241b5d42-3a36-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007996872s
STEP: Saw pod success
Feb 27 02:19:44.009: INFO: Pod "pod-241b5d42-3a36-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:19:44.011: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-241b5d42-3a36-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:19:44.025: INFO: Waiting for pod pod-241b5d42-3a36-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:19:44.027: INFO: Pod pod-241b5d42-3a36-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:19:44.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-clz2g" for this suite.
Feb 27 02:19:50.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:19:50.088: INFO: namespace: e2e-tests-emptydir-clz2g, resource: bindings, ignored listing per whitelist
Feb 27 02:19:50.107: INFO: namespace e2e-tests-emptydir-clz2g deletion completed in 6.076863258s

• [SLOW TEST:8.293 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:19:50.109: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9dkct
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 02:19:50.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9dkct'
Feb 27 02:19:50.452: INFO: stderr: ""
Feb 27 02:19:50.452: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb 27 02:19:50.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-9dkct'
Feb 27 02:19:57.673: INFO: stderr: ""
Feb 27 02:19:57.673: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:19:57.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9dkct" for this suite.
Feb 27 02:20:03.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:20:03.769: INFO: namespace: e2e-tests-kubectl-9dkct, resource: bindings, ignored listing per whitelist
Feb 27 02:20:03.777: INFO: namespace e2e-tests-kubectl-9dkct deletion completed in 6.100535435s

• [SLOW TEST:13.668 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:20:03.778: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hwxvt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 27 02:20:03.982: INFO: Waiting up to 5m0s for pod "pod-313568e2-3a36-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-hwxvt" to be "success or failure"
Feb 27 02:20:03.989: INFO: Pod "pod-313568e2-3a36-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.617182ms
Feb 27 02:20:05.992: INFO: Pod "pod-313568e2-3a36-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009783579s
STEP: Saw pod success
Feb 27 02:20:05.992: INFO: Pod "pod-313568e2-3a36-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:20:05.994: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-313568e2-3a36-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:20:06.007: INFO: Waiting for pod pod-313568e2-3a36-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:20:06.019: INFO: Pod pod-313568e2-3a36-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:20:06.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hwxvt" for this suite.
Feb 27 02:20:12.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:20:12.095: INFO: namespace: e2e-tests-emptydir-hwxvt, resource: bindings, ignored listing per whitelist
Feb 27 02:20:12.123: INFO: namespace e2e-tests-emptydir-hwxvt deletion completed in 6.10068323s

• [SLOW TEST:8.344 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:20:12.123: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-zg8hj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 27 02:20:16.343: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:20:16.345: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:20:18.346: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:20:18.349: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:20:20.346: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:20:20.349: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:20:22.346: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:20:22.349: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:20:24.346: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:20:24.349: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:20:26.346: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:20:26.350: INFO: Pod pod-with-poststart-http-hook still exists
Feb 27 02:20:28.346: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 27 02:20:28.350: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:20:28.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zg8hj" for this suite.
Feb 27 02:20:50.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:20:50.389: INFO: namespace: e2e-tests-container-lifecycle-hook-zg8hj, resource: bindings, ignored listing per whitelist
Feb 27 02:20:50.441: INFO: namespace e2e-tests-container-lifecycle-hook-zg8hj deletion completed in 22.088459117s

• [SLOW TEST:38.317 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:20:50.441: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-bs5zt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 02:20:50.625: INFO: Waiting up to 5m0s for pod "downward-api-4d0222cf-3a36-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-bs5zt" to be "success or failure"
Feb 27 02:20:50.640: INFO: Pod "downward-api-4d0222cf-3a36-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.124611ms
Feb 27 02:20:52.643: INFO: Pod "downward-api-4d0222cf-3a36-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018141439s
STEP: Saw pod success
Feb 27 02:20:52.643: INFO: Pod "downward-api-4d0222cf-3a36-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:20:52.646: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod downward-api-4d0222cf-3a36-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:20:52.673: INFO: Waiting for pod downward-api-4d0222cf-3a36-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:20:52.675: INFO: Pod downward-api-4d0222cf-3a36-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:20:52.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bs5zt" for this suite.
Feb 27 02:20:58.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:20:58.710: INFO: namespace: e2e-tests-downward-api-bs5zt, resource: bindings, ignored listing per whitelist
Feb 27 02:20:58.771: INFO: namespace e2e-tests-downward-api-bs5zt deletion completed in 6.093012575s

• [SLOW TEST:8.330 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:20:58.772: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-m6kr6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 02:20:58.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-m6kr6'
Feb 27 02:20:59.013: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 02:20:59.013: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb 27 02:20:59.017: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 27 02:20:59.028: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 27 02:20:59.043: INFO: scanned /root for discovery docs: <nil>
Feb 27 02:20:59.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-m6kr6'
Feb 27 02:21:14.796: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 27 02:21:14.796: INFO: stdout: "Created e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e\nScaling up e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb 27 02:21:14.796: INFO: stdout: "Created e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e\nScaling up e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb 27 02:21:14.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-m6kr6'
Feb 27 02:21:14.869: INFO: stderr: ""
Feb 27 02:21:14.869: INFO: stdout: "e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e-n5bck "
Feb 27 02:21:14.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e-n5bck -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m6kr6'
Feb 27 02:21:14.925: INFO: stderr: ""
Feb 27 02:21:14.925: INFO: stdout: "true"
Feb 27 02:21:14.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e-n5bck -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-m6kr6'
Feb 27 02:21:14.996: INFO: stderr: ""
Feb 27 02:21:14.996: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb 27 02:21:14.996: INFO: e2e-test-nginx-rc-536fd10cee1277d44d338bf4bc00e85e-n5bck is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb 27 02:21:14.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-m6kr6'
Feb 27 02:21:15.069: INFO: stderr: ""
Feb 27 02:21:15.069: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:21:15.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m6kr6" for this suite.
Feb 27 02:21:37.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:21:37.142: INFO: namespace: e2e-tests-kubectl-m6kr6, resource: bindings, ignored listing per whitelist
Feb 27 02:21:37.159: INFO: namespace e2e-tests-kubectl-m6kr6 deletion completed in 22.086916684s

• [SLOW TEST:38.387 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:21:37.160: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-mch5s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mch5s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 02:21:37.331: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 02:21:59.417: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.45.102 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mch5s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:21:59.417: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 02:22:00.515: INFO: Found all expected endpoints: [netserver-0]
Feb 27 02:22:00.518: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.87.195 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mch5s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:22:00.518: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 02:22:01.606: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:22:01.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mch5s" for this suite.
Feb 27 02:22:23.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:22:23.644: INFO: namespace: e2e-tests-pod-network-test-mch5s, resource: bindings, ignored listing per whitelist
Feb 27 02:22:23.720: INFO: namespace e2e-tests-pod-network-test-mch5s deletion completed in 22.106466737s

• [SLOW TEST:46.560 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:22:23.721: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-tm6hh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-tm6hh
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-tm6hh
STEP: Deleting pre-stop pod
Feb 27 02:22:34.937: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:22:34.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-tm6hh" for this suite.
Feb 27 02:23:12.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:23:13.027: INFO: namespace: e2e-tests-prestop-tm6hh, resource: bindings, ignored listing per whitelist
Feb 27 02:23:13.047: INFO: namespace e2e-tests-prestop-tm6hh deletion completed in 38.097354997s

• [SLOW TEST:49.326 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:23:13.047: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gwccv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a201373d-3a36-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:23:13.222: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a201a161-3a36-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-gwccv" to be "success or failure"
Feb 27 02:23:13.224: INFO: Pod "pod-projected-configmaps-a201a161-3a36-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043682ms
Feb 27 02:23:15.227: INFO: Pod "pod-projected-configmaps-a201a161-3a36-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005311462s
STEP: Saw pod success
Feb 27 02:23:15.227: INFO: Pod "pod-projected-configmaps-a201a161-3a36-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:23:15.228: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-configmaps-a201a161-3a36-11e9-853a-328ab8481bb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:23:15.245: INFO: Waiting for pod pod-projected-configmaps-a201a161-3a36-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:23:15.247: INFO: Pod pod-projected-configmaps-a201a161-3a36-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:23:15.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gwccv" for this suite.
Feb 27 02:23:21.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:23:21.319: INFO: namespace: e2e-tests-projected-gwccv, resource: bindings, ignored listing per whitelist
Feb 27 02:23:21.355: INFO: namespace e2e-tests-projected-gwccv deletion completed in 6.105366219s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:23:21.355: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-d8hcl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 02:23:21.519: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:23:25.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-d8hcl" for this suite.
Feb 27 02:23:47.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:23:47.304: INFO: namespace: e2e-tests-init-container-d8hcl, resource: bindings, ignored listing per whitelist
Feb 27 02:23:47.391: INFO: namespace e2e-tests-init-container-d8hcl deletion completed in 22.13450903s

• [SLOW TEST:26.036 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:23:47.394: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-8qx5p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 27 02:23:51.588: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 02:23:51.590: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 02:23:53.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 02:23:53.594: INFO: Pod pod-with-prestop-http-hook still exists
Feb 27 02:23:55.591: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 27 02:23:55.593: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:23:55.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8qx5p" for this suite.
Feb 27 02:24:17.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:24:17.689: INFO: namespace: e2e-tests-container-lifecycle-hook-8qx5p, resource: bindings, ignored listing per whitelist
Feb 27 02:24:17.695: INFO: namespace e2e-tests-container-lifecycle-hook-8qx5p deletion completed in 22.09348499s

• [SLOW TEST:30.301 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:24:17.695: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-rpnxx
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c892bf0f-3a36-11e9-853a-328ab8481bb7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:24:19.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rpnxx" for this suite.
Feb 27 02:24:41.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:24:42.023: INFO: namespace: e2e-tests-configmap-rpnxx, resource: bindings, ignored listing per whitelist
Feb 27 02:24:42.052: INFO: namespace e2e-tests-configmap-rpnxx deletion completed in 22.102204066s

• [SLOW TEST:24.357 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:24:42.052: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6m6nx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d7105725-3a36-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:24:42.243: INFO: Waiting up to 5m0s for pod "pod-secrets-d710fab8-3a36-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-6m6nx" to be "success or failure"
Feb 27 02:24:42.246: INFO: Pod "pod-secrets-d710fab8-3a36-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.812336ms
Feb 27 02:24:44.251: INFO: Pod "pod-secrets-d710fab8-3a36-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007841056s
STEP: Saw pod success
Feb 27 02:24:44.251: INFO: Pod "pod-secrets-d710fab8-3a36-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:24:44.254: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-d710fab8-3a36-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:24:44.276: INFO: Waiting for pod pod-secrets-d710fab8-3a36-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:24:44.279: INFO: Pod pod-secrets-d710fab8-3a36-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:24:44.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6m6nx" for this suite.
Feb 27 02:24:50.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:24:50.382: INFO: namespace: e2e-tests-secrets-6m6nx, resource: bindings, ignored listing per whitelist
Feb 27 02:24:50.383: INFO: namespace e2e-tests-secrets-6m6nx deletion completed in 6.091015481s

• [SLOW TEST:8.331 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:24:50.384: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-xqbst
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xqbst
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xqbst
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xqbst
Feb 27 02:24:50.562: INFO: Found 0 stateful pods, waiting for 1
Feb 27 02:25:00.566: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 27 02:25:00.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-xqbst ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:25:00.720: INFO: stderr: ""
Feb 27 02:25:00.720: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:25:00.720: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:25:00.722: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 27 02:25:10.726: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:25:10.726: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:25:10.734: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Feb 27 02:25:10.735: INFO: ss-0  worker-0ut0w-6f5f764f5c-rj65d  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:24:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:24:50 +0000 UTC  }]
Feb 27 02:25:10.735: INFO: 
Feb 27 02:25:10.735: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 27 02:25:11.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997518883s
Feb 27 02:25:12.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993583948s
Feb 27 02:25:13.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989059234s
Feb 27 02:25:14.750: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985540326s
Feb 27 02:25:15.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981979837s
Feb 27 02:25:16.757: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978257994s
Feb 27 02:25:17.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974649473s
Feb 27 02:25:18.765: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970868764s
Feb 27 02:25:19.769: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.165628ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xqbst
Feb 27 02:25:20.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-xqbst ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:25:20.910: INFO: stderr: ""
Feb 27 02:25:20.910: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:25:20.910: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:25:20.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-xqbst ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:25:21.064: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 27 02:25:21.064: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:25:21.064: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:25:21.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-xqbst ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb 27 02:25:21.221: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb 27 02:25:21.221: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb 27 02:25:21.221: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb 27 02:25:21.224: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:25:21.224: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:25:21.224: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 27 02:25:21.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-xqbst ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:25:21.390: INFO: stderr: ""
Feb 27 02:25:21.390: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:25:21.390: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:25:21.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-xqbst ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:25:21.542: INFO: stderr: ""
Feb 27 02:25:21.542: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:25:21.542: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:25:21.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 exec --namespace=e2e-tests-statefulset-xqbst ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb 27 02:25:21.741: INFO: stderr: ""
Feb 27 02:25:21.741: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb 27 02:25:21.741: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb 27 02:25:21.741: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:25:21.743: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 27 02:25:31.749: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:25:31.749: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:25:31.749: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 27 02:25:31.758: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Feb 27 02:25:31.758: INFO: ss-0  worker-0ut0w-6f5f764f5c-rj65d  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:24:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:24:50 +0000 UTC  }]
Feb 27 02:25:31.758: INFO: ss-1  worker-v332t-5ff768bb65-6znm5  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  }]
Feb 27 02:25:31.758: INFO: ss-2  worker-0ut0w-6f5f764f5c-rj65d  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  }]
Feb 27 02:25:31.758: INFO: 
Feb 27 02:25:31.758: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 27 02:25:32.762: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Feb 27 02:25:32.762: INFO: ss-0  worker-0ut0w-6f5f764f5c-rj65d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:24:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:24:50 +0000 UTC  }]
Feb 27 02:25:32.762: INFO: ss-1  worker-v332t-5ff768bb65-6znm5  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  }]
Feb 27 02:25:32.762: INFO: ss-2  worker-0ut0w-6f5f764f5c-rj65d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:25:10 +0000 UTC  }]
Feb 27 02:25:32.762: INFO: 
Feb 27 02:25:32.762: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 27 02:25:33.768: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.991507459s
Feb 27 02:25:34.771: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.986565901s
Feb 27 02:25:35.774: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.984004573s
Feb 27 02:25:36.780: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.980648337s
Feb 27 02:25:37.783: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.974790019s
Feb 27 02:25:38.786: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.971424708s
Feb 27 02:25:39.789: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.968948001s
Feb 27 02:25:40.790: INFO: Verifying statefulset ss doesn't scale past 0 for another 966.153038ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xqbst
Feb 27 02:25:41.793: INFO: Scaling statefulset ss to 0
Feb 27 02:25:41.800: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 02:25:41.803: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xqbst
Feb 27 02:25:41.805: INFO: Scaling statefulset ss to 0
Feb 27 02:25:41.811: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:25:41.813: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:25:41.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xqbst" for this suite.
Feb 27 02:25:47.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:25:47.852: INFO: namespace: e2e-tests-statefulset-xqbst, resource: bindings, ignored listing per whitelist
Feb 27 02:25:47.930: INFO: namespace e2e-tests-statefulset-xqbst deletion completed in 6.104498507s

• [SLOW TEST:57.547 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:25:47.932: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zdwg5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb 27 02:25:48.114: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-766965386 proxy --unix-socket=/tmp/kubectl-proxy-unix662974049/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:25:48.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zdwg5" for this suite.
Feb 27 02:25:54.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:25:54.228: INFO: namespace: e2e-tests-kubectl-zdwg5, resource: bindings, ignored listing per whitelist
Feb 27 02:25:54.241: INFO: namespace e2e-tests-kubectl-zdwg5 deletion completed in 6.082311344s

• [SLOW TEST:6.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:25:54.242: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-85kgg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 02:25:56.957: INFO: Successfully updated pod "annotationupdate0217ae44-3a37-11e9-853a-328ab8481bb7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:25:58.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-85kgg" for this suite.
Feb 27 02:26:20.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:26:21.051: INFO: namespace: e2e-tests-projected-85kgg, resource: bindings, ignored listing per whitelist
Feb 27 02:26:21.071: INFO: namespace e2e-tests-projected-85kgg deletion completed in 22.097411046s

• [SLOW TEST:26.829 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:26:21.071: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-58c2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 27 02:26:21.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-58c2t'
Feb 27 02:26:21.401: INFO: stderr: ""
Feb 27 02:26:21.401: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 02:26:22.404: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:26:22.404: INFO: Found 1 / 1
Feb 27 02:26:22.404: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 27 02:26:22.406: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:26:22.406: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 02:26:22.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 patch pod redis-master-552pw --namespace=e2e-tests-kubectl-58c2t -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 27 02:26:22.475: INFO: stderr: ""
Feb 27 02:26:22.475: INFO: stdout: "pod/redis-master-552pw patched\n"
STEP: checking annotations
Feb 27 02:26:22.477: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:26:22.477: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:26:22.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-58c2t" for this suite.
Feb 27 02:26:44.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:26:44.528: INFO: namespace: e2e-tests-kubectl-58c2t, resource: bindings, ignored listing per whitelist
Feb 27 02:26:44.592: INFO: namespace e2e-tests-kubectl-58c2t deletion completed in 22.111159743s

• [SLOW TEST:23.521 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:26:44.592: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-vd42l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb 27 02:26:44.771: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-vd42l" to be "success or failure"
Feb 27 02:26:44.775: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.921078ms
Feb 27 02:26:46.778: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007652655s
STEP: Saw pod success
Feb 27 02:26:46.778: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 27 02:26:46.780: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 27 02:26:46.793: INFO: Waiting for pod pod-host-path-test to disappear
Feb 27 02:26:46.795: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:26:46.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-vd42l" for this suite.
Feb 27 02:26:52.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:26:52.851: INFO: namespace: e2e-tests-hostpath-vd42l, resource: bindings, ignored listing per whitelist
Feb 27 02:26:52.883: INFO: namespace e2e-tests-hostpath-vd42l deletion completed in 6.084296317s

• [SLOW TEST:8.291 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:26:52.884: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-pzjz6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 02:26:53.047: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:26:55.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pzjz6" for this suite.
Feb 27 02:27:01.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:27:01.819: INFO: namespace: e2e-tests-init-container-pzjz6, resource: bindings, ignored listing per whitelist
Feb 27 02:27:01.854: INFO: namespace e2e-tests-init-container-pzjz6 deletion completed in 6.083797727s

• [SLOW TEST:8.970 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:27:01.855: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-grhhk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:27:02.086: INFO: (0) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.470727ms)
Feb 27 02:27:02.092: INFO: (1) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.516285ms)
Feb 27 02:27:02.099: INFO: (2) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.385952ms)
Feb 27 02:27:02.102: INFO: (3) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.63795ms)
Feb 27 02:27:02.104: INFO: (4) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.4763ms)
Feb 27 02:27:02.107: INFO: (5) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.037727ms)
Feb 27 02:27:02.116: INFO: (6) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.262156ms)
Feb 27 02:27:02.121: INFO: (7) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.924979ms)
Feb 27 02:27:02.124: INFO: (8) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.737536ms)
Feb 27 02:27:02.127: INFO: (9) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.918157ms)
Feb 27 02:27:02.131: INFO: (10) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.809635ms)
Feb 27 02:27:02.143: INFO: (11) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.32994ms)
Feb 27 02:27:02.153: INFO: (12) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.819903ms)
Feb 27 02:27:02.175: INFO: (13) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 21.899082ms)
Feb 27 02:27:02.182: INFO: (14) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 6.927131ms)
Feb 27 02:27:02.192: INFO: (15) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 9.378243ms)
Feb 27 02:27:02.195: INFO: (16) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.560361ms)
Feb 27 02:27:02.203: INFO: (17) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.929863ms)
Feb 27 02:27:02.217: INFO: (18) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.535494ms)
Feb 27 02:27:02.222: INFO: (19) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.35168ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:27:02.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-grhhk" for this suite.
Feb 27 02:27:08.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:27:08.307: INFO: namespace: e2e-tests-proxy-grhhk, resource: bindings, ignored listing per whitelist
Feb 27 02:27:08.315: INFO: namespace e2e-tests-proxy-grhhk deletion completed in 6.09006463s

• [SLOW TEST:6.461 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:27:08.315: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-xd87d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 27 02:27:12.528: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:12.530: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:14.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:14.534: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:16.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:16.535: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:18.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:18.534: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:20.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:20.534: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:22.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:22.534: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:24.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:24.535: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:26.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:26.534: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:28.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:28.533: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:30.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:30.534: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:32.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:32.533: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:34.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:34.537: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:36.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:36.534: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 27 02:27:38.530: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 27 02:27:38.534: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:27:38.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-xd87d" for this suite.
Feb 27 02:28:00.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:28:00.618: INFO: namespace: e2e-tests-container-lifecycle-hook-xd87d, resource: bindings, ignored listing per whitelist
Feb 27 02:28:00.622: INFO: namespace e2e-tests-container-lifecycle-hook-xd87d deletion completed in 22.084864182s

• [SLOW TEST:52.306 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:28:00.623: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-nthc5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 02:28:00.821: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:00.825: INFO: Number of nodes with available pods: 0
Feb 27 02:28:00.825: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:01.829: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:01.832: INFO: Number of nodes with available pods: 0
Feb 27 02:28:01.832: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:02.829: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:02.831: INFO: Number of nodes with available pods: 0
Feb 27 02:28:02.831: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:03.829: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:03.832: INFO: Number of nodes with available pods: 2
Feb 27 02:28:03.832: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 27 02:28:03.843: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:03.845: INFO: Number of nodes with available pods: 1
Feb 27 02:28:03.845: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:04.854: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:04.856: INFO: Number of nodes with available pods: 1
Feb 27 02:28:04.856: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:05.850: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:05.853: INFO: Number of nodes with available pods: 1
Feb 27 02:28:05.853: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:06.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:06.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:06.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:07.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:07.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:07.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:08.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:08.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:08.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:09.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:09.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:09.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:10.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:10.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:10.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:11.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:11.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:11.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:12.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:12.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:12.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:13.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:13.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:13.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:14.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:14.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:14.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:15.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:15.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:15.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:16.858: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:16.860: INFO: Number of nodes with available pods: 1
Feb 27 02:28:16.860: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:17.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:17.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:17.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:18.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:18.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:18.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:19.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:19.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:19.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:20.851: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:20.854: INFO: Number of nodes with available pods: 1
Feb 27 02:28:20.854: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:21.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:21.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:21.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:22.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:22.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:22.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:23.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:23.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:23.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:24.857: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:24.859: INFO: Number of nodes with available pods: 1
Feb 27 02:28:24.859: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:25.851: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:25.853: INFO: Number of nodes with available pods: 1
Feb 27 02:28:25.853: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:26.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:26.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:26.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:27.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:27.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:27.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:28.863: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:28.865: INFO: Number of nodes with available pods: 1
Feb 27 02:28:28.865: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:29.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:29.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:29.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:30.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:30.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:30.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:31.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:31.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:31.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:32.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:32.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:32.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:33.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:33.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:33.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:34.851: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:34.856: INFO: Number of nodes with available pods: 1
Feb 27 02:28:34.856: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:35.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:35.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:35.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:36.850: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:36.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:36.853: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:37.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:37.859: INFO: Number of nodes with available pods: 1
Feb 27 02:28:37.859: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:38.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:38.853: INFO: Number of nodes with available pods: 1
Feb 27 02:28:38.853: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:39.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:39.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:39.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:40.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:40.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:40.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:41.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:41.856: INFO: Number of nodes with available pods: 1
Feb 27 02:28:41.856: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:42.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:42.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:42.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:43.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:43.850: INFO: Number of nodes with available pods: 1
Feb 27 02:28:43.850: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:44.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:44.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:44.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:45.850: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:45.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:45.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:46.850: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:46.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:46.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:47.850: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:47.852: INFO: Number of nodes with available pods: 1
Feb 27 02:28:47.852: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:48.849: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:48.851: INFO: Number of nodes with available pods: 1
Feb 27 02:28:48.851: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:28:49.848: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:28:49.851: INFO: Number of nodes with available pods: 2
Feb 27 02:28:49.851: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nthc5, will wait for the garbage collector to delete the pods
Feb 27 02:28:49.915: INFO: Deleting DaemonSet.extensions daemon-set took: 3.879246ms
Feb 27 02:28:50.015: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.295507ms
Feb 27 02:29:23.817: INFO: Number of nodes with available pods: 0
Feb 27 02:29:23.817: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 02:29:23.819: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nthc5/daemonsets","resourceVersion":"23383"},"items":null}

Feb 27 02:29:23.820: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nthc5/pods","resourceVersion":"23383"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:29:23.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nthc5" for this suite.
Feb 27 02:29:29.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:29:29.909: INFO: namespace: e2e-tests-daemonsets-nthc5, resource: bindings, ignored listing per whitelist
Feb 27 02:29:29.917: INFO: namespace e2e-tests-daemonsets-nthc5 deletion completed in 6.088953016s

• [SLOW TEST:89.295 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:29:29.918: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-278vn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:29:30.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82a2f192-3a37-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-278vn" to be "success or failure"
Feb 27 02:29:30.096: INFO: Pod "downwardapi-volume-82a2f192-3a37-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.077419ms
Feb 27 02:29:32.099: INFO: Pod "downwardapi-volume-82a2f192-3a37-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009878937s
STEP: Saw pod success
Feb 27 02:29:32.100: INFO: Pod "downwardapi-volume-82a2f192-3a37-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:29:32.101: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-82a2f192-3a37-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:29:32.116: INFO: Waiting for pod downwardapi-volume-82a2f192-3a37-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:29:32.118: INFO: Pod downwardapi-volume-82a2f192-3a37-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:29:32.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-278vn" for this suite.
Feb 27 02:29:38.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:29:38.174: INFO: namespace: e2e-tests-projected-278vn, resource: bindings, ignored listing per whitelist
Feb 27 02:29:38.198: INFO: namespace e2e-tests-projected-278vn deletion completed in 6.077218706s

• [SLOW TEST:8.281 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:29:38.201: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-65w7b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb 27 02:29:38.895: INFO: created pod pod-service-account-defaultsa
Feb 27 02:29:38.896: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 27 02:29:38.914: INFO: created pod pod-service-account-mountsa
Feb 27 02:29:38.914: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 27 02:29:38.923: INFO: created pod pod-service-account-nomountsa
Feb 27 02:29:38.923: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 27 02:29:38.931: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 27 02:29:38.931: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 27 02:29:38.938: INFO: created pod pod-service-account-mountsa-mountspec
Feb 27 02:29:38.938: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 27 02:29:38.945: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 27 02:29:38.945: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 27 02:29:38.951: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 27 02:29:38.951: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 27 02:29:38.959: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 27 02:29:38.959: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 27 02:29:38.965: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 27 02:29:38.965: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:29:38.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-65w7b" for this suite.
Feb 27 02:29:45.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:29:45.080: INFO: namespace: e2e-tests-svcaccounts-65w7b, resource: bindings, ignored listing per whitelist
Feb 27 02:29:45.104: INFO: namespace e2e-tests-svcaccounts-65w7b deletion completed in 6.118413392s

• [SLOW TEST:6.903 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:29:45.105: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-hpqmt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:29:45.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hpqmt" for this suite.
Feb 27 02:29:51.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:29:51.394: INFO: namespace: e2e-tests-services-hpqmt, resource: bindings, ignored listing per whitelist
Feb 27 02:29:51.397: INFO: namespace e2e-tests-services-hpqmt deletion completed in 6.093917622s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.292 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:29:51.397: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-h2rkv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 27 02:29:51.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:51.873: INFO: stderr: ""
Feb 27 02:29:51.873: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 02:29:51.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:51.950: INFO: stderr: ""
Feb 27 02:29:51.950: INFO: stdout: "update-demo-nautilus-56tpg update-demo-nautilus-vzshj "
Feb 27 02:29:51.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-56tpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:52.024: INFO: stderr: ""
Feb 27 02:29:52.024: INFO: stdout: ""
Feb 27 02:29:52.024: INFO: update-demo-nautilus-56tpg is created but not running
Feb 27 02:29:57.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:57.087: INFO: stderr: ""
Feb 27 02:29:57.087: INFO: stdout: "update-demo-nautilus-56tpg update-demo-nautilus-vzshj "
Feb 27 02:29:57.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-56tpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:57.155: INFO: stderr: ""
Feb 27 02:29:57.155: INFO: stdout: "true"
Feb 27 02:29:57.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-56tpg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:57.224: INFO: stderr: ""
Feb 27 02:29:57.224: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:29:57.224: INFO: validating pod update-demo-nautilus-56tpg
Feb 27 02:29:57.227: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:29:57.227: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:29:57.227: INFO: update-demo-nautilus-56tpg is verified up and running
Feb 27 02:29:57.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-vzshj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:57.311: INFO: stderr: ""
Feb 27 02:29:57.311: INFO: stdout: "true"
Feb 27 02:29:57.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-vzshj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:57.391: INFO: stderr: ""
Feb 27 02:29:57.392: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:29:57.392: INFO: validating pod update-demo-nautilus-vzshj
Feb 27 02:29:57.395: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:29:57.395: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:29:57.395: INFO: update-demo-nautilus-vzshj is verified up and running
STEP: scaling down the replication controller
Feb 27 02:29:57.397: INFO: scanned /root for discovery docs: <nil>
Feb 27 02:29:57.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:58.491: INFO: stderr: ""
Feb 27 02:29:58.491: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 02:29:58.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:29:58.560: INFO: stderr: ""
Feb 27 02:29:58.560: INFO: stdout: "update-demo-nautilus-56tpg update-demo-nautilus-vzshj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 27 02:30:03.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:03.635: INFO: stderr: ""
Feb 27 02:30:03.635: INFO: stdout: "update-demo-nautilus-56tpg update-demo-nautilus-vzshj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 27 02:30:08.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:08.708: INFO: stderr: ""
Feb 27 02:30:08.708: INFO: stdout: "update-demo-nautilus-vzshj "
Feb 27 02:30:08.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-vzshj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:08.771: INFO: stderr: ""
Feb 27 02:30:08.771: INFO: stdout: "true"
Feb 27 02:30:08.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-vzshj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:08.828: INFO: stderr: ""
Feb 27 02:30:08.828: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:30:08.828: INFO: validating pod update-demo-nautilus-vzshj
Feb 27 02:30:08.831: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:30:08.831: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:30:08.831: INFO: update-demo-nautilus-vzshj is verified up and running
STEP: scaling up the replication controller
Feb 27 02:30:08.832: INFO: scanned /root for discovery docs: <nil>
Feb 27 02:30:08.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:09.917: INFO: stderr: ""
Feb 27 02:30:09.917: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 02:30:09.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:09.985: INFO: stderr: ""
Feb 27 02:30:09.985: INFO: stdout: "update-demo-nautilus-9qtst update-demo-nautilus-vzshj "
Feb 27 02:30:09.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-9qtst -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:10.065: INFO: stderr: ""
Feb 27 02:30:10.065: INFO: stdout: ""
Feb 27 02:30:10.065: INFO: update-demo-nautilus-9qtst is created but not running
Feb 27 02:30:15.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:15.125: INFO: stderr: ""
Feb 27 02:30:15.125: INFO: stdout: "update-demo-nautilus-9qtst update-demo-nautilus-vzshj "
Feb 27 02:30:15.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-9qtst -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:15.188: INFO: stderr: ""
Feb 27 02:30:15.188: INFO: stdout: "true"
Feb 27 02:30:15.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-9qtst -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:15.251: INFO: stderr: ""
Feb 27 02:30:15.251: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:30:15.251: INFO: validating pod update-demo-nautilus-9qtst
Feb 27 02:30:15.255: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:30:15.255: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:30:15.255: INFO: update-demo-nautilus-9qtst is verified up and running
Feb 27 02:30:15.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-vzshj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:15.326: INFO: stderr: ""
Feb 27 02:30:15.326: INFO: stdout: "true"
Feb 27 02:30:15.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-vzshj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:15.398: INFO: stderr: ""
Feb 27 02:30:15.398: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:30:15.398: INFO: validating pod update-demo-nautilus-vzshj
Feb 27 02:30:15.401: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:30:15.401: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:30:15.401: INFO: update-demo-nautilus-vzshj is verified up and running
STEP: using delete to clean up resources
Feb 27 02:30:15.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:15.468: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:30:15.468: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 27 02:30:15.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-h2rkv'
Feb 27 02:30:15.560: INFO: stderr: "No resources found.\n"
Feb 27 02:30:15.560: INFO: stdout: ""
Feb 27 02:30:15.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -l name=update-demo --namespace=e2e-tests-kubectl-h2rkv -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 02:30:15.674: INFO: stderr: ""
Feb 27 02:30:15.674: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:30:15.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h2rkv" for this suite.
Feb 27 02:30:37.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:30:37.773: INFO: namespace: e2e-tests-kubectl-h2rkv, resource: bindings, ignored listing per whitelist
Feb 27 02:30:37.781: INFO: namespace e2e-tests-kubectl-h2rkv deletion completed in 22.094970622s

• [SLOW TEST:46.384 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:30:37.782: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-zdgmv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:30:39.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zdgmv" for this suite.
Feb 27 02:31:30.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:31:30.056: INFO: namespace: e2e-tests-kubelet-test-zdgmv, resource: bindings, ignored listing per whitelist
Feb 27 02:31:30.085: INFO: namespace e2e-tests-kubelet-test-zdgmv deletion completed in 50.086986986s

• [SLOW TEST:52.303 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:31:30.087: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-49nsq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:31:30.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-49nsq" for this suite.
Feb 27 02:31:52.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:31:52.379: INFO: namespace: e2e-tests-pods-49nsq, resource: bindings, ignored listing per whitelist
Feb 27 02:31:52.388: INFO: namespace e2e-tests-pods-49nsq deletion completed in 22.092401998s

• [SLOW TEST:22.301 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:31:52.390: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nktn9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d78f953a-3a37-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:31:52.576: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d79022da-3a37-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-nktn9" to be "success or failure"
Feb 27 02:31:52.582: INFO: Pod "pod-projected-secrets-d79022da-3a37-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010754ms
Feb 27 02:31:54.586: INFO: Pod "pod-projected-secrets-d79022da-3a37-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010191674s
STEP: Saw pod success
Feb 27 02:31:54.586: INFO: Pod "pod-projected-secrets-d79022da-3a37-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:31:54.594: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-secrets-d79022da-3a37-11e9-853a-328ab8481bb7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:31:54.634: INFO: Waiting for pod pod-projected-secrets-d79022da-3a37-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:31:54.637: INFO: Pod pod-projected-secrets-d79022da-3a37-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:31:54.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nktn9" for this suite.
Feb 27 02:32:00.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:32:00.699: INFO: namespace: e2e-tests-projected-nktn9, resource: bindings, ignored listing per whitelist
Feb 27 02:32:00.737: INFO: namespace e2e-tests-projected-nktn9 deletion completed in 6.094736367s

• [SLOW TEST:8.348 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:32:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-7rj5z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:32:00.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7rj5z" for this suite.
Feb 27 02:32:06.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:32:07.017: INFO: namespace: e2e-tests-kubelet-test-7rj5z, resource: bindings, ignored listing per whitelist
Feb 27 02:32:07.025: INFO: namespace e2e-tests-kubelet-test-7rj5z deletion completed in 6.098185527s

• [SLOW TEST:6.288 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:32:07.026: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gq8nc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-e049380e-3a37-11e9-853a-328ab8481bb7
STEP: Creating secret with name secret-projected-all-test-volume-e04937fb-3a37-11e9-853a-328ab8481bb7
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 27 02:32:07.212: INFO: Waiting up to 5m0s for pod "projected-volume-e04937d5-3a37-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-gq8nc" to be "success or failure"
Feb 27 02:32:07.216: INFO: Pod "projected-volume-e04937d5-3a37-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.680506ms
Feb 27 02:32:09.219: INFO: Pod "projected-volume-e04937d5-3a37-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007202637s
STEP: Saw pod success
Feb 27 02:32:09.219: INFO: Pod "projected-volume-e04937d5-3a37-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:32:09.221: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod projected-volume-e04937d5-3a37-11e9-853a-328ab8481bb7 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 27 02:32:09.236: INFO: Waiting for pod projected-volume-e04937d5-3a37-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:32:09.239: INFO: Pod projected-volume-e04937d5-3a37-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:32:09.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gq8nc" for this suite.
Feb 27 02:32:15.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:32:15.273: INFO: namespace: e2e-tests-projected-gq8nc, resource: bindings, ignored listing per whitelist
Feb 27 02:32:15.349: INFO: namespace e2e-tests-projected-gq8nc deletion completed in 6.093993471s

• [SLOW TEST:8.324 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:32:15.350: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-j8pmc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-j4qh
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 02:32:15.535: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-j4qh" in namespace "e2e-tests-subpath-j8pmc" to be "success or failure"
Feb 27 02:32:15.538: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Pending", Reason="", readiness=false. Elapsed: 3.378157ms
Feb 27 02:32:17.542: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006965224s
Feb 27 02:32:19.546: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 4.010922919s
Feb 27 02:32:21.550: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 6.014618426s
Feb 27 02:32:23.553: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 8.018301563s
Feb 27 02:32:25.556: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 10.021329463s
Feb 27 02:32:27.559: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 12.02399276s
Feb 27 02:32:29.562: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 14.027339706s
Feb 27 02:32:31.565: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 16.030461706s
Feb 27 02:32:33.568: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 18.033388879s
Feb 27 02:32:35.577: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 20.041856757s
Feb 27 02:32:37.582: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Running", Reason="", readiness=false. Elapsed: 22.046931085s
Feb 27 02:32:39.586: INFO: Pod "pod-subpath-test-configmap-j4qh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051480794s
STEP: Saw pod success
Feb 27 02:32:39.587: INFO: Pod "pod-subpath-test-configmap-j4qh" satisfied condition "success or failure"
Feb 27 02:32:39.590: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod pod-subpath-test-configmap-j4qh container test-container-subpath-configmap-j4qh: <nil>
STEP: delete the pod
Feb 27 02:32:39.605: INFO: Waiting for pod pod-subpath-test-configmap-j4qh to disappear
Feb 27 02:32:39.608: INFO: Pod pod-subpath-test-configmap-j4qh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-j4qh
Feb 27 02:32:39.608: INFO: Deleting pod "pod-subpath-test-configmap-j4qh" in namespace "e2e-tests-subpath-j8pmc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:32:39.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-j8pmc" for this suite.
Feb 27 02:32:45.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:32:45.703: INFO: namespace: e2e-tests-subpath-j8pmc, resource: bindings, ignored listing per whitelist
Feb 27 02:32:45.712: INFO: namespace e2e-tests-subpath-j8pmc deletion completed in 6.098339194s

• [SLOW TEST:30.362 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:32:45.714: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gg4kw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb 27 02:32:45.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 cluster-info'
Feb 27 02:32:45.959: INFO: stderr: ""
Feb 27 02:32:45.959: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.31.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:32:45.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gg4kw" for this suite.
Feb 27 02:32:51.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:32:52.041: INFO: namespace: e2e-tests-kubectl-gg4kw, resource: bindings, ignored listing per whitelist
Feb 27 02:32:52.074: INFO: namespace e2e-tests-kubectl-gg4kw deletion completed in 6.112147002s

• [SLOW TEST:6.360 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:32:52.074: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-9lmp6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 27 02:32:52.269: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9lmp6,SelfLink:/api/v1/namespaces/e2e-tests-watch-9lmp6/configmaps/e2e-watch-test-label-changed,UID:fb2554e8-3a37-11e9-bb22-deadbe9ffdf9,ResourceVersion:24266,Generation:0,CreationTimestamp:2019-02-27 02:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:32:52.269: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9lmp6,SelfLink:/api/v1/namespaces/e2e-tests-watch-9lmp6/configmaps/e2e-watch-test-label-changed,UID:fb2554e8-3a37-11e9-bb22-deadbe9ffdf9,ResourceVersion:24267,Generation:0,CreationTimestamp:2019-02-27 02:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 27 02:32:52.269: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9lmp6,SelfLink:/api/v1/namespaces/e2e-tests-watch-9lmp6/configmaps/e2e-watch-test-label-changed,UID:fb2554e8-3a37-11e9-bb22-deadbe9ffdf9,ResourceVersion:24268,Generation:0,CreationTimestamp:2019-02-27 02:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 27 02:33:02.289: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9lmp6,SelfLink:/api/v1/namespaces/e2e-tests-watch-9lmp6/configmaps/e2e-watch-test-label-changed,UID:fb2554e8-3a37-11e9-bb22-deadbe9ffdf9,ResourceVersion:24285,Generation:0,CreationTimestamp:2019-02-27 02:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:33:02.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9lmp6,SelfLink:/api/v1/namespaces/e2e-tests-watch-9lmp6/configmaps/e2e-watch-test-label-changed,UID:fb2554e8-3a37-11e9-bb22-deadbe9ffdf9,ResourceVersion:24286,Generation:0,CreationTimestamp:2019-02-27 02:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 27 02:33:02.289: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9lmp6,SelfLink:/api/v1/namespaces/e2e-tests-watch-9lmp6/configmaps/e2e-watch-test-label-changed,UID:fb2554e8-3a37-11e9-bb22-deadbe9ffdf9,ResourceVersion:24287,Generation:0,CreationTimestamp:2019-02-27 02:32:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:33:02.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9lmp6" for this suite.
Feb 27 02:33:08.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:33:08.341: INFO: namespace: e2e-tests-watch-9lmp6, resource: bindings, ignored listing per whitelist
Feb 27 02:33:08.386: INFO: namespace e2e-tests-watch-9lmp6 deletion completed in 6.092845246s

• [SLOW TEST:16.311 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:33:08.386: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cw49j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:33:08.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04dc1ccc-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-cw49j" to be "success or failure"
Feb 27 02:33:08.572: INFO: Pod "downwardapi-volume-04dc1ccc-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.344114ms
Feb 27 02:33:10.580: INFO: Pod "downwardapi-volume-04dc1ccc-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011907537s
STEP: Saw pod success
Feb 27 02:33:10.580: INFO: Pod "downwardapi-volume-04dc1ccc-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:33:10.584: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-04dc1ccc-3a38-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:33:10.617: INFO: Waiting for pod downwardapi-volume-04dc1ccc-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:33:10.619: INFO: Pod downwardapi-volume-04dc1ccc-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:33:10.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cw49j" for this suite.
Feb 27 02:33:16.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:33:16.712: INFO: namespace: e2e-tests-downward-api-cw49j, resource: bindings, ignored listing per whitelist
Feb 27 02:33:16.714: INFO: namespace e2e-tests-downward-api-cw49j deletion completed in 6.091983381s

• [SLOW TEST:8.328 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:33:16.715: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-t8pb4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 27 02:33:18.918: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-09d3e6ab-3a38-11e9-853a-328ab8481bb7,GenerateName:,Namespace:e2e-tests-events-t8pb4,SelfLink:/api/v1/namespaces/e2e-tests-events-t8pb4/pods/send-events-09d3e6ab-3a38-11e9-853a-328ab8481bb7,UID:09d52624-3a38-11e9-bb22-deadbe9ffdf9,ResourceVersion:24372,Generation:0,CreationTimestamp:2019-02-27 02:33:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 897249844,},Annotations:map[string]string{kubernetes.io/psp: cert-exporter-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-knzmt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-knzmt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-knzmt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022aac40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022aac60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:33:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:33:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:33:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:33:16 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:192.168.87.229,StartTime:2019-02-27 02:33:16 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-27 02:33:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://80033c520af2fda359f06b8f9c9f6020b40296a5c5eb6089785c46d30d72785f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb 27 02:33:20.923: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 27 02:33:22.926: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:33:22.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-t8pb4" for this suite.
Feb 27 02:34:00.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:34:01.009: INFO: namespace: e2e-tests-events-t8pb4, resource: bindings, ignored listing per whitelist
Feb 27 02:34:01.018: INFO: namespace e2e-tests-events-t8pb4 deletion completed in 38.079482172s

• [SLOW TEST:44.303 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:34:01.019: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vbktl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 02:34:01.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-vbktl'
Feb 27 02:34:01.262: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 02:34:01.262: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb 27 02:34:03.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-vbktl'
Feb 27 02:34:03.344: INFO: stderr: ""
Feb 27 02:34:03.344: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:34:03.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vbktl" for this suite.
Feb 27 02:34:25.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:34:25.389: INFO: namespace: e2e-tests-kubectl-vbktl, resource: bindings, ignored listing per whitelist
Feb 27 02:34:25.438: INFO: namespace e2e-tests-kubectl-vbktl deletion completed in 22.090328668s

• [SLOW TEST:24.419 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:34:25.438: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2vjn4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:34:25.614: INFO: Waiting up to 5m0s for pod "downwardapi-volume-32c87d4c-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-2vjn4" to be "success or failure"
Feb 27 02:34:25.617: INFO: Pod "downwardapi-volume-32c87d4c-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.838173ms
Feb 27 02:34:27.620: INFO: Pod "downwardapi-volume-32c87d4c-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005387305s
STEP: Saw pod success
Feb 27 02:34:27.620: INFO: Pod "downwardapi-volume-32c87d4c-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:34:27.621: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-32c87d4c-3a38-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:34:27.637: INFO: Waiting for pod downwardapi-volume-32c87d4c-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:34:27.639: INFO: Pod downwardapi-volume-32c87d4c-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:34:27.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2vjn4" for this suite.
Feb 27 02:34:33.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:34:33.739: INFO: namespace: e2e-tests-downward-api-2vjn4, resource: bindings, ignored listing per whitelist
Feb 27 02:34:33.739: INFO: namespace e2e-tests-downward-api-2vjn4 deletion completed in 6.097147533s

• [SLOW TEST:8.301 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:34:33.740: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ccgs2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:34:33.926: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37bb5b05-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-ccgs2" to be "success or failure"
Feb 27 02:34:33.947: INFO: Pod "downwardapi-volume-37bb5b05-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.04871ms
Feb 27 02:34:35.950: INFO: Pod "downwardapi-volume-37bb5b05-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02388177s
STEP: Saw pod success
Feb 27 02:34:35.950: INFO: Pod "downwardapi-volume-37bb5b05-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:34:35.951: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-37bb5b05-3a38-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:34:35.973: INFO: Waiting for pod downwardapi-volume-37bb5b05-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:34:35.975: INFO: Pod downwardapi-volume-37bb5b05-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:34:35.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ccgs2" for this suite.
Feb 27 02:34:41.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:34:42.007: INFO: namespace: e2e-tests-projected-ccgs2, resource: bindings, ignored listing per whitelist
Feb 27 02:34:42.063: INFO: namespace e2e-tests-projected-ccgs2 deletion completed in 6.084890702s

• [SLOW TEST:8.323 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:34:42.063: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-96gxj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-8ndx
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 02:34:42.255: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-8ndx" in namespace "e2e-tests-subpath-96gxj" to be "success or failure"
Feb 27 02:34:42.257: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.397452ms
Feb 27 02:34:44.260: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005614453s
Feb 27 02:34:46.269: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 4.013773709s
Feb 27 02:34:48.272: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 6.017592684s
Feb 27 02:34:50.276: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 8.021014357s
Feb 27 02:34:52.279: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 10.024369378s
Feb 27 02:34:54.282: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 12.027132947s
Feb 27 02:34:56.286: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 14.031050974s
Feb 27 02:34:58.289: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 16.034602592s
Feb 27 02:35:00.293: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 18.038178663s
Feb 27 02:35:02.296: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 20.041335772s
Feb 27 02:35:04.299: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Running", Reason="", readiness=false. Elapsed: 22.044266576s
Feb 27 02:35:06.303: INFO: Pod "pod-subpath-test-secret-8ndx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.047748335s
STEP: Saw pod success
Feb 27 02:35:06.303: INFO: Pod "pod-subpath-test-secret-8ndx" satisfied condition "success or failure"
Feb 27 02:35:06.305: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod pod-subpath-test-secret-8ndx container test-container-subpath-secret-8ndx: <nil>
STEP: delete the pod
Feb 27 02:35:06.326: INFO: Waiting for pod pod-subpath-test-secret-8ndx to disappear
Feb 27 02:35:06.329: INFO: Pod pod-subpath-test-secret-8ndx no longer exists
STEP: Deleting pod pod-subpath-test-secret-8ndx
Feb 27 02:35:06.329: INFO: Deleting pod "pod-subpath-test-secret-8ndx" in namespace "e2e-tests-subpath-96gxj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:35:06.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-96gxj" for this suite.
Feb 27 02:35:12.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:35:12.416: INFO: namespace: e2e-tests-subpath-96gxj, resource: bindings, ignored listing per whitelist
Feb 27 02:35:12.436: INFO: namespace e2e-tests-subpath-96gxj deletion completed in 6.100982s

• [SLOW TEST:30.372 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:35:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7ljv4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4ece01cc-3a38-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:35:12.630: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ece7f0c-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-7ljv4" to be "success or failure"
Feb 27 02:35:12.633: INFO: Pod "pod-projected-configmaps-4ece7f0c-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.040403ms
Feb 27 02:35:14.636: INFO: Pod "pod-projected-configmaps-4ece7f0c-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006267127s
STEP: Saw pod success
Feb 27 02:35:14.637: INFO: Pod "pod-projected-configmaps-4ece7f0c-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:35:14.639: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-configmaps-4ece7f0c-3a38-11e9-853a-328ab8481bb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:35:14.652: INFO: Waiting for pod pod-projected-configmaps-4ece7f0c-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:35:14.654: INFO: Pod pod-projected-configmaps-4ece7f0c-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:35:14.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7ljv4" for this suite.
Feb 27 02:35:20.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:35:20.681: INFO: namespace: e2e-tests-projected-7ljv4, resource: bindings, ignored listing per whitelist
Feb 27 02:35:20.737: INFO: namespace e2e-tests-projected-7ljv4 deletion completed in 6.080429979s

• [SLOW TEST:8.301 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:35:20.738: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-c57kb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-c57kb/configmap-test-53bfa340-3a38-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:35:20.924: INFO: Waiting up to 5m0s for pod "pod-configmaps-53c00218-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-c57kb" to be "success or failure"
Feb 27 02:35:20.928: INFO: Pod "pod-configmaps-53c00218-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.102995ms
Feb 27 02:35:22.931: INFO: Pod "pod-configmaps-53c00218-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006098415s
STEP: Saw pod success
Feb 27 02:35:22.931: INFO: Pod "pod-configmaps-53c00218-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:35:22.932: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-53c00218-3a38-11e9-853a-328ab8481bb7 container env-test: <nil>
STEP: delete the pod
Feb 27 02:35:22.946: INFO: Waiting for pod pod-configmaps-53c00218-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:35:22.948: INFO: Pod pod-configmaps-53c00218-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:35:22.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c57kb" for this suite.
Feb 27 02:35:28.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:35:28.994: INFO: namespace: e2e-tests-configmap-c57kb, resource: bindings, ignored listing per whitelist
Feb 27 02:35:29.033: INFO: namespace e2e-tests-configmap-c57kb deletion completed in 6.082174993s

• [SLOW TEST:8.295 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:35:29.034: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-krx55
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-58b2bd81-3a38-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:35:29.230: INFO: Waiting up to 5m0s for pod "pod-secrets-58b38685-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-krx55" to be "success or failure"
Feb 27 02:35:29.231: INFO: Pod "pod-secrets-58b38685-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.805168ms
Feb 27 02:35:31.235: INFO: Pod "pod-secrets-58b38685-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005435614s
STEP: Saw pod success
Feb 27 02:35:31.235: INFO: Pod "pod-secrets-58b38685-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:35:31.237: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-58b38685-3a38-11e9-853a-328ab8481bb7 container secret-env-test: <nil>
STEP: delete the pod
Feb 27 02:35:31.251: INFO: Waiting for pod pod-secrets-58b38685-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:35:31.253: INFO: Pod pod-secrets-58b38685-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:35:31.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-krx55" for this suite.
Feb 27 02:35:37.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:35:37.345: INFO: namespace: e2e-tests-secrets-krx55, resource: bindings, ignored listing per whitelist
Feb 27 02:35:37.358: INFO: namespace e2e-tests-secrets-krx55 deletion completed in 6.102022471s

• [SLOW TEST:8.324 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:35:37.358: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7z5dc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 02:35:40.060: INFO: Successfully updated pod "annotationupdate5da6ffb6-3a38-11e9-853a-328ab8481bb7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:35:42.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7z5dc" for this suite.
Feb 27 02:36:04.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:36:04.149: INFO: namespace: e2e-tests-downward-api-7z5dc, resource: bindings, ignored listing per whitelist
Feb 27 02:36:04.159: INFO: namespace e2e-tests-downward-api-7z5dc deletion completed in 22.084114675s

• [SLOW TEST:26.801 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:36:04.159: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-22h76
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-6d9f3f9c-3a38-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:36:04.331: INFO: Waiting up to 5m0s for pod "pod-configmaps-6d9f97a1-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-22h76" to be "success or failure"
Feb 27 02:36:04.333: INFO: Pod "pod-configmaps-6d9f97a1-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.592908ms
Feb 27 02:36:06.337: INFO: Pod "pod-configmaps-6d9f97a1-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005797656s
STEP: Saw pod success
Feb 27 02:36:06.337: INFO: Pod "pod-configmaps-6d9f97a1-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:36:06.339: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-6d9f97a1-3a38-11e9-853a-328ab8481bb7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:36:06.353: INFO: Waiting for pod pod-configmaps-6d9f97a1-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:36:06.355: INFO: Pod pod-configmaps-6d9f97a1-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:36:06.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-22h76" for this suite.
Feb 27 02:36:12.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:36:12.387: INFO: namespace: e2e-tests-configmap-22h76, resource: bindings, ignored listing per whitelist
Feb 27 02:36:12.449: INFO: namespace e2e-tests-configmap-22h76 deletion completed in 6.090996172s

• [SLOW TEST:8.290 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:36:12.449: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-hd59k
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7291d0b2-3a38-11e9-853a-328ab8481bb7
STEP: Creating secret with name s-test-opt-upd-7291d0e1-3a38-11e9-853a-328ab8481bb7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7291d0b2-3a38-11e9-853a-328ab8481bb7
STEP: Updating secret s-test-opt-upd-7291d0e1-3a38-11e9-853a-328ab8481bb7
STEP: Creating secret with name s-test-opt-create-7291d0f5-3a38-11e9-853a-328ab8481bb7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:36:18.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hd59k" for this suite.
Feb 27 02:36:40.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:36:40.799: INFO: namespace: e2e-tests-secrets-hd59k, resource: bindings, ignored listing per whitelist
Feb 27 02:36:40.801: INFO: namespace e2e-tests-secrets-hd59k deletion completed in 22.085474835s

• [SLOW TEST:28.352 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:36:40.802: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cbpz8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 27 02:36:41.006: INFO: Waiting up to 5m0s for pod "pod-837b7931-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-cbpz8" to be "success or failure"
Feb 27 02:36:41.009: INFO: Pod "pod-837b7931-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.993655ms
Feb 27 02:36:43.011: INFO: Pod "pod-837b7931-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005629321s
STEP: Saw pod success
Feb 27 02:36:43.012: INFO: Pod "pod-837b7931-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:36:43.014: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-837b7931-3a38-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:36:43.027: INFO: Waiting for pod pod-837b7931-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:36:43.030: INFO: Pod pod-837b7931-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:36:43.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cbpz8" for this suite.
Feb 27 02:36:49.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:36:49.051: INFO: namespace: e2e-tests-emptydir-cbpz8, resource: bindings, ignored listing per whitelist
Feb 27 02:36:49.108: INFO: namespace e2e-tests-emptydir-cbpz8 deletion completed in 6.074620411s

• [SLOW TEST:8.306 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:36:49.108: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-9d8sw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:36:49.281: INFO: Creating deployment "test-recreate-deployment"
Feb 27 02:36:49.294: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 27 02:36:49.309: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb 27 02:36:51.315: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 27 02:36:51.316: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 27 02:36:51.322: INFO: Updating deployment test-recreate-deployment
Feb 27 02:36:51.322: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:36:51.396: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-9d8sw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9d8sw/deployments/test-recreate-deployment,UID:886c262b-3a38-11e9-bb22-deadbe9ffdf9,ResourceVersion:25204,Generation:2,CreationTimestamp:2019-02-27 02:36:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-27 02:36:51 +0000 UTC 2019-02-27 02:36:51 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-27 02:36:51 +0000 UTC 2019-02-27 02:36:49 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb 27 02:36:51.399: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-9d8sw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9d8sw/replicasets/test-recreate-deployment-697fbf54bf,UID:89a75a7c-3a38-11e9-bb22-deadbe9ffdf9,ResourceVersion:25203,Generation:1,CreationTimestamp:2019-02-27 02:36:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 886c262b-3a38-11e9-bb22-deadbe9ffdf9 0xc00244ccc7 0xc00244ccc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:36:51.399: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 27 02:36:51.399: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-9d8sw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9d8sw/replicasets/test-recreate-deployment-5dfdcc846d,UID:88701844-3a38-11e9-bb22-deadbe9ffdf9,ResourceVersion:25192,Generation:2,CreationTimestamp:2019-02-27 02:36:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 886c262b-3a38-11e9-bb22-deadbe9ffdf9 0xc00244cc07 0xc00244cc08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:36:51.402: INFO: Pod "test-recreate-deployment-697fbf54bf-6f74c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-6f74c,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-9d8sw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9d8sw/pods/test-recreate-deployment-697fbf54bf-6f74c,UID:89a7e266-3a38-11e9-bb22-deadbe9ffdf9,ResourceVersion:25201,Generation:0,CreationTimestamp:2019-02-27 02:36:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 89a75a7c-3a38-11e9-bb22-deadbe9ffdf9 0xc00244d557 0xc00244d558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5xq8r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5xq8r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5xq8r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00244d5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00244d5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:36:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:36:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:36:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:36:51 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:36:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:36:51.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9d8sw" for this suite.
Feb 27 02:36:57.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:36:57.494: INFO: namespace: e2e-tests-deployment-9d8sw, resource: bindings, ignored listing per whitelist
Feb 27 02:36:57.510: INFO: namespace e2e-tests-deployment-9d8sw deletion completed in 6.105958778s

• [SLOW TEST:8.402 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:36:57.511: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-h5ckb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 27 02:36:57.699: INFO: Waiting up to 5m0s for pod "pod-8d6ed239-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-h5ckb" to be "success or failure"
Feb 27 02:36:57.704: INFO: Pod "pod-8d6ed239-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.196957ms
Feb 27 02:36:59.707: INFO: Pod "pod-8d6ed239-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007678033s
STEP: Saw pod success
Feb 27 02:36:59.707: INFO: Pod "pod-8d6ed239-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:36:59.709: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-8d6ed239-3a38-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:36:59.737: INFO: Waiting for pod pod-8d6ed239-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:36:59.740: INFO: Pod pod-8d6ed239-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:36:59.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h5ckb" for this suite.
Feb 27 02:37:05.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:37:05.781: INFO: namespace: e2e-tests-emptydir-h5ckb, resource: bindings, ignored listing per whitelist
Feb 27 02:37:05.828: INFO: namespace e2e-tests-emptydir-h5ckb deletion completed in 6.081907489s

• [SLOW TEST:8.318 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:37:05.829: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fphjg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 02:37:06.021: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:37:06.023: INFO: Number of nodes with available pods: 0
Feb 27 02:37:06.023: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:37:07.026: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:37:07.028: INFO: Number of nodes with available pods: 0
Feb 27 02:37:07.028: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:37:08.027: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:37:08.029: INFO: Number of nodes with available pods: 2
Feb 27 02:37:08.029: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 27 02:37:08.045: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:37:08.049: INFO: Number of nodes with available pods: 1
Feb 27 02:37:08.049: INFO: Node worker-v332t-5ff768bb65-6znm5 is running more than one daemon pod
Feb 27 02:37:09.062: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:37:09.064: INFO: Number of nodes with available pods: 1
Feb 27 02:37:09.064: INFO: Node worker-v332t-5ff768bb65-6znm5 is running more than one daemon pod
Feb 27 02:37:10.053: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:37:10.056: INFO: Number of nodes with available pods: 2
Feb 27 02:37:10.056: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-fphjg, will wait for the garbage collector to delete the pods
Feb 27 02:37:10.118: INFO: Deleting DaemonSet.extensions daemon-set took: 4.98638ms
Feb 27 02:37:10.218: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.247165ms
Feb 27 02:37:43.521: INFO: Number of nodes with available pods: 0
Feb 27 02:37:43.521: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 02:37:43.523: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fphjg/daemonsets","resourceVersion":"25432"},"items":null}

Feb 27 02:37:43.524: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fphjg/pods","resourceVersion":"25432"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:37:43.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fphjg" for this suite.
Feb 27 02:37:49.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:37:49.598: INFO: namespace: e2e-tests-daemonsets-fphjg, resource: bindings, ignored listing per whitelist
Feb 27 02:37:49.621: INFO: namespace e2e-tests-daemonsets-fphjg deletion completed in 6.087500194s

• [SLOW TEST:43.793 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:37:49.621: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-w69gx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:37:51.853: INFO: Waiting up to 5m0s for pod "client-envvars-adb65ad2-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-pods-w69gx" to be "success or failure"
Feb 27 02:37:51.859: INFO: Pod "client-envvars-adb65ad2-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.656034ms
Feb 27 02:37:53.862: INFO: Pod "client-envvars-adb65ad2-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009015872s
STEP: Saw pod success
Feb 27 02:37:53.862: INFO: Pod "client-envvars-adb65ad2-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:37:53.864: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod client-envvars-adb65ad2-3a38-11e9-853a-328ab8481bb7 container env3cont: <nil>
STEP: delete the pod
Feb 27 02:37:53.878: INFO: Waiting for pod client-envvars-adb65ad2-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:37:53.881: INFO: Pod client-envvars-adb65ad2-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:37:53.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-w69gx" for this suite.
Feb 27 02:38:39.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:38:39.926: INFO: namespace: e2e-tests-pods-w69gx, resource: bindings, ignored listing per whitelist
Feb 27 02:38:39.965: INFO: namespace e2e-tests-pods-w69gx deletion completed in 46.081832848s

• [SLOW TEST:50.344 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:38:39.968: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ctc65
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 27 02:38:40.145: INFO: Waiting up to 5m0s for pod "pod-ca7e9d28-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-ctc65" to be "success or failure"
Feb 27 02:38:40.149: INFO: Pod "pod-ca7e9d28-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.517281ms
Feb 27 02:38:42.153: INFO: Pod "pod-ca7e9d28-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007482384s
STEP: Saw pod success
Feb 27 02:38:42.153: INFO: Pod "pod-ca7e9d28-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:38:42.155: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-ca7e9d28-3a38-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:38:42.180: INFO: Waiting for pod pod-ca7e9d28-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:38:42.197: INFO: Pod pod-ca7e9d28-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:38:42.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ctc65" for this suite.
Feb 27 02:38:48.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:38:48.270: INFO: namespace: e2e-tests-emptydir-ctc65, resource: bindings, ignored listing per whitelist
Feb 27 02:38:48.294: INFO: namespace e2e-tests-emptydir-ctc65 deletion completed in 6.093353107s

• [SLOW TEST:8.327 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:38:48.295: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-88drs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:38:48.466: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:38:50.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-88drs" for this suite.
Feb 27 02:39:42.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:39:42.570: INFO: namespace: e2e-tests-pods-88drs, resource: bindings, ignored listing per whitelist
Feb 27 02:39:42.578: INFO: namespace e2e-tests-pods-88drs deletion completed in 52.082923353s

• [SLOW TEST:54.284 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:39:42.579: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5mf2j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:39:42.762: INFO: Waiting up to 5m0s for pod "downwardapi-volume-efd15f9d-3a38-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-5mf2j" to be "success or failure"
Feb 27 02:39:42.764: INFO: Pod "downwardapi-volume-efd15f9d-3a38-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.760735ms
Feb 27 02:39:44.767: INFO: Pod "downwardapi-volume-efd15f9d-3a38-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005661046s
STEP: Saw pod success
Feb 27 02:39:44.768: INFO: Pod "downwardapi-volume-efd15f9d-3a38-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:39:44.772: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-efd15f9d-3a38-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:39:44.787: INFO: Waiting for pod downwardapi-volume-efd15f9d-3a38-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:39:44.794: INFO: Pod downwardapi-volume-efd15f9d-3a38-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:39:44.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5mf2j" for this suite.
Feb 27 02:39:50.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:39:50.900: INFO: namespace: e2e-tests-downward-api-5mf2j, resource: bindings, ignored listing per whitelist
Feb 27 02:39:50.911: INFO: namespace e2e-tests-downward-api-5mf2j deletion completed in 6.114506622s

• [SLOW TEST:8.333 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:39:50.913: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-sgghw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb 27 02:39:53.113: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-f4c7e504-3a38-11e9-853a-328ab8481bb7", GenerateName:"", Namespace:"e2e-tests-pods-sgghw", SelfLink:"/api/v1/namespaces/e2e-tests-pods-sgghw/pods/pod-submit-remove-f4c7e504-3a38-11e9-853a-328ab8481bb7", UID:"f4c9f968-3a38-11e9-bb22-deadbe9ffdf9", ResourceVersion:"25838", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686831991, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"83140106"}, Annotations:map[string]string{"kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4whzr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001688400), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4whzr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0016be738), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-0ut0w-6f5f764f5c-rj65d", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000be1a40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0016be770)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0016be7a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0016be7a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0016be7ac)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686831991, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686831992, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686831992, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686831991, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.23.1.234", PodIP:"192.168.87.245", StartTime:(*v1.Time)(0xc001704dc0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001704de0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://a6f35be71f6d3135b266afafb9fa9b532134cc6a234a93a1715608fd76f277b9"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:07.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sgghw" for this suite.
Feb 27 02:40:13.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:13.729: INFO: namespace: e2e-tests-pods-sgghw, resource: bindings, ignored listing per whitelist
Feb 27 02:40:13.771: INFO: namespace e2e-tests-pods-sgghw deletion completed in 6.093218851s

• [SLOW TEST:22.858 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:13.772: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-j4d65
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-026b2f87-3a39-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:40:13.974: INFO: Waiting up to 5m0s for pod "pod-secrets-026bb10c-3a39-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-j4d65" to be "success or failure"
Feb 27 02:40:13.979: INFO: Pod "pod-secrets-026bb10c-3a39-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.781403ms
Feb 27 02:40:15.983: INFO: Pod "pod-secrets-026bb10c-3a39-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009130397s
STEP: Saw pod success
Feb 27 02:40:15.983: INFO: Pod "pod-secrets-026bb10c-3a39-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:40:15.985: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-026bb10c-3a39-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:40:15.999: INFO: Waiting for pod pod-secrets-026bb10c-3a39-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:40:16.001: INFO: Pod pod-secrets-026bb10c-3a39-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:16.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j4d65" for this suite.
Feb 27 02:40:22.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:22.027: INFO: namespace: e2e-tests-secrets-j4d65, resource: bindings, ignored listing per whitelist
Feb 27 02:40:22.094: INFO: namespace e2e-tests-secrets-j4d65 deletion completed in 6.089317039s

• [SLOW TEST:8.322 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:22.096: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bzbwn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb 27 02:40:22.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 --namespace=e2e-tests-kubectl-bzbwn run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 27 02:40:24.300: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 27 02:40:24.300: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:26.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bzbwn" for this suite.
Feb 27 02:40:32.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:32.324: INFO: namespace: e2e-tests-kubectl-bzbwn, resource: bindings, ignored listing per whitelist
Feb 27 02:40:32.388: INFO: namespace e2e-tests-kubectl-bzbwn deletion completed in 6.08171054s

• [SLOW TEST:10.292 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:32.388: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-d4bkm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0227 02:40:42.596078      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 02:40:42.596: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:42.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d4bkm" for this suite.
Feb 27 02:40:48.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:40:48.674: INFO: namespace: e2e-tests-gc-d4bkm, resource: bindings, ignored listing per whitelist
Feb 27 02:40:48.683: INFO: namespace e2e-tests-gc-d4bkm deletion completed in 6.085359231s

• [SLOW TEST:16.295 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:40:48.684: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-kv59c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 27 02:40:51.385: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1737fe80-3a39-11e9-853a-328ab8481bb7"
Feb 27 02:40:51.385: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1737fe80-3a39-11e9-853a-328ab8481bb7" in namespace "e2e-tests-pods-kv59c" to be "terminated due to deadline exceeded"
Feb 27 02:40:51.388: INFO: Pod "pod-update-activedeadlineseconds-1737fe80-3a39-11e9-853a-328ab8481bb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.862688ms
Feb 27 02:40:53.395: INFO: Pod "pod-update-activedeadlineseconds-1737fe80-3a39-11e9-853a-328ab8481bb7": Phase="Running", Reason="", readiness=true. Elapsed: 2.009994119s
Feb 27 02:40:55.398: INFO: Pod "pod-update-activedeadlineseconds-1737fe80-3a39-11e9-853a-328ab8481bb7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.013392843s
Feb 27 02:40:55.398: INFO: Pod "pod-update-activedeadlineseconds-1737fe80-3a39-11e9-853a-328ab8481bb7" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:40:55.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kv59c" for this suite.
Feb 27 02:41:01.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:41:01.440: INFO: namespace: e2e-tests-pods-kv59c, resource: bindings, ignored listing per whitelist
Feb 27 02:41:01.488: INFO: namespace e2e-tests-pods-kv59c deletion completed in 6.086466943s

• [SLOW TEST:12.805 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:41:01.490: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mfw7r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 27 02:41:01.688: INFO: Waiting up to 5m0s for pod "pod-1edb4493-3a39-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-mfw7r" to be "success or failure"
Feb 27 02:41:01.690: INFO: Pod "pod-1edb4493-3a39-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.517039ms
Feb 27 02:41:03.695: INFO: Pod "pod-1edb4493-3a39-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007297408s
STEP: Saw pod success
Feb 27 02:41:03.695: INFO: Pod "pod-1edb4493-3a39-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:41:03.699: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-1edb4493-3a39-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:41:03.710: INFO: Waiting for pod pod-1edb4493-3a39-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:41:03.713: INFO: Pod pod-1edb4493-3a39-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:41:03.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mfw7r" for this suite.
Feb 27 02:41:09.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:41:09.749: INFO: namespace: e2e-tests-emptydir-mfw7r, resource: bindings, ignored listing per whitelist
Feb 27 02:41:09.804: INFO: namespace e2e-tests-emptydir-mfw7r deletion completed in 6.088351336s

• [SLOW TEST:8.314 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:41:09.805: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-78cp9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0227 02:41:11.036156      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 02:41:11.036: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:41:11.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-78cp9" for this suite.
Feb 27 02:41:17.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:41:17.078: INFO: namespace: e2e-tests-gc-78cp9, resource: bindings, ignored listing per whitelist
Feb 27 02:41:17.123: INFO: namespace e2e-tests-gc-78cp9 deletion completed in 6.084914255s

• [SLOW TEST:7.319 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:41:17.125: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-5g7p9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb 27 02:41:19.325: INFO: Pod pod-hostip-282b260b-3a39-11e9-853a-328ab8481bb7 has hostIP: 172.23.1.234
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:41:19.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5g7p9" for this suite.
Feb 27 02:41:41.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:41:41.401: INFO: namespace: e2e-tests-pods-5g7p9, resource: bindings, ignored listing per whitelist
Feb 27 02:41:41.430: INFO: namespace e2e-tests-pods-5g7p9 deletion completed in 22.100514161s

• [SLOW TEST:24.305 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:41:41.430: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-vpp25
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:41:41.611: INFO: Creating deployment "nginx-deployment"
Feb 27 02:41:41.621: INFO: Waiting for observed generation 1
Feb 27 02:41:43.627: INFO: Waiting for all required pods to come up
Feb 27 02:41:43.639: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 27 02:41:45.652: INFO: Waiting for deployment "nginx-deployment" to complete
Feb 27 02:41:45.655: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb 27 02:41:45.661: INFO: Updating deployment nginx-deployment
Feb 27 02:41:45.661: INFO: Waiting for observed generation 2
Feb 27 02:41:47.667: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 27 02:41:47.669: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 27 02:41:47.671: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 27 02:41:47.676: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 27 02:41:47.676: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 27 02:41:47.678: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb 27 02:41:47.681: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb 27 02:41:47.681: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb 27 02:41:47.686: INFO: Updating deployment nginx-deployment
Feb 27 02:41:47.686: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb 27 02:41:47.702: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 27 02:41:49.743: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:41:49.834: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-vpp25,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vpp25/deployments/nginx-deployment,UID:36aa7697-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26701,Generation:3,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-02-27 02:41:47 +0000 UTC 2019-02-27 02:41:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-27 02:41:47 +0000 UTC 2019-02-27 02:41:41 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb 27 02:41:49.841: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-vpp25,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vpp25/replicasets/nginx-deployment-65bbdb5f8,UID:39143d3c-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26699,Generation:3,CreationTimestamp:2019-02-27 02:41:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 36aa7697-3a39-11e9-bb22-deadbe9ffdf9 0xc0028ee327 0xc0028ee328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:41:49.841: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb 27 02:41:49.841: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-vpp25,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vpp25/replicasets/nginx-deployment-555b55d965,UID:36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26686,Generation:3,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 36aa7697-3a39-11e9-bb22-deadbe9ffdf9 0xc0028ee267 0xc0028ee268}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb 27 02:41:49.849: INFO: Pod "nginx-deployment-555b55d965-2n4rc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2n4rc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-2n4rc,UID:36ae3bff-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26521,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0028eed37 0xc0028eed38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028eeda0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028eedc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:192.168.87.252,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://c54cea7978da5350620248c2364748822ba64ea573ffa261c12251966b6b890c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.852: INFO: Pod "nginx-deployment-555b55d965-4cmgt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4cmgt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-4cmgt,UID:3a4f5674-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26733,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0028ef657 0xc0028ef658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ef6c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ef6e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.852: INFO: Pod "nginx-deployment-555b55d965-8x222" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8x222,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-8x222,UID:3a5031f5-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26703,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0028ef797 0xc0028ef798}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ef880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ef8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.853: INFO: Pod "nginx-deployment-555b55d965-99m9t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-99m9t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-99m9t,UID:3a4cfd0a-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26663,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0028ef957 0xc0028ef958}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028ef9c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028ef9e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.856: INFO: Pod "nginx-deployment-555b55d965-bpf86" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bpf86,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-bpf86,UID:36b20d05-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26528,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0028efd47 0xc0028efd48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0028efdb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0028efdd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:192.168.45.123,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://02cb88e1cfeb433e1e277268f2ded571c81e7cd0bbb75cbd942574c919573805}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.861: INFO: Pod "nginx-deployment-555b55d965-bvtmz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bvtmz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-bvtmz,UID:36b40569-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26537,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0028efe97 0xc0028efe98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f0390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f03b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:192.168.45.124,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://383090ec63805007fbf7eaf696ae95ee2de1e3f807e77f3d634e94d9170abe5f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.863: INFO: Pod "nginx-deployment-555b55d965-cfglw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cfglw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-cfglw,UID:36b8d0da-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26524,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f04a7 0xc0022f04a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f0510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f0750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:192.168.87.196,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ecdb82625ae16dce729c6f7b5cc04040dcf1ce7da15cf6bfd47294dc89475863}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.867: INFO: Pod "nginx-deployment-555b55d965-dsrz4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dsrz4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-dsrz4,UID:3a549fc2-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26707,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f0887 0xc0022f0888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f08f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f0910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.875: INFO: Pod "nginx-deployment-555b55d965-fd526" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fd526,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-fd526,UID:3a4c3b80-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26645,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f09c7 0xc0022f09c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f0b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f0b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.879: INFO: Pod "nginx-deployment-555b55d965-g64xj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g64xj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-g64xj,UID:3a565d0b-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26766,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f0c07 0xc0022f0c08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f0ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f0d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.905: INFO: Pod "nginx-deployment-555b55d965-hc75j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hc75j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-hc75j,UID:3a4d2c97-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26666,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f0de7 0xc0022f0de8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f0e50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f0f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.905: INFO: Pod "nginx-deployment-555b55d965-k2bf5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k2bf5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-k2bf5,UID:36b33006-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26515,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f1057 0xc0022f1058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f1200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f1220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:192.168.87.195,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://170a6fa4fee728d2dda3876cf5f86475358a1872a30da49a77bad1fd289fea2a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.920: INFO: Pod "nginx-deployment-555b55d965-mfz7b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mfz7b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-mfz7b,UID:36b13857-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26512,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f12e7 0xc0022f12e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f1430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f1450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:192.168.87.254,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://b1fa0ffdbf686ed9b946b8b996a7dbde9e925f4db5d7057cda56af43582850c4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.920: INFO: Pod "nginx-deployment-555b55d965-mx5z8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mx5z8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-mx5z8,UID:36b8f0cc-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26505,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f1517 0xc0022f1518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f1590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f1670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:192.168.45.120,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://94b66286da900a5c4f678409553256b78cb6e11bfeb4a69b631f9110a70488d5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.921: INFO: Pod "nginx-deployment-555b55d965-n2vzw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n2vzw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-n2vzw,UID:3a59d38b-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26683,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f17e7 0xc0022f17e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f18e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f1900}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.922: INFO: Pod "nginx-deployment-555b55d965-qcg8j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qcg8j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-qcg8j,UID:3a5a05a0-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26771,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f1970 0xc0022f1971}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f1a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f1ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.923: INFO: Pod "nginx-deployment-555b55d965-qjlxm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qjlxm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-qjlxm,UID:3a4ef6d2-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26689,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f1b87 0xc0022f1b88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f1bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f1d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.923: INFO: Pod "nginx-deployment-555b55d965-txqfd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-txqfd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-txqfd,UID:3a59724e-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26725,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc0022f1de7 0xc0022f1de8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f1eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f1ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.926: INFO: Pod "nginx-deployment-555b55d965-wdhs4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wdhs4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-wdhs4,UID:36b8a4ef-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26518,Generation:0,CreationTimestamp:2019-02-27 02:41:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc002430057 0xc002430058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024300c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024300e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:41 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:192.168.87.255,StartTime:2019-02-27 02:41:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-27 02:41:43 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ee5b14fff6fa90c1321dd75e7976c29cf72241393918dd5a75c7d66dee59aae7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.926: INFO: Pod "nginx-deployment-555b55d965-xf77t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xf77t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-555b55d965-xf77t,UID:3a4fd450-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26698,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 36ac1bbd-3a39-11e9-bb22-deadbe9ffdf9 0xc002430237 0xc002430238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024302a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024302c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.926: INFO: Pod "nginx-deployment-65bbdb5f8-449ms" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-449ms,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-449ms,UID:3a5629fd-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26736,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002430377 0xc002430378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002430490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024304b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.927: INFO: Pod "nginx-deployment-65bbdb5f8-5zjnb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5zjnb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-5zjnb,UID:3a5a5136-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26790,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002430570 0xc002430571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024305e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002430680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.927: INFO: Pod "nginx-deployment-65bbdb5f8-6gt9s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6gt9s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-6gt9s,UID:39154aee-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26563,Generation:0,CreationTimestamp:2019-02-27 02:41:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002430740 0xc002430741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024307b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024307d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.927: INFO: Pod "nginx-deployment-65bbdb5f8-9644k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9644k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-9644k,UID:3a4e64ea-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26679,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc0024309d0 0xc0024309d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002430a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002430a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.928: INFO: Pod "nginx-deployment-65bbdb5f8-f7c5j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-f7c5j,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-f7c5j,UID:3926c2e7-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26589,Generation:0,CreationTimestamp:2019-02-27 02:41:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002430c60 0xc002430c61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002430cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002430cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.928: INFO: Pod "nginx-deployment-65bbdb5f8-h9hdd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h9hdd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-h9hdd,UID:3a55e029-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26742,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002430db0 0xc002430db1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002430f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002430f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.928: INFO: Pod "nginx-deployment-65bbdb5f8-hjqsn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hjqsn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-hjqsn,UID:3a52276c-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26719,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002430fe0 0xc002430fe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002431050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024310d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.928: INFO: Pod "nginx-deployment-65bbdb5f8-l5tcl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-l5tcl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-l5tcl,UID:3a6128f0-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26691,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002431190 0xc002431191}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002431200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002431220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.928: INFO: Pod "nginx-deployment-65bbdb5f8-lp7wq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lp7wq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-lp7wq,UID:3a56ad69-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26750,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc0024312e0 0xc0024312e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002431350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002431370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.929: INFO: Pod "nginx-deployment-65bbdb5f8-ncmvh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ncmvh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-ncmvh,UID:3a51f543-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26696,Generation:0,CreationTimestamp:2019-02-27 02:41:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc002431430 0xc002431431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002431510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002431530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:47 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.929: INFO: Pod "nginx-deployment-65bbdb5f8-pbxq2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pbxq2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-pbxq2,UID:3918c853-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26572,Generation:0,CreationTimestamp:2019-02-27 02:41:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc0024315f0 0xc0024315f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002431660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002431690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:,StartTime:2019-02-27 02:41:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.929: INFO: Pod "nginx-deployment-65bbdb5f8-qtqsx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qtqsx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-qtqsx,UID:391760db-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26567,Generation:0,CreationTimestamp:2019-02-27 02:41:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc0024317c0 0xc0024317c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002431830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002431850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb 27 02:41:49.929: INFO: Pod "nginx-deployment-65bbdb5f8-rg5wr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rg5wr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-vpp25,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vpp25/pods/nginx-deployment-65bbdb5f8-rg5wr,UID:3924ff17-3a39-11e9-bb22-deadbe9ffdf9,ResourceVersion:26588,Generation:0,CreationTimestamp:2019-02-27 02:41:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 39143d3c-3a39-11e9-bb22-deadbe9ffdf9 0xc0024319c0 0xc0024319c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5hrrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-0ut0w-6f5f764f5c-rj65d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002431a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002431a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:41:45 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.234,PodIP:,StartTime:2019-02-27 02:41:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:41:49.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vpp25" for this suite.
Feb 27 02:41:57.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:41:58.326: INFO: namespace: e2e-tests-deployment-vpp25, resource: bindings, ignored listing per whitelist
Feb 27 02:41:58.335: INFO: namespace e2e-tests-deployment-vpp25 deletion completed in 8.402357386s

• [SLOW TEST:16.905 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:41:58.337: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mtzp2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:41:58.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 version --client'
Feb 27 02:41:58.654: INFO: stderr: ""
Feb 27 02:41:58.654: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb 27 02:41:58.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-mtzp2'
Feb 27 02:41:58.892: INFO: stderr: ""
Feb 27 02:41:58.892: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 27 02:41:58.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-mtzp2'
Feb 27 02:41:59.135: INFO: stderr: ""
Feb 27 02:41:59.135: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 02:42:00.138: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:42:00.138: INFO: Found 0 / 1
Feb 27 02:42:01.138: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:42:01.138: INFO: Found 1 / 1
Feb 27 02:42:01.138: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 02:42:01.140: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:42:01.140: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 02:42:01.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 describe pod redis-master-6kjsc --namespace=e2e-tests-kubectl-mtzp2'
Feb 27 02:42:01.218: INFO: stderr: ""
Feb 27 02:42:01.218: INFO: stdout: "Name:               redis-master-6kjsc\nNamespace:          e2e-tests-kubectl-mtzp2\nPriority:           0\nPriorityClassName:  <none>\nNode:               worker-0ut0w-6f5f764f5c-rj65d/172.23.1.234\nStart Time:         Wed, 27 Feb 2019 02:41:58 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 192.168.87.211\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://80f86df5bf37bc04f2efeed25c75caf0d115123c2bd75a36f1cccd8e43e9f904\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 27 Feb 2019 02:41:59 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gxws6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gxws6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gxws6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned e2e-tests-kubectl-mtzp2/redis-master-6kjsc to worker-0ut0w-6f5f764f5c-rj65d\n"
Feb 27 02:42:01.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 describe rc redis-master --namespace=e2e-tests-kubectl-mtzp2'
Feb 27 02:42:01.309: INFO: stderr: ""
Feb 27 02:42:01.309: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-mtzp2\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-6kjsc\n"
Feb 27 02:42:01.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 describe service redis-master --namespace=e2e-tests-kubectl-mtzp2'
Feb 27 02:42:01.384: INFO: stderr: ""
Feb 27 02:42:01.384: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-mtzp2\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.31.123.95\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.87.211:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 27 02:42:01.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 describe node master-gic7m-86f676f7c4-dhwls'
Feb 27 02:42:01.475: INFO: stderr: ""
Feb 27 02:42:01.475: INFO: stdout: "Name:               master-gic7m-86f676f7c4-dhwls\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    giantswarm.io/provider=kvm\n                    ip=172.23.1.74\n                    kubernetes.io/hostname=master-gic7m-86f676f7c4-dhwls\n                    kvm-operator.giantswarm.io/version=3.2.0\n                    node-role.kubernetes.io/master=\n                    role=master\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 26 Feb 2019 23:55:55 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 27 Feb 2019 02:41:56 +0000   Tue, 26 Feb 2019 23:55:48 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 27 Feb 2019 02:41:56 +0000   Tue, 26 Feb 2019 23:55:48 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 27 Feb 2019 02:41:56 +0000   Tue, 26 Feb 2019 23:55:48 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 27 Feb 2019 02:41:56 +0000   Tue, 26 Feb 2019 23:56:43 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.23.1.74\n  Hostname:    master-gic7m-86f676f7c4-dhwls\nCapacity:\n cpu:                2\n ephemeral-storage:  5110Mi\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8171124Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  5110Mi\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7966324Ki\n pods:               110\nSystem Info:\n Machine ID:                 994772c40c3d447d9a5a02ebb625ad49\n System UUID:                3d6ff2f75c7d3ae927580249a28e7e05\n Boot ID:                    585ad0b5-795b-4997-8249-4e401418cd48\n Kernel Version:             4.14.96-coreos\n OS Image:                   Container Linux by CoreOS 1967.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.3\n Kube-Proxy Version:         v1.13.3\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  giantswarm                 chart-operator-75bd6577bf-wxfsn                            250m (12%)    250m (12%)  250Mi (3%)       250Mi (3%)     161m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-5pdfr    0 (0%)        0 (0%)      0 (0%)           0 (0%)         61m\n  kube-system                calico-kube-controllers-778cfc5b6f-zbpnw                   250m (12%)    250m (12%)  100Mi (1%)       100Mi (1%)     165m\n  kube-system                calico-node-5zh85                                          250m (12%)    250m (12%)  150Mi (1%)       150Mi (1%)     165m\n  kube-system                cert-exporter-2gxx6                                        50m (2%)      50m (2%)    50Mi (0%)        50Mi (0%)      161m\n  kube-system                k8s-api-server-master-gic7m-86f676f7c4-dhwls               300m (15%)    0 (0%)      300Mi (3%)       0 (0%)         165m\n  kube-system                k8s-controller-manager-master-gic7m-86f676f7c4-dhwls       200m (10%)    0 (0%)      200Mi (2%)       0 (0%)         165m\n  kube-system                k8s-scheduler-master-gic7m-86f676f7c4-dhwls                100m (5%)     0 (0%)      100Mi (1%)       0 (0%)         165m\n  kube-system                kube-proxy-jklwq                                           75m (3%)      0 (0%)      80Mi (1%)        0 (0%)         165m\n  kube-system                net-exporter-rb5f9                                         50m (2%)      50m (2%)    50Mi (0%)        50Mi (0%)      160m\n  kube-system                node-exporter-dfbqt                                        55m (2%)      55m (2%)    75Mi (0%)        75Mi (0%)      160m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                1580m (79%)   905m (45%)\n  memory             1355Mi (17%)  675Mi (8%)\n  ephemeral-storage  0 (0%)        0 (0%)\nEvents:              <none>\n"
Feb 27 02:42:01.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 describe namespace e2e-tests-kubectl-mtzp2'
Feb 27 02:42:01.552: INFO: stderr: ""
Feb 27 02:42:01.552: INFO: stdout: "Name:         e2e-tests-kubectl-mtzp2\nLabels:       e2e-framework=kubectl\n              e2e-run=ae26e338-3a30-11e9-853a-328ab8481bb7\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:42:01.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mtzp2" for this suite.
Feb 27 02:42:23.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:42:23.574: INFO: namespace: e2e-tests-kubectl-mtzp2, resource: bindings, ignored listing per whitelist
Feb 27 02:42:23.645: INFO: namespace e2e-tests-kubectl-mtzp2 deletion completed in 22.09086481s

• [SLOW TEST:25.309 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:42:23.646: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4hcml
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4hcml
Feb 27 02:42:27.862: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4hcml
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:42:27.864: INFO: Initial restart count of pod liveness-http is 0
Feb 27 02:42:47.897: INFO: Restart count of pod e2e-tests-container-probe-4hcml/liveness-http is now 1 (20.032828978s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:42:47.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4hcml" for this suite.
Feb 27 02:42:53.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:42:53.970: INFO: namespace: e2e-tests-container-probe-4hcml, resource: bindings, ignored listing per whitelist
Feb 27 02:42:53.999: INFO: namespace e2e-tests-container-probe-4hcml deletion completed in 6.090894361s

• [SLOW TEST:30.353 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:42:54.000: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rj59q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 02:42:54.197: INFO: Waiting up to 5m0s for pod "downward-api-61ec3fe2-3a39-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-rj59q" to be "success or failure"
Feb 27 02:42:54.200: INFO: Pod "downward-api-61ec3fe2-3a39-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.15495ms
Feb 27 02:42:56.202: INFO: Pod "downward-api-61ec3fe2-3a39-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005065051s
STEP: Saw pod success
Feb 27 02:42:56.203: INFO: Pod "downward-api-61ec3fe2-3a39-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:42:56.208: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downward-api-61ec3fe2-3a39-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:42:56.249: INFO: Waiting for pod downward-api-61ec3fe2-3a39-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:42:56.253: INFO: Pod downward-api-61ec3fe2-3a39-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:42:56.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rj59q" for this suite.
Feb 27 02:43:02.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:43:02.314: INFO: namespace: e2e-tests-downward-api-rj59q, resource: bindings, ignored listing per whitelist
Feb 27 02:43:02.344: INFO: namespace e2e-tests-downward-api-rj59q deletion completed in 6.086305643s

• [SLOW TEST:8.343 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:43:02.344: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p76dm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-66e1451a-3a39-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:43:02.517: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-66e1a30c-3a39-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-p76dm" to be "success or failure"
Feb 27 02:43:02.519: INFO: Pod "pod-projected-configmaps-66e1a30c-3a39-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.985859ms
Feb 27 02:43:04.522: INFO: Pod "pod-projected-configmaps-66e1a30c-3a39-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004693701s
STEP: Saw pod success
Feb 27 02:43:04.522: INFO: Pod "pod-projected-configmaps-66e1a30c-3a39-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:43:04.524: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-configmaps-66e1a30c-3a39-11e9-853a-328ab8481bb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:43:04.555: INFO: Waiting for pod pod-projected-configmaps-66e1a30c-3a39-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:43:04.557: INFO: Pod pod-projected-configmaps-66e1a30c-3a39-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:43:04.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p76dm" for this suite.
Feb 27 02:43:10.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:43:10.601: INFO: namespace: e2e-tests-projected-p76dm, resource: bindings, ignored listing per whitelist
Feb 27 02:43:10.654: INFO: namespace e2e-tests-projected-p76dm deletion completed in 6.094185451s

• [SLOW TEST:8.311 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:43:10.654: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7mhdt
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-6bd95084-3a39-11e9-853a-328ab8481bb7
STEP: Creating configMap with name cm-test-opt-upd-6bd95155-3a39-11e9-853a-328ab8481bb7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6bd95084-3a39-11e9-853a-328ab8481bb7
STEP: Updating configmap cm-test-opt-upd-6bd95155-3a39-11e9-853a-328ab8481bb7
STEP: Creating configMap with name cm-test-opt-create-6bd9516b-3a39-11e9-853a-328ab8481bb7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:43:14.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7mhdt" for this suite.
Feb 27 02:43:36.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:43:36.960: INFO: namespace: e2e-tests-configmap-7mhdt, resource: bindings, ignored listing per whitelist
Feb 27 02:43:37.018: INFO: namespace e2e-tests-configmap-7mhdt deletion completed in 22.101231323s

• [SLOW TEST:26.363 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:43:37.019: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lc4pt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lc4pt/configmap-test-7b8e5ea4-3a39-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:43:37.208: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b8ee6cc-3a39-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-lc4pt" to be "success or failure"
Feb 27 02:43:37.213: INFO: Pod "pod-configmaps-7b8ee6cc-3a39-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.853962ms
Feb 27 02:43:39.217: INFO: Pod "pod-configmaps-7b8ee6cc-3a39-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009166589s
STEP: Saw pod success
Feb 27 02:43:39.217: INFO: Pod "pod-configmaps-7b8ee6cc-3a39-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:43:39.219: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-7b8ee6cc-3a39-11e9-853a-328ab8481bb7 container env-test: <nil>
STEP: delete the pod
Feb 27 02:43:39.234: INFO: Waiting for pod pod-configmaps-7b8ee6cc-3a39-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:43:39.237: INFO: Pod pod-configmaps-7b8ee6cc-3a39-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:43:39.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lc4pt" for this suite.
Feb 27 02:43:45.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:43:45.286: INFO: namespace: e2e-tests-configmap-lc4pt, resource: bindings, ignored listing per whitelist
Feb 27 02:43:45.337: INFO: namespace e2e-tests-configmap-lc4pt deletion completed in 6.096865629s

• [SLOW TEST:8.318 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:43:45.338: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-gtkxh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gtkxh
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 02:43:45.503: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 02:44:05.569: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.45.84:8080/dial?request=hostName&protocol=http&host=192.168.45.83&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-gtkxh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:44:05.569: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 02:44:05.657: INFO: Waiting for endpoints: map[]
Feb 27 02:44:05.659: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.45.84:8080/dial?request=hostName&protocol=http&host=192.168.87.219&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-gtkxh PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:44:05.659: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 02:44:05.796: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:44:05.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gtkxh" for this suite.
Feb 27 02:44:27.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:44:27.840: INFO: namespace: e2e-tests-pod-network-test-gtkxh, resource: bindings, ignored listing per whitelist
Feb 27 02:44:27.908: INFO: namespace e2e-tests-pod-network-test-gtkxh deletion completed in 22.109419669s

• [SLOW TEST:42.570 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:44:27.908: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-jbpcv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-99e38592-3a39-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:44:28.095: INFO: Waiting up to 5m0s for pod "pod-configmaps-99e3f69b-3a39-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-jbpcv" to be "success or failure"
Feb 27 02:44:28.098: INFO: Pod "pod-configmaps-99e3f69b-3a39-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.904872ms
Feb 27 02:44:30.101: INFO: Pod "pod-configmaps-99e3f69b-3a39-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005986315s
STEP: Saw pod success
Feb 27 02:44:30.101: INFO: Pod "pod-configmaps-99e3f69b-3a39-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:44:30.103: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-99e3f69b-3a39-11e9-853a-328ab8481bb7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:44:30.117: INFO: Waiting for pod pod-configmaps-99e3f69b-3a39-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:44:30.120: INFO: Pod pod-configmaps-99e3f69b-3a39-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:44:30.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jbpcv" for this suite.
Feb 27 02:44:36.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:44:36.159: INFO: namespace: e2e-tests-configmap-jbpcv, resource: bindings, ignored listing per whitelist
Feb 27 02:44:36.251: INFO: namespace e2e-tests-configmap-jbpcv deletion completed in 6.116656413s

• [SLOW TEST:8.343 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:44:36.252: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-tnf94
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 02:44:36.442: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 02:44:36.447: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 02:44:36.450: INFO: 
Logging pods the kubelet thinks is on node worker-0ut0w-6f5f764f5c-rj65d before test
Feb 27 02:44:36.457: INFO: sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-k7j65 from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:44:36.457: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 02:44:36.457: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 02:44:36.457: INFO: sonobuoy-e2e-job-72ebab7275a04425 from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:44:36.457: INFO: 	Container e2e ready: true, restart count 0
Feb 27 02:44:36.457: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 02:44:36.458: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-27 01:40:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 02:44:36.458: INFO: calico-node-bgfp9 from kube-system started at 2019-02-26 23:56:06 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 02:44:36.458: INFO: kube-proxy-6wvfj from kube-system started at 2019-02-26 23:56:23 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:44:36.458: INFO: coredns-7fb74c7cfc-r72ls from kube-system started at 2019-02-27 00:00:43 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container coredns ready: true, restart count 0
Feb 27 02:44:36.458: INFO: cert-exporter-8prd2 from kube-system started at 2019-02-27 00:00:46 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 02:44:36.458: INFO: default-http-backend-7bcdbb4896-667wr from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 02:44:36.458: INFO: node-exporter-4xmh6 from kube-system started at 2019-02-27 00:01:58 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 02:44:36.458: INFO: metrics-server-7fc59d6b67-6qzwd from kube-system started at 2019-02-27 00:01:05 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.458: INFO: 	Container metrics-server ready: true, restart count 0
Feb 27 02:44:36.459: INFO: net-exporter-m4zjg from kube-system started at 2019-02-27 00:01:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.459: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 02:44:36.459: INFO: nginx-ingress-controller-cbbd68d6f-hdp7m from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.459: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 02:44:36.459: INFO: 
Logging pods the kubelet thinks is on node worker-v332t-5ff768bb65-6znm5 before test
Feb 27 02:44:36.466: INFO: node-exporter-v4qxz from kube-system started at 2019-02-27 00:01:58 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.466: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 02:44:36.466: INFO: coredns-7fb74c7cfc-4bmlv from kube-system started at 2019-02-27 00:00:42 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.466: INFO: 	Container coredns ready: true, restart count 0
Feb 27 02:44:36.466: INFO: default-http-backend-7bcdbb4896-5c6nh from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.466: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 02:44:36.466: INFO: nginx-ingress-controller-cbbd68d6f-rggbs from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.467: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 02:44:36.467: INFO: net-exporter-htg57 from kube-system started at 2019-02-27 00:01:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.467: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 02:44:36.467: INFO: tiller-deploy-7d54987577-cxs4p from giantswarm started at 2019-02-26 23:59:50 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.467: INFO: 	Container tiller ready: true, restart count 0
Feb 27 02:44:36.467: INFO: cert-exporter-8fqlp from kube-system started at 2019-02-27 00:00:46 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.467: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 02:44:36.467: INFO: sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-pd7ll from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:44:36.467: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 02:44:36.467: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 02:44:36.467: INFO: kube-proxy-4c4d8 from kube-system started at 2019-02-26 23:56:23 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.467: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:44:36.467: INFO: kube-state-metrics-68f7795bbd-kfthv from kube-system started at 2019-02-27 00:01:06 +0000 UTC (2 container statuses recorded)
Feb 27 02:44:36.467: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 27 02:44:36.467: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 27 02:44:36.467: INFO: calico-node-lllw6 from kube-system started at 2019-02-26 23:56:06 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.468: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 02:44:36.468: INFO: tiller-deploy-59c6d74887-b9fhn from kube-system started at 2019-02-27 00:00:28 +0000 UTC (1 container statuses recorded)
Feb 27 02:44:36.468: INFO: 	Container tiller ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-a0178a44-3a39-11e9-853a-328ab8481bb7 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-a0178a44-3a39-11e9-853a-328ab8481bb7 off the node worker-0ut0w-6f5f764f5c-rj65d
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a0178a44-3a39-11e9-853a-328ab8481bb7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:44:40.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-tnf94" for this suite.
Feb 27 02:44:58.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:44:58.592: INFO: namespace: e2e-tests-sched-pred-tnf94, resource: bindings, ignored listing per whitelist
Feb 27 02:44:58.641: INFO: namespace e2e-tests-sched-pred-tnf94 deletion completed in 18.096034285s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.390 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:44:58.643: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-6wh8k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6wh8k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 02:44:58.828: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 02:45:12.913: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.87.225:8080/dial?request=hostName&protocol=udp&host=192.168.45.85&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6wh8k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:45:12.913: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 02:45:13.009: INFO: Waiting for endpoints: map[]
Feb 27 02:45:13.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.87.225:8080/dial?request=hostName&protocol=udp&host=192.168.87.223&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6wh8k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 02:45:13.011: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 02:45:13.095: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:45:13.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6wh8k" for this suite.
Feb 27 02:45:35.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:45:35.192: INFO: namespace: e2e-tests-pod-network-test-6wh8k, resource: bindings, ignored listing per whitelist
Feb 27 02:45:35.215: INFO: namespace e2e-tests-pod-network-test-6wh8k deletion completed in 22.116692764s

• [SLOW TEST:36.573 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:45:35.217: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lczt2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb 27 02:45:35.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 api-versions'
Feb 27 02:45:35.456: INFO: stderr: ""
Feb 27 02:45:35.456: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napplication.giantswarm.io/v1alpha1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncore.giantswarm.io/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:45:35.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lczt2" for this suite.
Feb 27 02:45:41.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:45:41.544: INFO: namespace: e2e-tests-kubectl-lczt2, resource: bindings, ignored listing per whitelist
Feb 27 02:45:41.546: INFO: namespace e2e-tests-kubectl-lczt2 deletion completed in 6.086487408s

• [SLOW TEST:6.330 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:45:41.547: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-69cbq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-69cbq
Feb 27 02:45:43.735: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-69cbq
STEP: checking the pod's current state and verifying that restartCount is present
Feb 27 02:45:43.737: INFO: Initial restart count of pod liveness-http is 0
Feb 27 02:45:59.774: INFO: Restart count of pod e2e-tests-container-probe-69cbq/liveness-http is now 1 (16.036198434s elapsed)
Feb 27 02:46:19.811: INFO: Restart count of pod e2e-tests-container-probe-69cbq/liveness-http is now 2 (36.073258113s elapsed)
Feb 27 02:46:39.846: INFO: Restart count of pod e2e-tests-container-probe-69cbq/liveness-http is now 3 (56.108724553s elapsed)
Feb 27 02:46:59.881: INFO: Restart count of pod e2e-tests-container-probe-69cbq/liveness-http is now 4 (1m16.143029342s elapsed)
Feb 27 02:47:59.999: INFO: Restart count of pod e2e-tests-container-probe-69cbq/liveness-http is now 5 (2m16.261320159s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:48:00.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-69cbq" for this suite.
Feb 27 02:48:06.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:48:06.067: INFO: namespace: e2e-tests-container-probe-69cbq, resource: bindings, ignored listing per whitelist
Feb 27 02:48:06.120: INFO: namespace e2e-tests-container-probe-69cbq deletion completed in 6.109783144s

• [SLOW TEST:144.572 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:48:06.120: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bcp4v
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 27 02:48:06.305: INFO: Waiting up to 5m0s for pod "pod-1bf3cc5b-3a3a-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-bcp4v" to be "success or failure"
Feb 27 02:48:06.318: INFO: Pod "pod-1bf3cc5b-3a3a-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.854653ms
Feb 27 02:48:08.321: INFO: Pod "pod-1bf3cc5b-3a3a-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015671133s
STEP: Saw pod success
Feb 27 02:48:08.321: INFO: Pod "pod-1bf3cc5b-3a3a-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:48:08.323: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-1bf3cc5b-3a3a-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:48:08.336: INFO: Waiting for pod pod-1bf3cc5b-3a3a-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:48:08.338: INFO: Pod pod-1bf3cc5b-3a3a-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:48:08.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bcp4v" for this suite.
Feb 27 02:48:14.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:48:14.413: INFO: namespace: e2e-tests-emptydir-bcp4v, resource: bindings, ignored listing per whitelist
Feb 27 02:48:14.430: INFO: namespace e2e-tests-emptydir-bcp4v deletion completed in 6.089201003s

• [SLOW TEST:8.310 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:48:14.432: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bd4jv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb 27 02:48:17.150: INFO: Successfully updated pod "labelsupdate20e76775-3a3a-11e9-853a-328ab8481bb7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:48:21.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bd4jv" for this suite.
Feb 27 02:48:43.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:48:43.235: INFO: namespace: e2e-tests-projected-bd4jv, resource: bindings, ignored listing per whitelist
Feb 27 02:48:43.258: INFO: namespace e2e-tests-projected-bd4jv deletion completed in 22.081218559s

• [SLOW TEST:28.827 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:48:43.260: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hmdzr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 02:48:43.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-hmdzr'
Feb 27 02:48:43.505: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 27 02:48:43.505: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb 27 02:48:43.518: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-qsj6w]
Feb 27 02:48:43.518: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-qsj6w" in namespace "e2e-tests-kubectl-hmdzr" to be "running and ready"
Feb 27 02:48:43.525: INFO: Pod "e2e-test-nginx-rc-qsj6w": Phase="Pending", Reason="", readiness=false. Elapsed: 7.379882ms
Feb 27 02:48:45.529: INFO: Pod "e2e-test-nginx-rc-qsj6w": Phase="Running", Reason="", readiness=true. Elapsed: 2.010648503s
Feb 27 02:48:45.529: INFO: Pod "e2e-test-nginx-rc-qsj6w" satisfied condition "running and ready"
Feb 27 02:48:45.529: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-qsj6w]
Feb 27 02:48:45.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hmdzr'
Feb 27 02:48:45.610: INFO: stderr: ""
Feb 27 02:48:45.610: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb 27 02:48:45.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hmdzr'
Feb 27 02:48:45.688: INFO: stderr: ""
Feb 27 02:48:45.689: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:48:45.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hmdzr" for this suite.
Feb 27 02:49:07.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:49:07.760: INFO: namespace: e2e-tests-kubectl-hmdzr, resource: bindings, ignored listing per whitelist
Feb 27 02:49:07.787: INFO: namespace e2e-tests-kubectl-hmdzr deletion completed in 22.087729485s

• [SLOW TEST:24.528 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:49:07.790: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-v5bb6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-40b76940-3a3a-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:49:07.991: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-40b7c430-3a3a-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-v5bb6" to be "success or failure"
Feb 27 02:49:07.994: INFO: Pod "pod-projected-configmaps-40b7c430-3a3a-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.657304ms
Feb 27 02:49:09.998: INFO: Pod "pod-projected-configmaps-40b7c430-3a3a-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00736108s
STEP: Saw pod success
Feb 27 02:49:09.998: INFO: Pod "pod-projected-configmaps-40b7c430-3a3a-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:49:10.000: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-configmaps-40b7c430-3a3a-11e9-853a-328ab8481bb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:49:10.018: INFO: Waiting for pod pod-projected-configmaps-40b7c430-3a3a-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:49:10.020: INFO: Pod pod-projected-configmaps-40b7c430-3a3a-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:49:10.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v5bb6" for this suite.
Feb 27 02:49:16.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:49:16.078: INFO: namespace: e2e-tests-projected-v5bb6, resource: bindings, ignored listing per whitelist
Feb 27 02:49:16.109: INFO: namespace e2e-tests-projected-v5bb6 deletion completed in 6.085953786s

• [SLOW TEST:8.319 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:49:16.111: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-hbpzc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-x66nd in namespace e2e-tests-proxy-hbpzc
I0227 02:49:16.289870      19 runners.go:184] Created replication controller with name: proxy-service-x66nd, namespace: e2e-tests-proxy-hbpzc, replica count: 1
I0227 02:49:17.340282      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 02:49:18.340532      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0227 02:49:19.340756      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 02:49:20.340970      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 02:49:21.341127      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 02:49:22.341293      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 02:49:23.341606      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0227 02:49:24.341812      19 runners.go:184] proxy-service-x66nd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 27 02:49:24.345: INFO: setup took 8.069065355s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 27 02:49:24.351: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 5.67281ms)
Feb 27 02:49:24.351: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 5.777818ms)
Feb 27 02:49:24.351: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 6.187711ms)
Feb 27 02:49:24.361: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 15.295166ms)
Feb 27 02:49:24.361: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 15.477688ms)
Feb 27 02:49:24.361: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 15.028844ms)
Feb 27 02:49:24.365: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 19.426203ms)
Feb 27 02:49:24.365: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 19.481965ms)
Feb 27 02:49:24.365: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 19.729242ms)
Feb 27 02:49:24.365: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 19.538885ms)
Feb 27 02:49:24.365: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 19.420991ms)
Feb 27 02:49:24.366: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 20.670225ms)
Feb 27 02:49:24.367: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 20.989073ms)
Feb 27 02:49:24.367: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 21.720076ms)
Feb 27 02:49:24.367: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 21.456493ms)
Feb 27 02:49:24.368: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 22.785557ms)
Feb 27 02:49:24.377: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 7.873784ms)
Feb 27 02:49:24.377: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 8.006592ms)
Feb 27 02:49:24.377: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.621819ms)
Feb 27 02:49:24.377: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 8.423936ms)
Feb 27 02:49:24.378: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 8.79148ms)
Feb 27 02:49:24.383: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 13.687867ms)
Feb 27 02:49:24.383: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 13.804843ms)
Feb 27 02:49:24.383: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 14.397867ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 14.319534ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 14.938702ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 14.564022ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 15.30288ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 15.276789ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 15.059945ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 15.192419ms)
Feb 27 02:49:24.384: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 15.805914ms)
Feb 27 02:49:24.389: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 4.965336ms)
Feb 27 02:49:24.390: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 5.103831ms)
Feb 27 02:49:24.391: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 6.194061ms)
Feb 27 02:49:24.391: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 6.195236ms)
Feb 27 02:49:24.391: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 6.398836ms)
Feb 27 02:49:24.392: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 7.253233ms)
Feb 27 02:49:24.392: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 7.140371ms)
Feb 27 02:49:24.392: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 7.211493ms)
Feb 27 02:49:24.393: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.328004ms)
Feb 27 02:49:24.393: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 7.27722ms)
Feb 27 02:49:24.393: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.813693ms)
Feb 27 02:49:24.394: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 9.278663ms)
Feb 27 02:49:24.394: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 9.646705ms)
Feb 27 02:49:24.395: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 9.203031ms)
Feb 27 02:49:24.395: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 9.335648ms)
Feb 27 02:49:24.395: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 9.496055ms)
Feb 27 02:49:24.399: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 3.778733ms)
Feb 27 02:49:24.403: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 7.727127ms)
Feb 27 02:49:24.403: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 8.027687ms)
Feb 27 02:49:24.403: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 7.917498ms)
Feb 27 02:49:24.403: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 7.781543ms)
Feb 27 02:49:24.404: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 7.672309ms)
Feb 27 02:49:24.404: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 8.233739ms)
Feb 27 02:49:24.404: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 8.270018ms)
Feb 27 02:49:24.404: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.128973ms)
Feb 27 02:49:24.404: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.204216ms)
Feb 27 02:49:24.404: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 8.617135ms)
Feb 27 02:49:24.406: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 10.206628ms)
Feb 27 02:49:24.406: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 10.669275ms)
Feb 27 02:49:24.406: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 10.215657ms)
Feb 27 02:49:24.407: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 11.01248ms)
Feb 27 02:49:24.406: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 10.488028ms)
Feb 27 02:49:24.413: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 6.368584ms)
Feb 27 02:49:24.414: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.248721ms)
Feb 27 02:49:24.414: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 7.461732ms)
Feb 27 02:49:24.415: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 7.762015ms)
Feb 27 02:49:24.415: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 8.337743ms)
Feb 27 02:49:24.415: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 8.064312ms)
Feb 27 02:49:24.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.698066ms)
Feb 27 02:49:24.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 8.719336ms)
Feb 27 02:49:24.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.187756ms)
Feb 27 02:49:24.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 9.522429ms)
Feb 27 02:49:24.416: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 9.583857ms)
Feb 27 02:49:24.419: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 12.049989ms)
Feb 27 02:49:24.419: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 12.020643ms)
Feb 27 02:49:24.419: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 12.648671ms)
Feb 27 02:49:24.420: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 12.725114ms)
Feb 27 02:49:24.420: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 13.19369ms)
Feb 27 02:49:24.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 6.695965ms)
Feb 27 02:49:24.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 6.899017ms)
Feb 27 02:49:24.427: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 7.178827ms)
Feb 27 02:49:24.428: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.660397ms)
Feb 27 02:49:24.429: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 8.358617ms)
Feb 27 02:49:24.429: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 8.302724ms)
Feb 27 02:49:24.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 9.367406ms)
Feb 27 02:49:24.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 9.199539ms)
Feb 27 02:49:24.430: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 9.884145ms)
Feb 27 02:49:24.431: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 10.660249ms)
Feb 27 02:49:24.431: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 10.205087ms)
Feb 27 02:49:24.431: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 11.068099ms)
Feb 27 02:49:24.434: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 13.404312ms)
Feb 27 02:49:24.434: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 12.953603ms)
Feb 27 02:49:24.434: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 13.476665ms)
Feb 27 02:49:24.434: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 13.209204ms)
Feb 27 02:49:24.441: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 6.893014ms)
Feb 27 02:49:24.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.360642ms)
Feb 27 02:49:24.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 7.269252ms)
Feb 27 02:49:24.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 7.134852ms)
Feb 27 02:49:24.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 8.060894ms)
Feb 27 02:49:24.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 7.972146ms)
Feb 27 02:49:24.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 8.520797ms)
Feb 27 02:49:24.444: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 9.424424ms)
Feb 27 02:49:24.444: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 9.001484ms)
Feb 27 02:49:24.444: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.366572ms)
Feb 27 02:49:24.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 11.062382ms)
Feb 27 02:49:24.446: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 12.125605ms)
Feb 27 02:49:24.447: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 12.156415ms)
Feb 27 02:49:24.447: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 11.854391ms)
Feb 27 02:49:24.447: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 12.64096ms)
Feb 27 02:49:24.447: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 12.7172ms)
Feb 27 02:49:24.452: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 4.565203ms)
Feb 27 02:49:24.452: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 4.966861ms)
Feb 27 02:49:24.453: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 4.981953ms)
Feb 27 02:49:24.456: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 8.340157ms)
Feb 27 02:49:24.456: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 8.45078ms)
Feb 27 02:49:24.460: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 12.44321ms)
Feb 27 02:49:24.461: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 13.82729ms)
Feb 27 02:49:24.461: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 13.811147ms)
Feb 27 02:49:24.462: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 13.934034ms)
Feb 27 02:49:24.462: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 14.058796ms)
Feb 27 02:49:24.462: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 14.289002ms)
Feb 27 02:49:24.462: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 14.68121ms)
Feb 27 02:49:24.463: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 14.891474ms)
Feb 27 02:49:24.463: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 14.988817ms)
Feb 27 02:49:24.463: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 15.188804ms)
Feb 27 02:49:24.463: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 15.370791ms)
Feb 27 02:49:24.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 6.943294ms)
Feb 27 02:49:24.471: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 7.154939ms)
Feb 27 02:49:24.471: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 7.72524ms)
Feb 27 02:49:24.471: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 7.516264ms)
Feb 27 02:49:24.471: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.839211ms)
Feb 27 02:49:24.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 8.468448ms)
Feb 27 02:49:24.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 8.643668ms)
Feb 27 02:49:24.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 8.533141ms)
Feb 27 02:49:24.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.877614ms)
Feb 27 02:49:24.473: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 9.667005ms)
Feb 27 02:49:24.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 9.991425ms)
Feb 27 02:49:24.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 10.475274ms)
Feb 27 02:49:24.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 10.861784ms)
Feb 27 02:49:24.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 10.984589ms)
Feb 27 02:49:24.475: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 11.089239ms)
Feb 27 02:49:24.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 12.418381ms)
Feb 27 02:49:24.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 6.138623ms)
Feb 27 02:49:24.482: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 6.546226ms)
Feb 27 02:49:24.483: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 6.663447ms)
Feb 27 02:49:24.486: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 9.791118ms)
Feb 27 02:49:24.486: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 9.991444ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 13.489392ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 13.163932ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 13.370602ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 13.344119ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 13.94025ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 13.586878ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 13.735672ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 13.704414ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 13.862449ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 14.018171ms)
Feb 27 02:49:24.490: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 13.589536ms)
Feb 27 02:49:24.497: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 6.631219ms)
Feb 27 02:49:24.497: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 6.146334ms)
Feb 27 02:49:24.498: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.101633ms)
Feb 27 02:49:24.499: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 8.157749ms)
Feb 27 02:49:24.499: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 8.384973ms)
Feb 27 02:49:24.499: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 8.420755ms)
Feb 27 02:49:24.500: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 9.267256ms)
Feb 27 02:49:24.500: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.824665ms)
Feb 27 02:49:24.501: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 9.744338ms)
Feb 27 02:49:24.501: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 10.240239ms)
Feb 27 02:49:24.501: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 10.14662ms)
Feb 27 02:49:24.501: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 10.207638ms)
Feb 27 02:49:24.501: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 10.75847ms)
Feb 27 02:49:24.501: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 10.432903ms)
Feb 27 02:49:24.503: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 12.902612ms)
Feb 27 02:49:24.503: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 12.488182ms)
Feb 27 02:49:24.514: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 10.325095ms)
Feb 27 02:49:24.515: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 11.512143ms)
Feb 27 02:49:24.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 11.872004ms)
Feb 27 02:49:24.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 12.201311ms)
Feb 27 02:49:24.516: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 12.155887ms)
Feb 27 02:49:24.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 12.725062ms)
Feb 27 02:49:24.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 13.36555ms)
Feb 27 02:49:24.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 13.49862ms)
Feb 27 02:49:24.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 13.251352ms)
Feb 27 02:49:24.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 13.375757ms)
Feb 27 02:49:24.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 13.594743ms)
Feb 27 02:49:24.517: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 13.506032ms)
Feb 27 02:49:24.518: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 14.190786ms)
Feb 27 02:49:24.518: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 13.997148ms)
Feb 27 02:49:24.518: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 14.022558ms)
Feb 27 02:49:24.519: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 14.700613ms)
Feb 27 02:49:24.522: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 3.381118ms)
Feb 27 02:49:24.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 4.159339ms)
Feb 27 02:49:24.523: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 4.212308ms)
Feb 27 02:49:24.526: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 6.886248ms)
Feb 27 02:49:24.530: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 10.638122ms)
Feb 27 02:49:24.530: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 10.837343ms)
Feb 27 02:49:24.530: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 11.462022ms)
Feb 27 02:49:24.531: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 11.421474ms)
Feb 27 02:49:24.531: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 11.804263ms)
Feb 27 02:49:24.531: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 11.751244ms)
Feb 27 02:49:24.531: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 12.016908ms)
Feb 27 02:49:24.531: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 12.794671ms)
Feb 27 02:49:24.532: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 12.249703ms)
Feb 27 02:49:24.534: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 14.421584ms)
Feb 27 02:49:24.534: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 15.080065ms)
Feb 27 02:49:24.534: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 15.5404ms)
Feb 27 02:49:24.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 7.308913ms)
Feb 27 02:49:24.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.463303ms)
Feb 27 02:49:24.544: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.886831ms)
Feb 27 02:49:24.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.898191ms)
Feb 27 02:49:24.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 10.296732ms)
Feb 27 02:49:24.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 10.631111ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 10.755107ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 10.969031ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 10.967629ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 11.288952ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 11.180464ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 11.40803ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 11.728992ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 11.746781ms)
Feb 27 02:49:24.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 11.787703ms)
Feb 27 02:49:24.547: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 11.831086ms)
Feb 27 02:49:24.552: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 5.531449ms)
Feb 27 02:49:24.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 6.207755ms)
Feb 27 02:49:24.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 6.383453ms)
Feb 27 02:49:24.553: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 6.385688ms)
Feb 27 02:49:24.554: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 6.386462ms)
Feb 27 02:49:24.554: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 6.630247ms)
Feb 27 02:49:24.557: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 10.09571ms)
Feb 27 02:49:24.557: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 9.557786ms)
Feb 27 02:49:24.557: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 9.895505ms)
Feb 27 02:49:24.558: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 10.565128ms)
Feb 27 02:49:24.558: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 10.674689ms)
Feb 27 02:49:24.558: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 11.086951ms)
Feb 27 02:49:24.558: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 11.173992ms)
Feb 27 02:49:24.559: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 11.624582ms)
Feb 27 02:49:24.559: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 11.877689ms)
Feb 27 02:49:24.559: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 12.094085ms)
Feb 27 02:49:24.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 4.710411ms)
Feb 27 02:49:24.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 5.18909ms)
Feb 27 02:49:24.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 5.331716ms)
Feb 27 02:49:24.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.272696ms)
Feb 27 02:49:24.568: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.163368ms)
Feb 27 02:49:24.569: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 8.585356ms)
Feb 27 02:49:24.569: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 9.120781ms)
Feb 27 02:49:24.569: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 9.306964ms)
Feb 27 02:49:24.569: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 9.468827ms)
Feb 27 02:49:24.569: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 9.462589ms)
Feb 27 02:49:24.569: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 10.041115ms)
Feb 27 02:49:24.572: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 12.047807ms)
Feb 27 02:49:24.572: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 12.44093ms)
Feb 27 02:49:24.573: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 13.542306ms)
Feb 27 02:49:24.573: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 13.384844ms)
Feb 27 02:49:24.574: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 13.708281ms)
Feb 27 02:49:24.579: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 5.116522ms)
Feb 27 02:49:24.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 8.283ms)
Feb 27 02:49:24.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.139065ms)
Feb 27 02:49:24.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 9.590056ms)
Feb 27 02:49:24.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 10.188036ms)
Feb 27 02:49:24.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 10.142759ms)
Feb 27 02:49:24.585: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 10.093858ms)
Feb 27 02:49:24.585: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 10.157895ms)
Feb 27 02:49:24.585: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 9.936798ms)
Feb 27 02:49:24.585: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 10.869726ms)
Feb 27 02:49:24.587: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 12.218691ms)
Feb 27 02:49:24.587: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 12.720386ms)
Feb 27 02:49:24.587: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 13.115337ms)
Feb 27 02:49:24.587: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 13.370111ms)
Feb 27 02:49:24.588: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 13.086554ms)
Feb 27 02:49:24.588: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 13.88691ms)
Feb 27 02:49:24.591: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 3.297493ms)
Feb 27 02:49:24.596: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 7.54209ms)
Feb 27 02:49:24.597: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.495452ms)
Feb 27 02:49:24.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 9.391771ms)
Feb 27 02:49:24.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 9.521952ms)
Feb 27 02:49:24.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 9.601402ms)
Feb 27 02:49:24.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.14827ms)
Feb 27 02:49:24.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 9.41943ms)
Feb 27 02:49:24.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 9.582223ms)
Feb 27 02:49:24.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 9.768787ms)
Feb 27 02:49:24.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 10.812784ms)
Feb 27 02:49:24.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 11.204613ms)
Feb 27 02:49:24.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 10.647068ms)
Feb 27 02:49:24.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 10.858556ms)
Feb 27 02:49:24.599: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 11.115119ms)
Feb 27 02:49:24.600: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 10.952233ms)
Feb 27 02:49:24.603: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 3.838107ms)
Feb 27 02:49:24.604: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 4.088034ms)
Feb 27 02:49:24.607: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 6.806373ms)
Feb 27 02:49:24.607: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 6.555211ms)
Feb 27 02:49:24.607: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 6.888029ms)
Feb 27 02:49:24.607: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 7.424521ms)
Feb 27 02:49:24.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 7.47897ms)
Feb 27 02:49:24.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 7.671166ms)
Feb 27 02:49:24.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 8.08364ms)
Feb 27 02:49:24.608: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 8.444422ms)
Feb 27 02:49:24.609: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 8.742981ms)
Feb 27 02:49:24.610: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 10.565941ms)
Feb 27 02:49:24.610: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 10.12195ms)
Feb 27 02:49:24.611: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 10.440931ms)
Feb 27 02:49:24.611: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 10.881607ms)
Feb 27 02:49:24.611: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 10.639651ms)
Feb 27 02:49:24.617: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:1080/proxy/rewri... (200; 5.185129ms)
Feb 27 02:49:24.617: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m/proxy/rewriteme"... (200; 5.708572ms)
Feb 27 02:49:24.617: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:1080/proxy/... (200; 5.631609ms)
Feb 27 02:49:24.617: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:443/proxy/... (200; 5.955126ms)
Feb 27 02:49:24.618: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:162/proxy/: bar (200; 6.592341ms)
Feb 27 02:49:24.618: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:460/proxy/: tls baz (200; 6.34997ms)
Feb 27 02:49:24.619: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/proxy-service-x66nd-zj84m:160/proxy/: foo (200; 7.369818ms)
Feb 27 02:49:24.619: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/https:proxy-service-x66nd-zj84m:462/proxy/: tls qux (200; 7.751735ms)
Feb 27 02:49:24.619: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:162/proxy/: bar (200; 8.168314ms)
Feb 27 02:49:24.619: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/pods/http:proxy-service-x66nd-zj84m:160/proxy/: foo (200; 7.564025ms)
Feb 27 02:49:24.620: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname2/proxy/: bar (200; 8.548401ms)
Feb 27 02:49:24.620: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname2/proxy/: bar (200; 8.488881ms)
Feb 27 02:49:24.620: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname2/proxy/: tls qux (200; 8.461976ms)
Feb 27 02:49:24.620: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/http:proxy-service-x66nd:portname1/proxy/: foo (200; 9.11699ms)
Feb 27 02:49:24.620: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/proxy-service-x66nd:portname1/proxy/: foo (200; 8.829734ms)
Feb 27 02:49:24.621: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-hbpzc/services/https:proxy-service-x66nd:tlsportname1/proxy/: tls baz (200; 9.305807ms)
STEP: deleting ReplicationController proxy-service-x66nd in namespace e2e-tests-proxy-hbpzc, will wait for the garbage collector to delete the pods
Feb 27 02:49:24.677: INFO: Deleting ReplicationController proxy-service-x66nd took: 4.298189ms
Feb 27 02:49:24.778: INFO: Terminating ReplicationController proxy-service-x66nd pods took: 101.336486ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:49:37.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hbpzc" for this suite.
Feb 27 02:49:43.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:49:43.728: INFO: namespace: e2e-tests-proxy-hbpzc, resource: bindings, ignored listing per whitelist
Feb 27 02:49:43.798: INFO: namespace e2e-tests-proxy-hbpzc deletion completed in 6.111826056s

• [SLOW TEST:27.688 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:49:43.798: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-kn7xn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 02:49:43.988: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 02:49:43.993: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 02:49:43.994: INFO: 
Logging pods the kubelet thinks is on node worker-0ut0w-6f5f764f5c-rj65d before test
Feb 27 02:49:44.001: INFO: cert-exporter-8prd2 from kube-system started at 2019-02-27 00:00:46 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.001: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 02:49:44.001: INFO: default-http-backend-7bcdbb4896-667wr from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.001: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 02:49:44.001: INFO: node-exporter-4xmh6 from kube-system started at 2019-02-27 00:01:58 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 02:49:44.002: INFO: metrics-server-7fc59d6b67-6qzwd from kube-system started at 2019-02-27 00:01:05 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container metrics-server ready: true, restart count 0
Feb 27 02:49:44.002: INFO: net-exporter-m4zjg from kube-system started at 2019-02-27 00:01:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 02:49:44.002: INFO: nginx-ingress-controller-cbbd68d6f-hdp7m from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 02:49:44.002: INFO: sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-k7j65 from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 02:49:44.002: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 02:49:44.002: INFO: sonobuoy-e2e-job-72ebab7275a04425 from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container e2e ready: true, restart count 0
Feb 27 02:49:44.002: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 02:49:44.002: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-27 01:40:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 02:49:44.002: INFO: calico-node-bgfp9 from kube-system started at 2019-02-26 23:56:06 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 02:49:44.002: INFO: kube-proxy-6wvfj from kube-system started at 2019-02-26 23:56:23 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.002: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:49:44.002: INFO: coredns-7fb74c7cfc-r72ls from kube-system started at 2019-02-27 00:00:43 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.003: INFO: 	Container coredns ready: true, restart count 0
Feb 27 02:49:44.003: INFO: 
Logging pods the kubelet thinks is on node worker-v332t-5ff768bb65-6znm5 before test
Feb 27 02:49:44.010: INFO: sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-pd7ll from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 02:49:44.010: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 02:49:44.010: INFO: tiller-deploy-7d54987577-cxs4p from giantswarm started at 2019-02-26 23:59:50 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container tiller ready: true, restart count 0
Feb 27 02:49:44.010: INFO: cert-exporter-8fqlp from kube-system started at 2019-02-27 00:00:46 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 02:49:44.010: INFO: kube-proxy-4c4d8 from kube-system started at 2019-02-26 23:56:23 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:49:44.010: INFO: kube-state-metrics-68f7795bbd-kfthv from kube-system started at 2019-02-27 00:01:06 +0000 UTC (2 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 27 02:49:44.010: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 27 02:49:44.010: INFO: calico-node-lllw6 from kube-system started at 2019-02-26 23:56:06 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 02:49:44.010: INFO: tiller-deploy-59c6d74887-b9fhn from kube-system started at 2019-02-27 00:00:28 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container tiller ready: true, restart count 0
Feb 27 02:49:44.010: INFO: node-exporter-v4qxz from kube-system started at 2019-02-27 00:01:58 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 02:49:44.010: INFO: coredns-7fb74c7cfc-4bmlv from kube-system started at 2019-02-27 00:00:42 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container coredns ready: true, restart count 0
Feb 27 02:49:44.010: INFO: default-http-backend-7bcdbb4896-5c6nh from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 02:49:44.010: INFO: nginx-ingress-controller-cbbd68d6f-rggbs from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 02:49:44.010: INFO: net-exporter-htg57 from kube-system started at 2019-02-27 00:01:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:49:44.010: INFO: 	Container net-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.158718ba0df36b3c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:49:45.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kn7xn" for this suite.
Feb 27 02:49:51.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:49:51.099: INFO: namespace: e2e-tests-sched-pred-kn7xn, resource: bindings, ignored listing per whitelist
Feb 27 02:49:51.154: INFO: namespace e2e-tests-sched-pred-kn7xn deletion completed in 6.122916951s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.356 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:49:51.155: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-fsvl9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb 27 02:49:51.868: INFO: Waiting up to 5m0s for pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-l8n28" in namespace "e2e-tests-svcaccounts-fsvl9" to be "success or failure"
Feb 27 02:49:51.879: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-l8n28": Phase="Pending", Reason="", readiness=false. Elapsed: 10.674566ms
Feb 27 02:49:53.883: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-l8n28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014426236s
STEP: Saw pod success
Feb 27 02:49:53.883: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-l8n28" satisfied condition "success or failure"
Feb 27 02:49:53.885: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-l8n28 container token-test: <nil>
STEP: delete the pod
Feb 27 02:49:53.898: INFO: Waiting for pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-l8n28 to disappear
Feb 27 02:49:53.900: INFO: Pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-l8n28 no longer exists
STEP: Creating a pod to test consume service account root CA
Feb 27 02:49:53.903: INFO: Waiting up to 5m0s for pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f" in namespace "e2e-tests-svcaccounts-fsvl9" to be "success or failure"
Feb 27 02:49:53.907: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.822707ms
Feb 27 02:49:55.910: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007292367s
Feb 27 02:49:57.914: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011187525s
STEP: Saw pod success
Feb 27 02:49:57.914: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f" satisfied condition "success or failure"
Feb 27 02:49:57.916: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f container root-ca-test: <nil>
STEP: delete the pod
Feb 27 02:49:57.932: INFO: Waiting for pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f to disappear
Feb 27 02:49:57.934: INFO: Pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-4vt9f no longer exists
STEP: Creating a pod to test consume service account namespace
Feb 27 02:49:57.937: INFO: Waiting up to 5m0s for pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-rzcp9" in namespace "e2e-tests-svcaccounts-fsvl9" to be "success or failure"
Feb 27 02:49:57.940: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-rzcp9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.653353ms
Feb 27 02:49:59.944: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-rzcp9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006360022s
STEP: Saw pod success
Feb 27 02:49:59.944: INFO: Pod "pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-rzcp9" satisfied condition "success or failure"
Feb 27 02:49:59.946: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-rzcp9 container namespace-test: <nil>
STEP: delete the pod
Feb 27 02:49:59.960: INFO: Waiting for pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-rzcp9 to disappear
Feb 27 02:49:59.962: INFO: Pod pod-service-account-5adf2fa8-3a3a-11e9-853a-328ab8481bb7-rzcp9 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:49:59.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fsvl9" for this suite.
Feb 27 02:50:05.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:50:06.016: INFO: namespace: e2e-tests-svcaccounts-fsvl9, resource: bindings, ignored listing per whitelist
Feb 27 02:50:06.052: INFO: namespace e2e-tests-svcaccounts-fsvl9 deletion completed in 6.086710581s

• [SLOW TEST:14.897 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:50:06.052: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-zsfg9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-tnqm
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 02:50:06.241: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-tnqm" in namespace "e2e-tests-subpath-zsfg9" to be "success or failure"
Feb 27 02:50:06.246: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Pending", Reason="", readiness=false. Elapsed: 5.094612ms
Feb 27 02:50:08.248: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007072345s
Feb 27 02:50:10.251: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 4.010219442s
Feb 27 02:50:12.262: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 6.020736826s
Feb 27 02:50:14.265: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 8.023632906s
Feb 27 02:50:16.268: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 10.02662498s
Feb 27 02:50:18.271: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 12.029394306s
Feb 27 02:50:20.273: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 14.031990254s
Feb 27 02:50:22.276: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 16.034408361s
Feb 27 02:50:24.278: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 18.036692051s
Feb 27 02:50:26.281: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 20.039821652s
Feb 27 02:50:28.285: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Running", Reason="", readiness=false. Elapsed: 22.044059528s
Feb 27 02:50:30.289: INFO: Pod "pod-subpath-test-downwardapi-tnqm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.047782978s
STEP: Saw pod success
Feb 27 02:50:30.289: INFO: Pod "pod-subpath-test-downwardapi-tnqm" satisfied condition "success or failure"
Feb 27 02:50:30.291: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod pod-subpath-test-downwardapi-tnqm container test-container-subpath-downwardapi-tnqm: <nil>
STEP: delete the pod
Feb 27 02:50:30.314: INFO: Waiting for pod pod-subpath-test-downwardapi-tnqm to disappear
Feb 27 02:50:30.316: INFO: Pod pod-subpath-test-downwardapi-tnqm no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-tnqm
Feb 27 02:50:30.316: INFO: Deleting pod "pod-subpath-test-downwardapi-tnqm" in namespace "e2e-tests-subpath-zsfg9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:50:30.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zsfg9" for this suite.
Feb 27 02:50:36.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:50:36.430: INFO: namespace: e2e-tests-subpath-zsfg9, resource: bindings, ignored listing per whitelist
Feb 27 02:50:36.437: INFO: namespace e2e-tests-subpath-zsfg9 deletion completed in 6.115013041s

• [SLOW TEST:30.385 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:50:36.437: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-dgrrr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-9d44
STEP: Creating a pod to test atomic-volume-subpath
Feb 27 02:50:36.643: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9d44" in namespace "e2e-tests-subpath-dgrrr" to be "success or failure"
Feb 27 02:50:36.646: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.82061ms
Feb 27 02:50:38.650: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00701301s
Feb 27 02:50:40.653: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 4.00983593s
Feb 27 02:50:42.656: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 6.013358675s
Feb 27 02:50:44.659: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 8.01638796s
Feb 27 02:50:46.663: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 10.019914927s
Feb 27 02:50:48.667: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 12.023833417s
Feb 27 02:50:50.670: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 14.027455308s
Feb 27 02:50:52.674: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 16.030630555s
Feb 27 02:50:54.677: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 18.03394031s
Feb 27 02:50:56.681: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Running", Reason="", readiness=false. Elapsed: 20.037613326s
Feb 27 02:50:58.697: INFO: Pod "pod-subpath-test-projected-9d44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.053759053s
STEP: Saw pod success
Feb 27 02:50:58.697: INFO: Pod "pod-subpath-test-projected-9d44" satisfied condition "success or failure"
Feb 27 02:50:58.699: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-subpath-test-projected-9d44 container test-container-subpath-projected-9d44: <nil>
STEP: delete the pod
Feb 27 02:50:58.738: INFO: Waiting for pod pod-subpath-test-projected-9d44 to disappear
Feb 27 02:50:58.742: INFO: Pod pod-subpath-test-projected-9d44 no longer exists
STEP: Deleting pod pod-subpath-test-projected-9d44
Feb 27 02:50:58.742: INFO: Deleting pod "pod-subpath-test-projected-9d44" in namespace "e2e-tests-subpath-dgrrr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:50:58.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dgrrr" for this suite.
Feb 27 02:51:04.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:51:04.782: INFO: namespace: e2e-tests-subpath-dgrrr, resource: bindings, ignored listing per whitelist
Feb 27 02:51:04.840: INFO: namespace e2e-tests-subpath-dgrrr deletion completed in 6.082946662s

• [SLOW TEST:28.403 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:51:04.840: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pkdtb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb 27 02:51:05.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pkdtb'
Feb 27 02:51:05.189: INFO: stderr: ""
Feb 27 02:51:05.189: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb 27 02:51:10.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pkdtb -o json'
Feb 27 02:51:10.303: INFO: stderr: ""
Feb 27 02:51:10.303: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"cert-exporter-psp\"\n        },\n        \"creationTimestamp\": \"2019-02-27T02:51:05Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-pkdtb\",\n        \"resourceVersion\": \"29110\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-pkdtb/pods/e2e-test-nginx-pod\",\n        \"uid\": \"8692acbe-3a3a-11e9-bb22-deadbe9ffdf9\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hqb4s\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker-0ut0w-6f5f764f5c-rj65d\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hqb4s\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hqb4s\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T02:51:05Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T02:51:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T02:51:06Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-27T02:51:05Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://96b474c580ee5d14ca504404e68ff1e9497fabd50c8131d219fdd8f66d57b0db\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-27T02:51:06Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.23.1.234\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.87.234\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-27T02:51:05Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 27 02:51:10.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 replace -f - --namespace=e2e-tests-kubectl-pkdtb'
Feb 27 02:51:10.427: INFO: stderr: ""
Feb 27 02:51:10.427: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb 27 02:51:10.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pkdtb'
Feb 27 02:51:11.898: INFO: stderr: ""
Feb 27 02:51:11.898: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:51:11.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pkdtb" for this suite.
Feb 27 02:51:17.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:51:17.984: INFO: namespace: e2e-tests-kubectl-pkdtb, resource: bindings, ignored listing per whitelist
Feb 27 02:51:17.994: INFO: namespace e2e-tests-kubectl-pkdtb deletion completed in 6.093066887s

• [SLOW TEST:13.155 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:51:17.996: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lx2l6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb 27 02:51:18.165: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-766965386 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:51:18.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lx2l6" for this suite.
Feb 27 02:51:24.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:51:24.242: INFO: namespace: e2e-tests-kubectl-lx2l6, resource: bindings, ignored listing per whitelist
Feb 27 02:51:24.297: INFO: namespace e2e-tests-kubectl-lx2l6 deletion completed in 6.082474215s

• [SLOW TEST:6.301 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:51:24.298: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ppnq9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-bn68q
STEP: Creating secret with name secret-test-92131f69-3a3a-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:51:24.621: INFO: Waiting up to 5m0s for pod "pod-secrets-92287970-3a3a-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-ppnq9" to be "success or failure"
Feb 27 02:51:24.630: INFO: Pod "pod-secrets-92287970-3a3a-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.245721ms
Feb 27 02:51:26.634: INFO: Pod "pod-secrets-92287970-3a3a-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012652387s
STEP: Saw pod success
Feb 27 02:51:26.634: INFO: Pod "pod-secrets-92287970-3a3a-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:51:26.636: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-92287970-3a3a-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:51:26.648: INFO: Waiting for pod pod-secrets-92287970-3a3a-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:51:26.651: INFO: Pod pod-secrets-92287970-3a3a-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:51:26.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ppnq9" for this suite.
Feb 27 02:51:32.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:51:32.695: INFO: namespace: e2e-tests-secrets-ppnq9, resource: bindings, ignored listing per whitelist
Feb 27 02:51:32.745: INFO: namespace e2e-tests-secrets-ppnq9 deletion completed in 6.090224841s
STEP: Destroying namespace "e2e-tests-secret-namespace-bn68q" for this suite.
Feb 27 02:51:38.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:51:38.782: INFO: namespace: e2e-tests-secret-namespace-bn68q, resource: bindings, ignored listing per whitelist
Feb 27 02:51:38.834: INFO: namespace e2e-tests-secret-namespace-bn68q deletion completed in 6.089714621s

• [SLOW TEST:14.537 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:51:38.836: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-6cttg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 27 02:51:39.018: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29258,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:51:39.018: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29258,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 27 02:51:49.024: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29275,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 27 02:51:49.024: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29275,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 27 02:51:59.030: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29291,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:51:59.030: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29291,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 27 02:52:09.035: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29307,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:52:09.035: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-a,UID:9abe8e44-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29307,Generation:0,CreationTimestamp:2019-02-27 02:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 27 02:52:19.040: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-b,UID:b2995006-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29324,Generation:0,CreationTimestamp:2019-02-27 02:52:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:52:19.041: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-b,UID:b2995006-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29324,Generation:0,CreationTimestamp:2019-02-27 02:52:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 27 02:52:29.046: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-b,UID:b2995006-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29340,Generation:0,CreationTimestamp:2019-02-27 02:52:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:52:29.046: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6cttg,SelfLink:/api/v1/namespaces/e2e-tests-watch-6cttg/configmaps/e2e-watch-test-configmap-b,UID:b2995006-3a3a-11e9-bb22-deadbe9ffdf9,ResourceVersion:29340,Generation:0,CreationTimestamp:2019-02-27 02:52:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:52:39.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6cttg" for this suite.
Feb 27 02:52:45.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:52:45.091: INFO: namespace: e2e-tests-watch-6cttg, resource: bindings, ignored listing per whitelist
Feb 27 02:52:45.138: INFO: namespace e2e-tests-watch-6cttg deletion completed in 6.087294892s

• [SLOW TEST:66.303 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:52:45.139: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ld79q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c242215b-3a3a-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:52:45.323: INFO: Waiting up to 5m0s for pod "pod-secrets-c2429952-3a3a-11e9-853a-328ab8481bb7" in namespace "e2e-tests-secrets-ld79q" to be "success or failure"
Feb 27 02:52:45.330: INFO: Pod "pod-secrets-c2429952-3a3a-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.838122ms
Feb 27 02:52:47.340: INFO: Pod "pod-secrets-c2429952-3a3a-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017293295s
STEP: Saw pod success
Feb 27 02:52:47.340: INFO: Pod "pod-secrets-c2429952-3a3a-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:52:47.351: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-secrets-c2429952-3a3a-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:52:47.371: INFO: Waiting for pod pod-secrets-c2429952-3a3a-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:52:47.380: INFO: Pod pod-secrets-c2429952-3a3a-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:52:47.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ld79q" for this suite.
Feb 27 02:52:53.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:52:53.418: INFO: namespace: e2e-tests-secrets-ld79q, resource: bindings, ignored listing per whitelist
Feb 27 02:52:53.475: INFO: namespace e2e-tests-secrets-ld79q deletion completed in 6.087475687s

• [SLOW TEST:8.336 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:52:53.475: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-cbcdd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-cbcdd
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cbcdd to expose endpoints map[]
Feb 27 02:52:53.669: INFO: Get endpoints failed (7.828757ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 27 02:52:54.672: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cbcdd exposes endpoints map[] (1.010834758s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-cbcdd
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cbcdd to expose endpoints map[pod1:[80]]
Feb 27 02:52:56.694: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cbcdd exposes endpoints map[pod1:[80]] (2.017545987s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-cbcdd
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cbcdd to expose endpoints map[pod2:[80] pod1:[80]]
Feb 27 02:52:58.720: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cbcdd exposes endpoints map[pod1:[80] pod2:[80]] (2.022682331s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-cbcdd
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cbcdd to expose endpoints map[pod2:[80]]
Feb 27 02:52:59.737: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cbcdd exposes endpoints map[pod2:[80]] (1.011246729s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-cbcdd
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-cbcdd to expose endpoints map[]
Feb 27 02:52:59.752: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-cbcdd exposes endpoints map[] (8.67695ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:52:59.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-cbcdd" for this suite.
Feb 27 02:53:21.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:53:21.831: INFO: namespace: e2e-tests-services-cbcdd, resource: bindings, ignored listing per whitelist
Feb 27 02:53:21.876: INFO: namespace e2e-tests-services-cbcdd deletion completed in 22.092266197s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.401 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:53:21.876: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-6r49j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb 27 02:53:22.059: INFO: Waiting up to 5m0s for pod "var-expansion-d828088c-3a3a-11e9-853a-328ab8481bb7" in namespace "e2e-tests-var-expansion-6r49j" to be "success or failure"
Feb 27 02:53:22.060: INFO: Pod "var-expansion-d828088c-3a3a-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.859557ms
Feb 27 02:53:24.064: INFO: Pod "var-expansion-d828088c-3a3a-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005018571s
STEP: Saw pod success
Feb 27 02:53:24.064: INFO: Pod "var-expansion-d828088c-3a3a-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:53:24.066: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod var-expansion-d828088c-3a3a-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:53:24.080: INFO: Waiting for pod var-expansion-d828088c-3a3a-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:53:24.082: INFO: Pod var-expansion-d828088c-3a3a-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:53:24.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6r49j" for this suite.
Feb 27 02:53:30.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:53:30.150: INFO: namespace: e2e-tests-var-expansion-6r49j, resource: bindings, ignored listing per whitelist
Feb 27 02:53:30.174: INFO: namespace e2e-tests-var-expansion-6r49j deletion completed in 6.089557442s

• [SLOW TEST:8.298 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:53:30.174: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xdhjh
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-dd1c8847-3a3a-11e9-853a-328ab8481bb7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-dd1c8847-3a3a-11e9-853a-328ab8481bb7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:53:34.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xdhjh" for this suite.
Feb 27 02:53:56.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:53:56.456: INFO: namespace: e2e-tests-configmap-xdhjh, resource: bindings, ignored listing per whitelist
Feb 27 02:53:56.509: INFO: namespace e2e-tests-configmap-xdhjh deletion completed in 22.105588725s

• [SLOW TEST:26.335 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:53:56.511: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-49cv2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb 27 02:53:56.688: INFO: namespace e2e-tests-kubectl-49cv2
Feb 27 02:53:56.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-49cv2'
Feb 27 02:53:56.819: INFO: stderr: ""
Feb 27 02:53:56.819: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 27 02:53:57.823: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:53:57.823: INFO: Found 0 / 1
Feb 27 02:53:58.823: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:53:58.823: INFO: Found 1 / 1
Feb 27 02:53:58.823: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 02:53:58.825: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:53:58.825: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 27 02:53:58.825: INFO: wait on redis-master startup in e2e-tests-kubectl-49cv2 
Feb 27 02:53:58.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 logs redis-master-klrjk redis-master --namespace=e2e-tests-kubectl-49cv2'
Feb 27 02:53:58.895: INFO: stderr: ""
Feb 27 02:53:58.895: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 02:53:57.724 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 02:53:57.725 # Server started, Redis version 3.2.12\n1:M 27 Feb 02:53:57.725 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 02:53:57.725 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb 27 02:53:58.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-49cv2'
Feb 27 02:53:58.972: INFO: stderr: ""
Feb 27 02:53:58.972: INFO: stdout: "service/rm2 exposed\n"
Feb 27 02:53:58.974: INFO: Service rm2 in namespace e2e-tests-kubectl-49cv2 found.
STEP: exposing service
Feb 27 02:54:00.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-49cv2'
Feb 27 02:54:01.066: INFO: stderr: ""
Feb 27 02:54:01.066: INFO: stdout: "service/rm3 exposed\n"
Feb 27 02:54:01.069: INFO: Service rm3 in namespace e2e-tests-kubectl-49cv2 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:54:03.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-49cv2" for this suite.
Feb 27 02:54:25.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:54:25.113: INFO: namespace: e2e-tests-kubectl-49cv2, resource: bindings, ignored listing per whitelist
Feb 27 02:54:25.155: INFO: namespace e2e-tests-kubectl-49cv2 deletion completed in 22.07857809s

• [SLOW TEST:28.644 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:54:25.156: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-pp448
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:54:25.346: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 27 02:54:25.352: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:25.354: INFO: Number of nodes with available pods: 0
Feb 27 02:54:25.354: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:54:26.359: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:26.362: INFO: Number of nodes with available pods: 0
Feb 27 02:54:26.362: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:54:27.358: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:27.360: INFO: Number of nodes with available pods: 2
Feb 27 02:54:27.360: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 27 02:54:27.390: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:27.390: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:27.393: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:28.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:28.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:28.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:29.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:29.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:29.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:30.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:30.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:30.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:31.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:31.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:31.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:32.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:32.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:32.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:33.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:33.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:33.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:34.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:34.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:34.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:35.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:35.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:35.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:36.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:36.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:36.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:37.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:37.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:37.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:38.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:38.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:38.398: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:39.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:39.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:39.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:40.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:40.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:40.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:41.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:41.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:41.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:42.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:42.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:42.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:43.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:43.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:43.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:44.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:44.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:44.398: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:45.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:45.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:45.398: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:46.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:46.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:46.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:47.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:47.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:47.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:48.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:48.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:48.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:49.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:49.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:49.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:50.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:50.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:50.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:51.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:51.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:51.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:52.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:52.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:52.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:53.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:53.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:53.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:54.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:54.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:54.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:55.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:55.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:55.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:56.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:56.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:56.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:57.409: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:57.410: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:57.412: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:58.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:58.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:58.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:54:59.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:59.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:54:59.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:00.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:00.397: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:00.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:01.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:01.396: INFO: Wrong image for pod: daemon-set-rfmkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:01.396: INFO: Pod daemon-set-rfmkj is not available
Feb 27 02:55:01.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:02.397: INFO: Pod daemon-set-2mfxw is not available
Feb 27 02:55:02.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:02.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:03.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:03.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:04.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:04.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:05.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:05.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:06.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:06.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:07.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:07.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:08.398: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:08.403: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:09.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:09.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:10.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:10.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:11.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:11.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:12.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:12.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:13.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:13.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:14.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:14.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:15.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:15.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:16.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:16.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:17.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:17.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:18.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:18.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:19.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:19.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:20.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:20.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:21.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:21.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:22.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:22.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:23.398: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:23.402: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:24.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:24.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:25.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:25.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:26.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:26.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:27.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:27.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:28.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:28.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:29.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:29.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:30.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:30.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:31.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:31.401: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:32.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:32.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:33.396: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:33.398: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:34.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:34.397: INFO: Pod daemon-set-4lqtz is not available
Feb 27 02:55:34.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:35.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:35.397: INFO: Pod daemon-set-4lqtz is not available
Feb 27 02:55:35.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:36.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:36.397: INFO: Pod daemon-set-4lqtz is not available
Feb 27 02:55:36.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:37.397: INFO: Wrong image for pod: daemon-set-4lqtz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb 27 02:55:37.397: INFO: Pod daemon-set-4lqtz is not available
Feb 27 02:55:37.400: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:38.396: INFO: Pod daemon-set-hm2m6 is not available
Feb 27 02:55:38.399: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 27 02:55:38.407: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:38.410: INFO: Number of nodes with available pods: 1
Feb 27 02:55:38.410: INFO: Node worker-0ut0w-6f5f764f5c-rj65d is running more than one daemon pod
Feb 27 02:55:39.415: INFO: DaemonSet pods can't tolerate node master-gic7m-86f676f7c4-dhwls with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 27 02:55:39.421: INFO: Number of nodes with available pods: 2
Feb 27 02:55:39.421: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-pp448, will wait for the garbage collector to delete the pods
Feb 27 02:55:39.491: INFO: Deleting DaemonSet.extensions daemon-set took: 4.380429ms
Feb 27 02:55:39.591: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.267424ms
Feb 27 02:55:47.697: INFO: Number of nodes with available pods: 0
Feb 27 02:55:47.697: INFO: Number of running nodes: 0, number of available pods: 0
Feb 27 02:55:47.699: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pp448/daemonsets","resourceVersion":"29994"},"items":null}

Feb 27 02:55:47.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pp448/pods","resourceVersion":"29994"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:55:47.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pp448" for this suite.
Feb 27 02:55:53.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:55:53.746: INFO: namespace: e2e-tests-daemonsets-pp448, resource: bindings, ignored listing per whitelist
Feb 27 02:55:53.809: INFO: namespace e2e-tests-daemonsets-pp448 deletion completed in 6.086128578s

• [SLOW TEST:88.654 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:55:53.810: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-hvbbl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:55:57.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-hvbbl" for this suite.
Feb 27 02:56:04.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:56:04.098: INFO: namespace: e2e-tests-kubelet-test-hvbbl, resource: bindings, ignored listing per whitelist
Feb 27 02:56:04.098: INFO: namespace e2e-tests-kubelet-test-hvbbl deletion completed in 6.100644441s

• [SLOW TEST:10.288 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:56:04.098: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-gz7pl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:56:25.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-gz7pl" for this suite.
Feb 27 02:56:31.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:56:31.549: INFO: namespace: e2e-tests-container-runtime-gz7pl, resource: bindings, ignored listing per whitelist
Feb 27 02:56:31.553: INFO: namespace e2e-tests-container-runtime-gz7pl deletion completed in 6.091365553s

• [SLOW TEST:27.455 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:56:31.555: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-grl26
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:56:31.761: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 27 02:56:36.765: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 27 02:56:36.765: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 27 02:56:38.772: INFO: Creating deployment "test-rollover-deployment"
Feb 27 02:56:38.785: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 27 02:56:40.794: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 27 02:56:40.798: INFO: Ensure that both replica sets have 1 created replica
Feb 27 02:56:40.802: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 27 02:56:40.810: INFO: Updating deployment test-rollover-deployment
Feb 27 02:56:40.810: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 27 02:56:42.819: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 27 02:56:42.823: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 27 02:56:42.827: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:56:42.827: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:56:44.833: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:56:44.833: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:56:46.833: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:56:46.833: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:56:48.832: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:56:48.833: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:56:50.833: INFO: all replica sets need to contain the pod-template-hash label
Feb 27 02:56:50.833: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833002, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686832998, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 27 02:56:52.835: INFO: 
Feb 27 02:56:52.835: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb 27 02:56:52.845: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-grl26,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grl26/deployments/test-rollover-deployment,UID:4d6a8473-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30338,Generation:2,CreationTimestamp:2019-02-27 02:56:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-27 02:56:38 +0000 UTC 2019-02-27 02:56:38 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-27 02:56:52 +0000 UTC 2019-02-27 02:56:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb 27 02:56:52.850: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-grl26,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grl26/replicasets/test-rollover-deployment-6b7f9d6597,UID:4ea0ea28-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30329,Generation:2,CreationTimestamp:2019-02-27 02:56:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 4d6a8473-3a3b-11e9-bb22-deadbe9ffdf9 0xc0016bf0b7 0xc0016bf0b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb 27 02:56:52.850: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 27 02:56:52.850: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-grl26,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grl26/replicasets/test-rollover-controller,UID:493a101f-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30337,Generation:2,CreationTimestamp:2019-02-27 02:56:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 4d6a8473-3a3b-11e9-bb22-deadbe9ffdf9 0xc0016bee87 0xc0016bee88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:56:52.850: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-grl26,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-grl26/replicasets/test-rollover-deployment-6586df867b,UID:4d6ce3de-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30296,Generation:2,CreationTimestamp:2019-02-27 02:56:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 4d6a8473-3a3b-11e9-bb22-deadbe9ffdf9 0xc0016bef57 0xc0016bef58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb 27 02:56:52.852: INFO: Pod "test-rollover-deployment-6b7f9d6597-bkqn5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-bkqn5,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-grl26,SelfLink:/api/v1/namespaces/e2e-tests-deployment-grl26/pods/test-rollover-deployment-6b7f9d6597-bkqn5,UID:4ea6fb80-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30311,Generation:0,CreationTimestamp:2019-02-27 02:56:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 4ea0ea28-3a3b-11e9-bb22-deadbe9ffdf9 0xc0019c7ad7 0xc0019c7ad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-x4pss {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x4pss,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-x4pss true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-v332t-5ff768bb65-6znm5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019c7c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019c7c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:56:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:56:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:56:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-27 02:56:40 +0000 UTC  }],Message:,Reason:,HostIP:172.23.1.190,PodIP:192.168.45.91,StartTime:2019-02-27 02:56:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-27 02:56:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://ed4ea29d038528cd6d2b1d7bc4d8ee2e468115f9a8f8069c0d6456cfd357fdb5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:56:52.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-grl26" for this suite.
Feb 27 02:56:58.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:56:58.881: INFO: namespace: e2e-tests-deployment-grl26, resource: bindings, ignored listing per whitelist
Feb 27 02:56:58.939: INFO: namespace e2e-tests-deployment-grl26 deletion completed in 6.079785255s

• [SLOW TEST:27.384 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:56:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-m9v5r
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 27 02:56:59.130: INFO: Waiting up to 5m0s for pod "pod-598a978e-3a3b-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-m9v5r" to be "success or failure"
Feb 27 02:56:59.133: INFO: Pod "pod-598a978e-3a3b-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334603ms
Feb 27 02:57:01.148: INFO: Pod "pod-598a978e-3a3b-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018181803s
STEP: Saw pod success
Feb 27 02:57:01.148: INFO: Pod "pod-598a978e-3a3b-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:57:01.150: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-598a978e-3a3b-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 02:57:01.170: INFO: Waiting for pod pod-598a978e-3a3b-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:57:01.174: INFO: Pod pod-598a978e-3a3b-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:57:01.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m9v5r" for this suite.
Feb 27 02:57:07.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:57:07.262: INFO: namespace: e2e-tests-emptydir-m9v5r, resource: bindings, ignored listing per whitelist
Feb 27 02:57:07.320: INFO: namespace e2e-tests-emptydir-m9v5r deletion completed in 6.130048036s

• [SLOW TEST:8.381 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:57:07.320: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5hjt2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb 27 02:57:07.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:07.635: INFO: stderr: ""
Feb 27 02:57:07.635: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 02:57:07.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:07.727: INFO: stderr: ""
Feb 27 02:57:07.727: INFO: stdout: "update-demo-nautilus-ls689 update-demo-nautilus-w74zz "
Feb 27 02:57:07.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-ls689 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:07.807: INFO: stderr: ""
Feb 27 02:57:07.807: INFO: stdout: ""
Feb 27 02:57:07.807: INFO: update-demo-nautilus-ls689 is created but not running
Feb 27 02:57:12.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:12.865: INFO: stderr: ""
Feb 27 02:57:12.865: INFO: stdout: "update-demo-nautilus-ls689 update-demo-nautilus-w74zz "
Feb 27 02:57:12.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-ls689 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:12.924: INFO: stderr: ""
Feb 27 02:57:12.924: INFO: stdout: "true"
Feb 27 02:57:12.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-ls689 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:12.992: INFO: stderr: ""
Feb 27 02:57:12.992: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:57:12.992: INFO: validating pod update-demo-nautilus-ls689
Feb 27 02:57:12.995: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:57:12.995: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:57:12.995: INFO: update-demo-nautilus-ls689 is verified up and running
Feb 27 02:57:12.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-w74zz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:13.054: INFO: stderr: ""
Feb 27 02:57:13.054: INFO: stdout: "true"
Feb 27 02:57:13.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-w74zz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:13.123: INFO: stderr: ""
Feb 27 02:57:13.123: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 02:57:13.123: INFO: validating pod update-demo-nautilus-w74zz
Feb 27 02:57:13.134: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 02:57:13.134: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 02:57:13.134: INFO: update-demo-nautilus-w74zz is verified up and running
STEP: using delete to clean up resources
Feb 27 02:57:13.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:13.200: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:57:13.200: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 27 02:57:13.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-5hjt2'
Feb 27 02:57:13.289: INFO: stderr: "No resources found.\n"
Feb 27 02:57:13.289: INFO: stdout: ""
Feb 27 02:57:13.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -l name=update-demo --namespace=e2e-tests-kubectl-5hjt2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 02:57:13.425: INFO: stderr: ""
Feb 27 02:57:13.425: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:57:13.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5hjt2" for this suite.
Feb 27 02:57:19.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:57:19.488: INFO: namespace: e2e-tests-kubectl-5hjt2, resource: bindings, ignored listing per whitelist
Feb 27 02:57:19.523: INFO: namespace e2e-tests-kubectl-5hjt2 deletion completed in 6.095174562s

• [SLOW TEST:12.203 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:57:19.524: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5b2v6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-65d1c3fd-3a3b-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 02:57:19.732: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-65d24ef6-3a3b-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-5b2v6" to be "success or failure"
Feb 27 02:57:19.735: INFO: Pod "pod-projected-secrets-65d24ef6-3a3b-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.355207ms
Feb 27 02:57:21.738: INFO: Pod "pod-projected-secrets-65d24ef6-3a3b-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006450295s
STEP: Saw pod success
Feb 27 02:57:21.738: INFO: Pod "pod-projected-secrets-65d24ef6-3a3b-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:57:21.740: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-secrets-65d24ef6-3a3b-11e9-853a-328ab8481bb7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 27 02:57:21.763: INFO: Waiting for pod pod-projected-secrets-65d24ef6-3a3b-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:57:21.765: INFO: Pod pod-projected-secrets-65d24ef6-3a3b-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:57:21.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5b2v6" for this suite.
Feb 27 02:57:27.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:57:27.859: INFO: namespace: e2e-tests-projected-5b2v6, resource: bindings, ignored listing per whitelist
Feb 27 02:57:27.867: INFO: namespace e2e-tests-projected-5b2v6 deletion completed in 6.099185876s

• [SLOW TEST:8.343 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:57:27.867: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-565zs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb 27 02:57:28.121: INFO: Waiting up to 5m0s for pod "var-expansion-6ad1a8c2-3a3b-11e9-853a-328ab8481bb7" in namespace "e2e-tests-var-expansion-565zs" to be "success or failure"
Feb 27 02:57:28.125: INFO: Pod "var-expansion-6ad1a8c2-3a3b-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.502086ms
Feb 27 02:57:30.128: INFO: Pod "var-expansion-6ad1a8c2-3a3b-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006572185s
STEP: Saw pod success
Feb 27 02:57:30.128: INFO: Pod "var-expansion-6ad1a8c2-3a3b-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:57:30.130: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod var-expansion-6ad1a8c2-3a3b-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 02:57:30.147: INFO: Waiting for pod var-expansion-6ad1a8c2-3a3b-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:57:30.149: INFO: Pod var-expansion-6ad1a8c2-3a3b-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:57:30.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-565zs" for this suite.
Feb 27 02:57:36.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:57:36.200: INFO: namespace: e2e-tests-var-expansion-565zs, resource: bindings, ignored listing per whitelist
Feb 27 02:57:36.256: INFO: namespace e2e-tests-var-expansion-565zs deletion completed in 6.103075427s

• [SLOW TEST:8.388 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:57:36.256: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tckw2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-6fc6a656-3a3b-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 02:57:36.437: INFO: Waiting up to 5m0s for pod "pod-configmaps-6fc70cac-3a3b-11e9-853a-328ab8481bb7" in namespace "e2e-tests-configmap-tckw2" to be "success or failure"
Feb 27 02:57:36.441: INFO: Pod "pod-configmaps-6fc70cac-3a3b-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.739453ms
Feb 27 02:57:38.449: INFO: Pod "pod-configmaps-6fc70cac-3a3b-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012794425s
STEP: Saw pod success
Feb 27 02:57:38.450: INFO: Pod "pod-configmaps-6fc70cac-3a3b-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:57:38.452: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-configmaps-6fc70cac-3a3b-11e9-853a-328ab8481bb7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 02:57:38.468: INFO: Waiting for pod pod-configmaps-6fc70cac-3a3b-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:57:38.470: INFO: Pod pod-configmaps-6fc70cac-3a3b-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:57:38.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tckw2" for this suite.
Feb 27 02:57:44.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:57:44.523: INFO: namespace: e2e-tests-configmap-tckw2, resource: bindings, ignored listing per whitelist
Feb 27 02:57:44.569: INFO: namespace e2e-tests-configmap-tckw2 deletion completed in 6.094818327s

• [SLOW TEST:8.313 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:57:44.569: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-7z4zp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 27 02:57:44.749: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7z4zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-7z4zp/configmaps/e2e-watch-test-watch-closed,UID:74bc10cb-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30682,Generation:0,CreationTimestamp:2019-02-27 02:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 27 02:57:44.749: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7z4zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-7z4zp/configmaps/e2e-watch-test-watch-closed,UID:74bc10cb-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30683,Generation:0,CreationTimestamp:2019-02-27 02:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 27 02:57:44.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7z4zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-7z4zp/configmaps/e2e-watch-test-watch-closed,UID:74bc10cb-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30684,Generation:0,CreationTimestamp:2019-02-27 02:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 27 02:57:44.759: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-7z4zp,SelfLink:/api/v1/namespaces/e2e-tests-watch-7z4zp/configmaps/e2e-watch-test-watch-closed,UID:74bc10cb-3a3b-11e9-bb22-deadbe9ffdf9,ResourceVersion:30685,Generation:0,CreationTimestamp:2019-02-27 02:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:57:44.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7z4zp" for this suite.
Feb 27 02:57:50.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:57:50.787: INFO: namespace: e2e-tests-watch-7z4zp, resource: bindings, ignored listing per whitelist
Feb 27 02:57:50.853: INFO: namespace e2e-tests-watch-7z4zp deletion completed in 6.091035289s

• [SLOW TEST:6.283 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:57:50.853: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-zcq6b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zcq6b
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb 27 02:57:51.035: INFO: Found 0 stateful pods, waiting for 3
Feb 27 02:58:01.039: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:58:01.039: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:58:01.039: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb 27 02:58:01.065: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 27 02:58:11.096: INFO: Updating stateful set ss2
Feb 27 02:58:11.101: INFO: Waiting for Pod e2e-tests-statefulset-zcq6b/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb 27 02:58:21.162: INFO: Found 2 stateful pods, waiting for 3
Feb 27 02:58:31.166: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:58:31.166: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 27 02:58:31.166: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 27 02:58:31.189: INFO: Updating stateful set ss2
Feb 27 02:58:31.196: INFO: Waiting for Pod e2e-tests-statefulset-zcq6b/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb 27 02:58:41.218: INFO: Updating stateful set ss2
Feb 27 02:58:41.224: INFO: Waiting for StatefulSet e2e-tests-statefulset-zcq6b/ss2 to complete update
Feb 27 02:58:41.224: INFO: Waiting for Pod e2e-tests-statefulset-zcq6b/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb 27 02:58:51.230: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zcq6b
Feb 27 02:58:51.233: INFO: Scaling statefulset ss2 to 0
Feb 27 02:59:01.245: INFO: Waiting for statefulset status.replicas updated to 0
Feb 27 02:59:01.247: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:59:01.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zcq6b" for this suite.
Feb 27 02:59:07.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:59:07.299: INFO: namespace: e2e-tests-statefulset-zcq6b, resource: bindings, ignored listing per whitelist
Feb 27 02:59:07.382: INFO: namespace e2e-tests-statefulset-zcq6b deletion completed in 6.11743353s

• [SLOW TEST:76.529 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:59:07.383: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nmsw8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 02:59:07.576: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a619bef8-3a3b-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-nmsw8" to be "success or failure"
Feb 27 02:59:07.578: INFO: Pod "downwardapi-volume-a619bef8-3a3b-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.524466ms
Feb 27 02:59:09.581: INFO: Pod "downwardapi-volume-a619bef8-3a3b-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005819891s
STEP: Saw pod success
Feb 27 02:59:09.582: INFO: Pod "downwardapi-volume-a619bef8-3a3b-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 02:59:09.585: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-a619bef8-3a3b-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 02:59:09.599: INFO: Waiting for pod downwardapi-volume-a619bef8-3a3b-11e9-853a-328ab8481bb7 to disappear
Feb 27 02:59:09.601: INFO: Pod downwardapi-volume-a619bef8-3a3b-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:59:09.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nmsw8" for this suite.
Feb 27 02:59:15.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:59:15.679: INFO: namespace: e2e-tests-projected-nmsw8, resource: bindings, ignored listing per whitelist
Feb 27 02:59:15.709: INFO: namespace e2e-tests-projected-nmsw8 deletion completed in 6.10461916s

• [SLOW TEST:8.326 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:59:15.709: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mkqx8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb 27 02:59:15.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-mkqx8'
Feb 27 02:59:16.047: INFO: stderr: ""
Feb 27 02:59:16.047: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb 27 02:59:17.057: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:59:17.057: INFO: Found 0 / 1
Feb 27 02:59:18.050: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:59:18.050: INFO: Found 1 / 1
Feb 27 02:59:18.050: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 27 02:59:18.052: INFO: Selector matched 1 pods for map[app:redis]
Feb 27 02:59:18.052: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb 27 02:59:18.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 logs redis-master-82l48 redis-master --namespace=e2e-tests-kubectl-mkqx8'
Feb 27 02:59:18.123: INFO: stderr: ""
Feb 27 02:59:18.123: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 02:59:16.992 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 02:59:16.992 # Server started, Redis version 3.2.12\n1:M 27 Feb 02:59:16.992 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 02:59:16.992 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb 27 02:59:18.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 log redis-master-82l48 redis-master --namespace=e2e-tests-kubectl-mkqx8 --tail=1'
Feb 27 02:59:18.191: INFO: stderr: ""
Feb 27 02:59:18.191: INFO: stdout: "1:M 27 Feb 02:59:16.992 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb 27 02:59:18.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 log redis-master-82l48 redis-master --namespace=e2e-tests-kubectl-mkqx8 --limit-bytes=1'
Feb 27 02:59:18.261: INFO: stderr: ""
Feb 27 02:59:18.261: INFO: stdout: " "
STEP: exposing timestamps
Feb 27 02:59:18.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 log redis-master-82l48 redis-master --namespace=e2e-tests-kubectl-mkqx8 --tail=1 --timestamps'
Feb 27 02:59:18.358: INFO: stderr: ""
Feb 27 02:59:18.358: INFO: stdout: "2019-02-27T02:59:16.992841097Z 1:M 27 Feb 02:59:16.992 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb 27 02:59:20.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 log redis-master-82l48 redis-master --namespace=e2e-tests-kubectl-mkqx8 --since=1s'
Feb 27 02:59:20.930: INFO: stderr: ""
Feb 27 02:59:20.930: INFO: stdout: ""
Feb 27 02:59:20.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 log redis-master-82l48 redis-master --namespace=e2e-tests-kubectl-mkqx8 --since=24h'
Feb 27 02:59:21.002: INFO: stderr: ""
Feb 27 02:59:21.002: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Feb 02:59:16.992 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Feb 02:59:16.992 # Server started, Redis version 3.2.12\n1:M 27 Feb 02:59:16.992 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Feb 02:59:16.992 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb 27 02:59:21.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mkqx8'
Feb 27 02:59:21.092: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 27 02:59:21.092: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb 27 02:59:21.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-mkqx8'
Feb 27 02:59:21.166: INFO: stderr: "No resources found.\n"
Feb 27 02:59:21.166: INFO: stdout: ""
Feb 27 02:59:21.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -l name=nginx --namespace=e2e-tests-kubectl-mkqx8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 27 02:59:21.242: INFO: stderr: ""
Feb 27 02:59:21.242: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:59:21.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mkqx8" for this suite.
Feb 27 02:59:43.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:59:43.346: INFO: namespace: e2e-tests-kubectl-mkqx8, resource: bindings, ignored listing per whitelist
Feb 27 02:59:43.352: INFO: namespace e2e-tests-kubectl-mkqx8 deletion completed in 22.102592494s

• [SLOW TEST:27.643 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:59:43.352: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-grgcb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb 27 02:59:43.533: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 27 02:59:43.540: INFO: Waiting for terminating namespaces to be deleted...
Feb 27 02:59:43.541: INFO: 
Logging pods the kubelet thinks is on node worker-0ut0w-6f5f764f5c-rj65d before test
Feb 27 02:59:43.548: INFO: sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-k7j65 from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:59:43.548: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 02:59:43.548: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 02:59:43.548: INFO: sonobuoy-e2e-job-72ebab7275a04425 from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:59:43.548: INFO: 	Container e2e ready: true, restart count 0
Feb 27 02:59:43.548: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 27 02:59:43.548: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-27 01:40:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.548: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 27 02:59:43.548: INFO: calico-node-bgfp9 from kube-system started at 2019-02-26 23:56:06 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 02:59:43.549: INFO: kube-proxy-6wvfj from kube-system started at 2019-02-26 23:56:23 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:59:43.549: INFO: coredns-7fb74c7cfc-r72ls from kube-system started at 2019-02-27 00:00:43 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container coredns ready: true, restart count 0
Feb 27 02:59:43.549: INFO: cert-exporter-8prd2 from kube-system started at 2019-02-27 00:00:46 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 02:59:43.549: INFO: default-http-backend-7bcdbb4896-667wr from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 02:59:43.549: INFO: node-exporter-4xmh6 from kube-system started at 2019-02-27 00:01:58 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 02:59:43.549: INFO: metrics-server-7fc59d6b67-6qzwd from kube-system started at 2019-02-27 00:01:05 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container metrics-server ready: true, restart count 0
Feb 27 02:59:43.549: INFO: net-exporter-m4zjg from kube-system started at 2019-02-27 00:01:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.549: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 02:59:43.549: INFO: nginx-ingress-controller-cbbd68d6f-hdp7m from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.550: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 02:59:43.550: INFO: 
Logging pods the kubelet thinks is on node worker-v332t-5ff768bb65-6znm5 before test
Feb 27 02:59:43.557: INFO: node-exporter-v4qxz from kube-system started at 2019-02-27 00:01:58 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container node-exporter ready: true, restart count 0
Feb 27 02:59:43.557: INFO: coredns-7fb74c7cfc-4bmlv from kube-system started at 2019-02-27 00:00:42 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container coredns ready: true, restart count 0
Feb 27 02:59:43.557: INFO: default-http-backend-7bcdbb4896-5c6nh from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container default-http-backend ready: true, restart count 0
Feb 27 02:59:43.557: INFO: nginx-ingress-controller-cbbd68d6f-rggbs from kube-system started at 2019-02-27 00:01:11 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 27 02:59:43.557: INFO: net-exporter-htg57 from kube-system started at 2019-02-27 00:01:08 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container net-exporter ready: true, restart count 0
Feb 27 02:59:43.557: INFO: sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-pd7ll from heptio-sonobuoy started at 2019-02-27 01:40:12 +0000 UTC (2 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb 27 02:59:43.557: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 27 02:59:43.557: INFO: tiller-deploy-7d54987577-cxs4p from giantswarm started at 2019-02-26 23:59:50 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container tiller ready: true, restart count 0
Feb 27 02:59:43.557: INFO: cert-exporter-8fqlp from kube-system started at 2019-02-27 00:00:46 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container cert-exporter ready: true, restart count 0
Feb 27 02:59:43.557: INFO: kube-proxy-4c4d8 from kube-system started at 2019-02-26 23:56:23 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 27 02:59:43.557: INFO: kube-state-metrics-68f7795bbd-kfthv from kube-system started at 2019-02-27 00:01:06 +0000 UTC (2 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 27 02:59:43.557: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 27 02:59:43.557: INFO: calico-node-lllw6 from kube-system started at 2019-02-26 23:56:06 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container calico-node ready: true, restart count 0
Feb 27 02:59:43.557: INFO: tiller-deploy-59c6d74887-b9fhn from kube-system started at 2019-02-27 00:00:28 +0000 UTC (1 container statuses recorded)
Feb 27 02:59:43.557: INFO: 	Container tiller ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node worker-0ut0w-6f5f764f5c-rj65d
STEP: verifying the node has the label node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod tiller-deploy-7d54987577-cxs4p requesting resource cpu=0m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod sonobuoy-e2e-job-72ebab7275a04425 requesting resource cpu=0m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-k7j65 requesting resource cpu=0m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod sonobuoy-systemd-logs-daemon-set-5b50a3ce176b47f6-pd7ll requesting resource cpu=0m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod calico-node-bgfp9 requesting resource cpu=250m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod calico-node-lllw6 requesting resource cpu=250m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod cert-exporter-8fqlp requesting resource cpu=50m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod cert-exporter-8prd2 requesting resource cpu=50m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod coredns-7fb74c7cfc-4bmlv requesting resource cpu=250m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod coredns-7fb74c7cfc-r72ls requesting resource cpu=250m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod default-http-backend-7bcdbb4896-5c6nh requesting resource cpu=10m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod default-http-backend-7bcdbb4896-667wr requesting resource cpu=10m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod kube-proxy-4c4d8 requesting resource cpu=75m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod kube-proxy-6wvfj requesting resource cpu=75m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod kube-state-metrics-68f7795bbd-kfthv requesting resource cpu=353m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod metrics-server-7fc59d6b67-6qzwd requesting resource cpu=0m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod net-exporter-htg57 requesting resource cpu=50m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod net-exporter-m4zjg requesting resource cpu=50m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod nginx-ingress-controller-cbbd68d6f-hdp7m requesting resource cpu=500m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod nginx-ingress-controller-cbbd68d6f-rggbs requesting resource cpu=500m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod node-exporter-4xmh6 requesting resource cpu=55m on Node worker-0ut0w-6f5f764f5c-rj65d
Feb 27 02:59:43.586: INFO: Pod node-exporter-v4qxz requesting resource cpu=55m on Node worker-v332t-5ff768bb65-6znm5
Feb 27 02:59:43.586: INFO: Pod tiller-deploy-59c6d74887-b9fhn requesting resource cpu=0m on Node worker-v332t-5ff768bb65-6znm5
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb91867b-3a3b-11e9-853a-328ab8481bb7.15871945a796eb29], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-grgcb/filler-pod-bb91867b-3a3b-11e9-853a-328ab8481bb7 to worker-0ut0w-6f5f764f5c-rj65d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb91867b-3a3b-11e9-853a-328ab8481bb7.15871945d5094c03], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb91867b-3a3b-11e9-853a-328ab8481bb7.15871945d66ac53b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb91867b-3a3b-11e9-853a-328ab8481bb7.15871945dbb63630], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb9363ba-3a3b-11e9-853a-328ab8481bb7.15871945a837135a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-grgcb/filler-pod-bb9363ba-3a3b-11e9-853a-328ab8481bb7 to worker-v332t-5ff768bb65-6znm5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb9363ba-3a3b-11e9-853a-328ab8481bb7.15871945d6642d75], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb9363ba-3a3b-11e9-853a-328ab8481bb7.15871945d7daee7a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bb9363ba-3a3b-11e9-853a-328ab8481bb7.15871945dd03cd8b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1587194620166efe], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node worker-0ut0w-6f5f764f5c-rj65d
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker-v332t-5ff768bb65-6znm5
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:59:46.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-grgcb" for this suite.
Feb 27 02:59:52.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 02:59:52.735: INFO: namespace: e2e-tests-sched-pred-grgcb, resource: bindings, ignored listing per whitelist
Feb 27 02:59:52.759: INFO: namespace e2e-tests-sched-pred-grgcb deletion completed in 6.098115153s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.407 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 02:59:52.759: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rrxcv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 02:59:53.008: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"c12de798-3a3b-11e9-bb22-deadbe9ffdf9", Controller:(*bool)(0xc000dd3a76), BlockOwnerDeletion:(*bool)(0xc000dd3a77)}}
Feb 27 02:59:53.013: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"c12b7e8b-3a3b-11e9-bb22-deadbe9ffdf9", Controller:(*bool)(0xc0011b99e6), BlockOwnerDeletion:(*bool)(0xc0011b99e7)}}
Feb 27 02:59:53.026: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"c12c3d4b-3a3b-11e9-bb22-deadbe9ffdf9", Controller:(*bool)(0xc000dd3d36), BlockOwnerDeletion:(*bool)(0xc000dd3d37)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 02:59:58.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rrxcv" for this suite.
Feb 27 03:00:04.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:00:04.082: INFO: namespace: e2e-tests-gc-rrxcv, resource: bindings, ignored listing per whitelist
Feb 27 03:00:04.132: INFO: namespace e2e-tests-gc-rrxcv deletion completed in 6.090818164s

• [SLOW TEST:11.373 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:00:04.133: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7cxs6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:00:04.309: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7ea7932-3a3b-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-7cxs6" to be "success or failure"
Feb 27 03:00:04.314: INFO: Pod "downwardapi-volume-c7ea7932-3a3b-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912096ms
Feb 27 03:00:06.318: INFO: Pod "downwardapi-volume-c7ea7932-3a3b-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00843474s
STEP: Saw pod success
Feb 27 03:00:06.318: INFO: Pod "downwardapi-volume-c7ea7932-3a3b-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 03:00:06.320: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod downwardapi-volume-c7ea7932-3a3b-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 03:00:06.333: INFO: Waiting for pod downwardapi-volume-c7ea7932-3a3b-11e9-853a-328ab8481bb7 to disappear
Feb 27 03:00:06.336: INFO: Pod downwardapi-volume-c7ea7932-3a3b-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:00:06.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7cxs6" for this suite.
Feb 27 03:00:12.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:00:12.368: INFO: namespace: e2e-tests-downward-api-7cxs6, resource: bindings, ignored listing per whitelist
Feb 27 03:00:12.441: INFO: namespace e2e-tests-downward-api-7cxs6 deletion completed in 6.101814236s

• [SLOW TEST:8.308 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:00:12.441: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-snwcs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0227 03:00:18.636809      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 27 03:00:18.636: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:00:18.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-snwcs" for this suite.
Feb 27 03:00:24.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:00:24.686: INFO: namespace: e2e-tests-gc-snwcs, resource: bindings, ignored listing per whitelist
Feb 27 03:00:24.722: INFO: namespace e2e-tests-gc-snwcs deletion completed in 6.083024896s

• [SLOW TEST:12.281 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:00:24.722: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-48tv2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:00:26.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-48tv2" for this suite.
Feb 27 03:01:08.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:01:08.958: INFO: namespace: e2e-tests-kubelet-test-48tv2, resource: bindings, ignored listing per whitelist
Feb 27 03:01:09.041: INFO: namespace e2e-tests-kubelet-test-48tv2 deletion completed in 42.109045313s

• [SLOW TEST:44.319 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:01:09.041: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t96vc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:01:09.227: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee9c19f3-3a3b-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-t96vc" to be "success or failure"
Feb 27 03:01:09.229: INFO: Pod "downwardapi-volume-ee9c19f3-3a3b-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.909889ms
Feb 27 03:01:11.233: INFO: Pod "downwardapi-volume-ee9c19f3-3a3b-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005984573s
STEP: Saw pod success
Feb 27 03:01:11.233: INFO: Pod "downwardapi-volume-ee9c19f3-3a3b-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 03:01:11.235: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod downwardapi-volume-ee9c19f3-3a3b-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 03:01:11.271: INFO: Waiting for pod downwardapi-volume-ee9c19f3-3a3b-11e9-853a-328ab8481bb7 to disappear
Feb 27 03:01:11.275: INFO: Pod downwardapi-volume-ee9c19f3-3a3b-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:01:11.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t96vc" for this suite.
Feb 27 03:01:17.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:01:17.319: INFO: namespace: e2e-tests-downward-api-t96vc, resource: bindings, ignored listing per whitelist
Feb 27 03:01:17.403: INFO: namespace e2e-tests-downward-api-t96vc deletion completed in 6.124381284s

• [SLOW TEST:8.362 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:01:17.403: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lqmhj
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-f3977828-3a3b-11e9-853a-328ab8481bb7
STEP: Creating secret with name s-test-opt-upd-f3977859-3a3b-11e9-853a-328ab8481bb7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f3977828-3a3b-11e9-853a-328ab8481bb7
STEP: Updating secret s-test-opt-upd-f3977859-3a3b-11e9-853a-328ab8481bb7
STEP: Creating secret with name s-test-opt-create-f397786d-3a3b-11e9-853a-328ab8481bb7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:01:21.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lqmhj" for this suite.
Feb 27 03:01:43.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:01:43.729: INFO: namespace: e2e-tests-projected-lqmhj, resource: bindings, ignored listing per whitelist
Feb 27 03:01:43.741: INFO: namespace e2e-tests-projected-lqmhj deletion completed in 22.088644827s

• [SLOW TEST:26.338 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:01:43.741: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-f2kx4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb 27 03:01:43.964: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0350c129-3a3c-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-f2kx4" to be "success or failure"
Feb 27 03:01:43.967: INFO: Pod "downwardapi-volume-0350c129-3a3c-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.374365ms
Feb 27 03:01:45.971: INFO: Pod "downwardapi-volume-0350c129-3a3c-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006623778s
STEP: Saw pod success
Feb 27 03:01:45.971: INFO: Pod "downwardapi-volume-0350c129-3a3c-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 03:01:45.973: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod downwardapi-volume-0350c129-3a3c-11e9-853a-328ab8481bb7 container client-container: <nil>
STEP: delete the pod
Feb 27 03:01:45.987: INFO: Waiting for pod downwardapi-volume-0350c129-3a3c-11e9-853a-328ab8481bb7 to disappear
Feb 27 03:01:45.990: INFO: Pod downwardapi-volume-0350c129-3a3c-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:01:45.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f2kx4" for this suite.
Feb 27 03:01:52.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:01:52.047: INFO: namespace: e2e-tests-downward-api-f2kx4, resource: bindings, ignored listing per whitelist
Feb 27 03:01:52.086: INFO: namespace e2e-tests-downward-api-f2kx4 deletion completed in 6.092745831s

• [SLOW TEST:8.345 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:01:52.089: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wg5dj
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-0844500e-3a3c-11e9-853a-328ab8481bb7
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-0844500e-3a3c-11e9-853a-328ab8481bb7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:01:56.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wg5dj" for this suite.
Feb 27 03:02:18.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:02:18.326: INFO: namespace: e2e-tests-projected-wg5dj, resource: bindings, ignored listing per whitelist
Feb 27 03:02:18.388: INFO: namespace e2e-tests-projected-wg5dj deletion completed in 22.085515064s

• [SLOW TEST:26.300 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:02:18.388: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7cxnl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 27 03:02:18.607: INFO: Waiting up to 5m0s for pod "pod-17f56e52-3a3c-11e9-853a-328ab8481bb7" in namespace "e2e-tests-emptydir-7cxnl" to be "success or failure"
Feb 27 03:02:18.609: INFO: Pod "pod-17f56e52-3a3c-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.144622ms
Feb 27 03:02:20.612: INFO: Pod "pod-17f56e52-3a3c-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005251602s
STEP: Saw pod success
Feb 27 03:02:20.612: INFO: Pod "pod-17f56e52-3a3c-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 03:02:20.614: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-17f56e52-3a3c-11e9-853a-328ab8481bb7 container test-container: <nil>
STEP: delete the pod
Feb 27 03:02:20.642: INFO: Waiting for pod pod-17f56e52-3a3c-11e9-853a-328ab8481bb7 to disappear
Feb 27 03:02:20.647: INFO: Pod pod-17f56e52-3a3c-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:02:20.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7cxnl" for this suite.
Feb 27 03:02:26.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:02:26.707: INFO: namespace: e2e-tests-emptydir-7cxnl, resource: bindings, ignored listing per whitelist
Feb 27 03:02:26.756: INFO: namespace e2e-tests-emptydir-7cxnl deletion completed in 6.106313801s

• [SLOW TEST:8.367 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:02:26.756: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-r7hm4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb 27 03:02:26.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 create -f - --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:27.189: INFO: stderr: ""
Feb 27 03:02:27.189: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 03:02:27.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:27.273: INFO: stderr: ""
Feb 27 03:02:27.273: INFO: stdout: "update-demo-nautilus-5zvbc update-demo-nautilus-xtfqv "
Feb 27 03:02:27.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-5zvbc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:27.372: INFO: stderr: ""
Feb 27 03:02:27.372: INFO: stdout: ""
Feb 27 03:02:27.372: INFO: update-demo-nautilus-5zvbc is created but not running
Feb 27 03:02:32.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:32.440: INFO: stderr: ""
Feb 27 03:02:32.441: INFO: stdout: "update-demo-nautilus-5zvbc update-demo-nautilus-xtfqv "
Feb 27 03:02:32.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-5zvbc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:32.508: INFO: stderr: ""
Feb 27 03:02:32.508: INFO: stdout: "true"
Feb 27 03:02:32.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-5zvbc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:32.595: INFO: stderr: ""
Feb 27 03:02:32.595: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:02:32.595: INFO: validating pod update-demo-nautilus-5zvbc
Feb 27 03:02:32.599: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:02:32.599: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:02:32.599: INFO: update-demo-nautilus-5zvbc is verified up and running
Feb 27 03:02:32.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-xtfqv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:32.664: INFO: stderr: ""
Feb 27 03:02:32.664: INFO: stdout: "true"
Feb 27 03:02:32.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-nautilus-xtfqv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:32.721: INFO: stderr: ""
Feb 27 03:02:32.721: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 27 03:02:32.722: INFO: validating pod update-demo-nautilus-xtfqv
Feb 27 03:02:32.726: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 27 03:02:32.726: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 27 03:02:32.726: INFO: update-demo-nautilus-xtfqv is verified up and running
STEP: rolling-update to new replication controller
Feb 27 03:02:32.728: INFO: scanned /root for discovery docs: <nil>
Feb 27 03:02:32.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:55.065: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 27 03:02:55.065: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 27 03:02:55.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:02:55.133: INFO: stderr: ""
Feb 27 03:02:55.133: INFO: stdout: "update-demo-kitten-gxttk update-demo-kitten-sdndt update-demo-nautilus-xtfqv "
STEP: Replicas for name=update-demo: expected=2 actual=3
Feb 27 03:03:00.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:03:00.196: INFO: stderr: ""
Feb 27 03:03:00.196: INFO: stdout: "update-demo-kitten-gxttk update-demo-kitten-sdndt "
Feb 27 03:03:00.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-kitten-gxttk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:03:00.255: INFO: stderr: ""
Feb 27 03:03:00.255: INFO: stdout: "true"
Feb 27 03:03:00.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-kitten-gxttk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:03:00.317: INFO: stderr: ""
Feb 27 03:03:00.317: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 27 03:03:00.317: INFO: validating pod update-demo-kitten-gxttk
Feb 27 03:03:00.321: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 27 03:03:00.321: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 27 03:03:00.321: INFO: update-demo-kitten-gxttk is verified up and running
Feb 27 03:03:00.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-kitten-sdndt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:03:00.386: INFO: stderr: ""
Feb 27 03:03:00.386: INFO: stdout: "true"
Feb 27 03:03:00.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-766965386 get pods update-demo-kitten-sdndt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r7hm4'
Feb 27 03:03:00.451: INFO: stderr: ""
Feb 27 03:03:00.451: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 27 03:03:00.451: INFO: validating pod update-demo-kitten-sdndt
Feb 27 03:03:00.455: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 27 03:03:00.455: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 27 03:03:00.455: INFO: update-demo-kitten-sdndt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:03:00.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r7hm4" for this suite.
Feb 27 03:03:22.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:03:22.499: INFO: namespace: e2e-tests-kubectl-r7hm4, resource: bindings, ignored listing per whitelist
Feb 27 03:03:22.539: INFO: namespace e2e-tests-kubectl-r7hm4 deletion completed in 22.078662478s

• [SLOW TEST:55.783 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:03:22.540: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5mrxc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb 27 03:03:22.711: INFO: Waiting up to 5m0s for pod "downward-api-3e2c73c1-3a3c-11e9-853a-328ab8481bb7" in namespace "e2e-tests-downward-api-5mrxc" to be "success or failure"
Feb 27 03:03:22.714: INFO: Pod "downward-api-3e2c73c1-3a3c-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981827ms
Feb 27 03:03:24.717: INFO: Pod "downward-api-3e2c73c1-3a3c-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005725245s
STEP: Saw pod success
Feb 27 03:03:24.717: INFO: Pod "downward-api-3e2c73c1-3a3c-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 03:03:24.719: INFO: Trying to get logs from node worker-v332t-5ff768bb65-6znm5 pod downward-api-3e2c73c1-3a3c-11e9-853a-328ab8481bb7 container dapi-container: <nil>
STEP: delete the pod
Feb 27 03:03:24.736: INFO: Waiting for pod downward-api-3e2c73c1-3a3c-11e9-853a-328ab8481bb7 to disappear
Feb 27 03:03:24.739: INFO: Pod downward-api-3e2c73c1-3a3c-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:03:24.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5mrxc" for this suite.
Feb 27 03:03:30.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:03:30.824: INFO: namespace: e2e-tests-downward-api-5mrxc, resource: bindings, ignored listing per whitelist
Feb 27 03:03:30.830: INFO: namespace e2e-tests-downward-api-5mrxc deletion completed in 6.088389299s

• [SLOW TEST:8.290 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:03:30.831: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-z4nnt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-z4nnt
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 27 03:03:31.013: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 27 03:03:53.072: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.45.109:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-z4nnt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:03:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 03:03:53.157: INFO: Found all expected endpoints: [netserver-0]
Feb 27 03:03:53.159: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.87.217:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-z4nnt PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 27 03:03:53.159: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
Feb 27 03:03:53.243: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:03:53.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-z4nnt" for this suite.
Feb 27 03:04:15.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:04:15.287: INFO: namespace: e2e-tests-pod-network-test-z4nnt, resource: bindings, ignored listing per whitelist
Feb 27 03:04:15.350: INFO: namespace e2e-tests-pod-network-test-z4nnt deletion completed in 22.102969221s

• [SLOW TEST:44.519 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:04:15.350: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-xwmvk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb 27 03:04:15.520: INFO: PodSpec: initContainers in spec.initContainers
Feb 27 03:05:03.892: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5da75503-3a3c-11e9-853a-328ab8481bb7", GenerateName:"", Namespace:"e2e-tests-init-container-xwmvk", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-xwmvk/pods/pod-init-5da75503-3a3c-11e9-853a-328ab8481bb7", UID:"5da867ca-3a3c-11e9-bb22-deadbe9ffdf9", ResourceVersion:"32736", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63686833455, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"520726298"}, Annotations:map[string]string{"kubernetes.io/psp":"cert-exporter-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4dmxj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001e14300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4dmxj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4dmxj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4dmxj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001fc63a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-0ut0w-6f5f764f5c-rj65d", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001de80c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fc64a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fc64c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001fc64c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001fc64cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833455, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833455, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833455, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63686833455, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.23.1.234", PodIP:"192.168.87.220", StartTime:(*v1.Time)(0xc0023b2100), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001d602a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001d60310)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://acbf93ceb73c5bd599538bd91ccf9c8e64337645b109f14351e66e7b5cf3787c"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0023b2140), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0023b2120), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:05:03.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xwmvk" for this suite.
Feb 27 03:05:25.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:05:25.971: INFO: namespace: e2e-tests-init-container-xwmvk, resource: bindings, ignored listing per whitelist
Feb 27 03:05:25.998: INFO: namespace e2e-tests-init-container-xwmvk deletion completed in 22.097991636s

• [SLOW TEST:70.648 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:05:25.999: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6rjrs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-87c3c999-3a3c-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume secrets
Feb 27 03:05:26.183: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-87c44f04-3a3c-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-6rjrs" to be "success or failure"
Feb 27 03:05:26.188: INFO: Pod "pod-projected-secrets-87c44f04-3a3c-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.744898ms
Feb 27 03:05:28.190: INFO: Pod "pod-projected-secrets-87c44f04-3a3c-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007043703s
STEP: Saw pod success
Feb 27 03:05:28.190: INFO: Pod "pod-projected-secrets-87c44f04-3a3c-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 03:05:28.192: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-secrets-87c44f04-3a3c-11e9-853a-328ab8481bb7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 27 03:05:28.205: INFO: Waiting for pod pod-projected-secrets-87c44f04-3a3c-11e9-853a-328ab8481bb7 to disappear
Feb 27 03:05:28.207: INFO: Pod pod-projected-secrets-87c44f04-3a3c-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:05:28.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6rjrs" for this suite.
Feb 27 03:05:34.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:05:34.250: INFO: namespace: e2e-tests-projected-6rjrs, resource: bindings, ignored listing per whitelist
Feb 27 03:05:34.294: INFO: namespace e2e-tests-projected-6rjrs deletion completed in 6.082971455s

• [SLOW TEST:8.295 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:05:34.294: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-zhphm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb 27 03:05:34.476: INFO: (0) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 7.417487ms)
Feb 27 03:05:34.479: INFO: (1) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.479112ms)
Feb 27 03:05:34.481: INFO: (2) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.558801ms)
Feb 27 03:05:34.484: INFO: (3) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.410036ms)
Feb 27 03:05:34.486: INFO: (4) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.300036ms)
Feb 27 03:05:34.488: INFO: (5) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.039719ms)
Feb 27 03:05:34.491: INFO: (6) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.349568ms)
Feb 27 03:05:34.493: INFO: (7) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.654938ms)
Feb 27 03:05:34.496: INFO: (8) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.332476ms)
Feb 27 03:05:34.499: INFO: (9) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.847934ms)
Feb 27 03:05:34.501: INFO: (10) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.446749ms)
Feb 27 03:05:34.504: INFO: (11) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.512691ms)
Feb 27 03:05:34.506: INFO: (12) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.339892ms)
Feb 27 03:05:34.509: INFO: (13) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.893295ms)
Feb 27 03:05:34.512: INFO: (14) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.725028ms)
Feb 27 03:05:34.515: INFO: (15) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.919481ms)
Feb 27 03:05:34.518: INFO: (16) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.72083ms)
Feb 27 03:05:34.520: INFO: (17) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.470525ms)
Feb 27 03:05:34.523: INFO: (18) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.769558ms)
Feb 27 03:05:34.526: INFO: (19) /api/v1/nodes/worker-0ut0w-6f5f764f5c-rj65d/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.425447ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:05:34.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-zhphm" for this suite.
Feb 27 03:05:40.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:05:40.566: INFO: namespace: e2e-tests-proxy-zhphm, resource: bindings, ignored listing per whitelist
Feb 27 03:05:40.612: INFO: namespace e2e-tests-proxy-zhphm deletion completed in 6.08259189s

• [SLOW TEST:6.317 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:05:40.612: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rptph
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-907a205d-3a3c-11e9-853a-328ab8481bb7
STEP: Creating a pod to test consume configMaps
Feb 27 03:05:40.799: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-907af188-3a3c-11e9-853a-328ab8481bb7" in namespace "e2e-tests-projected-rptph" to be "success or failure"
Feb 27 03:05:40.818: INFO: Pod "pod-projected-configmaps-907af188-3a3c-11e9-853a-328ab8481bb7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.600316ms
Feb 27 03:05:42.822: INFO: Pod "pod-projected-configmaps-907af188-3a3c-11e9-853a-328ab8481bb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022616926s
STEP: Saw pod success
Feb 27 03:05:42.822: INFO: Pod "pod-projected-configmaps-907af188-3a3c-11e9-853a-328ab8481bb7" satisfied condition "success or failure"
Feb 27 03:05:42.824: INFO: Trying to get logs from node worker-0ut0w-6f5f764f5c-rj65d pod pod-projected-configmaps-907af188-3a3c-11e9-853a-328ab8481bb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 27 03:05:42.839: INFO: Waiting for pod pod-projected-configmaps-907af188-3a3c-11e9-853a-328ab8481bb7 to disappear
Feb 27 03:05:42.841: INFO: Pod pod-projected-configmaps-907af188-3a3c-11e9-853a-328ab8481bb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:05:42.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rptph" for this suite.
Feb 27 03:05:48.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:05:48.923: INFO: namespace: e2e-tests-projected-rptph, resource: bindings, ignored listing per whitelist
Feb 27 03:05:48.926: INFO: namespace e2e-tests-projected-rptph deletion completed in 6.08150445s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb 27 03:05:48.927: INFO: >>> kubeConfig: /tmp/kubeconfig-766965386
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mrbrw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-956e189a-3a3c-11e9-853a-328ab8481bb7
STEP: Creating configMap with name cm-test-opt-upd-956e18c9-3a3c-11e9-853a-328ab8481bb7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-956e189a-3a3c-11e9-853a-328ab8481bb7
STEP: Updating configmap cm-test-opt-upd-956e18c9-3a3c-11e9-853a-328ab8481bb7
STEP: Creating configMap with name cm-test-opt-create-956e18da-3a3c-11e9-853a-328ab8481bb7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb 27 03:07:05.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mrbrw" for this suite.
Feb 27 03:07:27.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 27 03:07:27.564: INFO: namespace: e2e-tests-projected-mrbrw, resource: bindings, ignored listing per whitelist
Feb 27 03:07:27.581: INFO: namespace e2e-tests-projected-mrbrw deletion completed in 22.094912984s

• [SLOW TEST:98.655 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSFeb 27 03:07:27.583: INFO: Running AfterSuite actions on all nodes
Feb 27 03:07:27.584: INFO: Running AfterSuite actions on node 1
Feb 27 03:07:27.584: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5210.364 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h26m51.029470914s
Test Suite Passed
