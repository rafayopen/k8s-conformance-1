Activated service account credentials for: [gob-prow@gob-prow.iam.gserviceaccount.com]
fatal: Not a git repository (or any of the parent directories): .git
+ /workspace/scenarios/kubernetes_e2e.py --check-leaked-resources --check-version-skew=false --cluster= --deployment=gke --extract=gke-latest-1.13 --gcp-cloud-sdk=gs://cloud-sdk-testing/rc --gcp-node-image=gci --gcp-project-type=gke-internal-project --gcp-zone=us-east1-d --gke-environment=prod --provider=gke '--test_args=--ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\] --minStartupPods=8' --timeout=200m
starts with local mode
Environment:
ARTIFACTS=/logs/artifacts
BAZEL_REMOTE_CACHE_ENABLED=false
BAZEL_VERSION=0.23.2
BOSKOS_METRICS_PORT=tcp://10.47.252.108:8888
BOSKOS_METRICS_PORT_8888_TCP=tcp://10.47.252.108:8888
BOSKOS_METRICS_PORT_8888_TCP_ADDR=10.47.252.108
BOSKOS_METRICS_PORT_8888_TCP_PORT=8888
BOSKOS_METRICS_PORT_8888_TCP_PROTO=tcp
BOSKOS_METRICS_SERVICE_HOST=10.47.252.108
BOSKOS_METRICS_SERVICE_PORT=8888
BOSKOS_METRICS_SERVICE_PORT_DEFAULT=8888
BOSKOS_PORT=tcp://10.47.245.87:80
BOSKOS_PORT_80_TCP=tcp://10.47.245.87:80
BOSKOS_PORT_80_TCP_ADDR=10.47.245.87
BOSKOS_PORT_80_TCP_PORT=80
BOSKOS_PORT_80_TCP_PROTO=tcp
BOSKOS_SERVICE_HOST=10.47.245.87
BOSKOS_SERVICE_PORT=80
BOSKOS_SERVICE_PORT_DEFAULT=80
BUILD_ID=1128552988365819906
BUILD_NUMBER=1128552988365819906
CLOUDSDK_COMPONENT_MANAGER_DISABLE_UPDATE_CHECK=true
CLOUDSDK_CORE_DISABLE_PROMPTS=1
CLOUDSDK_EXPERIMENTAL_FAST_COMPONENT_UPDATE=false
DOCKER_IN_DOCKER_ENABLED=false
E2E_GOOGLE_APPLICATION_CREDENTIALS=/etc/service-account/service-account.json
ENTRYPOINT_OPTIONS={"timeout":13200000000000,"grace_period":15000000000,"artifact_dir":"/logs/artifacts","args":["runner.sh","/workspace/scenarios/kubernetes_e2e.py","--check-leaked-resources","--check-version-skew=false","--cluster=","--deployment=gke","--extract=gke-latest-1.13","--gcp-cloud-sdk=gs://cloud-sdk-testing/rc","--gcp-node-image=gci","--gcp-project-type=gke-internal-project","--gcp-zone=us-east1-d","--gke-environment=prod","--provider=gke","--test_args=--ginkgo.focus=\\[Conformance\\] --ginkgo.skip=Alpha|\\[(Disruptive|Feature:[^\\]]+|Flaky)\\] --minStartupPods=8","--timeout=200m"],"process_log":"/logs/process-log.txt","marker_file":"/logs/marker-file.txt","metadata_file":"/logs/artifacts/metadata.json"}
GOOGLE_APPLICATION_CREDENTIALS=/etc/service-account/service-account.json
GOPATH=/home/prow/go
GO_TARBALL=go1.12.1b4.linux-amd64.tar.gz
HOME=/workspace
HOSTNAME=8709e068-76dd-11e9-9653-7621f038c66b
IMAGE=gcr.io/k8s-testimages/kubekins-e2e:v20190419-3a36c16-master
INSTANCE_PREFIX=e2e-a9ed4389fc-72cc1
JENKINS_GCE_SSH_PRIVATE_KEY_FILE=/workspace/.ssh/google_compute_engine
JENKINS_GCE_SSH_PUBLIC_KEY_FILE=/workspace/.ssh/google_compute_engine.pub
JOB_NAME=ci-kubernetes-e2e-gke-prod-1-13-conformance
JOB_SPEC={"type":"periodic","job":"ci-kubernetes-e2e-gke-prod-1-13-conformance","buildid":"1128552988365819906","prowjobid":"8709e068-76dd-11e9-9653-7621f038c66b"}
JOB_TYPE=periodic
KUBERNETES_PORT=tcp://10.47.240.1:443
KUBERNETES_PORT_443_TCP=tcp://10.47.240.1:443
KUBERNETES_PORT_443_TCP_ADDR=10.47.240.1
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_SERVICE_HOST=10.47.240.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBETEST_IN_DOCKER=true
KUBETEST_MANUAL_DUMP=y
KUBE_AWS_INSTANCE_PREFIX=e2e-a9ed4389fc-72cc1
KUBE_GCE_INSTANCE_PREFIX=e2e-a9ed4389fc-72cc1
PATH=/home/prow/go/bin:/go/bin:/usr/local/go/bin:/google-cloud-sdk/bin:/workspace:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PROW_JOB_ID=8709e068-76dd-11e9-9653-7621f038c66b
PWD=/workspace
SHLVL=1
SOURCE_DATE_EPOCH=
TERM=xterm
USER=prow
WORKSPACE=/workspace
_=/workspace/scenarios/kubernetes_e2e.py
Run: ('kubetest', '--dump=/logs/artifacts', '--gcp-service-account=/etc/service-account/service-account.json', '--up', '--down', '--test', '--deployment=gke', '--provider=gke', '--cluster=e2e-a9ed4389fc-72cc1', '--gcp-network=e2e-a9ed4389fc-72cc1', '--check-leaked-resources', '--check-version-skew=false', '--extract=gke-latest-1.13', '--gcp-cloud-sdk=gs://cloud-sdk-testing/rc', '--gcp-node-image=gci', '--gcp-project-type=gke-internal-project', '--gcp-zone=us-east1-d', '--gke-environment=prod', '--test_args=--ginkgo.focus=\\[Conformance\\] --ginkgo.skip=Alpha|\\[(Disruptive|Feature:[^\\]]+|Flaky)\\] --minStartupPods=8', '--timeout=200m')
2019/05/15 06:50:19 main.go:321: Limiting testing to 3h20m0s
2019/05/15 06:50:19 main.go:714: --gcp-project is missing, trying to fetch a project from boskos.
(for local runs please set --gcp-project to your dev project)
2019/05/15 06:50:19 main.go:726: provider gke, will acquire project type gke-internal-project from boskos
2019/05/15 06:50:19 process.go:153: Running: gcloud config set project prow-gob-internal-boskos-62
Updated property [core/project].
2019/05/15 06:50:20 process.go:155: Step 'gcloud config set project prow-gob-internal-boskos-62' finished in 323.268005ms
2019/05/15 06:50:20 process.go:153: Running: gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json
Activated service account credentials for: [gob-prow@gob-prow.iam.gserviceaccount.com]
2019/05/15 06:50:20 process.go:155: Step 'gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json' finished in 587.745747ms
2019/05/15 06:50:20 main.go:770: Checking existing of GCP ssh keys...
2019/05/15 06:50:20 main.go:780: Checking presence of public key in prow-gob-internal-boskos-62
2019/05/15 06:50:20 process.go:153: Running: gcloud compute --project=prow-gob-internal-boskos-62 project-info describe
2019/05/15 06:50:21 process.go:155: Step 'gcloud compute --project=prow-gob-internal-boskos-62 project-info describe' finished in 992.207589ms
2019/05/15 06:50:21 process.go:153: Running: gsutil -mq cp -r gs://cloud-sdk-testing/rc /workspace
2019/05/15 06:50:51 process.go:155: Step 'gsutil -mq cp -r gs://cloud-sdk-testing/rc /workspace' finished in 29.442172727s
2019/05/15 06:50:51 process.go:153: Running: tar xzf /workspace/repo/google-cloud-sdk.tar.gz -C /workspace/cloudsdk
2019/05/15 06:50:52 process.go:155: Step 'tar xzf /workspace/repo/google-cloud-sdk.tar.gz -C /workspace/cloudsdk' finished in 987.280719ms
2019/05/15 06:50:52 process.go:153: Running: /workspace/cloudsdk/google-cloud-sdk/install.sh --disable-installation-options --bash-completion=false --path-update=false --usage-reporting=false
Welcome to the Google Cloud SDK!
WARNING: You appear to be running this script as root. This may cause 
the installation to be inaccessible to users other than the root user.
WARNING: You are using an overridden snapshot URL: [file:///workspace/repo/components-2.json]


Your current Cloud SDK version is: 246.0.0
Installing components from version: 246.0.0

+----------------------------------------------------------------------------+
|                    These components will be installed.                     |
+-----------------------------------------------------+------------+---------+
|                         Name                        |  Version   |   Size  |
+-----------------------------------------------------+------------+---------+
| BigQuery Command Line Tool                          |     2.0.43 | < 1 MiB |
| BigQuery Command Line Tool (Platform Specific)      |     2.0.43 | < 1 MiB |
| Cloud SDK Core Libraries (Platform Specific)        | 2019.05.10 | < 1 MiB |
| Cloud Storage Command Line Tool                     |       4.38 | 3.8 MiB |
| Cloud Storage Command Line Tool (Platform Specific) |       4.38 | < 1 MiB |
| Default set of gcloud commands                      |            |         |
| gcloud cli dependencies                             | 2019.05.10 | 8.6 MiB |
+-----------------------------------------------------+------------+---------+

For the latest full release notes, please visit:
  https://cloud.google.com/sdk/release_notes

#============================================================#
#= Creating update staging area                             =#
#============================================================#
#= Installing: BigQuery Command Line Tool                   =#
#============================================================#
#= Installing: BigQuery Command Line Tool (Platform Spec... =#
#============================================================#
#= Installing: Cloud SDK Core Libraries (Platform Specific) =#
#============================================================#
#= Installing: Cloud Storage Command Line Tool              =#
#============================================================#
#= Installing: Cloud Storage Command Line Tool (Platform... =#
#============================================================#
#= Installing: Default set of gcloud commands               =#
#============================================================#
#= Installing: gcloud cli dependencies                      =#
#============================================================#
#= Creating backup and activating new installation          =#
#============================================================#

Performing post processing steps...
......................................done.

Update done!

WARNING:   There are older versions of Google Cloud Platform tools on your system PATH.
  Please remove the following to avoid accidentally invoking these old tools:

  /google-cloud-sdk/bin/gsutil
/google-cloud-sdk/bin/dev_appserver.py
/google-cloud-sdk/bin/gcloud
/google-cloud-sdk/bin/endpointscfg.py
/google-cloud-sdk/bin/bq
/google-cloud-sdk/bin/docker-credential-gcloud
/google-cloud-sdk/bin/git-credential-gcloud.sh
/google-cloud-sdk/bin/java_dev_appserver.sh

  

This will install all the core command line tools necessary for working with
the Google Cloud Platform.

==> Source [/workspace/cloudsdk/google-cloud-sdk/completion.bash.inc] in your profile to enable shell command completion for gcloud.
==> Source [/workspace/cloudsdk/google-cloud-sdk/path.bash.inc] in your profile to add the Google Cloud SDK command line tools to your $PATH.

For more information on how to get started, please visit:
  https://cloud.google.com/sdk/docs/quickstarts


2019/05/15 06:51:06 process.go:155: Step '/workspace/cloudsdk/google-cloud-sdk/install.sh --disable-installation-options --bash-completion=false --path-update=false --usage-reporting=false' finished in 13.890341963s
2019/05/15 06:51:06 process.go:153: Running: gcloud components install alpha
WARNING: You are using an overridden snapshot URL: [file:///workspace/repo/components-2.json]


Your current Cloud SDK version is: 246.0.0
Installing components from version: 246.0.0

+----------------------------------------------+
|     These components will be installed.      |
+-----------------------+------------+---------+
|          Name         |  Version   |   Size  |
+-----------------------+------------+---------+
| gcloud Alpha Commands | 2019.05.10 | < 1 MiB |
+-----------------------+------------+---------+

For the latest full release notes, please visit:
  https://cloud.google.com/sdk/release_notes

#============================================================#
#= Creating update staging area                             =#
#============================================================#
#= Installing: gcloud Alpha Commands                        =#
#============================================================#
#= Creating backup and activating new installation          =#
#============================================================#

Performing post processing steps...
..done.

Update done!

WARNING:   There are older versions of Google Cloud Platform tools on your system PATH.
  Please remove the following to avoid accidentally invoking these old tools:

  /google-cloud-sdk/bin/gsutil
/google-cloud-sdk/bin/dev_appserver.py
/google-cloud-sdk/bin/gcloud
/google-cloud-sdk/bin/endpointscfg.py
/google-cloud-sdk/bin/bq
/google-cloud-sdk/bin/docker-credential-gcloud
/google-cloud-sdk/bin/git-credential-gcloud.sh
/google-cloud-sdk/bin/java_dev_appserver.sh

  
2019/05/15 06:51:10 process.go:155: Step 'gcloud components install alpha' finished in 4.290806822s
2019/05/15 06:51:10 process.go:153: Running: gcloud components install beta
WARNING: You are using an overridden snapshot URL: [file:///workspace/repo/components-2.json]


Your current Cloud SDK version is: 246.0.0
Installing components from version: 246.0.0

+---------------------------------------------+
|     These components will be installed.     |
+----------------------+------------+---------+
|         Name         |  Version   |   Size  |
+----------------------+------------+---------+
| gcloud Beta Commands | 2019.05.10 | < 1 MiB |
+----------------------+------------+---------+

For the latest full release notes, please visit:
  https://cloud.google.com/sdk/release_notes

#============================================================#
#= Creating update staging area                             =#
#============================================================#
#= Installing: gcloud Beta Commands                         =#
#============================================================#
#= Creating backup and activating new installation          =#
#============================================================#

Performing post processing steps...
..done.

Update done!

WARNING:   There are older versions of Google Cloud Platform tools on your system PATH.
  Please remove the following to avoid accidentally invoking these old tools:

  /google-cloud-sdk/bin/gsutil
/google-cloud-sdk/bin/dev_appserver.py
/google-cloud-sdk/bin/gcloud
/google-cloud-sdk/bin/endpointscfg.py
/google-cloud-sdk/bin/bq
/google-cloud-sdk/bin/docker-credential-gcloud
/google-cloud-sdk/bin/git-credential-gcloud.sh
/google-cloud-sdk/bin/java_dev_appserver.sh

  
2019/05/15 06:51:15 process.go:155: Step 'gcloud components install beta' finished in 4.773260695s
2019/05/15 06:51:15 process.go:153: Running: gcloud info
WARNING: You are using an overridden snapshot URL: [file:///workspace/repo/components-2.json]
Google Cloud SDK [246.0.0]

Platform: [Linux, x86_64] ('Linux', '8709e068-76dd-11e9-9653-7621f038c66b', '4.14.91+', '#1 SMP Wed Jan 23 21:34:58 PST 2019', 'x86_64', '')
Python Version: [2.7.13 (default, Sep 26 2018, 18:42:22)  [GCC 6.3.0 20170516]]
Python Location: [/usr/bin/python2]
Site Packages: [Disabled]

Installation Root: [/workspace/cloudsdk/google-cloud-sdk]
Installed Components:
  core: [2019.05.10]
  beta: [2019.05.10]
  gsutil: [4.38]
  bq: [2.0.43]
  alpha: [2019.05.10]
System PATH: [/workspace/cloudsdk/google-cloud-sdk/bin:/home/prow/go/bin:/go/bin:/usr/local/go/bin:/google-cloud-sdk/bin:/workspace:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin]
Python PATH: [/workspace/cloudsdk/google-cloud-sdk/lib/third_party:/workspace/cloudsdk/google-cloud-sdk/lib:/usr/lib/python2.7:/usr/lib/python2.7/plat-x86_64-linux-gnu:/usr/lib/python2.7/lib-tk:/usr/lib/python2.7/lib-old:/usr/lib/python2.7/lib-dynload]
Cloud SDK on PATH: [True]
Kubectl on PATH: [/usr/local/bin/kubectl]

WARNING: There are old versions of the Google Cloud Platform tools on your system PATH.
  /google-cloud-sdk/bin/gsutil
  /google-cloud-sdk/bin/dev_appserver.py
  /google-cloud-sdk/bin/gcloud
  /google-cloud-sdk/bin/endpointscfg.py
  /google-cloud-sdk/bin/bq
  /google-cloud-sdk/bin/docker-credential-gcloud
  /google-cloud-sdk/bin/git-credential-gcloud.sh
  /google-cloud-sdk/bin/java_dev_appserver.sh

Installation Properties: [/workspace/cloudsdk/google-cloud-sdk/properties]
User Config Directory: [/workspace/.config/gcloud]
Active Configuration Name: [default]
Active Configuration Path: [/workspace/.config/gcloud/configurations/config_default]

Account: [gob-prow@gob-prow.iam.gserviceaccount.com]
Project: [prow-gob-internal-boskos-62]

Current Properties:
  [core]
    project: [prow-gob-internal-boskos-62]
    account: [gob-prow@gob-prow.iam.gserviceaccount.com]
    disable_prompts: [1]
    disable_usage_reporting: [True]
    print_unhandled_tracebacks: [1]
  [component_manager]
    disable_update_check: [true]
    snapshot_url: [file:///workspace/repo/components-2.json]
  [experimental]
    fast_component_update: [false]

Logs Directory: [/workspace/.config/gcloud/logs]
Last Log File: [/workspace/.config/gcloud/logs/2019.05.15/06.51.14.639079.log]

git: [git version 2.11.0]
ssh: [OpenSSH_7.4p1 Debian-10+deb9u5, OpenSSL 1.0.2q  20 Nov 2018]


2019/05/15 06:51:15 process.go:155: Step 'gcloud info' finished in 407.786159ms
2019/05/15 06:51:15 process.go:153: Running: gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json
Activated service account credentials for: [gob-prow@gob-prow.iam.gserviceaccount.com]
2019/05/15 06:51:16 process.go:155: Step 'gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json' finished in 662.47944ms
2019/05/15 06:51:16 extract_k8s.go:135: rm kubernetes
2019/05/15 06:51:16 process.go:153: Running: gcloud container get-server-config --project=prow-gob-internal-boskos-62 --format=value(validMasterVersions) --zone=us-east1-d
Fetching server config for us-east1-d
2019/05/15 06:51:16 process.go:155: Step 'gcloud container get-server-config --project=prow-gob-internal-boskos-62 --format=value(validMasterVersions) --zone=us-east1-d' finished in 643.09823ms
2019/05/15 06:51:16 extract_k8s.go:287: U=https://storage.googleapis.com/kubernetes-release-gke/release R=v1.13.5-gke.10 get-kube.sh
2019/05/15 06:51:16 process.go:153: Running: ./get-kube.sh
Downloading kubernetes release v1.13.5-gke.10
  from https://storage.googleapis.com/kubernetes-release-gke/release/v1.13.5-gke.10/kubernetes.tar.gz
  to /workspace/kubernetes.tar.gz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100 2146k  100 2146k    0     0  6071k      0 --:--:-- --:--:-- --:--:-- 6079k
Unpacking kubernetes release v1.13.5-gke.10
Kubernetes release: v1.13.5-gke.10
Server: linux/amd64  (to override, set KUBERNETES_SERVER_ARCH)
Client: linux/amd64  (autodetected)

Will download kubernetes-server-linux-amd64.tar.gz from https://storage.googleapis.com/kubernetes-release-gke/release/v1.13.5-gke.10
Will download and extract kubernetes-client-linux-amd64.tar.gz from https://storage.googleapis.com/kubernetes-release-gke/release/v1.13.5-gke.10
Will download and extract kubernetes-test.tar.gz from https://storage.googleapis.com/kubernetes-release-gke/release/v1.13.5-gke.10
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  3  424M    3 16.7M    0     0  19.9M      0  0:00:21 --:--:--  0:00:21 19.9M 35  424M   35  151M    0     0  85.1M      0  0:00:04  0:00:01  0:00:03 85.1M 62  424M   62  264M    0     0  89.9M      0  0:00:04  0:00:02  0:00:02 89.9M 81  424M   81  344M    0     0  85.6M      0  0:00:04  0:00:04 --:--:-- 85.6M 96  424M   96  408M    0     0  81.0M      0  0:00:05  0:00:05 --:--:-- 81.0M100  424M  100  424M    0     0  83.2M      0  0:00:05  0:00:05 --:--:-- 95.7M

md5sum(kubernetes-server-linux-amd64.tar.gz)=d044ca7b92f37810798d9165ee47f1b0
sha1sum(kubernetes-server-linux-amd64.tar.gz)=bd166aa6cfd8662bd8c8759f65363eed016fbf2e

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 33 12.1M   33 4144k    0     0  4658k      0  0:00:02 --:--:--  0:00:02 4656k100 12.1M  100 12.1M    0     0  8963k      0  0:00:01  0:00:01 --:--:-- 8967k

md5sum(kubernetes-client-linux-amd64.tar.gz)=78fef66644505cf20475e573f5461571
sha1sum(kubernetes-client-linux-amd64.tar.gz)=bacacebe74122e6e6efa69033dfd5ec22249365a

Extracting /workspace/kubernetes/client/kubernetes-client-linux-amd64.tar.gz into /workspace/kubernetes/platforms/linux/amd64
Add '/workspace/kubernetes/client/bin' to your PATH to use newly-installed binaries.
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  2  202M    2 4904k    0     0  8312k      0  0:00:24 --:--:--  0:00:24 8311k 52  202M   52  106M    0     0  68.9M      0  0:00:02  0:00:01  0:00:01 68.9M 95  202M   95  192M    0     0  69.9M      0  0:00:02  0:00:02 --:--:-- 69.9M100  202M  100  202M    0     0  72.4M      0  0:00:02  0:00:02 --:--:-- 72.4M

md5sum(kubernetes-test.tar.gz)=384e38714dd06c70d56e14470c22a8b2
sha1sum(kubernetes-test.tar.gz)=3abe203e9eddc5d66481dbdf2716629c0bc64dfa

Extracting kubernetes-test.tar.gz into /workspace/kubernetes
2019/05/15 06:51:40 process.go:155: Step './get-kube.sh' finished in 23.149724491s
2019/05/15 06:51:40 e2e.go:444: Listing resources...
2019/05/15 06:51:40 process.go:153: Running: ./cluster/gce/list-resources.sh
Listed 0 items.
Listed 0 items.
Listed 0 items.
Listed 0 items.
Listed 0 items.

To show all fields of the firewall, please show in JSON format: --format=json
To show all fields in table format, please see the examples in --help.

Listed 0 items.
Listed 0 items.
Listed 0 items.
2019/05/15 06:51:51 process.go:155: Step './cluster/gce/list-resources.sh' finished in 10.391636782s
2019/05/15 06:51:51 process.go:153: Running: gcloud compute networks describe e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --format=value(name)
2019/05/15 06:51:52 process.go:155: Step 'gcloud compute networks describe e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --format=value(name)' finished in 931.269905ms
2019/05/15 06:51:52 gke.go:276: Couldn't describe network 'e2e-a9ed4389fc-72cc1', assuming it doesn't exist and creating it
2019/05/15 06:51:52 process.go:153: Running: gcloud compute networks create e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --subnet-mode=auto
Created [https://www.googleapis.com/compute/v1/projects/prow-gob-internal-boskos-62/global/networks/e2e-a9ed4389fc-72cc1].
NAME                  SUBNET_MODE  BGP_ROUTING_MODE  IPV4_RANGE  GATEWAY_IPV4
e2e-a9ed4389fc-72cc1  AUTO         REGIONAL

Instances on this network will not be reachable until firewall rules
are created. As an example, you can allow all internal traffic between
instances as well as SSH, RDP, and ICMP by running:

$ gcloud compute firewall-rules create <FIREWALL_NAME> --network e2e-a9ed4389fc-72cc1 --allow tcp,udp,icmp --source-ranges <IP_RANGE>
$ gcloud compute firewall-rules create <FIREWALL_NAME> --network e2e-a9ed4389fc-72cc1 --allow tcp:22,tcp:3389,icmp

2019/05/15 06:52:41 process.go:155: Step 'gcloud compute networks create e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --subnet-mode=auto' finished in 49.258838474s
2019/05/15 06:52:41 process.go:153: Running: gcloud container clusters create --quiet --project=prow-gob-internal-boskos-62 --zone=us-east1-d --machine-type=n1-standard-2 --image-type=gci --num-nodes=3 --network=e2e-a9ed4389fc-72cc1 --cluster-version=1.13.5-gke.10 e2e-a9ed4389fc-72cc1
WARNING: In June 2019, node auto-upgrade will be enabled by default for newly created clusters and node pools. To disable it, use the `--no-enable-autoupgrade` flag.
WARNING: Starting in 1.12, new clusters will have basic authentication disabled by default. Basic authentication can be enabled (or disabled) manually using the `--[no-]enable-basic-auth` flag.
WARNING: Starting in 1.12, new clusters will not have a client certificate issued. You can manually enable (or disable) the issuance of the client certificate using the `--[no-]issue-client-certificate` flag.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting in 1.12, default node pools in new clusters will have their legacy Compute Engine instance metadata endpoints disabled by default. To create a cluster with legacy instance metadata endpoints disabled in the default node pool, run `clusters create` with the flag `--metadata disable-legacy-endpoints=true`.
WARNING: Your Pod address range (`--cluster-ipv4-cidr`) can accommodate at most 1008 node(s). 
This will disable the autorepair feature for nodes. Please see https://cloud.google.com/kubernetes-engine/docs/node-auto-repair for more information on node autorepairs.
Creating cluster e2e-a9ed4389fc-72cc1 in us-east1-d...
.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.
Created [https://container.googleapis.com/v1/projects/prow-gob-internal-boskos-62/zones/us-east1-d/clusters/e2e-a9ed4389fc-72cc1].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-east1-d/e2e-a9ed4389fc-72cc1?project=prow-gob-internal-boskos-62
kubeconfig entry generated for e2e-a9ed4389fc-72cc1.
NAME                  LOCATION    MASTER_VERSION  MASTER_IP      MACHINE_TYPE   NODE_VERSION   NUM_NODES  STATUS
e2e-a9ed4389fc-72cc1  us-east1-d  1.13.5-gke.10   35.231.193.88  n1-standard-2  1.13.5-gke.10  3          RUNNING
2019/05/15 06:55:03 process.go:155: Step 'gcloud container clusters create --quiet --project=prow-gob-internal-boskos-62 --zone=us-east1-d --machine-type=n1-standard-2 --image-type=gci --num-nodes=3 --network=e2e-a9ed4389fc-72cc1 --cluster-version=1.13.5-gke.10 e2e-a9ed4389fc-72cc1' finished in 2m22.359861445s
2019/05/15 06:55:03 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false version
2019/05/15 06:55:04 process.go:155: Step './cluster/kubectl.sh --match-server-version=false version' finished in 941.47163ms
2019/05/15 06:55:04 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false get nodes -oyaml
2019/05/15 06:55:05 process.go:155: Step './cluster/kubectl.sh --match-server-version=false get nodes -oyaml' finished in 1.032021663s
2019/05/15 06:55:05 e2e.go:444: Listing resources...
2019/05/15 06:55:05 process.go:153: Running: ./cluster/gce/list-resources.sh
Listed 0 items.

To show all fields of the firewall, please show in JSON format: --format=json
To show all fields in table format, please see the examples in --help.

Listed 0 items.
Listed 0 items.
Listed 0 items.
2019/05/15 06:55:15 process.go:155: Step './cluster/gce/list-resources.sh' finished in 9.899222138s
2019/05/15 06:55:15 process.go:153: Running: gcloud container clusters get-credentials e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --zone=us-east1-d
Fetching cluster endpoint and auth data.
kubeconfig entry generated for e2e-a9ed4389fc-72cc1.
2019/05/15 06:55:16 process.go:155: Step 'gcloud container clusters get-credentials e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --zone=us-east1-d' finished in 669.815238ms
2019/05/15 06:55:17 process.go:153: Running: gcloud compute firewall-rules describe e2e-ports-f216a26d --project=prow-gob-internal-boskos-62 --format=value(name)
2019/05/15 06:55:18 process.go:155: Step 'gcloud compute firewall-rules describe e2e-ports-f216a26d --project=prow-gob-internal-boskos-62 --format=value(name)' finished in 973.545701ms
2019/05/15 06:55:18 gke.go:497: Couldn't describe firewall 'e2e-ports-f216a26d', assuming it doesn't exist and creating it
2019/05/15 06:55:20 process.go:153: Running: gcloud compute firewall-rules create e2e-ports-f216a26d --project=prow-gob-internal-boskos-62 --network=e2e-a9ed4389fc-72cc1 --allow=tcp:22,tcp:80,tcp:8080,tcp:30000-32767,udp:30000-32767 --target-tags=gke-e2e-a9ed4389fc-72cc1-169dc6b3-node
Creating firewall...
............................................................Created [https://www.googleapis.com/compute/v1/projects/prow-gob-internal-boskos-62/global/firewalls/e2e-ports-f216a26d].
.done.
NAME                NETWORK               DIRECTION  PRIORITY  ALLOW                                                   DENY  DISABLED
e2e-ports-f216a26d  e2e-a9ed4389fc-72cc1  INGRESS    1000      tcp:22,tcp:80,tcp:8080,tcp:30000-32767,udp:30000-32767        False
2019/05/15 06:55:33 process.go:155: Step 'gcloud compute firewall-rules create e2e-ports-f216a26d --project=prow-gob-internal-boskos-62 --network=e2e-a9ed4389fc-72cc1 --allow=tcp:22,tcp:80,tcp:8080,tcp:30000-32767,udp:30000-32767 --target-tags=gke-e2e-a9ed4389fc-72cc1-169dc6b3-node' finished in 13.191200076s
2019/05/15 06:55:33 process.go:153: Running: kubectl get nodes --no-headers
2019/05/15 06:55:35 process.go:155: Step 'kubectl get nodes --no-headers' finished in 2.037249896s
2019/05/15 06:55:35 e2e.go:462: Cluster nodes:
gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz   Ready   <none>   38s   v1.13.5-gke.10
gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r   Ready   <none>   38s   v1.13.5-gke.10
gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx   Ready   <none>   37s   v1.13.5-gke.10
2019/05/15 06:55:35 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false version
2019/05/15 06:55:35 process.go:155: Step './cluster/kubectl.sh --match-server-version=false version' finished in 410.231401ms
2019/05/15 06:55:35 process.go:153: Running: ./hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\] --minStartupPods=8 --num-nodes=3 --report-dir=/logs/artifacts --disable-log-dump=true
Conformance test: not doing test setup.
May 15 06:55:37.027: INFO: Fetching cloud provider for "gke"
I0515 06:55:37.027438    1545 gce.go:874] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc0000e0018), conf:(*jwt.Config)(0xc001560e00)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
I0515 06:55:37.152594    1545 gce.go:874] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc0000e0018), conf:(*jwt.Config)(0xc0016a8600)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
I0515 06:55:37.183593    1545 gce.go:874] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc0000e0018), conf:(*jwt.Config)(0xc001560000)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
W0515 06:55:37.209942    1545 gce.go:469] No network name or URL specified.
I0515 06:55:37.210169    1545 e2e.go:224] Starting e2e run "7129cc3f-76de-11e9-9e56-3ac139a44f02" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: [1m1557903336[0m - Will randomize all specs
Will run [1m201[0m of [1m2161[0m specs

May 15 06:55:39.986: INFO: cluster-master-image: 
May 15 06:55:39.986: INFO: cluster-node-image: gke-1135-gke10-cos-73-11647-121-0-v190410-pre
May 15 06:55:39.986: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 06:55:39.989: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 15 06:55:40.332: INFO: Waiting up to 10m0s for all pods (need at least 8) in namespace 'kube-system' to be running and ready
May 15 06:55:40.728: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 15 06:55:40.728: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May 15 06:55:40.728: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 15 06:55:40.835: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'fluentd-gcp-v3.2.0' (0 seconds elapsed)
May 15 06:55:40.835: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'metadata-proxy-v0.1' (0 seconds elapsed)
May 15 06:55:40.835: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
May 15 06:55:40.835: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'prometheus-to-sd' (0 seconds elapsed)
May 15 06:55:40.835: INFO: e2e test version: v1.13.5-gke.10
May 15 06:55:40.908: INFO: kube-apiserver version: v1.13.5-gke.10
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy through a service and a pod  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] version v1
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 06:55:40.908: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
E0515 06:55:43.118552    1545 memcache.go:135] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
[1mSTEP[0m: Building a namespace api object, basename proxy
May 15 06:55:43.892: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: starting an echo server on multiple ports
[1mSTEP[0m: creating replication controller proxy-service-74gmc in namespace e2e-tests-proxy-xmbs9
I0515 06:55:44.173361    1545 runners.go:184] Created replication controller with name: proxy-service-74gmc, namespace: e2e-tests-proxy-xmbs9, replica count: 1
I0515 06:55:45.324099    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0515 06:55:46.324514    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0515 06:55:47.324798    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0515 06:55:48.325188    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0515 06:55:49.325608    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0515 06:55:50.325954    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0515 06:55:51.326327    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0515 06:55:52.326701    1545 runners.go:184] proxy-service-74gmc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 15 06:55:52.524: INFO: setup took 8.56185065s, starting test cases
[1mSTEP[0m: running 16 cases, 20 attempts per case, 320 total attempts
May 15 06:55:52.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 245.052345ms)
May 15 06:55:52.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 245.310285ms)
May 15 06:55:52.809: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 284.480926ms)
May 15 06:55:52.811: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 286.130801ms)
May 15 06:55:52.811: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 286.000556ms)
May 15 06:55:52.811: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 286.230519ms)
May 15 06:55:52.827: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 302.729655ms)
May 15 06:55:52.849: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 324.399272ms)
May 15 06:55:52.849: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 324.61382ms)
May 15 06:55:52.866: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 341.650958ms)
May 15 06:55:52.867: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 342.378405ms)
May 15 06:55:52.867: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 342.837168ms)
May 15 06:55:52.886: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 361.477787ms)
May 15 06:55:52.907: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 382.764092ms)
May 15 06:55:52.968: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 443.475854ms)
May 15 06:55:53.116: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 591.828935ms)
May 15 06:55:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 217.976752ms)
May 15 06:55:53.355: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 238.294166ms)
May 15 06:55:53.375: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 256.95936ms)
May 15 06:55:53.381: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 263.799464ms)
May 15 06:55:53.382: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 264.239024ms)
May 15 06:55:53.387: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 269.300272ms)
May 15 06:55:53.387: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 269.275681ms)
May 15 06:55:53.389: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 270.847245ms)
May 15 06:55:53.389: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 271.774616ms)
May 15 06:55:53.389: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 272.045112ms)
May 15 06:55:53.432: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 314.627837ms)
May 15 06:55:53.432: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 313.743737ms)
May 15 06:55:53.432: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 314.729023ms)
May 15 06:55:53.432: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 314.82406ms)
May 15 06:55:53.448: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 331.03241ms)
May 15 06:55:53.469: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 351.610366ms)
May 15 06:55:53.672: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 202.68228ms)
May 15 06:55:53.692: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 223.102151ms)
May 15 06:55:53.692: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 223.20769ms)
May 15 06:55:53.694: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 225.158757ms)
May 15 06:55:53.694: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 225.261313ms)
May 15 06:55:53.694: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 225.424095ms)
May 15 06:55:53.694: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 225.350039ms)
May 15 06:55:53.714: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 244.935199ms)
May 15 06:55:53.716: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 247.115454ms)
May 15 06:55:53.716: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 247.235113ms)
May 15 06:55:53.717: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 247.733113ms)
May 15 06:55:53.717: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 247.78137ms)
May 15 06:55:53.720: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 251.337419ms)
May 15 06:55:53.720: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 251.238532ms)
May 15 06:55:53.743: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 273.500352ms)
May 15 06:55:53.743: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 273.461374ms)
May 15 06:55:53.923: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 180.034728ms)
May 15 06:55:53.954: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 210.949766ms)
May 15 06:55:53.954: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 210.88155ms)
May 15 06:55:53.954: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 210.982389ms)
May 15 06:55:53.954: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 210.821677ms)
May 15 06:55:53.969: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 226.26725ms)
May 15 06:55:53.971: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 227.987712ms)
May 15 06:55:53.971: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 227.974983ms)
May 15 06:55:53.974: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 230.7665ms)
May 15 06:55:53.974: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 230.789824ms)
May 15 06:55:53.974: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 230.989453ms)
May 15 06:55:53.974: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 231.105395ms)
May 15 06:55:53.975: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 232.024067ms)
May 15 06:55:53.989: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 245.873958ms)
May 15 06:55:53.990: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 246.710178ms)
May 15 06:55:54.011: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 267.38569ms)
May 15 06:55:54.183: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 172.124724ms)
May 15 06:55:54.183: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 172.7778ms)
May 15 06:55:54.204: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 193.299833ms)
May 15 06:55:54.206: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 194.247684ms)
May 15 06:55:54.227: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 215.973925ms)
May 15 06:55:54.227: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 216.624398ms)
May 15 06:55:54.228: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 216.651571ms)
May 15 06:55:54.228: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 216.639676ms)
May 15 06:55:54.228: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 216.883806ms)
May 15 06:55:54.228: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 216.72644ms)
May 15 06:55:54.228: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 216.66808ms)
May 15 06:55:54.230: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 218.586229ms)
May 15 06:55:54.230: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 218.721065ms)
May 15 06:55:54.254: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 242.964172ms)
May 15 06:55:54.254: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 242.780813ms)
May 15 06:55:54.276: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 264.905491ms)
May 15 06:55:54.491: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 215.271919ms)
May 15 06:55:54.500: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 223.576896ms)
May 15 06:55:54.515: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 238.477247ms)
May 15 06:55:54.515: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 238.434123ms)
May 15 06:55:54.516: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 239.934851ms)
May 15 06:55:54.516: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 239.898752ms)
May 15 06:55:54.516: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 240.011462ms)
May 15 06:55:54.517: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 240.415589ms)
May 15 06:55:54.517: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 240.669963ms)
May 15 06:55:54.517: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 240.795454ms)
May 15 06:55:54.531: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 254.718452ms)
May 15 06:55:54.531: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 255.015209ms)
May 15 06:55:54.565: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 288.790269ms)
May 15 06:55:54.566: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 290.551939ms)
May 15 06:55:54.580: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 303.563747ms)
May 15 06:55:54.601: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 324.728845ms)
May 15 06:55:54.827: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 225.639141ms)
May 15 06:55:54.827: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 226.174742ms)
May 15 06:55:54.827: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 225.588251ms)
May 15 06:55:54.846: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 244.8579ms)
May 15 06:55:54.867: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 265.09124ms)
May 15 06:55:54.867: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 264.992356ms)
May 15 06:55:54.867: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 265.48628ms)
May 15 06:55:54.887: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 285.293322ms)
May 15 06:55:54.890: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 288.024512ms)
May 15 06:55:54.890: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 287.954499ms)
May 15 06:55:54.913: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 312.089533ms)
May 15 06:55:54.951: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 349.566495ms)
May 15 06:55:54.951: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 349.879459ms)
May 15 06:55:54.952: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 349.854513ms)
May 15 06:55:54.952: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 350.487835ms)
May 15 06:55:54.968: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 366.250596ms)
May 15 06:55:55.132: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 164.087397ms)
May 15 06:55:55.172: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 203.983549ms)
May 15 06:55:55.172: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 204.066044ms)
May 15 06:55:55.173: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 204.702365ms)
May 15 06:55:55.173: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 204.746977ms)
May 15 06:55:55.173: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 204.808247ms)
May 15 06:55:55.173: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 205.351348ms)
May 15 06:55:55.194: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 226.086494ms)
May 15 06:55:55.194: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 225.879207ms)
May 15 06:55:55.194: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 225.990973ms)
May 15 06:55:55.195: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 227.629822ms)
May 15 06:55:55.196: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 227.853143ms)
May 15 06:55:55.237: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 268.808031ms)
May 15 06:55:55.237: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 268.864871ms)
May 15 06:55:55.237: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 268.791719ms)
May 15 06:55:55.253: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 284.882063ms)
May 15 06:55:55.452: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 199.509604ms)
May 15 06:55:55.453: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 199.29059ms)
May 15 06:55:55.453: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 199.312041ms)
May 15 06:55:55.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 221.2853ms)
May 15 06:55:55.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 221.243594ms)
May 15 06:55:55.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 221.404084ms)
May 15 06:55:55.475: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 221.514352ms)
May 15 06:55:55.475: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 221.771476ms)
May 15 06:55:55.492: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 239.085714ms)
May 15 06:55:55.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 240.839701ms)
May 15 06:55:55.513: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 259.438396ms)
May 15 06:55:55.513: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 260.523319ms)
May 15 06:55:55.514: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 260.662323ms)
May 15 06:55:55.534: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 280.608496ms)
May 15 06:55:55.553: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 300.087646ms)
May 15 06:55:55.554: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 300.357243ms)
May 15 06:55:55.652: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 98.127569ms)
May 15 06:55:55.652: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 98.271245ms)
May 15 06:55:55.652: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 98.642173ms)
May 15 06:55:55.652: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 98.773431ms)
May 15 06:55:55.653: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 98.609444ms)
May 15 06:55:55.653: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 98.66102ms)
May 15 06:55:55.659: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 105.743748ms)
May 15 06:55:55.659: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 105.597296ms)
May 15 06:55:55.660: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 105.889482ms)
May 15 06:55:55.660: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 106.248102ms)
May 15 06:55:55.660: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 106.093023ms)
May 15 06:55:55.660: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 106.320941ms)
May 15 06:55:55.660: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 106.284585ms)
May 15 06:55:55.660: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 106.513855ms)
May 15 06:55:55.664: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 110.654495ms)
May 15 06:55:55.664: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 110.633726ms)
May 15 06:55:55.742: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 77.770493ms)
May 15 06:55:55.746: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 80.860433ms)
May 15 06:55:55.746: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 81.536187ms)
May 15 06:55:55.747: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 81.857997ms)
May 15 06:55:55.753: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 88.837314ms)
May 15 06:55:55.755: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 90.470118ms)
May 15 06:55:55.755: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 90.482562ms)
May 15 06:55:55.755: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 90.67801ms)
May 15 06:55:55.756: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 90.992143ms)
May 15 06:55:55.758: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 93.431154ms)
May 15 06:55:55.758: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 93.357305ms)
May 15 06:55:55.758: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 93.485608ms)
May 15 06:55:55.758: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 93.633008ms)
May 15 06:55:55.758: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 93.647329ms)
May 15 06:55:55.760: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 95.711673ms)
May 15 06:55:55.760: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 95.549483ms)
May 15 06:55:55.841: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 80.886911ms)
May 15 06:55:55.841: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 80.899927ms)
May 15 06:55:55.847: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 86.241271ms)
May 15 06:55:55.848: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 87.347817ms)
May 15 06:55:55.848: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 87.407065ms)
May 15 06:55:55.848: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 87.906028ms)
May 15 06:55:55.849: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 88.318585ms)
May 15 06:55:55.851: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 90.874848ms)
May 15 06:55:55.851: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 91.077132ms)
May 15 06:55:55.851: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 91.040076ms)
May 15 06:55:55.852: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 91.108403ms)
May 15 06:55:55.854: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 93.199274ms)
May 15 06:55:55.854: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 93.542014ms)
May 15 06:55:55.854: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 93.527236ms)
May 15 06:55:55.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 93.443225ms)
May 15 06:55:55.856: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 95.233124ms)
May 15 06:55:55.937: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 81.433717ms)
May 15 06:55:55.938: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 81.491467ms)
May 15 06:55:55.940: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 83.779072ms)
May 15 06:55:55.940: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 84.466861ms)
May 15 06:55:55.941: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 84.579216ms)
May 15 06:55:55.943: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 87.173734ms)
May 15 06:55:55.944: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 88.279027ms)
May 15 06:55:55.947: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 90.999382ms)
May 15 06:55:55.947: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 91.314217ms)
May 15 06:55:55.947: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 91.411394ms)
May 15 06:55:55.947: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 91.394956ms)
May 15 06:55:55.949: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 93.274474ms)
May 15 06:55:55.949: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 93.213919ms)
May 15 06:55:55.949: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 92.88296ms)
May 15 06:55:55.950: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 93.6658ms)
May 15 06:55:55.951: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 94.690723ms)
May 15 06:55:56.030: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 78.721666ms)
May 15 06:55:56.033: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 82.12173ms)
May 15 06:55:56.034: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 82.842867ms)
May 15 06:55:56.034: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 83.276443ms)
May 15 06:55:56.034: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 83.401768ms)
May 15 06:55:56.035: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 84.359834ms)
May 15 06:55:56.035: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 84.513039ms)
May 15 06:55:56.036: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 84.640068ms)
May 15 06:55:56.037: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 86.256324ms)
May 15 06:55:56.037: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 86.220855ms)
May 15 06:55:56.038: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 87.255822ms)
May 15 06:55:56.040: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 88.747314ms)
May 15 06:55:56.042: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 90.856596ms)
May 15 06:55:56.042: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 91.355535ms)
May 15 06:55:56.043: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 91.631599ms)
May 15 06:55:56.044: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 93.198237ms)
May 15 06:55:56.130: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 85.438644ms)
May 15 06:55:56.130: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 85.610956ms)
May 15 06:55:56.143: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 98.298917ms)
May 15 06:55:56.143: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 98.143978ms)
May 15 06:55:56.146: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 101.395213ms)
May 15 06:55:56.156: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 111.713316ms)
May 15 06:55:56.156: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 111.816976ms)
May 15 06:55:56.156: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 111.883388ms)
May 15 06:55:56.156: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 111.937132ms)
May 15 06:55:56.156: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 112.077108ms)
May 15 06:55:56.156: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 111.984697ms)
May 15 06:55:56.163: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 118.541066ms)
May 15 06:55:56.163: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 118.664456ms)
May 15 06:55:56.163: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 118.656966ms)
May 15 06:55:56.163: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 118.702398ms)
May 15 06:55:56.163: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 118.751507ms)
May 15 06:55:56.270: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 106.291694ms)
May 15 06:55:56.274: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 111.114941ms)
May 15 06:55:56.274: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 111.244999ms)
May 15 06:55:56.275: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 111.551478ms)
May 15 06:55:56.275: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 111.560149ms)
May 15 06:55:56.275: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 111.498372ms)
May 15 06:55:56.287: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 123.730182ms)
May 15 06:55:56.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 124.523477ms)
May 15 06:55:56.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 124.715117ms)
May 15 06:55:56.288: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 124.65587ms)
May 15 06:55:56.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 129.14397ms)
May 15 06:55:56.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 129.06177ms)
May 15 06:55:56.292: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 129.056258ms)
May 15 06:55:56.296: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 132.685574ms)
May 15 06:55:56.296: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 132.560281ms)
May 15 06:55:56.296: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 132.580531ms)
May 15 06:55:56.402: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 105.722866ms)
May 15 06:55:56.407: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 111.383364ms)
May 15 06:55:56.408: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 111.717566ms)
May 15 06:55:56.424: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 127.454816ms)
May 15 06:55:56.424: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 127.491668ms)
May 15 06:55:56.430: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 134.0903ms)
May 15 06:55:56.443: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 146.361496ms)
May 15 06:55:56.443: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 146.379118ms)
May 15 06:55:56.446: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 149.993981ms)
May 15 06:55:56.446: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 149.78789ms)
May 15 06:55:56.446: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 149.776909ms)
May 15 06:55:56.446: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 149.768774ms)
May 15 06:55:56.446: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 149.761003ms)
May 15 06:55:56.460: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 163.649889ms)
May 15 06:55:56.460: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 163.697283ms)
May 15 06:55:56.460: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 163.776555ms)
May 15 06:55:56.539: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 79.352858ms)
May 15 06:55:56.542: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 81.579728ms)
May 15 06:55:56.542: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 81.986268ms)
May 15 06:55:56.542: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 82.035042ms)
May 15 06:55:56.543: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 82.25291ms)
May 15 06:55:56.545: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 84.86307ms)
May 15 06:55:56.547: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 87.251087ms)
May 15 06:55:56.548: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 88.145704ms)
May 15 06:55:56.548: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 87.968338ms)
May 15 06:55:56.548: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 87.949719ms)
May 15 06:55:56.549: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 88.485219ms)
May 15 06:55:56.552: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 91.843305ms)
May 15 06:55:56.553: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 92.312777ms)
May 15 06:55:56.555: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 94.414956ms)
May 15 06:55:56.555: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 94.88626ms)
May 15 06:55:56.555: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 94.925367ms)
May 15 06:55:56.638: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 82.867404ms)
May 15 06:55:56.638: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 82.791858ms)
May 15 06:55:56.640: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 83.903098ms)
May 15 06:55:56.640: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 84.940357ms)
May 15 06:55:56.640: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 84.727354ms)
May 15 06:55:56.640: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 84.786872ms)
May 15 06:55:56.642: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 86.040842ms)
May 15 06:55:56.642: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 86.118005ms)
May 15 06:55:56.643: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 87.727803ms)
May 15 06:55:56.644: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 88.905165ms)
May 15 06:55:56.648: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 92.247367ms)
May 15 06:55:56.649: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 93.275989ms)
May 15 06:55:56.649: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 93.245603ms)
May 15 06:55:56.649: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 93.293793ms)
May 15 06:55:56.650: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 94.033578ms)
May 15 06:55:56.650: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 94.21148ms)
May 15 06:55:56.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:443/proxy/... (200; 81.032249ms)
May 15 06:55:56.732: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:462/proxy/: tls qux (200; 81.922233ms)
May 15 06:55:56.732: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:162/proxy/: bar (200; 82.183986ms)
May 15 06:55:56.736: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt/proxy/rewriteme"... (200; 86.044827ms)
May 15 06:55:56.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:160/proxy/: foo (200; 86.654629ms)
May 15 06:55:56.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:162/proxy/: bar (200; 86.619009ms)
May 15 06:55:56.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:160/proxy/: foo (200; 86.732927ms)
May 15 06:55:56.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/http:proxy-service-74gmc-bdblt:1080/proxy/... (200; 86.74787ms)
May 15 06:55:56.737: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/https:proxy-service-74gmc-bdblt:460/proxy/: tls baz (200; 87.379297ms)
May 15 06:55:56.738: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xmbs9/pods/proxy-service-74gmc-bdblt:1080/proxy/rewri... (200; 87.536794ms)
May 15 06:55:56.740: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname1/proxy/: foo (200; 89.651528ms)
May 15 06:55:56.741: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname2/proxy/: bar (200; 90.916156ms)
May 15 06:55:56.741: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/proxy-service-74gmc:portname2/proxy/: bar (200; 91.101518ms)
May 15 06:55:56.741: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname1/proxy/: tls baz (200; 91.167155ms)
May 15 06:55:56.743: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/https:proxy-service-74gmc:tlsportname2/proxy/: tls qux (200; 93.490812ms)
May 15 06:55:56.744: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xmbs9/services/http:proxy-service-74gmc:portname1/proxy/: foo (200; 93.499723ms)
[1mSTEP[0m: deleting ReplicationController proxy-service-74gmc in namespace e2e-tests-proxy-xmbs9, will wait for the garbage collector to delete the pods
May 15 06:55:57.038: INFO: Deleting ReplicationController proxy-service-74gmc took: 97.393243ms
May 15 06:55:57.139: INFO: Terminating ReplicationController proxy-service-74gmc pods took: 100.375746ms
[AfterEach] version v1
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 06:56:08.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-xmbs9" for this suite.
May 15 06:56:14.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 06:56:17.456: INFO: namespace: e2e-tests-proxy-xmbs9, resource: bindings, ignored listing per whitelist
May 15 06:56:19.480: INFO: namespace e2e-tests-proxy-xmbs9 deletion completed in 11.069935784s

[32m [SLOW TEST:38.572 seconds][0m
[sig-network] Proxy
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy through a service and a pod  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl label[0m 
  [1mshould update the label on a resource  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 06:56:19.480: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
[1mSTEP[0m: creating the pod
May 15 06:56:21.930: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-6n7rm'
May 15 06:56:22.933: INFO: stderr: ""
May 15 06:56:22.933: INFO: stdout: "pod/pause created\n"
May 15 06:56:22.933: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 15 06:56:22.933: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-6n7rm" to be "running and ready"
May 15 06:56:23.030: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 97.226378ms
May 15 06:56:25.101: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.167905303s
May 15 06:56:25.101: INFO: Pod "pause" satisfied condition "running and ready"
May 15 06:56:25.101: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: adding the label testing-label with value testing-label-value to a pod
May 15 06:56:25.101: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-6n7rm'
May 15 06:56:25.611: INFO: stderr: ""
May 15 06:56:25.611: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod has the label testing-label with the value testing-label-value
May 15 06:56:25.611: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6n7rm'
May 15 06:56:25.989: INFO: stderr: ""
May 15 06:56:25.989: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
[1mSTEP[0m: removing the label testing-label of a pod
May 15 06:56:25.989: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 label pods pause testing-label- --namespace=e2e-tests-kubectl-6n7rm'
May 15 06:56:26.444: INFO: stderr: ""
May 15 06:56:26.444: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod doesn't have the label testing-label
May 15 06:56:26.444: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6n7rm'
May 15 06:56:26.823: INFO: stderr: ""
May 15 06:56:26.823: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
[1mSTEP[0m: using delete to clean up resources
May 15 06:56:26.823: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6n7rm'
May 15 06:56:27.346: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 06:56:27.346: INFO: stdout: "pod \"pause\" force deleted\n"
May 15 06:56:27.346: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-6n7rm'
May 15 06:56:27.895: INFO: stderr: "No resources found.\n"
May 15 06:56:27.895: INFO: stdout: ""
May 15 06:56:27.895: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -l name=pause --namespace=e2e-tests-kubectl-6n7rm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 15 06:56:28.307: INFO: stderr: ""
May 15 06:56:28.308: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 06:56:28.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-6n7rm" for this suite.
May 15 06:56:34.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 06:56:35.466: INFO: namespace: e2e-tests-kubectl-6n7rm, resource: bindings, ignored listing per whitelist
May 15 06:56:38.922: INFO: namespace e2e-tests-kubectl-6n7rm deletion completed in 10.544111288s

[32m [SLOW TEST:19.442 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl label
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should update the label on a resource  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on tmpfs should have the correct mode [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 06:56:38.923: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir volume type on tmpfs
May 15 06:56:41.532: INFO: Waiting up to 5m0s for pod "pod-97debdf1-76de-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-8lpx2" to be "success or failure"
May 15 06:56:41.631: INFO: Pod "pod-97debdf1-76de-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 98.925504ms
May 15 06:56:43.702: INFO: Pod "pod-97debdf1-76de-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.16980639s
[1mSTEP[0m: Saw pod success
May 15 06:56:43.702: INFO: Pod "pod-97debdf1-76de-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 06:56:43.773: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-97debdf1-76de-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 06:56:44.004: INFO: Waiting for pod pod-97debdf1-76de-11e9-9e56-3ac139a44f02 to disappear
May 15 06:56:44.114: INFO: Pod pod-97debdf1-76de-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 06:56:44.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-8lpx2" for this suite.
May 15 06:56:50.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 06:56:54.682: INFO: namespace: e2e-tests-emptydir-8lpx2, resource: bindings, ignored listing per whitelist
May 15 06:56:55.613: INFO: namespace e2e-tests-emptydir-8lpx2 deletion completed in 11.428043461s

[32m [SLOW TEST:16.690 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould provide secure master service  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 06:56:55.614: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 06:56:58.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-qwbrr" for this suite.
May 15 06:57:04.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 06:57:08.872: INFO: namespace: e2e-tests-services-qwbrr, resource: bindings, ignored listing per whitelist
May 15 06:57:09.249: INFO: namespace e2e-tests-services-qwbrr deletion completed in 10.947676614s
[AfterEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

[32m [SLOW TEST:13.635 seconds][0m
[sig-network] Services
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide secure master service  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mBurst scaling should run to completion even with unhealthy pods [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 06:57:09.249: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-b8crc
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating stateful set ss in namespace e2e-tests-statefulset-b8crc
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-b8crc
May 15 06:57:12.462: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 15 06:57:22.536: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 15 06:57:22.606: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-b8crc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 06:57:23.688: INFO: stderr: ""
May 15 06:57:23.688: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 06:57:23.688: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 06:57:23.758: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 15 06:57:33.830: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 15 06:57:33.830: INFO: Waiting for statefulset status.replicas updated to 0
May 15 06:57:34.202: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998826s
May 15 06:57:35.274: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.924173178s
May 15 06:57:36.346: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.85219475s
May 15 06:57:37.420: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.780252511s
May 15 06:57:38.491: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.705775491s
May 15 06:57:39.563: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.634980739s
May 15 06:57:40.634: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.563504402s
May 15 06:57:41.705: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.491588737s
May 15 06:57:42.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.420887188s
May 15 06:57:43.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 349.129597ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-b8crc
May 15 06:57:44.918: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-b8crc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 06:57:45.939: INFO: stderr: ""
May 15 06:57:45.940: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 06:57:45.940: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 06:57:45.940: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-b8crc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 06:57:46.987: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 15 06:57:46.987: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 06:57:46.987: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 06:57:46.987: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-b8crc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 06:57:48.077: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 15 06:57:48.077: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 06:57:48.077: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 06:57:48.148: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 15 06:57:48.148: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 15 06:57:48.148: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Scale down will not halt with unhealthy stateful pod
May 15 06:57:48.219: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-b8crc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 06:57:49.201: INFO: stderr: ""
May 15 06:57:49.201: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 06:57:49.201: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 06:57:49.202: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-b8crc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 06:57:50.187: INFO: stderr: ""
May 15 06:57:50.187: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 06:57:50.187: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 06:57:50.187: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-b8crc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 06:57:51.191: INFO: stderr: ""
May 15 06:57:51.191: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 06:57:51.191: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 06:57:51.191: INFO: Waiting for statefulset status.replicas updated to 0
May 15 06:57:51.260: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 15 06:58:01.402: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 15 06:58:01.402: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 15 06:58:01.402: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 15 06:58:01.643: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 15 06:58:01.643: INFO: ss-0  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  }]
May 15 06:58:01.643: INFO: ss-1  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:01.643: INFO: ss-2  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:01.644: INFO: 
May 15 06:58:01.644: INFO: StatefulSet ss has not reached scale 0, at 3
May 15 06:58:02.719: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 15 06:58:02.719: INFO: ss-0  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  }]
May 15 06:58:02.719: INFO: ss-1  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:02.719: INFO: ss-2  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:02.719: INFO: 
May 15 06:58:02.719: INFO: StatefulSet ss has not reached scale 0, at 3
May 15 06:58:03.790: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 15 06:58:03.790: INFO: ss-0  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  }]
May 15 06:58:03.790: INFO: ss-1  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:03.790: INFO: ss-2  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:03.790: INFO: 
May 15 06:58:03.790: INFO: StatefulSet ss has not reached scale 0, at 3
May 15 06:58:04.861: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 15 06:58:04.861: INFO: ss-0  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  }]
May 15 06:58:04.861: INFO: ss-1  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:04.861: INFO: ss-2  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:04.861: INFO: 
May 15 06:58:04.861: INFO: StatefulSet ss has not reached scale 0, at 3
May 15 06:58:05.931: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 15 06:58:05.931: INFO: ss-0  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  }]
May 15 06:58:05.931: INFO: ss-1  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:05.931: INFO: ss-2  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:05.931: INFO: 
May 15 06:58:05.931: INFO: StatefulSet ss has not reached scale 0, at 3
May 15 06:58:07.002: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 15 06:58:07.002: INFO: ss-0  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:12 +0000 UTC  }]
May 15 06:58:07.002: INFO: ss-1  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:07.002: INFO: ss-2  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 06:57:34 +0000 UTC  }]
May 15 06:58:07.002: INFO: 
May 15 06:58:07.002: INFO: StatefulSet ss has not reached scale 0, at 3
May 15 06:58:08.073: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.544704035s
May 15 06:58:09.142: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.474203355s
May 15 06:58:10.213: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.404224176s
May 15 06:58:11.283: INFO: Verifying statefulset ss doesn't scale past 0 for another 333.767314ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-b8crc
May 15 06:58:12.354: INFO: Scaling statefulset ss to 0
May 15 06:58:12.565: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 15 06:58:12.636: INFO: Deleting all statefulset in ns e2e-tests-statefulset-b8crc
May 15 06:58:12.732: INFO: Scaling statefulset ss to 0
May 15 06:58:12.943: INFO: Waiting for statefulset status.replicas updated to 0
May 15 06:58:13.037: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 06:58:13.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-b8crc" for this suite.
May 15 06:58:19.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 06:58:20.598: INFO: namespace: e2e-tests-statefulset-b8crc, resource: bindings, ignored listing per whitelist
May 15 06:58:24.012: INFO: namespace e2e-tests-statefulset-b8crc deletion completed in 10.556442333s

[32m [SLOW TEST:74.763 seconds][0m
[sig-apps] StatefulSet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected combined[0m 
  [1mshould project all components that make up the projection API [Projection][NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected combined
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 06:58:24.012: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-projected-all-test-volume-d6859e16-76de-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating secret with name secret-projected-all-test-volume-d6859df6-76de-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test Check all projections for projected volume plugin
May 15 06:58:26.845: INFO: Waiting up to 5m0s for pod "projected-volume-d6859d8d-76de-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-xc544" to be "success or failure"
May 15 06:58:26.939: INFO: Pod "projected-volume-d6859d8d-76de-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 94.800859ms
May 15 06:58:29.009: INFO: Pod "projected-volume-d6859d8d-76de-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.164849386s
[1mSTEP[0m: Saw pod success
May 15 06:58:29.009: INFO: Pod "projected-volume-d6859d8d-76de-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 06:58:29.079: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod projected-volume-d6859d8d-76de-11e9-9e56-3ac139a44f02 container projected-all-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 06:58:29.304: INFO: Waiting for pod projected-volume-d6859d8d-76de-11e9-9e56-3ac139a44f02 to disappear
May 15 06:58:29.523: INFO: Pod projected-volume-d6859d8d-76de-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 06:58:29.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-xc544" for this suite.
May 15 06:58:35.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 06:58:39.765: INFO: namespace: e2e-tests-projected-xc544, resource: bindings, ignored listing per whitelist
May 15 06:58:40.421: INFO: namespace e2e-tests-projected-xc544 deletion completed in 10.826781666s

[32m [SLOW TEST:16.408 seconds][0m
[sig-storage] Projected combined
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31[0m
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Guestbook application[0m 
  [1mshould create and stop a working application  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 06:58:40.421: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating all guestbook components
May 15 06:58:42.884: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 15 06:58:42.884: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:58:43.551: INFO: stderr: ""
May 15 06:58:43.551: INFO: stdout: "service/redis-slave created\n"
May 15 06:58:43.552: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 15 06:58:43.552: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:58:44.146: INFO: stderr: ""
May 15 06:58:44.146: INFO: stdout: "service/redis-master created\n"
May 15 06:58:44.146: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 15 06:58:44.146: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:58:44.753: INFO: stderr: ""
May 15 06:58:44.753: INFO: stdout: "service/frontend created\n"
May 15 06:58:44.753: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 15 06:58:44.753: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:58:45.421: INFO: stderr: ""
May 15 06:58:45.421: INFO: stdout: "deployment.extensions/frontend created\n"
May 15 06:58:45.421: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 15 06:58:45.421: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:58:46.045: INFO: stderr: ""
May 15 06:58:46.045: INFO: stdout: "deployment.extensions/redis-master created\n"
May 15 06:58:46.045: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 15 06:58:46.045: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:58:46.662: INFO: stderr: ""
May 15 06:58:46.662: INFO: stdout: "deployment.extensions/redis-slave created\n"
[1mSTEP[0m: validating guestbook app
May 15 06:58:46.662: INFO: Waiting for all frontend pods to be Running.
May 15 06:59:06.814: INFO: Waiting for frontend to serve content.
May 15 06:59:06.935: INFO: Trying to add a new entry to the guestbook.
May 15 06:59:07.021: INFO: Verifying that added entry can be retrieved.
May 15 06:59:07.110: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 15 06:59:12.196: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
[1mSTEP[0m: using delete to clean up resources
May 15 06:59:17.685: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:59:18.796: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 06:59:18.796: INFO: stdout: "service \"redis-slave\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 15 06:59:18.796: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:59:20.032: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 06:59:20.032: INFO: stdout: "service \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 15 06:59:20.032: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:59:21.145: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 06:59:21.146: INFO: stdout: "service \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 15 06:59:21.146: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:59:21.719: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 06:59:21.719: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 15 06:59:21.719: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:59:22.237: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 06:59:22.237: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 15 06:59:22.237: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cjqbv'
May 15 06:59:22.748: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 06:59:22.748: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 06:59:22.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-cjqbv" for this suite.
May 15 07:00:01.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:00:02.901: INFO: namespace: e2e-tests-kubectl-cjqbv, resource: bindings, ignored listing per whitelist
May 15 07:00:05.139: INFO: namespace e2e-tests-kubectl-cjqbv deletion completed in 42.287205047s

[32m [SLOW TEST:84.719 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Guestbook application
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create and stop a working application  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:00:05.139: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating secret e2e-tests-secrets-x8blt/secret-test-12c63257-76df-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:00:07.837: INFO: Waiting up to 5m0s for pod "pod-configmaps-12d5a11b-76df-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-x8blt" to be "success or failure"
May 15 07:00:07.944: INFO: Pod "pod-configmaps-12d5a11b-76df-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 106.945585ms
May 15 07:00:10.014: INFO: Pod "pod-configmaps-12d5a11b-76df-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.177099053s
[1mSTEP[0m: Saw pod success
May 15 07:00:10.014: INFO: Pod "pod-configmaps-12d5a11b-76df-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:00:10.084: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-configmaps-12d5a11b-76df-11e9-9e56-3ac139a44f02 container env-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:00:10.306: INFO: Waiting for pod pod-configmaps-12d5a11b-76df-11e9-9e56-3ac139a44f02 to disappear
May 15 07:00:10.406: INFO: Pod pod-configmaps-12d5a11b-76df-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:00:10.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-x8blt" for this suite.
May 15 07:00:16.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:00:19.338: INFO: namespace: e2e-tests-secrets-x8blt, resource: bindings, ignored listing per whitelist
May 15 07:00:20.690: INFO: namespace e2e-tests-secrets-x8blt deletion completed in 10.213490732s

[32m [SLOW TEST:15.551 seconds][0m
[sig-api-machinery] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32[0m
  should be consumable via the environment [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be updated [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:00:20.690: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
May 15 07:00:26.411: INFO: Successfully updated pod "pod-update-1c19aa85-76df-11e9-9e56-3ac139a44f02"
[1mSTEP[0m: verifying the updated pod is in kubernetes
May 15 07:00:26.551: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:00:26.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-6z22g" for this suite.
May 15 07:00:48.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:00:49.908: INFO: namespace: e2e-tests-pods-6z22g, resource: bindings, ignored listing per whitelist
May 15 07:00:53.177: INFO: namespace e2e-tests-pods-6z22g deletion completed in 26.555921949s

[32m [SLOW TEST:32.487 seconds][0m
[k8s.io] Pods
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be updated [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Namespaces [Serial][0m 
  [1mshould ensure that all pods are removed when a namespace is deleted [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:00:53.178: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename namespaces
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a test namespace
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[1mSTEP[0m: Creating a pod in the namespace
[1mSTEP[0m: Waiting for the pod to have running status
[1mSTEP[0m: Creating an uninitialized pod in the namespace
May 15 07:00:58.233: INFO: error from create uninitialized namespace: <nil>
[1mSTEP[0m: Deleting the namespace
[1mSTEP[0m: Waiting for the namespace to be removed.
[1mSTEP[0m: Recreating the namespace
[1mSTEP[0m: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:01:20.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-namespaces-l78t5" for this suite.
May 15 07:01:27.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:01:32.317: INFO: namespace: e2e-tests-namespaces-l78t5, resource: bindings, ignored listing per whitelist
May 15 07:01:32.510: INFO: namespace e2e-tests-namespaces-l78t5 deletion completed in 11.62716436s
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-qbn5r" for this suite.
May 15 07:01:32.612: INFO: Namespace e2e-tests-nsdeletetest-qbn5r was already deleted
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-lc4fd" for this suite.
May 15 07:01:38.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:01:42.307: INFO: namespace: e2e-tests-nsdeletetest-lc4fd, resource: bindings, ignored listing per whitelist
May 15 07:01:42.804: INFO: namespace e2e-tests-nsdeletetest-lc4fd deletion completed in 10.191180465s

[32m [SLOW TEST:49.626 seconds][0m
[sig-api-machinery] Namespaces [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,tmpfs) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:01:42.804: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
May 15 07:01:45.492: INFO: Waiting up to 5m0s for pod "pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-d6dpp" to be "success or failure"
May 15 07:01:45.588: INFO: Pod "pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 95.562081ms
May 15 07:01:47.666: INFO: Pod "pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.173907935s
May 15 07:01:49.737: INFO: Pod "pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.245024986s
[1mSTEP[0m: Saw pod success
May 15 07:01:49.737: INFO: Pod "pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:01:49.807: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:01:50.498: INFO: Waiting for pod pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02 to disappear
May 15 07:01:50.596: INFO: Pod pod-4d0aaf94-76df-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:01:50.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-d6dpp" for this suite.
May 15 07:01:57.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:02:00.912: INFO: namespace: e2e-tests-emptydir-d6dpp, resource: bindings, ignored listing per whitelist
May 15 07:02:01.822: INFO: namespace e2e-tests-emptydir-d6dpp deletion completed in 10.763419104s

[32m [SLOW TEST:19.018 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Pods Set QOS Class[0m 
  [1mshould be submitted and removed  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:02:01.822: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:02:04.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-wt9xr" for this suite.
May 15 07:02:27.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:02:27.624: INFO: namespace: e2e-tests-pods-wt9xr, resource: bindings, ignored listing per whitelist
May 15 07:02:31.702: INFO: namespace e2e-tests-pods-wt9xr deletion completed in 26.959443569s

[32m [SLOW TEST:29.880 seconds][0m
[k8s.io] [sig-node] Pods Extended
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  [k8s.io] Pods Set QOS Class
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should be submitted and removed  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform canary updates and phased rolling updates of template modifications [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:02:31.703: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-2gtpx
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a new StaefulSet
May 15 07:02:34.664: INFO: Found 1 stateful pods, waiting for 3
May 15 07:02:44.736: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 15 07:02:44.736: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 15 07:02:44.736: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 15 07:02:45.167: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Not applying an update when the partition is greater than the number of replicas
[1mSTEP[0m: Performing a canary update
May 15 07:02:45.464: INFO: Updating stateful set ss2
May 15 07:02:45.606: INFO: Waiting for Pod e2e-tests-statefulset-2gtpx/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 15 07:02:55.748: INFO: Waiting for Pod e2e-tests-statefulset-2gtpx/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
[1mSTEP[0m: Restoring Pods to the correct revision when they are deleted
May 15 07:03:06.074: INFO: Found 2 stateful pods, waiting for 3
May 15 07:03:16.146: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 15 07:03:16.146: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 15 07:03:16.146: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Performing a phased rolling update
May 15 07:03:16.446: INFO: Updating stateful set ss2
May 15 07:03:16.587: INFO: Waiting for Pod e2e-tests-statefulset-2gtpx/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 15 07:03:26.999: INFO: Updating stateful set ss2
May 15 07:03:27.139: INFO: Waiting for StatefulSet e2e-tests-statefulset-2gtpx/ss2 to complete update
May 15 07:03:27.140: INFO: Waiting for Pod e2e-tests-statefulset-2gtpx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 15 07:03:37.284: INFO: Waiting for StatefulSet e2e-tests-statefulset-2gtpx/ss2 to complete update
May 15 07:03:37.284: INFO: Waiting for Pod e2e-tests-statefulset-2gtpx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 15 07:03:47.282: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2gtpx
May 15 07:03:47.385: INFO: Scaling statefulset ss2 to 0
May 15 07:04:17.844: INFO: Waiting for statefulset status.replicas updated to 0
May 15 07:04:18.012: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:04:19.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-2gtpx" for this suite.
May 15 07:04:26.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:04:30.022: INFO: namespace: e2e-tests-statefulset-2gtpx, resource: bindings, ignored listing per whitelist
May 15 07:04:30.521: INFO: namespace e2e-tests-statefulset-2gtpx deletion completed in 10.934916056s

[32m [SLOW TEST:118.819 seconds][0m
[sig-apps] StatefulSet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould create and stop a replication controller  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:04:30.522: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a replication controller
May 15 07:04:33.016: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:33.757: INFO: stderr: ""
May 15 07:04:33.757: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 15 07:04:33.757: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:34.171: INFO: stderr: ""
May 15 07:04:34.171: INFO: stdout: "update-demo-nautilus-47znn update-demo-nautilus-g2smk "
May 15 07:04:34.171: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-47znn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:34.611: INFO: stderr: ""
May 15 07:04:34.611: INFO: stdout: ""
May 15 07:04:34.611: INFO: update-demo-nautilus-47znn is created but not running
May 15 07:04:39.611: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:40.009: INFO: stderr: ""
May 15 07:04:40.009: INFO: stdout: "update-demo-nautilus-47znn update-demo-nautilus-g2smk "
May 15 07:04:40.009: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-47znn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:40.404: INFO: stderr: ""
May 15 07:04:40.404: INFO: stdout: "true"
May 15 07:04:40.404: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-47znn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:40.800: INFO: stderr: ""
May 15 07:04:40.800: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:04:40.800: INFO: validating pod update-demo-nautilus-47znn
May 15 07:04:40.914: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:04:40.914: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:04:40.914: INFO: update-demo-nautilus-47znn is verified up and running
May 15 07:04:40.914: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-g2smk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:41.401: INFO: stderr: ""
May 15 07:04:41.401: INFO: stdout: "true"
May 15 07:04:41.401: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-g2smk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:41.803: INFO: stderr: ""
May 15 07:04:41.803: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:04:41.803: INFO: validating pod update-demo-nautilus-g2smk
May 15 07:04:41.908: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:04:41.909: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:04:41.909: INFO: update-demo-nautilus-g2smk is verified up and running
[1mSTEP[0m: using delete to clean up resources
May 15 07:04:41.909: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:42.430: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 07:04:42.430: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 15 07:04:42.430: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zjjrd'
May 15 07:04:42.958: INFO: stderr: "No resources found.\n"
May 15 07:04:42.958: INFO: stdout: ""
May 15 07:04:42.958: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zjjrd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 15 07:04:43.364: INFO: stderr: ""
May 15 07:04:43.364: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:04:43.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-zjjrd" for this suite.
May 15 07:04:49.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:04:52.366: INFO: namespace: e2e-tests-kubectl-zjjrd, resource: bindings, ignored listing per whitelist
May 15 07:04:54.006: INFO: namespace e2e-tests-kubectl-zjjrd deletion completed in 10.570917272s

[32m [SLOW TEST:23.484 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create and stop a replication controller  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould be consumable via environment variable [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-node] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:04:54.006: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap e2e-tests-configmap-rr66j/configmap-test-beecdee3-76df-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:04:56.667: INFO: Waiting up to 5m0s for pod "pod-configmaps-befc6734-76df-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-rr66j" to be "success or failure"
May 15 07:04:56.782: INFO: Pod "pod-configmaps-befc6734-76df-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 114.789924ms
May 15 07:04:58.862: INFO: Pod "pod-configmaps-befc6734-76df-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.194758629s
[1mSTEP[0m: Saw pod success
May 15 07:04:58.862: INFO: Pod "pod-configmaps-befc6734-76df-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:04:58.935: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-configmaps-befc6734-76df-11e9-9e56-3ac139a44f02 container env-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:04:59.147: INFO: Waiting for pod pod-configmaps-befc6734-76df-11e9-9e56-3ac139a44f02 to disappear
May 15 07:04:59.248: INFO: Pod pod-configmaps-befc6734-76df-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:04:59.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-rr66j" for this suite.
May 15 07:05:05.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:05:10.188: INFO: namespace: e2e-tests-configmap-rr66j, resource: bindings, ignored listing per whitelist
May 15 07:05:10.612: INFO: namespace e2e-tests-configmap-rr66j deletion completed in 11.293642306s

[32m [SLOW TEST:16.606 seconds][0m
[sig-node] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31[0m
  should be consumable via environment variable [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run deployment[0m 
  [1mshould create a deployment from an image  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:05:10.612: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
May 15 07:05:13.064: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-q8xkh'
May 15 07:05:16.276: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 15 07:05:16.277: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the deployment e2e-test-nginx-deployment was created
[1mSTEP[0m: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
May 15 07:05:18.479: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-q8xkh'
May 15 07:05:19.005: INFO: stderr: ""
May 15 07:05:19.005: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:05:19.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-q8xkh" for this suite.
May 15 07:05:25.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:05:27.803: INFO: namespace: e2e-tests-kubectl-q8xkh, resource: bindings, ignored listing per whitelist
May 15 07:05:29.600: INFO: namespace e2e-tests-kubectl-q8xkh deletion completed in 10.52397087s

[32m [SLOW TEST:18.988 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run deployment
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a deployment from an image  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:05:29.600: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-d4499bb5-76df-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-d4499bff-76df-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-d4499bb5-76df-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Updating configmap cm-test-opt-upd-d4499bff-76df-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-d4499c15-76df-11e9-9e56-3ac139a44f02
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:06:57.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-v7gcx" for this suite.
May 15 07:07:21.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:07:25.203: INFO: namespace: e2e-tests-projected-v7gcx, resource: bindings, ignored listing per whitelist
May 15 07:07:25.310: INFO: namespace e2e-tests-projected-v7gcx deletion completed in 28.217863422s

[32m [SLOW TEST:115.710 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl rolling-update[0m 
  [1mshould support rolling-update to same image  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:07:25.311: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
May 15 07:07:27.770: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-9fs4g'
May 15 07:07:28.334: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 15 07:07:28.334: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: rolling-update to same image controller
May 15 07:07:28.534: INFO: scanned /workspace for discovery docs: <nil>
May 15 07:07:28.534: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-9fs4g'
May 15 07:07:40.706: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 15 07:07:40.706: INFO: stdout: "Created e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429\nScaling up e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 15 07:07:40.706: INFO: stdout: "Created e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429\nScaling up e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
[1mSTEP[0m: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 15 07:07:40.706: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9fs4g'
May 15 07:07:41.138: INFO: stderr: ""
May 15 07:07:41.138: INFO: stdout: "e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429-qr5l4 "
May 15 07:07:41.138: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429-qr5l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9fs4g'
May 15 07:07:41.543: INFO: stderr: ""
May 15 07:07:41.543: INFO: stdout: "true"
May 15 07:07:41.543: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429-qr5l4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9fs4g'
May 15 07:07:41.934: INFO: stderr: ""
May 15 07:07:41.934: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 15 07:07:41.934: INFO: e2e-test-nginx-rc-d266073a6631ef8bfae085c80d832429-qr5l4 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
May 15 07:07:41.935: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-9fs4g'
May 15 07:07:42.431: INFO: stderr: ""
May 15 07:07:42.431: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:07:42.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-9fs4g" for this suite.
May 15 07:07:48.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:07:50.420: INFO: namespace: e2e-tests-kubectl-9fs4g, resource: bindings, ignored listing per whitelist
May 15 07:07:54.529: INFO: namespace e2e-tests-kubectl-9fs4g deletion completed in 12.004074656s

[32m [SLOW TEST:29.218 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl rolling-update
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should support rolling-update to same image  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould get a host IP [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:07:54.529: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating pod
May 15 07:07:59.422: INFO: Pod pod-hostip-2a8b4e9c-76e0-11e9-9e56-3ac139a44f02 has hostIP: 10.142.0.2
[AfterEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:07:59.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-pnq7b" for this suite.
May 15 07:08:21.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:08:22.825: INFO: namespace: e2e-tests-pods-pnq7b, resource: bindings, ignored listing per whitelist
May 15 07:08:26.148: INFO: namespace e2e-tests-pods-pnq7b deletion completed in 26.655546249s

[32m [SLOW TEST:31.619 seconds][0m
[k8s.io] Pods
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should get a host IP [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,default) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:08:26.148: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
May 15 07:08:28.758: INFO: Waiting up to 5m0s for pod "pod-3d6864bb-76e0-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-4bfdk" to be "success or failure"
May 15 07:08:28.853: INFO: Pod "pod-3d6864bb-76e0-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 94.800383ms
May 15 07:08:30.952: INFO: Pod "pod-3d6864bb-76e0-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.193419464s
[1mSTEP[0m: Saw pod success
May 15 07:08:30.952: INFO: Pod "pod-3d6864bb-76e0-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:08:31.023: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-3d6864bb-76e0-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:08:31.256: INFO: Waiting for pod pod-3d6864bb-76e0-11e9-9e56-3ac139a44f02 to disappear
May 15 07:08:31.359: INFO: Pod pod-3d6864bb-76e0-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:08:31.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-4bfdk" for this suite.
May 15 07:08:37.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:08:41.444: INFO: namespace: e2e-tests-emptydir-4bfdk, resource: bindings, ignored listing per whitelist
May 15 07:08:42.502: INFO: namespace e2e-tests-emptydir-4bfdk deletion completed in 11.07275653s

[32m [SLOW TEST:16.354 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould retry creating failed daemon pods [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:08:42.502: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
May 15 07:08:45.971: INFO: Number of nodes with available pods: 0
May 15 07:08:45.971: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 07:08:47.114: INFO: Number of nodes with available pods: 1
May 15 07:08:47.114: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 07:08:48.202: INFO: Number of nodes with available pods: 3
May 15 07:08:48.202: INFO: Number of running nodes: 3, number of available pods: 3
[1mSTEP[0m: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 15 07:08:48.727: INFO: Number of nodes with available pods: 2
May 15 07:08:48.727: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:08:49.870: INFO: Number of nodes with available pods: 2
May 15 07:08:49.870: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:08:50.875: INFO: Number of nodes with available pods: 2
May 15 07:08:50.875: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:08:51.869: INFO: Number of nodes with available pods: 3
May 15 07:08:51.869: INFO: Number of running nodes: 3, number of available pods: 3
[1mSTEP[0m: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zxnml, will wait for the garbage collector to delete the pods
May 15 07:08:52.360: INFO: Deleting DaemonSet.extensions daemon-set took: 100.319209ms
May 15 07:08:52.461: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.387935ms
May 15 07:08:57.932: INFO: Number of nodes with available pods: 0
May 15 07:08:57.932: INFO: Number of running nodes: 0, number of available pods: 0
May 15 07:08:58.003: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zxnml/daemonsets","resourceVersion":"4096"},"items":null}

May 15 07:08:58.073: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zxnml/pods","resourceVersion":"4096"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:08:58.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-zxnml" for this suite.
May 15 07:09:05.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:09:09.146: INFO: namespace: e2e-tests-daemonsets-zxnml, resource: bindings, ignored listing per whitelist
May 15 07:09:09.811: INFO: namespace e2e-tests-daemonsets-zxnml deletion completed in 11.384974006s

[32m [SLOW TEST:27.308 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should retry creating failed daemon pods [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe add, update, and delete watch notifications on configmaps [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:09:09.811: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a watch on configmaps with label A
[1mSTEP[0m: creating a watch on configmaps with label B
[1mSTEP[0m: creating a watch on configmaps with label A or B
[1mSTEP[0m: creating a configmap with label A and ensuring the correct watchers observe the notification
May 15 07:09:12.600: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4155,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 15 07:09:12.601: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4155,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A and ensuring the correct watchers observe the notification
May 15 07:09:22.819: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4184,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 15 07:09:22.820: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4184,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A again and ensuring the correct watchers observe the notification
May 15 07:09:32.969: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4214,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 15 07:09:32.970: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4214,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap A and ensuring the correct watchers observe the notification
May 15 07:09:43.109: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4244,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 15 07:09:43.109: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-a,UID:5791a1eb-76e0-11e9-8329-42010a8e0130,ResourceVersion:4244,Generation:0,CreationTimestamp:2019-05-15 07:09:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: creating a configmap with label B and ensuring the correct watchers observe the notification
May 15 07:09:53.213: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-b,UID:6fc6c1dc-76e0-11e9-8329-42010a8e0130,ResourceVersion:4277,Generation:0,CreationTimestamp:2019-05-15 07:09:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 15 07:09:53.213: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-b,UID:6fc6c1dc-76e0-11e9-8329-42010a8e0130,ResourceVersion:4277,Generation:0,CreationTimestamp:2019-05-15 07:09:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap B and ensuring the correct watchers observe the notification
May 15 07:10:03.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-b,UID:6fc6c1dc-76e0-11e9-8329-42010a8e0130,ResourceVersion:4307,Generation:0,CreationTimestamp:2019-05-15 07:09:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 15 07:10:03.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2m98z,SelfLink:/api/v1/namespaces/e2e-tests-watch-2m98z/configmaps/e2e-watch-test-configmap-b,UID:6fc6c1dc-76e0-11e9-8329-42010a8e0130,ResourceVersion:4307,Generation:0,CreationTimestamp:2019-05-15 07:09:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:10:13.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-2m98z" for this suite.
May 15 07:10:19.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:10:23.738: INFO: namespace: e2e-tests-watch-2m98z, resource: bindings, ignored listing per whitelist
May 15 07:10:23.928: INFO: namespace e2e-tests-watch-2m98z deletion completed in 10.505316191s

[32m [SLOW TEST:74.117 seconds][0m
[sig-api-machinery] Watchers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command that always fails in a pod[0m 
  [1mshould be possible to delete [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:10:23.928: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:10:26.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubelet-test-csvns" for this suite.
May 15 07:10:49.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:10:52.533: INFO: namespace: e2e-tests-kubelet-test-csvns, resource: bindings, ignored listing per whitelist
May 15 07:10:54.779: INFO: namespace e2e-tests-kubelet-test-csvns deletion completed in 28.083943367s

[32m [SLOW TEST:30.851 seconds][0m
[k8s.io] Kubelet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when scheduling a busybox command that always fails in a pod
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78[0m
    should be possible to delete [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop http hook properly [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:10:54.780: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: delete the pod with lifecycle hook
May 15 07:11:04.008: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:04.107: INFO: Pod pod-with-prestop-http-hook still exists
May 15 07:11:06.108: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:06.178: INFO: Pod pod-with-prestop-http-hook still exists
May 15 07:11:08.108: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:08.179: INFO: Pod pod-with-prestop-http-hook still exists
May 15 07:11:10.108: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:10.179: INFO: Pod pod-with-prestop-http-hook still exists
May 15 07:11:12.108: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:12.178: INFO: Pod pod-with-prestop-http-hook still exists
May 15 07:11:14.108: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:14.178: INFO: Pod pod-with-prestop-http-hook still exists
May 15 07:11:16.108: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:16.180: INFO: Pod pod-with-prestop-http-hook still exists
May 15 07:11:18.108: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 15 07:11:18.183: INFO: Pod pod-with-prestop-http-hook no longer exists
[1mSTEP[0m: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:11:18.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-zhmm4" for this suite.
May 15 07:11:40.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:11:43.711: INFO: namespace: e2e-tests-container-lifecycle-hook-zhmm4, resource: bindings, ignored listing per whitelist
May 15 07:11:45.382: INFO: namespace e2e-tests-container-lifecycle-hook-zhmm4 deletion completed in 27.010840714s

[32m [SLOW TEST:50.602 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute prestop http hook properly [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:11:45.382: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with configMap that has name projected-configmap-test-upd-b43ac840-76e0-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap projected-configmap-test-upd-b43ac840-76e0-11e9-9e56-3ac139a44f02
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:13:14.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-tzgxb" for this suite.
May 15 07:13:36.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:13:40.292: INFO: namespace: e2e-tests-projected-tzgxb, resource: bindings, ignored listing per whitelist
May 15 07:13:40.801: INFO: namespace e2e-tests-projected-tzgxb deletion completed in 26.620552623s

[32m [SLOW TEST:115.419 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:13:40.802: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename replicaset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 07:13:43.282: INFO: Creating ReplicaSet my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02
May 15 07:13:43.496: INFO: Pod name my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02: Found 1 pods out of 1
May 15 07:13:43.496: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02" is running
May 15 07:13:47.679: INFO: Pod "my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02-lw5sj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 07:13:43 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 07:13:43 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 07:13:43 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 07:13:43 +0000 UTC Reason: Message:}])
May 15 07:13:47.679: INFO: Trying to dial the pod
May 15 07:13:52.951: INFO: Controller my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02: Got expected result from replica 1 [my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02-lw5sj]: "my-hostname-basic-f8f148ef-76e0-11e9-9e56-3ac139a44f02-lw5sj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:13:52.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replicaset-k9lvk" for this suite.
May 15 07:13:59.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:13:59.760: INFO: namespace: e2e-tests-replicaset-k9lvk, resource: bindings, ignored listing per whitelist
May 15 07:14:03.771: INFO: namespace e2e-tests-replicaset-k9lvk deletion completed in 10.749232939s

[32m [SLOW TEST:22.970 seconds][0m
[sig-apps] ReplicaSet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should serve a basic image on each replica with a public image  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:14:03.772: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-06a968dd-76e1-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:14:06.522: INFO: Waiting up to 5m0s for pod "pod-secrets-06b907cd-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-fn48b" to be "success or failure"
May 15 07:14:06.630: INFO: Pod "pod-secrets-06b907cd-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 108.210286ms
May 15 07:14:08.700: INFO: Pod "pod-secrets-06b907cd-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.178366366s
[1mSTEP[0m: Saw pod success
May 15 07:14:08.700: INFO: Pod "pod-secrets-06b907cd-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:14:08.770: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-secrets-06b907cd-76e1-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:14:08.989: INFO: Waiting for pod pod-secrets-06b907cd-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:14:09.084: INFO: Pod pod-secrets-06b907cd-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:14:09.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-fn48b" for this suite.
May 15 07:14:15.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:14:19.362: INFO: namespace: e2e-tests-secrets-fn48b, resource: bindings, ignored listing per whitelist
May 15 07:14:23.398: INFO: namespace e2e-tests-secrets-fn48b deletion completed in 14.218107056s

[32m [SLOW TEST:19.626 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:14:23.398: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-upd-125d43f5-76e1-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap configmap-test-upd-125d43f5-76e1-11e9-9e56-3ac139a44f02
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:14:32.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-twd6c" for this suite.
May 15 07:14:57.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:15:01.117: INFO: namespace: e2e-tests-configmap-twd6c, resource: bindings, ignored listing per whitelist
May 15 07:15:03.189: INFO: namespace e2e-tests-configmap-twd6c deletion completed in 30.269789622s

[32m [SLOW TEST:39.791 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartNever pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:15:03.189: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
May 15 07:15:05.647: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:15:09.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-56rgt" for this suite.
May 15 07:15:15.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:15:18.738: INFO: namespace: e2e-tests-init-container-56rgt, resource: bindings, ignored listing per whitelist
May 15 07:15:20.368: INFO: namespace e2e-tests-init-container-56rgt deletion completed in 10.65973538s

[32m [SLOW TEST:17.179 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should invoke init containers on a RestartNever pod [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl cluster-info[0m 
  [1mshould check if Kubernetes master services is included in cluster-info  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:15:20.368: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: validating cluster-info
May 15 07:15:22.859: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 cluster-info'
May 15 07:15:23.718: INFO: stderr: ""
May 15 07:15:23.718: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://35.231.193.88\x1b[0m\n\x1b[0;32mGLBCDefaultBackend\x1b[0m is running at \x1b[0;33mhttps://35.231.193.88/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://35.231.193.88/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://35.231.193.88/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://35.231.193.88/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:15:23.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-q8pq7" for this suite.
May 15 07:15:30.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:15:32.371: INFO: namespace: e2e-tests-kubectl-q8pq7, resource: bindings, ignored listing per whitelist
May 15 07:15:34.125: INFO: namespace e2e-tests-kubectl-q8pq7 deletion completed in 10.331039813s

[32m [SLOW TEST:13.757 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl cluster-info
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:15:34.125: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0515 07:15:43.546241    1545 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 15 07:15:43.546: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:15:43.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-xc4kp" for this suite.
May 15 07:15:49.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:15:54.735: INFO: namespace: e2e-tests-gc-xc4kp, resource: bindings, ignored listing per whitelist
May 15 07:15:55.023: INFO: namespace e2e-tests-gc-xc4kp deletion completed in 11.406427364s

[32m [SLOW TEST:20.897 seconds][0m
[sig-api-machinery] Garbage collector
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl version[0m 
  [1mshould check is all data is printed  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:15:55.023: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 07:15:57.653: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 version'
May 15 07:15:58.031: INFO: stderr: ""
May 15 07:15:58.032: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13+\", GitVersion:\"v1.13.5-gke.10\", GitCommit:\"f5949b3427099d4e410ef96d6e0fea3cd4794e10\", GitTreeState:\"clean\", BuildDate:\"2019-04-10T19:06:57Z\", GoVersion:\"go1.11.5b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13+\", GitVersion:\"v1.13.5-gke.10\", GitCommit:\"f5949b3427099d4e410ef96d6e0fea3cd4794e10\", GitTreeState:\"clean\", BuildDate:\"2019-04-10T19:05:37Z\", GoVersion:\"go1.11.5b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:15:58.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-kwsch" for this suite.
May 15 07:16:04.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:16:05.826: INFO: namespace: e2e-tests-kubectl-kwsch, resource: bindings, ignored listing per whitelist
May 15 07:16:09.339: INFO: namespace e2e-tests-kubectl-kwsch deletion completed in 11.23640493s

[32m [SLOW TEST:14.316 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl version
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check is all data is printed  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould contain environment variables for services [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:16:09.339: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 07:16:15.631: INFO: Waiting up to 5m0s for pod "client-envvars-53b41e1c-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-pods-cdht8" to be "success or failure"
May 15 07:16:15.727: INFO: Pod "client-envvars-53b41e1c-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 95.721374ms
May 15 07:16:17.823: INFO: Pod "client-envvars-53b41e1c-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.191458498s
[1mSTEP[0m: Saw pod success
May 15 07:16:17.823: INFO: Pod "client-envvars-53b41e1c-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:16:17.894: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod client-envvars-53b41e1c-76e1-11e9-9e56-3ac139a44f02 container env3cont: <nil>
[1mSTEP[0m: delete the pod
May 15 07:16:18.199: INFO: Waiting for pod client-envvars-53b41e1c-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:16:18.305: INFO: Pod client-envvars-53b41e1c-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:16:18.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-cdht8" for this suite.
May 15 07:16:56.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:16:59.577: INFO: namespace: e2e-tests-pods-cdht8, resource: bindings, ignored listing per whitelist
May 15 07:17:01.501: INFO: namespace e2e-tests-pods-cdht8 deletion completed in 43.088380329s

[32m [SLOW TEST:52.162 seconds][0m
[k8s.io] Pods
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should contain environment variables for services [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:17:01.502: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-qbnw6
May 15 07:17:08.369: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qbnw6
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 15 07:17:08.440: INFO: Initial restart count of pod liveness-http is 0
May 15 07:17:25.078: INFO: Restart count of pod e2e-tests-container-probe-qbnw6/liveness-http is now 1 (16.638737269s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:17:25.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-qbnw6" for this suite.
May 15 07:17:31.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:17:34.215: INFO: namespace: e2e-tests-container-probe-qbnw6, resource: bindings, ignored listing per whitelist
May 15 07:17:37.265: INFO: namespace e2e-tests-container-probe-qbnw6 deletion completed in 11.997396314s

[32m [SLOW TEST:35.763 seconds][0m
[k8s.io] Probing container
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set DefaultMode on files [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:17:37.268: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:17:39.874: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85e574e4-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-b8j7p" to be "success or failure"
May 15 07:17:39.992: INFO: Pod "downwardapi-volume-85e574e4-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 118.156493ms
May 15 07:17:42.064: INFO: Pod "downwardapi-volume-85e574e4-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.189672014s
[1mSTEP[0m: Saw pod success
May 15 07:17:42.064: INFO: Pod "downwardapi-volume-85e574e4-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:17:42.134: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downwardapi-volume-85e574e4-76e1-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:17:42.346: INFO: Waiting for pod downwardapi-volume-85e574e4-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:17:42.466: INFO: Pod downwardapi-volume-85e574e4-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:17:42.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-b8j7p" for this suite.
May 15 07:17:48.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:17:52.784: INFO: namespace: e2e-tests-downward-api-b8j7p, resource: bindings, ignored listing per whitelist
May 15 07:17:53.814: INFO: namespace e2e-tests-downward-api-b8j7p deletion completed in 11.275959758s

[32m [SLOW TEST:16.546 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should set DefaultMode on files [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run rc[0m 
  [1mshould create an rc from an image  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:17:53.814: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
May 15 07:17:56.264: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nklm7'
May 15 07:17:57.854: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 15 07:17:57.854: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: verifying the pod controlled by rc e2e-test-nginx-rc was created
[1mSTEP[0m: confirm that you can get logs from an rc
May 15 07:17:58.376: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-mxvzg]
May 15 07:17:58.376: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-mxvzg" in namespace "e2e-tests-kubectl-nklm7" to be "running and ready"
May 15 07:17:58.473: INFO: Pod "e2e-test-nginx-rc-mxvzg": Phase="Pending", Reason="", readiness=false. Elapsed: 96.749502ms
May 15 07:18:00.543: INFO: Pod "e2e-test-nginx-rc-mxvzg": Phase="Running", Reason="", readiness=true. Elapsed: 2.16669161s
May 15 07:18:00.543: INFO: Pod "e2e-test-nginx-rc-mxvzg" satisfied condition "running and ready"
May 15 07:18:00.543: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-mxvzg]
May 15 07:18:00.543: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nklm7'
May 15 07:18:01.109: INFO: stderr: ""
May 15 07:18:01.109: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
May 15 07:18:01.109: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nklm7'
May 15 07:18:01.662: INFO: stderr: ""
May 15 07:18:01.662: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:18:01.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-nklm7" for this suite.
May 15 07:18:24.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:18:26.704: INFO: namespace: e2e-tests-kubectl-nklm7, resource: bindings, ignored listing per whitelist
May 15 07:18:28.004: INFO: namespace e2e-tests-kubectl-nklm7 deletion completed in 26.271105949s

[32m [SLOW TEST:34.190 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run rc
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create an rc from an image  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-node] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:18:28.004: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap e2e-tests-configmap-5vx6p/configmap-test-a422047a-76e1-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:18:30.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-a430d18e-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-5vx6p" to be "success or failure"
May 15 07:18:30.795: INFO: Pod "pod-configmaps-a430d18e-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 97.53696ms
May 15 07:18:32.869: INFO: Pod "pod-configmaps-a430d18e-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.17111814s
[1mSTEP[0m: Saw pod success
May 15 07:18:32.869: INFO: Pod "pod-configmaps-a430d18e-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:18:32.941: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-configmaps-a430d18e-76e1-11e9-9e56-3ac139a44f02 container env-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:18:33.611: INFO: Waiting for pod pod-configmaps-a430d18e-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:18:33.707: INFO: Pod pod-configmaps-a430d18e-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:18:33.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-5vx6p" for this suite.
May 15 07:18:40.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:18:41.519: INFO: namespace: e2e-tests-configmap-5vx6p, resource: bindings, ignored listing per whitelist
May 15 07:18:44.081: INFO: namespace e2e-tests-configmap-5vx6p deletion completed in 10.278446203s

[32m [SLOW TEST:16.078 seconds][0m
[sig-node] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31[0m
  should be consumable via the environment [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete pods created by rc when not orphaning [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:18:44.082: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for all pods to be garbage collected
[1mSTEP[0m: Gathering metrics
W0515 07:18:57.090664    1545 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 15 07:18:57.090: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:18:57.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-7bvpk" for this suite.
May 15 07:19:03.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:19:04.412: INFO: namespace: e2e-tests-gc-7bvpk, resource: bindings, ignored listing per whitelist
May 15 07:19:07.799: INFO: namespace e2e-tests-gc-7bvpk deletion completed in 10.638342114s

[32m [SLOW TEST:23.717 seconds][0m
[sig-api-machinery] Garbage collector
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should delete pods created by rc when not orphaning [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:19:07.799: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test override command
May 15 07:19:10.340: INFO: Waiting up to 5m0s for pod "client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-containers-kkv2n" to be "success or failure"
May 15 07:19:10.436: INFO: Pod "client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 96.445214ms
May 15 07:19:12.507: INFO: Pod "client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167059184s
May 15 07:19:14.577: INFO: Pod "client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.237316305s
[1mSTEP[0m: Saw pod success
May 15 07:19:14.577: INFO: Pod "client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:19:14.648: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:19:14.856: INFO: Waiting for pod client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:19:14.958: INFO: Pod client-containers-bbd2baaf-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:19:14.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-kkv2n" for this suite.
May 15 07:19:21.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:19:21.720: INFO: namespace: e2e-tests-containers-kkv2n, resource: bindings, ignored listing per whitelist
May 15 07:19:25.623: INFO: namespace e2e-tests-containers-kkv2n deletion completed in 10.594814443s

[32m [SLOW TEST:17.824 seconds][0m
[k8s.io] Docker Containers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:19:25.624: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-c6807902-76e1-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:19:28.364: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c6902b64-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-g57j7" to be "success or failure"
May 15 07:19:28.457: INFO: Pod "pod-projected-configmaps-c6902b64-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 93.051182ms
May 15 07:19:30.527: INFO: Pod "pod-projected-configmaps-c6902b64-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.163447312s
[1mSTEP[0m: Saw pod success
May 15 07:19:30.527: INFO: Pod "pod-projected-configmaps-c6902b64-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:19:30.597: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-projected-configmaps-c6902b64-76e1-11e9-9e56-3ac139a44f02 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:19:30.827: INFO: Waiting for pod pod-projected-configmaps-c6902b64-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:19:30.927: INFO: Pod pod-projected-configmaps-c6902b64-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:19:30.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-g57j7" for this suite.
May 15 07:19:37.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:19:37.616: INFO: namespace: e2e-tests-projected-g57j7, resource: bindings, ignored listing per whitelist
May 15 07:19:42.424: INFO: namespace e2e-tests-projected-g57j7 deletion completed in 11.424159577s

[32m [SLOW TEST:16.801 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0777,default) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:19:42.424: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
May 15 07:19:45.338: INFO: Waiting up to 5m0s for pod "pod-d07722da-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-vp949" to be "success or failure"
May 15 07:19:45.437: INFO: Pod "pod-d07722da-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 98.445535ms
May 15 07:19:47.507: INFO: Pod "pod-d07722da-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.169168808s
[1mSTEP[0m: Saw pod success
May 15 07:19:47.507: INFO: Pod "pod-d07722da-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:19:47.675: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-d07722da-76e1-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:19:47.906: INFO: Waiting for pod pod-d07722da-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:19:48.008: INFO: Pod pod-d07722da-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:19:48.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-vp949" for this suite.
May 15 07:19:54.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:19:55.027: INFO: namespace: e2e-tests-emptydir-vp949, resource: bindings, ignored listing per whitelist
May 15 07:19:58.720: INFO: namespace e2e-tests-emptydir-vp949 deletion completed in 10.640250038s

[32m [SLOW TEST:16.296 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:19:58.720: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-da2e6d9f-76e1-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:20:01.400: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-da3d5eb4-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-pnff9" to be "success or failure"
May 15 07:20:01.498: INFO: Pod "pod-projected-secrets-da3d5eb4-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 97.69248ms
May 15 07:20:03.568: INFO: Pod "pod-projected-secrets-da3d5eb4-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.167834565s
[1mSTEP[0m: Saw pod success
May 15 07:20:03.568: INFO: Pod "pod-projected-secrets-da3d5eb4-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:20:03.638: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-projected-secrets-da3d5eb4-76e1-11e9-9e56-3ac139a44f02 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:20:03.858: INFO: Waiting for pod pod-projected-secrets-da3d5eb4-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:20:03.958: INFO: Pod pod-projected-secrets-da3d5eb4-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:20:03.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-pnff9" for this suite.
May 15 07:20:10.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:20:14.699: INFO: namespace: e2e-tests-projected-pnff9, resource: bindings, ignored listing per whitelist
May 15 07:20:14.907: INFO: namespace e2e-tests-projected-pnff9 deletion completed in 10.878221352s

[32m [SLOW TEST:16.187 seconds][0m
[sig-storage] Projected secret
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34[0m
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable from pods in env vars [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:20:14.907: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-e3e882bc-76e1-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:20:17.766: INFO: Waiting up to 5m0s for pod "pod-secrets-e4001b13-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-hgmgw" to be "success or failure"
May 15 07:20:17.865: INFO: Pod "pod-secrets-e4001b13-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 99.276378ms
May 15 07:20:19.936: INFO: Pod "pod-secrets-e4001b13-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.170486787s
[1mSTEP[0m: Saw pod success
May 15 07:20:19.936: INFO: Pod "pod-secrets-e4001b13-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:20:20.006: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-secrets-e4001b13-76e1-11e9-9e56-3ac139a44f02 container secret-env-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:20:20.219: INFO: Waiting for pod pod-secrets-e4001b13-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:20:20.314: INFO: Pod pod-secrets-e4001b13-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:20:20.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-hgmgw" for this suite.
May 15 07:20:26.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:20:30.757: INFO: namespace: e2e-tests-secrets-hgmgw, resource: bindings, ignored listing per whitelist
May 15 07:20:30.860: INFO: namespace e2e-tests-secrets-hgmgw deletion completed in 10.436759801s

[32m [SLOW TEST:15.953 seconds][0m
[sig-api-machinery] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32[0m
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:20:30.860: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:20:33.750: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-rkktw" to be "success or failure"
May 15 07:20:33.848: INFO: Pod "downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 97.914528ms
May 15 07:20:35.919: INFO: Pod "downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.169552377s
May 15 07:20:37.990: INFO: Pod "downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.23976017s
[1mSTEP[0m: Saw pod success
May 15 07:20:37.990: INFO: Pod "downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:20:38.060: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:20:38.295: INFO: Waiting for pod downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02 to disappear
May 15 07:20:38.411: INFO: Pod downwardapi-volume-ed825213-76e1-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:20:38.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-rkktw" for this suite.
May 15 07:20:44.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:20:46.119: INFO: namespace: e2e-tests-downward-api-rkktw, resource: bindings, ignored listing per whitelist
May 15 07:20:48.608: INFO: namespace e2e-tests-downward-api-rkktw deletion completed in 10.126100495s

[32m [SLOW TEST:17.748 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's cpu request [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: http [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:20:48.608: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-ktkgq
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 15 07:20:51.168: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
May 15 07:21:12.888: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.0.15:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ktkgq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:21:12.888: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:21:14.354: INFO: Found all expected endpoints: [netserver-0]
May 15 07:21:14.424: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.2.33:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ktkgq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:21:14.424: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:21:15.064: INFO: Found all expected endpoints: [netserver-1]
May 15 07:21:15.134: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.1.41:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ktkgq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:21:15.134: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:21:16.749: INFO: Failed to execute "curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.1.41:8080/hostName | grep -v '^\\s*$'": command terminated with exit code 1, stdout: "", stderr: ""
May 15 07:21:16.749: INFO: Waiting for [netserver-2] endpoints (expected=[netserver-2], actual=[])
May 15 07:21:18.821: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.1.41:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ktkgq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:21:18.821: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:21:20.923: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:21:20.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-ktkgq" for this suite.
May 15 07:21:43.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:21:44.623: INFO: namespace: e2e-tests-pod-network-test-ktkgq, resource: bindings, ignored listing per whitelist
May 15 07:21:47.508: INFO: namespace e2e-tests-pod-network-test-ktkgq deletion completed in 26.512877047s

[32m [SLOW TEST:58.899 seconds][0m
[sig-network] Networking
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for node-pod communication: http [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould support retrieving logs from the container over websockets [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:21:47.508: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 07:21:50.099: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:21:52.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-42pdq" for this suite.
May 15 07:22:31.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:22:34.096: INFO: namespace: e2e-tests-pods-42pdq, resource: bindings, ignored listing per whitelist
May 15 07:22:35.585: INFO: namespace e2e-tests-pods-42pdq deletion completed in 42.756798544s

[32m [SLOW TEST:48.077 seconds][0m
[k8s.io] Pods
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen starting a container that exits[0m 
  [1mshould run with the expected status [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Runtime
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:22:35.585: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:23:02.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-runtime-fvtk6" for this suite.
May 15 07:23:08.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:23:10.083: INFO: namespace: e2e-tests-container-runtime-fvtk6, resource: bindings, ignored listing per whitelist
May 15 07:23:12.968: INFO: namespace e2e-tests-container-runtime-fvtk6 deletion completed in 10.855066202s

[32m [SLOW TEST:37.382 seconds][0m
[k8s.io] Container Runtime
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  blackbox test
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37[0m
    when starting a container that exits
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38[0m
      should run with the expected status [NodeConformance] [Conformance]
      [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould allow opting out of API token automount  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:23:12.968: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: getting the auto-created API token
May 15 07:23:16.443: INFO: created pod pod-service-account-defaultsa
May 15 07:23:16.443: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 15 07:23:16.533: INFO: created pod pod-service-account-mountsa
May 15 07:23:16.533: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 15 07:23:16.610: INFO: created pod pod-service-account-nomountsa
May 15 07:23:16.610: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 15 07:23:16.688: INFO: created pod pod-service-account-defaultsa-mountspec
May 15 07:23:16.688: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 15 07:23:16.766: INFO: created pod pod-service-account-mountsa-mountspec
May 15 07:23:16.766: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 15 07:23:16.845: INFO: created pod pod-service-account-nomountsa-mountspec
May 15 07:23:16.845: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 15 07:23:16.929: INFO: created pod pod-service-account-defaultsa-nomountspec
May 15 07:23:16.929: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 15 07:23:17.010: INFO: created pod pod-service-account-mountsa-nomountspec
May 15 07:23:17.010: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 15 07:23:17.088: INFO: created pod pod-service-account-nomountsa-nomountspec
May 15 07:23:17.088: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:23:17.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svcaccounts-vrkqf" for this suite.
May 15 07:23:23.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:23:25.614: INFO: namespace: e2e-tests-svcaccounts-vrkqf, resource: bindings, ignored listing per whitelist
May 15 07:23:29.015: INFO: namespace e2e-tests-svcaccounts-vrkqf deletion completed in 11.856578668s

[32m [SLOW TEST:16.048 seconds][0m
[sig-auth] ServiceAccounts
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22[0m
  should allow opting out of API token automount  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:23:29.017: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-5790280f-76e2-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:23:31.741: INFO: Waiting up to 5m0s for pod "pod-configmaps-579fc46c-76e2-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-5m5sm" to be "success or failure"
May 15 07:23:31.844: INFO: Pod "pod-configmaps-579fc46c-76e2-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 102.357585ms
May 15 07:23:33.914: INFO: Pod "pod-configmaps-579fc46c-76e2-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.172882326s
[1mSTEP[0m: Saw pod success
May 15 07:23:33.914: INFO: Pod "pod-configmaps-579fc46c-76e2-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:23:33.984: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-configmaps-579fc46c-76e2-11e9-9e56-3ac139a44f02 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:23:34.220: INFO: Waiting for pod pod-configmaps-579fc46c-76e2-11e9-9e56-3ac139a44f02 to disappear
May 15 07:23:34.315: INFO: Pod pod-configmaps-579fc46c-76e2-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:23:34.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-5m5sm" for this suite.
May 15 07:23:40.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:23:44.312: INFO: namespace: e2e-tests-configmap-5m5sm, resource: bindings, ignored listing per whitelist
May 15 07:23:44.968: INFO: namespace e2e-tests-configmap-5m5sm deletion completed in 10.583730373s

[32m [SLOW TEST:15.952 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for services  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] DNS
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:23:44.971: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a test headless service
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-545xd;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-545xd;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-545xd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-545xd.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-545xd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 104.246.11.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.11.246.104_udp@PTR;check="$$(dig +tcp +noall +answer +search 104.246.11.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.11.246.104_tcp@PTR;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-545xd;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-545xd;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-545xd.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-545xd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-545xd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-545xd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-545xd.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-545xd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 104.246.11.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.11.246.104_udp@PTR;check="$$(dig +tcp +noall +answer +search 104.246.11.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.11.246.104_tcp@PTR;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
May 15 07:24:02.133: INFO: DNS probes using e2e-tests-dns-545xd/dns-test-612d0604-76e2-11e9-9e56-3ac139a44f02 succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: deleting the test service
[1mSTEP[0m: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:24:02.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-dns-545xd" for this suite.
May 15 07:24:08.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:24:10.505: INFO: namespace: e2e-tests-dns-545xd, resource: bindings, ignored listing per whitelist
May 15 07:24:13.234: INFO: namespace e2e-tests-dns-545xd deletion completed in 10.565405606s

[32m [SLOW TEST:28.263 seconds][0m
[sig-network] DNS
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide DNS for services  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:24:13.234: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
May 15 07:24:21.765: INFO: Successfully updated pod "annotationupdate71e46494-76e2-11e9-9e56-3ac139a44f02"
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:24:23.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-79lqz" for this suite.
May 15 07:24:44.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:24:47.114: INFO: namespace: e2e-tests-downward-api-79lqz, resource: bindings, ignored listing per whitelist
May 15 07:24:48.375: INFO: namespace e2e-tests-downward-api-79lqz deletion completed in 24.38541497s

[32m [SLOW TEST:35.141 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should update annotations on modification [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support --unix-socket=/path  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:24:48.375: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Starting the proxy
May 15 07:24:50.999: INFO: Asynchronously running '/workspace/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 proxy --unix-socket=/tmp/kubectl-proxy-unix657818882/test'
[1mSTEP[0m: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:24:51.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-q2k67" for this suite.
May 15 07:24:57.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:24:58.643: INFO: namespace: e2e-tests-kubectl-q2k67, resource: bindings, ignored listing per whitelist
May 15 07:25:01.776: INFO: namespace e2e-tests-kubectl-q2k67 deletion completed in 10.509032737s

[32m [SLOW TEST:13.400 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Proxy server
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should support --unix-socket=/path  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command and arguments [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:25:01.776: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test override all
May 15 07:25:04.485: INFO: Waiting up to 5m0s for pod "client-containers-8ee4daef-76e2-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-containers-smnq9" to be "success or failure"
May 15 07:25:04.609: INFO: Pod "client-containers-8ee4daef-76e2-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 123.340338ms
May 15 07:25:06.678: INFO: Pod "client-containers-8ee4daef-76e2-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.19301259s
[1mSTEP[0m: Saw pod success
May 15 07:25:06.679: INFO: Pod "client-containers-8ee4daef-76e2-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:25:06.749: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod client-containers-8ee4daef-76e2-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:25:06.955: INFO: Waiting for pod client-containers-8ee4daef-76e2-11e9-9e56-3ac139a44f02 to disappear
May 15 07:25:07.060: INFO: Pod client-containers-8ee4daef-76e2-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:25:07.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-smnq9" for this suite.
May 15 07:25:13.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:25:14.216: INFO: namespace: e2e-tests-containers-smnq9, resource: bindings, ignored listing per whitelist
May 15 07:25:19.411: INFO: namespace e2e-tests-containers-smnq9 deletion completed in 12.28023249s

[32m [SLOW TEST:17.635 seconds][0m
[k8s.io] Docker Containers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: udp [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:25:19.411: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-5tl7d
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 15 07:25:22.355: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
May 15 07:25:46.061: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.8.2.41 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5tl7d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:25:46.061: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:25:47.716: INFO: Found all expected endpoints: [netserver-0]
May 15 07:25:47.791: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.8.1.53 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5tl7d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:25:47.791: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:25:49.412: INFO: Found all expected endpoints: [netserver-1]
May 15 07:25:49.481: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.8.0.17 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5tl7d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:25:49.481: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:25:51.095: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:25:51.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-5tl7d" for this suite.
May 15 07:26:13.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:26:15.403: INFO: namespace: e2e-tests-pod-network-test-5tl7d, resource: bindings, ignored listing per whitelist
May 15 07:26:17.777: INFO: namespace e2e-tests-pod-network-test-5tl7d deletion completed in 26.611089381s

[32m [SLOW TEST:58.366 seconds][0m
[sig-network] Networking
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould set mode on item file [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:26:17.777: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:26:20.325: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc1c55e9-76e2-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-fzk9d" to be "success or failure"
May 15 07:26:20.426: INFO: Pod "downwardapi-volume-bc1c55e9-76e2-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 101.326979ms
May 15 07:26:22.496: INFO: Pod "downwardapi-volume-bc1c55e9-76e2-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.171414649s
[1mSTEP[0m: Saw pod success
May 15 07:26:22.496: INFO: Pod "downwardapi-volume-bc1c55e9-76e2-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:26:22.566: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downwardapi-volume-bc1c55e9-76e2-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:26:22.778: INFO: Waiting for pod downwardapi-volume-bc1c55e9-76e2-11e9-9e56-3ac139a44f02 to disappear
May 15 07:26:22.881: INFO: Pod downwardapi-volume-bc1c55e9-76e2-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:26:22.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-fzk9d" for this suite.
May 15 07:26:29.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:26:33.668: INFO: namespace: e2e-tests-downward-api-fzk9d, resource: bindings, ignored listing per whitelist
May 15 07:26:34.769: INFO: namespace e2e-tests-downward-api-fzk9d deletion completed in 11.81793861s

[32m [SLOW TEST:16.992 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should set mode on item file [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:26:34.770: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:26:37.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c645ec73-76e2-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-s58fw" to be "success or failure"
May 15 07:26:37.500: INFO: Pod "downwardapi-volume-c645ec73-76e2-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 96.428495ms
May 15 07:26:39.570: INFO: Pod "downwardapi-volume-c645ec73-76e2-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.166960975s
[1mSTEP[0m: Saw pod success
May 15 07:26:39.570: INFO: Pod "downwardapi-volume-c645ec73-76e2-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:26:39.640: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-c645ec73-76e2-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:26:39.900: INFO: Waiting for pod downwardapi-volume-c645ec73-76e2-11e9-9e56-3ac139a44f02 to disappear
May 15 07:26:39.994: INFO: Pod downwardapi-volume-c645ec73-76e2-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:26:39.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-s58fw" for this suite.
May 15 07:26:46.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:26:50.200: INFO: namespace: e2e-tests-downward-api-s58fw, resource: bindings, ignored listing per whitelist
May 15 07:26:51.283: INFO: namespace e2e-tests-downward-api-s58fw deletion completed in 11.193244471s

[32m [SLOW TEST:16.513 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's memory request [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:26:51.283: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-d0209003-76e2-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:26:54.470: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d07647a5-76e2-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-gtnhx" to be "success or failure"
May 15 07:26:55.051: INFO: Pod "pod-projected-secrets-d07647a5-76e2-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 580.939391ms
May 15 07:26:57.121: INFO: Pod "pod-projected-secrets-d07647a5-76e2-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.651002335s
[1mSTEP[0m: Saw pod success
May 15 07:26:57.121: INFO: Pod "pod-projected-secrets-d07647a5-76e2-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:26:57.191: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-projected-secrets-d07647a5-76e2-11e9-9e56-3ac139a44f02 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:26:57.443: INFO: Waiting for pod pod-projected-secrets-d07647a5-76e2-11e9-9e56-3ac139a44f02 to disappear
May 15 07:26:57.592: INFO: Pod pod-projected-secrets-d07647a5-76e2-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:26:57.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-gtnhx" for this suite.
May 15 07:27:03.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:27:08.045: INFO: namespace: e2e-tests-projected-gtnhx, resource: bindings, ignored listing per whitelist
May 15 07:27:08.233: INFO: namespace e2e-tests-projected-gtnhx deletion completed in 10.570516009s

[32m [SLOW TEST:16.950 seconds][0m
[sig-storage] Projected secret
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if matching  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:27:08.234: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 15 07:27:10.672: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 15 07:27:10.820: INFO: Waiting for terminating namespaces to be deleted...
May 15 07:27:10.919: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz before test
May 15 07:27:11.232: INFO: event-exporter-v0.2.3-f67d895d8-8gtbv from kube-system started at 2019-05-15 06:54:58 +0000 UTC (2 container statuses recorded)
May 15 07:27:11.232: INFO: 	Container event-exporter ready: true, restart count 0
May 15 07:27:11.232: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:27:11.232: INFO: prometheus-to-sd-gfglj from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:27:11.232: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:27:11.232: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz from kube-system started at <nil> (0 container statuses recorded)
May 15 07:27:11.232: INFO: fluentd-gcp-v3.2.0-mmn4z from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 07:27:11.232: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 07:27:11.232: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:27:11.232: INFO: l7-default-backend-fd59995cd-qmgxp from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:27:11.232: INFO: 	Container default-http-backend ready: true, restart count 0
May 15 07:27:11.232: INFO: kube-dns-6987857fdb-hs77r from kube-system started at 2019-05-15 06:54:58 +0000 UTC (4 container statuses recorded)
May 15 07:27:11.232: INFO: 	Container dnsmasq ready: true, restart count 0
May 15 07:27:11.232: INFO: 	Container kubedns ready: true, restart count 0
May 15 07:27:11.232: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:27:11.232: INFO: 	Container sidecar ready: true, restart count 0
May 15 07:27:11.232: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r before test
May 15 07:27:11.330: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r from kube-system started at <nil> (0 container statuses recorded)
May 15 07:27:11.331: INFO: fluentd-gcp-scaler-68b55c6dc5-596nw from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:27:11.331: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 15 07:27:11.331: INFO: fluentd-gcp-v3.2.0-ngtmk from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 07:27:11.331: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 07:27:11.331: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:27:11.331: INFO: metrics-server-v0.3.1-65cd4f6fd8-4f249 from kube-system started at 2019-05-15 06:55:12 +0000 UTC (2 container statuses recorded)
May 15 07:27:11.331: INFO: 	Container metrics-server ready: true, restart count 0
May 15 07:27:11.331: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 15 07:27:11.331: INFO: prometheus-to-sd-b572x from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:27:11.331: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:27:11.331: INFO: kube-dns-autoscaler-bb58c6784-j4zhb from kube-system started at 2019-05-15 06:55:12 +0000 UTC (1 container statuses recorded)
May 15 07:27:11.331: INFO: 	Container autoscaler ready: true, restart count 0
May 15 07:27:11.331: INFO: heapster-v1.6.0-beta.1-798666ff5c-74dbk from kube-system started at 2019-05-15 06:55:12 +0000 UTC (3 container statuses recorded)
May 15 07:27:11.331: INFO: 	Container heapster ready: true, restart count 0
May 15 07:27:11.331: INFO: 	Container heapster-nanny ready: true, restart count 0
May 15 07:27:11.331: INFO: 	Container prom-to-sd ready: true, restart count 0
May 15 07:27:11.331: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx before test
May 15 07:27:11.427: INFO: fluentd-gcp-v3.2.0-ljmkc from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 07:27:11.427: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 07:27:11.427: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:27:11.427: INFO: prometheus-to-sd-fzxr4 from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:27:11.427: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:27:11.427: INFO: kube-dns-6987857fdb-g4phv from kube-system started at 2019-05-15 06:55:17 +0000 UTC (4 container statuses recorded)
May 15 07:27:11.427: INFO: 	Container dnsmasq ready: true, restart count 0
May 15 07:27:11.427: INFO: 	Container kubedns ready: true, restart count 0
May 15 07:27:11.427: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:27:11.427: INFO: 	Container sidecar ready: true, restart count 0
May 15 07:27:11.427: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Trying to launch a pod without a label to get a node which can launch it.
[1mSTEP[0m: Explicitly delete pod here to free the resource it takes.
[1mSTEP[0m: Trying to apply a random label on the found node.
[1mSTEP[0m: verifying the node has the label kubernetes.io/e2e-dc199f9f-76e2-11e9-9e56-3ac139a44f02 42
[1mSTEP[0m: Trying to relaunch the pod, now with labels.
[1mSTEP[0m: removing the label kubernetes.io/e2e-dc199f9f-76e2-11e9-9e56-3ac139a44f02 off the node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
[1mSTEP[0m: verifying the node doesn't have the label kubernetes.io/e2e-dc199f9f-76e2-11e9-9e56-3ac139a44f02
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:27:16.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-qj4cp" for this suite.
May 15 07:27:24.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:27:29.335: INFO: namespace: e2e-tests-sched-pred-qj4cp, resource: bindings, ignored listing per whitelist
May 15 07:27:29.335: INFO: namespace e2e-tests-sched-pred-qj4cp deletion completed in 12.613258163s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

[32m [SLOW TEST:21.102 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates that NodeSelector is respected if matching  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with configmap pod with mountPath of existing file [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:27:29.336: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-configmap-tvtf
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
May 15 07:27:32.381: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tvtf" in namespace "e2e-tests-subpath-58f65" to be "success or failure"
May 15 07:27:32.509: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Pending", Reason="", readiness=false. Elapsed: 128.33471ms
May 15 07:27:34.674: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.292741127s
May 15 07:27:36.744: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 4.36322104s
May 15 07:27:38.815: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 6.433776516s
May 15 07:27:40.885: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 8.504133916s
May 15 07:27:42.956: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 10.574538888s
May 15 07:27:45.026: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 12.645266834s
May 15 07:27:47.097: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 14.715648874s
May 15 07:27:49.167: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 16.785922698s
May 15 07:27:51.237: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 18.85624904s
May 15 07:27:53.309: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Running", Reason="", readiness=false. Elapsed: 20.928332445s
May 15 07:27:55.380: INFO: Pod "pod-subpath-test-configmap-tvtf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.999382619s
[1mSTEP[0m: Saw pod success
May 15 07:27:55.381: INFO: Pod "pod-subpath-test-configmap-tvtf" satisfied condition "success or failure"
May 15 07:27:55.451: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-subpath-test-configmap-tvtf container test-container-subpath-configmap-tvtf: <nil>
[1mSTEP[0m: delete the pod
May 15 07:27:55.686: INFO: Waiting for pod pod-subpath-test-configmap-tvtf to disappear
May 15 07:27:55.793: INFO: Pod pod-subpath-test-configmap-tvtf no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-configmap-tvtf
May 15 07:27:55.793: INFO: Deleting pod "pod-subpath-test-configmap-tvtf" in namespace "e2e-tests-subpath-58f65"
[AfterEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:27:55.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-58f65" for this suite.
May 15 07:28:02.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:28:03.410: INFO: namespace: e2e-tests-subpath-58f65, resource: bindings, ignored listing per whitelist
May 15 07:28:06.766: INFO: namespace e2e-tests-subpath-58f65 deletion completed in 10.832598349s

[32m [SLOW TEST:37.430 seconds][0m
[sig-storage] Subpath
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support proxy with --port 0  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:28:06.766: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: starting the proxy server
May 15 07:28:09.209: INFO: Asynchronously running '/workspace/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 proxy -p 0 --disable-filter'
[1mSTEP[0m: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:28:09.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-mqcnp" for this suite.
May 15 07:28:15.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:28:16.704: INFO: namespace: e2e-tests-kubectl-mqcnp, resource: bindings, ignored listing per whitelist
May 15 07:28:20.449: INFO: namespace e2e-tests-kubectl-mqcnp deletion completed in 10.809016934s

[32m [SLOW TEST:13.683 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Proxy server
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should support proxy with --port 0  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,default) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:28:20.449: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
May 15 07:28:23.098: INFO: Waiting up to 5m0s for pod "pod-0543b9b7-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-vpt26" to be "success or failure"
May 15 07:28:23.193: INFO: Pod "pod-0543b9b7-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 95.069823ms
May 15 07:28:25.263: INFO: Pod "pod-0543b9b7-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.165130263s
[1mSTEP[0m: Saw pod success
May 15 07:28:25.263: INFO: Pod "pod-0543b9b7-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:28:25.333: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-0543b9b7-76e3-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:28:25.589: INFO: Waiting for pod pod-0543b9b7-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:28:25.708: INFO: Pod pod-0543b9b7-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:28:25.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-vpt26" for this suite.
May 15 07:28:32.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:28:33.697: INFO: namespace: e2e-tests-emptydir-vpt26, resource: bindings, ignored listing per whitelist
May 15 07:28:36.093: INFO: namespace e2e-tests-emptydir-vpt26 deletion completed in 10.314835214s

[32m [SLOW TEST:15.644 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl logs[0m 
  [1mshould be able to retrieve and filter logs  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:28:36.094: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
[1mSTEP[0m: creating an rc
May 15 07:28:38.548: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-psdfk'
May 15 07:28:41.644: INFO: stderr: ""
May 15 07:28:41.644: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Waiting for Redis master to start.
May 15 07:28:42.742: INFO: Selector matched 1 pods for map[app:redis]
May 15 07:28:42.742: INFO: Found 0 / 1
May 15 07:28:43.715: INFO: Selector matched 1 pods for map[app:redis]
May 15 07:28:43.715: INFO: Found 1 / 1
May 15 07:28:43.715: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 15 07:28:43.792: INFO: Selector matched 1 pods for map[app:redis]
May 15 07:28:43.792: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[1mSTEP[0m: checking for a matching strings
May 15 07:28:43.792: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 logs redis-master-cvq5c redis-master --namespace=e2e-tests-kubectl-psdfk'
May 15 07:28:44.340: INFO: stderr: ""
May 15 07:28:44.340: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 May 07:28:43.134 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 May 07:28:43.134 # Server started, Redis version 3.2.12\n1:M 15 May 07:28:43.134 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 May 07:28:43.134 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log lines
May 15 07:28:44.341: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 log redis-master-cvq5c redis-master --namespace=e2e-tests-kubectl-psdfk --tail=1'
May 15 07:28:44.805: INFO: stderr: ""
May 15 07:28:44.805: INFO: stdout: "1:M 15 May 07:28:43.134 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log bytes
May 15 07:28:44.805: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 log redis-master-cvq5c redis-master --namespace=e2e-tests-kubectl-psdfk --limit-bytes=1'
May 15 07:28:45.275: INFO: stderr: ""
May 15 07:28:45.275: INFO: stdout: " "
[1mSTEP[0m: exposing timestamps
May 15 07:28:45.276: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 log redis-master-cvq5c redis-master --namespace=e2e-tests-kubectl-psdfk --tail=1 --timestamps'
May 15 07:28:45.859: INFO: stderr: ""
May 15 07:28:45.859: INFO: stdout: "2019-05-15T07:28:43.134605207Z 1:M 15 May 07:28:43.134 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: restricting to a time range
May 15 07:28:48.359: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 log redis-master-cvq5c redis-master --namespace=e2e-tests-kubectl-psdfk --since=1s'
May 15 07:28:48.818: INFO: stderr: ""
May 15 07:28:48.818: INFO: stdout: ""
May 15 07:28:48.818: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 log redis-master-cvq5c redis-master --namespace=e2e-tests-kubectl-psdfk --since=24h'
May 15 07:28:49.276: INFO: stderr: ""
May 15 07:28:49.276: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 May 07:28:43.134 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 May 07:28:43.134 # Server started, Redis version 3.2.12\n1:M 15 May 07:28:43.134 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 May 07:28:43.134 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
[1mSTEP[0m: using delete to clean up resources
May 15 07:28:49.276: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-psdfk'
May 15 07:28:49.788: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 07:28:49.788: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 15 07:28:49.788: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-psdfk'
May 15 07:28:50.303: INFO: stderr: "No resources found.\n"
May 15 07:28:50.303: INFO: stdout: ""
May 15 07:28:50.303: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -l name=nginx --namespace=e2e-tests-kubectl-psdfk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 15 07:28:50.703: INFO: stderr: ""
May 15 07:28:50.703: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:28:50.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-psdfk" for this suite.
May 15 07:29:13.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:29:15.141: INFO: namespace: e2e-tests-kubectl-psdfk, resource: bindings, ignored listing per whitelist
May 15 07:29:19.038: INFO: namespace e2e-tests-kubectl-psdfk deletion completed in 28.233744135s

[32m [SLOW TEST:42.945 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl logs
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should be able to retrieve and filter logs  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:29:19.038: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-28a449cc-76e3-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:29:22.529: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-28b4cf8a-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-bs4pw" to be "success or failure"
May 15 07:29:22.625: INFO: Pod "pod-projected-configmaps-28b4cf8a-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 96.026837ms
May 15 07:29:24.697: INFO: Pod "pod-projected-configmaps-28b4cf8a-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.167721286s
[1mSTEP[0m: Saw pod success
May 15 07:29:24.697: INFO: Pod "pod-projected-configmaps-28b4cf8a-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:29:24.767: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-configmaps-28b4cf8a-76e3-11e9-9e56-3ac139a44f02 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:29:25.006: INFO: Waiting for pod pod-projected-configmaps-28b4cf8a-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:29:25.107: INFO: Pod pod-projected-configmaps-28b4cf8a-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:29:25.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-bs4pw" for this suite.
May 15 07:29:31.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:29:32.011: INFO: namespace: e2e-tests-projected-bs4pw, resource: bindings, ignored listing per whitelist
May 15 07:29:35.614: INFO: namespace e2e-tests-projected-bs4pw deletion completed in 10.427672056s

[32m [SLOW TEST:16.575 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl api-versions[0m 
  [1mshould check if v1 is in available api versions  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:29:35.614: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: validating api versions
May 15 07:29:38.104: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 api-versions'
May 15 07:29:38.551: INFO: stderr: ""
May 15 07:29:38.551: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncloud.google.com/v1beta1\ncoordination.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.gke.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscalingpolicy.kope.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:29:38.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-nzbtp" for this suite.
May 15 07:29:44.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:29:45.705: INFO: namespace: e2e-tests-kubectl-nzbtp, resource: bindings, ignored listing per whitelist
May 15 07:29:49.989: INFO: namespace e2e-tests-kubectl-nzbtp deletion completed in 11.368156842s

[32m [SLOW TEST:14.376 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl api-versions
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check if v1 is in available api versions  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:29:49.990: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-3a9bb61b-76e3-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:29:52.952: INFO: Waiting up to 5m0s for pod "pod-secrets-3ad4bd94-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-7kgf2" to be "success or failure"
May 15 07:29:53.043: INFO: Pod "pod-secrets-3ad4bd94-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 91.410033ms
May 15 07:29:55.114: INFO: Pod "pod-secrets-3ad4bd94-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.161985348s
[1mSTEP[0m: Saw pod success
May 15 07:29:55.114: INFO: Pod "pod-secrets-3ad4bd94-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:29:55.185: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-secrets-3ad4bd94-76e3-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:29:55.403: INFO: Waiting for pod pod-secrets-3ad4bd94-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:29:55.503: INFO: Pod pod-secrets-3ad4bd94-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:29:55.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-7kgf2" for this suite.
May 15 07:30:01.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:30:05.709: INFO: namespace: e2e-tests-secrets-7kgf2, resource: bindings, ignored listing per whitelist
May 15 07:30:05.934: INFO: namespace e2e-tests-secrets-7kgf2 deletion completed in 10.360464532s
[1mSTEP[0m: Destroying namespace "e2e-tests-secret-namespace-jxj64" for this suite.
May 15 07:30:12.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:30:16.310: INFO: namespace: e2e-tests-secret-namespace-jxj64, resource: bindings, ignored listing per whitelist
May 15 07:30:17.801: INFO: namespace e2e-tests-secret-namespace-jxj64 deletion completed in 11.867094139s

[32m [SLOW TEST:27.811 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould adopt matching pods on creation and release no longer matching pods [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:30:17.801: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename replicaset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Given a Pod with a 'name' label pod-adoption-release is created
[1mSTEP[0m: When a replicaset with a matching selector is created
[1mSTEP[0m: Then the orphan pod is adopted
[1mSTEP[0m: When the matched label of one of its pods change
May 15 07:30:26.892: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
[1mSTEP[0m: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:30:27.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replicaset-j5qj8" for this suite.
May 15 07:30:49.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:30:52.313: INFO: namespace: e2e-tests-replicaset-j5qj8, resource: bindings, ignored listing per whitelist
May 15 07:30:53.811: INFO: namespace e2e-tests-replicaset-j5qj8 deletion completed in 26.599794831s

[32m [SLOW TEST:36.010 seconds][0m
[sig-apps] ReplicaSet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,tmpfs) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:30:53.811: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
May 15 07:30:56.445: INFO: Waiting up to 5m0s for pod "pod-60aebc19-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-hkzdf" to be "success or failure"
May 15 07:30:56.547: INFO: Pod "pod-60aebc19-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 101.371541ms
May 15 07:30:58.621: INFO: Pod "pod-60aebc19-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.175631797s
[1mSTEP[0m: Saw pod success
May 15 07:30:58.621: INFO: Pod "pod-60aebc19-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:30:58.691: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-60aebc19-76e3-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:30:58.937: INFO: Waiting for pod pod-60aebc19-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:30:59.036: INFO: Pod pod-60aebc19-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:30:59.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-hkzdf" for this suite.
May 15 07:31:05.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:31:08.327: INFO: namespace: e2e-tests-emptydir-hkzdf, resource: bindings, ignored listing per whitelist
May 15 07:31:09.809: INFO: namespace e2e-tests-emptydir-hkzdf deletion completed in 10.67806154s

[32m [SLOW TEST:15.998 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mbinary data should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:31:09.809: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-upd-6a49011e-76e3-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Waiting for pod with text data
[1mSTEP[0m: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:31:15.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-gd7kk" for this suite.
May 15 07:31:37.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:31:38.635: INFO: namespace: e2e-tests-configmap-gd7kk, resource: bindings, ignored listing per whitelist
May 15 07:31:41.398: INFO: namespace e2e-tests-configmap-gd7kk deletion completed in 26.268645095s

[32m [SLOW TEST:31.590 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  binary data should be reflected in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's args [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:31:41.399: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test substitution in container's args
May 15 07:31:44.114: INFO: Waiting up to 5m0s for pod "var-expansion-7d140b29-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-var-expansion-d4ks4" to be "success or failure"
May 15 07:31:44.228: INFO: Pod "var-expansion-7d140b29-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 113.988619ms
May 15 07:31:46.300: INFO: Pod "var-expansion-7d140b29-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.185403821s
[1mSTEP[0m: Saw pod success
May 15 07:31:46.300: INFO: Pod "var-expansion-7d140b29-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:31:46.370: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod var-expansion-7d140b29-76e3-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:31:46.592: INFO: Waiting for pod var-expansion-7d140b29-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:31:46.684: INFO: Pod var-expansion-7d140b29-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:31:46.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-d4ks4" for this suite.
May 15 07:31:53.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:31:55.429: INFO: namespace: e2e-tests-var-expansion-d4ks4, resource: bindings, ignored listing per whitelist
May 15 07:31:57.331: INFO: namespace e2e-tests-var-expansion-d4ks4 deletion completed in 10.576857059s

[32m [SLOW TEST:15.932 seconds][0m
[k8s.io] Variable Expansion
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould set mode on item file [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:31:57.331: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:31:59.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8681690c-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-4748v" to be "success or failure"
May 15 07:31:59.987: INFO: Pod "downwardapi-volume-8681690c-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 99.156095ms
May 15 07:32:02.058: INFO: Pod "downwardapi-volume-8681690c-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.170488218s
[1mSTEP[0m: Saw pod success
May 15 07:32:02.058: INFO: Pod "downwardapi-volume-8681690c-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:32:02.128: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downwardapi-volume-8681690c-76e3-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:32:02.349: INFO: Waiting for pod downwardapi-volume-8681690c-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:32:02.456: INFO: Pod downwardapi-volume-8681690c-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:32:02.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-4748v" for this suite.
May 15 07:32:08.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:32:12.210: INFO: namespace: e2e-tests-projected-4748v, resource: bindings, ignored listing per whitelist
May 15 07:32:12.994: INFO: namespace e2e-tests-projected-4748v deletion completed in 10.371463073s

[32m [SLOW TEST:15.663 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should set mode on item file [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould release no longer matching pods [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] ReplicationController
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:32:12.994: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Given a ReplicationController is created
[1mSTEP[0m: When the matched label of one of its pods change
May 15 07:32:15.654: INFO: Pod name pod-release: Found 1 pods out of 1
[1mSTEP[0m: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:32:15.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replication-controller-f754h" for this suite.
May 15 07:32:22.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:32:25.755: INFO: namespace: e2e-tests-replication-controller-f754h, resource: bindings, ignored listing per whitelist
May 15 07:32:27.917: INFO: namespace e2e-tests-replication-controller-f754h deletion completed in 11.909533414s

[32m [SLOW TEST:14.923 seconds][0m
[sig-apps] ReplicationController
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should release no longer matching pods [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:32:27.918: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:32:30.568: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98cb0df1-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-wkwcw" to be "success or failure"
May 15 07:32:30.715: INFO: Pod "downwardapi-volume-98cb0df1-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 146.321351ms
May 15 07:32:32.789: INFO: Pod "downwardapi-volume-98cb0df1-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.220909881s
[1mSTEP[0m: Saw pod success
May 15 07:32:32.790: INFO: Pod "downwardapi-volume-98cb0df1-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:32:32.862: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-98cb0df1-76e3-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:32:33.102: INFO: Waiting for pod downwardapi-volume-98cb0df1-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:32:33.209: INFO: Pod downwardapi-volume-98cb0df1-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:32:33.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-wkwcw" for this suite.
May 15 07:32:39.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:32:41.866: INFO: namespace: e2e-tests-projected-wkwcw, resource: bindings, ignored listing per whitelist
May 15 07:32:43.915: INFO: namespace e2e-tests-projected-wkwcw deletion completed in 10.631305162s

[32m [SLOW TEST:15.997 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:32:43.915: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
May 15 07:32:49.588: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a2557066-76e3-11e9-9e56-3ac139a44f02"
May 15 07:32:49.588: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a2557066-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-pods-nqr6r" to be "terminated due to deadline exceeded"
May 15 07:32:49.658: INFO: Pod "pod-update-activedeadlineseconds-a2557066-76e3-11e9-9e56-3ac139a44f02": Phase="Running", Reason="", readiness=true. Elapsed: 69.565339ms
May 15 07:32:51.730: INFO: Pod "pod-update-activedeadlineseconds-a2557066-76e3-11e9-9e56-3ac139a44f02": Phase="Running", Reason="", readiness=true. Elapsed: 2.14171717s
May 15 07:32:53.800: INFO: Pod "pod-update-activedeadlineseconds-a2557066-76e3-11e9-9e56-3ac139a44f02": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.211831313s
May 15 07:32:53.800: INFO: Pod "pod-update-activedeadlineseconds-a2557066-76e3-11e9-9e56-3ac139a44f02" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:32:53.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-nqr6r" for this suite.
May 15 07:33:00.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:33:04.223: INFO: namespace: e2e-tests-pods-nqr6r, resource: bindings, ignored listing per whitelist
May 15 07:33:04.663: INFO: namespace e2e-tests-pods-nqr6r deletion completed in 10.792311137s

[32m [SLOW TEST:20.748 seconds][0m
[k8s.io] Pods
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:33:04.664: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-aeaeee66-76e3-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:33:07.411: INFO: Waiting up to 5m0s for pod "pod-configmaps-aec05980-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-88fpj" to be "success or failure"
May 15 07:33:07.505: INFO: Pod "pod-configmaps-aec05980-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 94.027058ms
May 15 07:33:09.576: INFO: Pod "pod-configmaps-aec05980-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.16495202s
[1mSTEP[0m: Saw pod success
May 15 07:33:09.576: INFO: Pod "pod-configmaps-aec05980-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:33:09.646: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-configmaps-aec05980-76e3-11e9-9e56-3ac139a44f02 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:33:09.865: INFO: Waiting for pod pod-configmaps-aec05980-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:33:09.966: INFO: Pod pod-configmaps-aec05980-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:33:09.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-88fpj" for this suite.
May 15 07:33:17.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:33:17.732: INFO: namespace: e2e-tests-configmap-88fpj, resource: bindings, ignored listing per whitelist
May 15 07:33:21.537: INFO: namespace e2e-tests-configmap-88fpj deletion completed in 11.039858298s

[32m [SLOW TEST:16.873 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node using proxy subresource  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] version v1
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:33:21.537: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 07:33:24.235: INFO: (0) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 103.035587ms)
May 15 07:33:24.307: INFO: (1) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.125396ms)
May 15 07:33:24.380: INFO: (2) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.359387ms)
May 15 07:33:24.452: INFO: (3) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.47612ms)
May 15 07:33:24.524: INFO: (4) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.079045ms)
May 15 07:33:24.596: INFO: (5) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.88564ms)
May 15 07:33:24.671: INFO: (6) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 74.949641ms)
May 15 07:33:24.743: INFO: (7) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.996947ms)
May 15 07:33:24.815: INFO: (8) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.54097ms)
May 15 07:33:24.888: INFO: (9) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.873343ms)
May 15 07:33:24.960: INFO: (10) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.945559ms)
May 15 07:33:25.034: INFO: (11) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 73.878251ms)
May 15 07:33:25.106: INFO: (12) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.293283ms)
May 15 07:33:25.178: INFO: (13) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.060043ms)
May 15 07:33:25.250: INFO: (14) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.8334ms)
May 15 07:33:25.322: INFO: (15) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.750564ms)
May 15 07:33:25.395: INFO: (16) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.511188ms)
May 15 07:33:25.467: INFO: (17) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.588475ms)
May 15 07:33:25.539: INFO: (18) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.164415ms)
May 15 07:33:25.612: INFO: (19) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.308476ms)
[AfterEach] version v1
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:33:25.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-xjgfr" for this suite.
May 15 07:33:31.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:33:33.814: INFO: namespace: e2e-tests-proxy-xjgfr, resource: bindings, ignored listing per whitelist
May 15 07:33:38.020: INFO: namespace e2e-tests-proxy-xjgfr deletion completed in 12.337557471s

[32m [SLOW TEST:16.483 seconds][0m
[sig-network] Proxy
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy logs on node using proxy subresource  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: udp [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:33:38.020: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-vr8lw
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 15 07:33:40.550: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
May 15 07:34:04.595: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.2.54:8080/dial?request=hostName&protocol=udp&host=10.8.0.18&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vr8lw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:34:04.595: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:34:05.258: INFO: Waiting for endpoints: map[]
May 15 07:34:05.332: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.2.54:8080/dial?request=hostName&protocol=udp&host=10.8.2.53&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vr8lw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:34:05.332: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:34:05.959: INFO: Waiting for endpoints: map[]
May 15 07:34:06.030: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.2.54:8080/dial?request=hostName&protocol=udp&host=10.8.1.66&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vr8lw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:34:06.030: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:34:06.732: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:34:06.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-vr8lw" for this suite.
May 15 07:34:29.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:34:30.951: INFO: namespace: e2e-tests-pod-network-test-vr8lw, resource: bindings, ignored listing per whitelist
May 15 07:34:33.680: INFO: namespace e2e-tests-pod-network-test-vr8lw deletion completed in 26.876734348s

[32m [SLOW TEST:55.660 seconds][0m
[sig-network] Networking
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0644,default) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:34:33.680: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on node default medium
May 15 07:34:36.366: INFO: Waiting up to 5m0s for pod "pod-e3c62658-76e3-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-p7d5n" to be "success or failure"
May 15 07:34:36.469: INFO: Pod "pod-e3c62658-76e3-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 102.922962ms
May 15 07:34:38.540: INFO: Pod "pod-e3c62658-76e3-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.173934676s
[1mSTEP[0m: Saw pod success
May 15 07:34:38.540: INFO: Pod "pod-e3c62658-76e3-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:34:38.610: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-e3c62658-76e3-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:34:38.843: INFO: Waiting for pod pod-e3c62658-76e3-11e9-9e56-3ac139a44f02 to disappear
May 15 07:34:38.935: INFO: Pod pod-e3c62658-76e3-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:34:38.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-p7d5n" for this suite.
May 15 07:34:45.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:34:48.317: INFO: namespace: e2e-tests-emptydir-p7d5n, resource: bindings, ignored listing per whitelist
May 15 07:34:49.413: INFO: namespace e2e-tests-emptydir-p7d5n deletion completed in 10.406651355s

[32m [SLOW TEST:15.732 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0644,default) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command in a pod[0m 
  [1mshould print the output to logs [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:34:49.413: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:34:54.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubelet-test-mnvlb" for this suite.
May 15 07:35:40.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:35:43.369: INFO: namespace: e2e-tests-kubelet-test-mnvlb, resource: bindings, ignored listing per whitelist
May 15 07:35:47.119: INFO: namespace e2e-tests-kubelet-test-mnvlb deletion completed in 52.69218849s

[32m [SLOW TEST:57.707 seconds][0m
[k8s.io] Kubelet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when scheduling a busybox command in a pod
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40[0m
    should print the output to logs [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox Pod with hostAliases[0m 
  [1mshould write entries to /etc/hosts [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:35:47.120: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:35:52.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubelet-test-vff8f" for this suite.
May 15 07:36:40.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:36:44.507: INFO: namespace: e2e-tests-kubelet-test-vff8f, resource: bindings, ignored listing per whitelist
May 15 07:36:44.903: INFO: namespace e2e-tests-kubelet-test-vff8f deletion completed in 52.54825888s

[32m [SLOW TEST:57.784 seconds][0m
[k8s.io] Kubelet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when scheduling a busybox Pod with hostAliases
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136[0m
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:36:44.904: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
May 15 07:36:47.454: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:36:50.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-s9zcg" for this suite.
May 15 07:36:57.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:36:58.317: INFO: namespace: e2e-tests-init-container-s9zcg, resource: bindings, ignored listing per whitelist
May 15 07:37:01.696: INFO: namespace e2e-tests-init-container-s9zcg deletion completed in 10.652145065s

[32m [SLOW TEST:16.792 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop simple daemon [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:37:01.696: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating simple DaemonSet "daemon-set"
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
May 15 07:37:05.164: INFO: Number of nodes with available pods: 0
May 15 07:37:05.164: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 07:37:06.305: INFO: Number of nodes with available pods: 0
May 15 07:37:06.305: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 07:37:07.305: INFO: Number of nodes with available pods: 3
May 15 07:37:07.305: INFO: Number of running nodes: 3, number of available pods: 3
[1mSTEP[0m: Stop a daemon pod, check that the daemon pod is revived.
May 15 07:37:07.735: INFO: Number of nodes with available pods: 2
May 15 07:37:07.735: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:08.875: INFO: Number of nodes with available pods: 2
May 15 07:37:08.875: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:09.877: INFO: Number of nodes with available pods: 2
May 15 07:37:09.877: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:10.877: INFO: Number of nodes with available pods: 2
May 15 07:37:10.877: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:11.877: INFO: Number of nodes with available pods: 2
May 15 07:37:11.877: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:12.876: INFO: Number of nodes with available pods: 2
May 15 07:37:12.876: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:13.876: INFO: Number of nodes with available pods: 2
May 15 07:37:13.876: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:14.877: INFO: Number of nodes with available pods: 2
May 15 07:37:14.877: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:15.880: INFO: Number of nodes with available pods: 2
May 15 07:37:15.880: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:16.959: INFO: Number of nodes with available pods: 2
May 15 07:37:16.959: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:18.029: INFO: Number of nodes with available pods: 2
May 15 07:37:18.029: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:18.884: INFO: Number of nodes with available pods: 2
May 15 07:37:18.884: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 07:37:19.884: INFO: Number of nodes with available pods: 3
May 15 07:37:19.884: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vr9tm, will wait for the garbage collector to delete the pods
May 15 07:37:20.326: INFO: Deleting DaemonSet.extensions daemon-set took: 119.193867ms
May 15 07:37:20.426: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.416447ms
May 15 07:37:28.098: INFO: Number of nodes with available pods: 0
May 15 07:37:28.098: INFO: Number of running nodes: 0, number of available pods: 0
May 15 07:37:28.168: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vr9tm/daemonsets","resourceVersion":"10920"},"items":null}

May 15 07:37:28.238: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vr9tm/pods","resourceVersion":"10920"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:37:28.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-vr9tm" for this suite.
May 15 07:37:34.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:37:38.213: INFO: namespace: e2e-tests-daemonsets-vr9tm, resource: bindings, ignored listing per whitelist
May 15 07:37:41.292: INFO: namespace e2e-tests-daemonsets-vr9tm deletion completed in 12.621944375s

[32m [SLOW TEST:39.596 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should run and stop simple daemon [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,tmpfs) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:37:41.292: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on tmpfs
May 15 07:37:43.898: INFO: Waiting up to 5m0s for pod "pod-538c365b-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-99n9n" to be "success or failure"
May 15 07:37:44.004: INFO: Pod "pod-538c365b-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 105.07762ms
May 15 07:37:46.074: INFO: Pod "pod-538c365b-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.175550477s
[1mSTEP[0m: Saw pod success
May 15 07:37:46.074: INFO: Pod "pod-538c365b-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:37:46.144: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-538c365b-76e4-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:37:46.353: INFO: Waiting for pod pod-538c365b-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:37:46.451: INFO: Pod pod-538c365b-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:37:46.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-99n9n" for this suite.
May 15 07:37:52.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:37:56.300: INFO: namespace: e2e-tests-emptydir-99n9n, resource: bindings, ignored listing per whitelist
May 15 07:37:57.115: INFO: namespace e2e-tests-emptydir-99n9n deletion completed in 10.593370905s

[32m [SLOW TEST:15.823 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould adopt matching pods on creation [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] ReplicationController
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:37:57.115: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Given a Pod with a 'name' label pod-adoption is created
[1mSTEP[0m: When a replication controller with a matching selector is created
[1mSTEP[0m: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:38:02.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replication-controller-bkk75" for this suite.
May 15 07:38:24.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:38:28.454: INFO: namespace: e2e-tests-replication-controller-bkk75, resource: bindings, ignored listing per whitelist
May 15 07:38:29.609: INFO: namespace e2e-tests-replication-controller-bkk75 deletion completed in 27.34926843s

[32m [SLOW TEST:32.494 seconds][0m
[sig-apps] ReplicationController
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should adopt matching pods on creation [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:38:29.610: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:38:32.276: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7061c104-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-rnzxh" to be "success or failure"
May 15 07:38:32.374: INFO: Pod "downwardapi-volume-7061c104-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 97.772405ms
May 15 07:38:34.444: INFO: Pod "downwardapi-volume-7061c104-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.167734646s
[1mSTEP[0m: Saw pod success
May 15 07:38:34.444: INFO: Pod "downwardapi-volume-7061c104-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:38:34.514: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downwardapi-volume-7061c104-76e4-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:38:34.739: INFO: Waiting for pod downwardapi-volume-7061c104-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:38:34.837: INFO: Pod downwardapi-volume-7061c104-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:38:34.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-rnzxh" for this suite.
May 15 07:38:41.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:38:41.627: INFO: namespace: e2e-tests-downward-api-rnzxh, resource: bindings, ignored listing per whitelist
May 15 07:38:45.225: INFO: namespace e2e-tests-downward-api-rnzxh deletion completed in 10.317641267s

[32m [SLOW TEST:15.615 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:38:45.225: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:38:48.017: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-nchms" to be "success or failure"
May 15 07:38:48.128: INFO: Pod "downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 110.848584ms
May 15 07:38:50.198: INFO: Pod "downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.181197143s
May 15 07:38:52.269: INFO: Pod "downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.251682296s
[1mSTEP[0m: Saw pod success
May 15 07:38:52.269: INFO: Pod "downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:38:52.338: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:38:52.561: INFO: Waiting for pod downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:38:52.654: INFO: Pod downwardapi-volume-79c1258a-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:38:52.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-nchms" for this suite.
May 15 07:38:58.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:39:00.907: INFO: namespace: e2e-tests-downward-api-nchms, resource: bindings, ignored listing per whitelist
May 15 07:39:03.160: INFO: namespace e2e-tests-downward-api-nchms deletion completed in 10.434940546s

[32m [SLOW TEST:17.935 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's cpu limit [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:39:03.160: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-map-84542966-76e4-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:39:05.855: INFO: Waiting up to 5m0s for pod "pod-secrets-8465a522-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-hn6s7" to be "success or failure"
May 15 07:39:05.966: INFO: Pod "pod-secrets-8465a522-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 110.691732ms
May 15 07:39:08.036: INFO: Pod "pod-secrets-8465a522-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.180627279s
[1mSTEP[0m: Saw pod success
May 15 07:39:08.036: INFO: Pod "pod-secrets-8465a522-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:39:08.106: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-secrets-8465a522-76e4-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:39:08.325: INFO: Waiting for pod pod-secrets-8465a522-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:39:08.419: INFO: Pod pod-secrets-8465a522-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:39:08.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-hn6s7" for this suite.
May 15 07:39:14.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:39:18.965: INFO: namespace: e2e-tests-secrets-hn6s7, resource: bindings, ignored listing per whitelist
May 15 07:39:21.449: INFO: namespace e2e-tests-secrets-hn6s7 deletion completed in 12.959359111s

[32m [SLOW TEST:18.289 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0644,tmpfs) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:39:21.449: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0644 on tmpfs
May 15 07:39:24.528: INFO: Waiting up to 5m0s for pod "pod-8f4721d6-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-gvpkf" to be "success or failure"
May 15 07:39:24.630: INFO: Pod "pod-8f4721d6-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 102.043499ms
May 15 07:39:26.701: INFO: Pod "pod-8f4721d6-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.172419508s
[1mSTEP[0m: Saw pod success
May 15 07:39:26.701: INFO: Pod "pod-8f4721d6-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:39:26.770: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-8f4721d6-76e4-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:39:27.000: INFO: Waiting for pod pod-8f4721d6-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:39:27.099: INFO: Pod pod-8f4721d6-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:39:27.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-gvpkf" for this suite.
May 15 07:39:33.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:39:36.574: INFO: namespace: e2e-tests-emptydir-gvpkf, resource: bindings, ignored listing per whitelist
May 15 07:39:38.514: INFO: namespace e2e-tests-emptydir-gvpkf deletion completed in 11.292142486s

[32m [SLOW TEST:17.064 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:39:38.514: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-996e7a75-76e4-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:39:41.238: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-997ea656-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-x9xv6" to be "success or failure"
May 15 07:39:41.332: INFO: Pod "pod-projected-secrets-997ea656-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 93.580866ms
May 15 07:39:43.402: INFO: Pod "pod-projected-secrets-997ea656-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.163998051s
[1mSTEP[0m: Saw pod success
May 15 07:39:43.402: INFO: Pod "pod-projected-secrets-997ea656-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:39:43.474: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-projected-secrets-997ea656-76e4-11e9-9e56-3ac139a44f02 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:39:43.694: INFO: Waiting for pod pod-projected-secrets-997ea656-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:39:43.790: INFO: Pod pod-projected-secrets-997ea656-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:39:43.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-x9xv6" for this suite.
May 15 07:39:50.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:39:50.646: INFO: namespace: e2e-tests-projected-x9xv6, resource: bindings, ignored listing per whitelist
May 15 07:39:54.388: INFO: namespace e2e-tests-projected-x9xv6 deletion completed in 10.528242926s

[32m [SLOW TEST:15.875 seconds][0m
[sig-storage] Projected secret
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:39:54.389: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name projected-secret-test-a2db2147-76e4-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:39:57.087: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a2eec0dd-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-tjqsp" to be "success or failure"
May 15 07:39:57.505: INFO: Pod "pod-projected-secrets-a2eec0dd-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 417.577443ms
May 15 07:39:59.575: INFO: Pod "pod-projected-secrets-a2eec0dd-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.487928376s
[1mSTEP[0m: Saw pod success
May 15 07:39:59.575: INFO: Pod "pod-projected-secrets-a2eec0dd-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:39:59.645: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-secrets-a2eec0dd-76e4-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:39:59.858: INFO: Waiting for pod pod-projected-secrets-a2eec0dd-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:39:59.959: INFO: Pod pod-projected-secrets-a2eec0dd-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:39:59.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-tjqsp" for this suite.
May 15 07:40:06.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:40:09.199: INFO: namespace: e2e-tests-projected-tjqsp, resource: bindings, ignored listing per whitelist
May 15 07:40:11.211: INFO: namespace e2e-tests-projected-tjqsp deletion completed in 11.181121221s

[32m [SLOW TEST:16.822 seconds][0m
[sig-storage] Projected secret
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34[0m
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:40:11.211: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
May 15 07:40:13.789: INFO: Waiting up to 5m0s for pod "downward-api-ace3e4fe-76e4-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-vv5l7" to be "success or failure"
May 15 07:40:13.883: INFO: Pod "downward-api-ace3e4fe-76e4-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 94.023627ms
May 15 07:40:15.955: INFO: Pod "downward-api-ace3e4fe-76e4-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.166108683s
[1mSTEP[0m: Saw pod success
May 15 07:40:15.955: INFO: Pod "downward-api-ace3e4fe-76e4-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:40:16.024: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downward-api-ace3e4fe-76e4-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:40:16.231: INFO: Waiting for pod downward-api-ace3e4fe-76e4-11e9-9e56-3ac139a44f02 to disappear
May 15 07:40:16.332: INFO: Pod downward-api-ace3e4fe-76e4-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:40:16.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-vv5l7" for this suite.
May 15 07:40:22.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:40:24.220: INFO: namespace: e2e-tests-downward-api-vv5l7, resource: bindings, ignored listing per whitelist
May 15 07:40:27.012: INFO: namespace e2e-tests-downward-api-vv5l7 deletion completed in 10.609711535s

[32m [SLOW TEST:15.801 seconds][0m
[sig-node] Downward API
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:40:27.012: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:41:29.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-9tcx7" for this suite.
May 15 07:41:52.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:41:56.578: INFO: namespace: e2e-tests-container-probe-9tcx7, resource: bindings, ignored listing per whitelist
May 15 07:41:57.793: INFO: namespace e2e-tests-container-probe-9tcx7 deletion completed in 27.841432101s

[32m [SLOW TEST:90.780 seconds][0m
[k8s.io] Probing container
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to restart watching from the last resource version observed by the previous watch [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:41:57.793: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a watch on configmaps
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: closing the watch once it receives two notifications
May 15 07:42:01.708: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-x5bhv,SelfLink:/api/v1/namespaces/e2e-tests-watch-x5bhv/configmaps/e2e-watch-test-watch-closed,UID:ed1e7701-76e4-11e9-8329-42010a8e0130,ResourceVersion:11974,Generation:0,CreationTimestamp:2019-05-15 07:42:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 15 07:42:01.708: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-x5bhv,SelfLink:/api/v1/namespaces/e2e-tests-watch-x5bhv/configmaps/e2e-watch-test-watch-closed,UID:ed1e7701-76e4-11e9-8329-42010a8e0130,ResourceVersion:11975,Generation:0,CreationTimestamp:2019-05-15 07:42:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time, while the watch is closed
[1mSTEP[0m: creating a new watch on configmaps from the last resource version observed by the first watch
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 15 07:42:02.028: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-x5bhv,SelfLink:/api/v1/namespaces/e2e-tests-watch-x5bhv/configmaps/e2e-watch-test-watch-closed,UID:ed1e7701-76e4-11e9-8329-42010a8e0130,ResourceVersion:11976,Generation:0,CreationTimestamp:2019-05-15 07:42:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 15 07:42:02.029: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-x5bhv,SelfLink:/api/v1/namespaces/e2e-tests-watch-x5bhv/configmaps/e2e-watch-test-watch-closed,UID:ed1e7701-76e4-11e9-8329-42010a8e0130,ResourceVersion:11978,Generation:0,CreationTimestamp:2019-05-15 07:42:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:42:02.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-x5bhv" for this suite.
May 15 07:42:08.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:42:10.118: INFO: namespace: e2e-tests-watch-x5bhv, resource: bindings, ignored listing per whitelist
May 15 07:42:13.431: INFO: namespace e2e-tests-watch-x5bhv deletion completed in 11.331004121s

[32m [SLOW TEST:15.638 seconds][0m
[sig-api-machinery] Watchers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mShould recreate evicted statefulset [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:42:13.431: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-6vtlp
[It] Should recreate evicted statefulset [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Looking for a node to schedule stateful set and pod
[1mSTEP[0m: Creating pod with conflicting port in namespace e2e-tests-statefulset-6vtlp
[1mSTEP[0m: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-6vtlp
[1mSTEP[0m: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-6vtlp
[1mSTEP[0m: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-6vtlp
May 15 07:42:20.805: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6vtlp, name: ss-0, uid: f8683200-76e4-11e9-8329-42010a8e0130, status phase: Pending. Waiting for statefulset controller to delete.
May 15 07:42:21.008: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6vtlp, name: ss-0, uid: f8683200-76e4-11e9-8329-42010a8e0130, status phase: Failed. Waiting for statefulset controller to delete.
May 15 07:42:21.019: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6vtlp, name: ss-0, uid: f8683200-76e4-11e9-8329-42010a8e0130, status phase: Failed. Waiting for statefulset controller to delete.
May 15 07:42:21.027: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-6vtlp
[1mSTEP[0m: Removing pod with conflicting port in namespace e2e-tests-statefulset-6vtlp
[1mSTEP[0m: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-6vtlp and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 15 07:42:25.376: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6vtlp
May 15 07:42:25.475: INFO: Scaling statefulset ss to 0
May 15 07:42:45.877: INFO: Waiting for statefulset status.replicas updated to 0
May 15 07:42:45.947: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:42:46.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-6vtlp" for this suite.
May 15 07:42:52.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:42:53.419: INFO: namespace: e2e-tests-statefulset-6vtlp, resource: bindings, ignored listing per whitelist
May 15 07:42:58.031: INFO: namespace e2e-tests-statefulset-6vtlp deletion completed in 11.69210505s

[32m [SLOW TEST:44.600 seconds][0m
[sig-apps] StatefulSet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    Should recreate evicted statefulset [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates resource limits of pods that are allowed to run  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:42:58.031: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 15 07:43:00.476: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 15 07:43:00.617: INFO: Waiting for terminating namespaces to be deleted...
May 15 07:43:00.736: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz before test
May 15 07:43:00.837: INFO: prometheus-to-sd-gfglj from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:43:00.837: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:43:00.837: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz from kube-system started at <nil> (0 container statuses recorded)
May 15 07:43:00.837: INFO: fluentd-gcp-v3.2.0-mmn4z from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 07:43:00.837: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 07:43:00.837: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:43:00.837: INFO: l7-default-backend-fd59995cd-qmgxp from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:43:00.837: INFO: 	Container default-http-backend ready: true, restart count 0
May 15 07:43:00.837: INFO: kube-dns-6987857fdb-hs77r from kube-system started at 2019-05-15 06:54:58 +0000 UTC (4 container statuses recorded)
May 15 07:43:00.837: INFO: 	Container dnsmasq ready: true, restart count 0
May 15 07:43:00.837: INFO: 	Container kubedns ready: true, restart count 0
May 15 07:43:00.837: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:43:00.837: INFO: 	Container sidecar ready: true, restart count 0
May 15 07:43:00.837: INFO: event-exporter-v0.2.3-f67d895d8-8gtbv from kube-system started at 2019-05-15 06:54:58 +0000 UTC (2 container statuses recorded)
May 15 07:43:00.837: INFO: 	Container event-exporter ready: true, restart count 0
May 15 07:43:00.837: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:43:00.837: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r before test
May 15 07:43:00.936: INFO: prometheus-to-sd-b572x from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:43:00.936: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:43:00.936: INFO: kube-dns-autoscaler-bb58c6784-j4zhb from kube-system started at 2019-05-15 06:55:12 +0000 UTC (1 container statuses recorded)
May 15 07:43:00.936: INFO: 	Container autoscaler ready: true, restart count 0
May 15 07:43:00.936: INFO: heapster-v1.6.0-beta.1-798666ff5c-74dbk from kube-system started at 2019-05-15 06:55:12 +0000 UTC (3 container statuses recorded)
May 15 07:43:00.936: INFO: 	Container heapster ready: true, restart count 0
May 15 07:43:00.936: INFO: 	Container heapster-nanny ready: true, restart count 0
May 15 07:43:00.936: INFO: 	Container prom-to-sd ready: true, restart count 0
May 15 07:43:00.936: INFO: metrics-server-v0.3.1-65cd4f6fd8-4f249 from kube-system started at 2019-05-15 06:55:12 +0000 UTC (2 container statuses recorded)
May 15 07:43:00.936: INFO: 	Container metrics-server ready: true, restart count 0
May 15 07:43:00.936: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 15 07:43:00.936: INFO: fluentd-gcp-scaler-68b55c6dc5-596nw from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:43:00.936: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 15 07:43:00.936: INFO: fluentd-gcp-v3.2.0-ngtmk from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 07:43:00.936: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 07:43:00.936: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:43:00.936: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r from kube-system started at <nil> (0 container statuses recorded)
May 15 07:43:00.936: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx before test
May 15 07:43:01.056: INFO: fluentd-gcp-v3.2.0-ljmkc from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 07:43:01.056: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 07:43:01.056: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 07:43:01.056: INFO: prometheus-to-sd-fzxr4 from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 07:43:01.056: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:43:01.056: INFO: kube-dns-6987857fdb-g4phv from kube-system started at 2019-05-15 06:55:17 +0000 UTC (4 container statuses recorded)
May 15 07:43:01.056: INFO: 	Container dnsmasq ready: true, restart count 0
May 15 07:43:01.056: INFO: 	Container kubedns ready: true, restart count 0
May 15 07:43:01.056: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 07:43:01.056: INFO: 	Container sidecar ready: true, restart count 0
May 15 07:43:01.056: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx from kube-system started at <nil> (0 container statuses recorded)
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: verifying the node has the label node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
[1mSTEP[0m: verifying the node has the label node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
[1mSTEP[0m: verifying the node has the label node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx
May 15 07:43:01.824: INFO: Pod event-exporter-v0.2.3-f67d895d8-8gtbv requesting resource cpu=0m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
May 15 07:43:01.825: INFO: Pod fluentd-gcp-scaler-68b55c6dc5-596nw requesting resource cpu=0m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
May 15 07:43:01.825: INFO: Pod fluentd-gcp-v3.2.0-ljmkc requesting resource cpu=100m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx
May 15 07:43:01.825: INFO: Pod fluentd-gcp-v3.2.0-mmn4z requesting resource cpu=100m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
May 15 07:43:01.825: INFO: Pod fluentd-gcp-v3.2.0-ngtmk requesting resource cpu=100m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
May 15 07:43:01.825: INFO: Pod heapster-v1.6.0-beta.1-798666ff5c-74dbk requesting resource cpu=63m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
May 15 07:43:01.825: INFO: Pod kube-dns-6987857fdb-g4phv requesting resource cpu=260m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx
May 15 07:43:01.825: INFO: Pod kube-dns-6987857fdb-hs77r requesting resource cpu=260m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
May 15 07:43:01.825: INFO: Pod kube-dns-autoscaler-bb58c6784-j4zhb requesting resource cpu=20m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
May 15 07:43:01.825: INFO: Pod kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz requesting resource cpu=100m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
May 15 07:43:01.825: INFO: Pod kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r requesting resource cpu=100m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
May 15 07:43:01.825: INFO: Pod kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx requesting resource cpu=100m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx
May 15 07:43:01.825: INFO: Pod l7-default-backend-fd59995cd-qmgxp requesting resource cpu=10m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
May 15 07:43:01.825: INFO: Pod metrics-server-v0.3.1-65cd4f6fd8-4f249 requesting resource cpu=48m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
May 15 07:43:01.825: INFO: Pod prometheus-to-sd-b572x requesting resource cpu=1m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
May 15 07:43:01.825: INFO: Pod prometheus-to-sd-fzxr4 requesting resource cpu=1m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx
May 15 07:43:01.825: INFO: Pod prometheus-to-sd-gfglj requesting resource cpu=1m on Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
[1mSTEP[0m: Starting Pods to consume most of the cluster CPU.
[1mSTEP[0m: Creating another pod that requires unavailable amount of CPU.
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-111d956b-76e5-11e9-9e56-3ac139a44f02.159ecb6b1448cf22], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-z9tsc/filler-pod-111d956b-76e5-11e9-9e56-3ac139a44f02 to gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-111d956b-76e5-11e9-9e56-3ac139a44f02.159ecb6b48956dfb], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-111d956b-76e5-11e9-9e56-3ac139a44f02.159ecb6b4b833fe4], Reason = [Created], Message = [Created container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-111d956b-76e5-11e9-9e56-3ac139a44f02.159ecb6b590bd7ae], Reason = [Started], Message = [Started container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-112e5ed6-76e5-11e9-9e56-3ac139a44f02.159ecb6b1936f34b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-z9tsc/filler-pod-112e5ed6-76e5-11e9-9e56-3ac139a44f02 to gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-112e5ed6-76e5-11e9-9e56-3ac139a44f02.159ecb6b50502469], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-112e5ed6-76e5-11e9-9e56-3ac139a44f02.159ecb6b535adc25], Reason = [Created], Message = [Created container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-112e5ed6-76e5-11e9-9e56-3ac139a44f02.159ecb6b5f33add5], Reason = [Started], Message = [Started container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-113a8c34-76e5-11e9-9e56-3ac139a44f02.159ecb6b1dbf6685], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-z9tsc/filler-pod-113a8c34-76e5-11e9-9e56-3ac139a44f02 to gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-113a8c34-76e5-11e9-9e56-3ac139a44f02.159ecb6b50ba7324], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-113a8c34-76e5-11e9-9e56-3ac139a44f02.159ecb6b53f7dc5e], Reason = [Created], Message = [Created container]
[1mSTEP[0m: Considering event: 
Type = [Normal], Name = [filler-pod-113a8c34-76e5-11e9-9e56-3ac139a44f02.159ecb6b5e8e2db7], Reason = [Started], Message = [Started container]
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [additional-pod.159ecb6bd7b86129], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
[1mSTEP[0m: removing the label node off the node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
[1mSTEP[0m: verifying the node doesn't have the label node
[1mSTEP[0m: removing the label node off the node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx
[1mSTEP[0m: verifying the node doesn't have the label node
[1mSTEP[0m: removing the label node off the node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz
[1mSTEP[0m: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:43:07.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-z9tsc" for this suite.
May 15 07:43:13.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:43:15.653: INFO: namespace: e2e-tests-sched-pred-z9tsc, resource: bindings, ignored listing per whitelist
May 15 07:43:17.353: INFO: namespace e2e-tests-sched-pred-z9tsc deletion completed in 10.184844651s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

[32m [SLOW TEST:19.322 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates resource limits of pods that are allowed to run  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan pods created by rc if delete options say so [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:43:17.353: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
[1mSTEP[0m: Gathering metrics
W0515 07:44:00.838610    1545 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 15 07:44:00.838: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:44:00.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-4mcwq" for this suite.
May 15 07:44:07.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:44:09.443: INFO: namespace: e2e-tests-gc-4mcwq, resource: bindings, ignored listing per whitelist
May 15 07:44:11.713: INFO: namespace e2e-tests-gc-4mcwq deletion completed in 10.804398917s

[32m [SLOW TEST:54.360 seconds][0m
[sig-api-machinery] Garbage collector
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should orphan pods created by rc if delete options say so [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:44:11.713: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
May 15 07:44:14.400: INFO: Waiting up to 5m0s for pod "downward-api-3c4e0b95-76e5-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-rmsmv" to be "success or failure"
May 15 07:44:14.499: INFO: Pod "downward-api-3c4e0b95-76e5-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 99.891363ms
May 15 07:44:16.741: INFO: Pod "downward-api-3c4e0b95-76e5-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.341432278s
[1mSTEP[0m: Saw pod success
May 15 07:44:16.741: INFO: Pod "downward-api-3c4e0b95-76e5-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:44:16.900: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downward-api-3c4e0b95-76e5-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:44:17.595: INFO: Waiting for pod downward-api-3c4e0b95-76e5-11e9-9e56-3ac139a44f02 to disappear
May 15 07:44:17.909: INFO: Pod downward-api-3c4e0b95-76e5-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:44:17.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-rmsmv" for this suite.
May 15 07:44:24.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:44:28.111: INFO: namespace: e2e-tests-downward-api-rmsmv, resource: bindings, ignored listing per whitelist
May 15 07:44:28.633: INFO: namespace e2e-tests-downward-api-rmsmv deletion completed in 10.490627901s

[32m [SLOW TEST:16.920 seconds][0m
[sig-node] Downward API
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-network] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: http [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:44:28.633: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Performing setup for networking test in namespace e2e-tests-pod-network-test-dxrmm
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 15 07:44:31.266: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[1mSTEP[0m: Creating test pods
May 15 07:44:54.893: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.1.83:8080/dial?request=hostName&protocol=http&host=10.8.1.82&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-dxrmm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:44:54.893: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:44:55.585: INFO: Waiting for endpoints: map[]
May 15 07:44:55.655: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.1.83:8080/dial?request=hostName&protocol=http&host=10.8.0.25&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-dxrmm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:44:55.655: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:44:56.285: INFO: Waiting for endpoints: map[]
May 15 07:44:56.354: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.1.83:8080/dial?request=hostName&protocol=http&host=10.8.2.68&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-dxrmm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 07:44:56.354: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 07:44:56.988: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:44:56.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pod-network-test-dxrmm" for this suite.
May 15 07:45:21.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:45:24.529: INFO: namespace: e2e-tests-pod-network-test-dxrmm, resource: bindings, ignored listing per whitelist
May 15 07:45:25.340: INFO: namespace e2e-tests-pod-network-test-dxrmm deletion completed in 28.281401943s

[32m [SLOW TEST:56.707 seconds][0m
[sig-network] Networking
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25[0m
  Granular Checks: Pods
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28[0m
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould do a rolling update of a replication controller  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:45:25.341: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the initial replication controller
May 15 07:45:27.854: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:30.959: INFO: stderr: ""
May 15 07:45:30.959: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 15 07:45:30.959: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:31.427: INFO: stderr: ""
May 15 07:45:31.427: INFO: stdout: "update-demo-nautilus-5k4xw update-demo-nautilus-pf85v "
May 15 07:45:31.428: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-5k4xw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:31.844: INFO: stderr: ""
May 15 07:45:31.844: INFO: stdout: ""
May 15 07:45:31.844: INFO: update-demo-nautilus-5k4xw is created but not running
May 15 07:45:36.844: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:37.236: INFO: stderr: ""
May 15 07:45:37.236: INFO: stdout: "update-demo-nautilus-5k4xw update-demo-nautilus-pf85v "
May 15 07:45:37.236: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-5k4xw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:37.626: INFO: stderr: ""
May 15 07:45:37.626: INFO: stdout: "true"
May 15 07:45:37.626: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-5k4xw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:38.008: INFO: stderr: ""
May 15 07:45:38.008: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:45:38.008: INFO: validating pod update-demo-nautilus-5k4xw
May 15 07:45:38.115: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:45:38.115: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:45:38.115: INFO: update-demo-nautilus-5k4xw is verified up and running
May 15 07:45:38.115: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-pf85v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:38.524: INFO: stderr: ""
May 15 07:45:38.524: INFO: stdout: "true"
May 15 07:45:38.525: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-pf85v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:38.910: INFO: stderr: ""
May 15 07:45:38.910: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:45:38.910: INFO: validating pod update-demo-nautilus-pf85v
May 15 07:45:39.027: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:45:39.027: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:45:39.027: INFO: update-demo-nautilus-pf85v is verified up and running
[1mSTEP[0m: rolling-update to new replication controller
May 15 07:45:39.029: INFO: scanned /workspace for discovery docs: <nil>
May 15 07:45:39.029: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:55.162: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 15 07:45:55.162: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 15 07:45:55.162: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:55.552: INFO: stderr: ""
May 15 07:45:55.553: INFO: stdout: "update-demo-kitten-cf89r update-demo-kitten-z4gdl "
May 15 07:45:55.553: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-kitten-cf89r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:55.983: INFO: stderr: ""
May 15 07:45:55.983: INFO: stdout: "true"
May 15 07:45:55.983: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-kitten-cf89r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:56.368: INFO: stderr: ""
May 15 07:45:56.368: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 15 07:45:56.368: INFO: validating pod update-demo-kitten-cf89r
May 15 07:45:56.474: INFO: got data: {
  "image": "kitten.jpg"
}

May 15 07:45:56.474: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 15 07:45:56.474: INFO: update-demo-kitten-cf89r is verified up and running
May 15 07:45:56.474: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-kitten-z4gdl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:56.881: INFO: stderr: ""
May 15 07:45:56.881: INFO: stdout: "true"
May 15 07:45:56.881: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-kitten-z4gdl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bh7rr'
May 15 07:45:57.272: INFO: stderr: ""
May 15 07:45:57.272: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 15 07:45:57.272: INFO: validating pod update-demo-kitten-z4gdl
May 15 07:45:57.408: INFO: got data: {
  "image": "kitten.jpg"
}

May 15 07:45:57.408: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 15 07:45:57.408: INFO: update-demo-kitten-z4gdl is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:45:57.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-bh7rr" for this suite.
May 15 07:46:21.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:46:22.221: INFO: namespace: e2e-tests-kubectl-bh7rr, resource: bindings, ignored listing per whitelist
May 15 07:46:26.311: INFO: namespace e2e-tests-kubectl-bh7rr deletion completed in 28.786574756s

[32m [SLOW TEST:60.970 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should do a rolling update of a replication controller  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform rolling updates and roll backs of template modifications [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:46:26.311: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-m9lgl
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a new StatefulSet
May 15 07:46:29.160: INFO: Found 1 stateful pods, waiting for 3
May 15 07:46:39.232: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 15 07:46:39.232: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 15 07:46:39.232: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 15 07:46:39.470: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-m9lgl ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 07:46:40.566: INFO: stderr: ""
May 15 07:46:40.566: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 07:46:40.566: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

[1mSTEP[0m: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 15 07:46:51.038: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Updating Pods in reverse ordinal order
May 15 07:46:51.249: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-m9lgl ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 07:46:52.239: INFO: stderr: ""
May 15 07:46:52.239: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 07:46:52.239: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 07:46:52.533: INFO: Waiting for StatefulSet e2e-tests-statefulset-m9lgl/ss2 to complete update
May 15 07:46:52.533: INFO: Waiting for Pod e2e-tests-statefulset-m9lgl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 15 07:46:52.533: INFO: Waiting for Pod e2e-tests-statefulset-m9lgl/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 15 07:46:52.533: INFO: Waiting for Pod e2e-tests-statefulset-m9lgl/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 15 07:47:02.778: INFO: Waiting for StatefulSet e2e-tests-statefulset-m9lgl/ss2 to complete update
May 15 07:47:02.778: INFO: Waiting for Pod e2e-tests-statefulset-m9lgl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 15 07:47:12.675: INFO: Waiting for StatefulSet e2e-tests-statefulset-m9lgl/ss2 to complete update
May 15 07:47:12.675: INFO: Waiting for Pod e2e-tests-statefulset-m9lgl/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[1mSTEP[0m: Rolling back to a previous revision
May 15 07:47:22.675: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-m9lgl ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 07:47:23.677: INFO: stderr: ""
May 15 07:47:23.677: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 07:47:23.677: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 07:47:34.112: INFO: Updating stateful set ss2
[1mSTEP[0m: Rolling back update in reverse ordinal order
May 15 07:47:34.338: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-m9lgl ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 07:47:35.381: INFO: stderr: ""
May 15 07:47:35.381: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 07:47:35.381: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 07:47:45.908: INFO: Waiting for StatefulSet e2e-tests-statefulset-m9lgl/ss2 to complete update
May 15 07:47:45.908: INFO: Waiting for Pod e2e-tests-statefulset-m9lgl/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 15 07:47:56.053: INFO: Waiting for StatefulSet e2e-tests-statefulset-m9lgl/ss2 to complete update
May 15 07:47:56.053: INFO: Waiting for Pod e2e-tests-statefulset-m9lgl/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 15 07:48:06.050: INFO: Deleting all statefulset in ns e2e-tests-statefulset-m9lgl
May 15 07:48:06.149: INFO: Scaling statefulset ss2 to 0
May 15 07:48:26.473: INFO: Waiting for statefulset status.replicas updated to 0
May 15 07:48:26.544: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:48:26.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-m9lgl" for this suite.
May 15 07:48:33.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:48:37.442: INFO: namespace: e2e-tests-statefulset-m9lgl, resource: bindings, ignored listing per whitelist
May 15 07:48:38.169: INFO: namespace e2e-tests-statefulset-m9lgl deletion completed in 11.20206733s

[32m [SLOW TEST:131.857 seconds][0m
[sig-apps] StatefulSet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should perform rolling updates and roll backs of template modifications [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run --rm job[0m 
  [1mshould create a job from an image, then delete the job  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:48:38.169: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: executing a command with run --rm and attach with stdin
May 15 07:48:40.693: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 --namespace=e2e-tests-kubectl-qg6js run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 15 07:48:44.258: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 15 07:48:44.258: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
[1mSTEP[0m: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:48:46.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-qg6js" for this suite.
May 15 07:48:52.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:48:55.871: INFO: namespace: e2e-tests-kubectl-qg6js, resource: bindings, ignored listing per whitelist
May 15 07:48:56.715: INFO: namespace e2e-tests-kubectl-qg6js deletion completed in 10.245558566s

[32m [SLOW TEST:18.546 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run --rm job
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a job from an image, then delete the job  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with downward pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:48:56.715: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-downwardapi-skln
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
May 15 07:48:59.979: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-skln" in namespace "e2e-tests-subpath-knkhd" to be "success or failure"
May 15 07:49:00.081: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Pending", Reason="", readiness=false. Elapsed: 101.518494ms
May 15 07:49:02.159: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Pending", Reason="", readiness=false. Elapsed: 2.179875157s
May 15 07:49:04.233: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 4.253752862s
May 15 07:49:06.305: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 6.325096587s
May 15 07:49:08.376: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 8.396059285s
May 15 07:49:10.446: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 10.466673178s
May 15 07:49:12.516: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 12.536523077s
May 15 07:49:14.586: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 14.606711998s
May 15 07:49:16.750: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 16.770640729s
May 15 07:49:19.002: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 19.022959673s
May 15 07:49:21.151: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Running", Reason="", readiness=false. Elapsed: 21.171171064s
May 15 07:49:23.223: INFO: Pod "pod-subpath-test-downwardapi-skln": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.243581812s
[1mSTEP[0m: Saw pod success
May 15 07:49:23.223: INFO: Pod "pod-subpath-test-downwardapi-skln" satisfied condition "success or failure"
May 15 07:49:23.294: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-subpath-test-downwardapi-skln container test-container-subpath-downwardapi-skln: <nil>
[1mSTEP[0m: delete the pod
May 15 07:49:23.531: INFO: Waiting for pod pod-subpath-test-downwardapi-skln to disappear
May 15 07:49:23.632: INFO: Pod pod-subpath-test-downwardapi-skln no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-downwardapi-skln
May 15 07:49:23.632: INFO: Deleting pod "pod-subpath-test-downwardapi-skln" in namespace "e2e-tests-subpath-knkhd"
[AfterEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:49:23.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-knkhd" for this suite.
May 15 07:49:30.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:49:32.344: INFO: namespace: e2e-tests-subpath-knkhd, resource: bindings, ignored listing per whitelist
May 15 07:49:34.845: INFO: namespace e2e-tests-subpath-knkhd deletion completed in 11.072345655s

[32m [SLOW TEST:38.130 seconds][0m
[sig-storage] Subpath
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with downward pod [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:49:34.845: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
May 15 07:49:40.543: INFO: Successfully updated pod "annotationupdatefcd7aaea-76e5-11e9-9e56-3ac139a44f02"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:49:42.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-v7dbp" for this suite.
May 15 07:50:07.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:50:11.620: INFO: namespace: e2e-tests-projected-v7dbp, resource: bindings, ignored listing per whitelist
May 15 07:50:12.018: INFO: namespace e2e-tests-projected-v7dbp deletion completed in 29.245850017s

[32m [SLOW TEST:37.173 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should update annotations on modification [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:50:12.018: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-130359bd-76e6-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:50:14.721: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-13133324-76e6-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-rbf57" to be "success or failure"
May 15 07:50:14.820: INFO: Pod "pod-projected-configmaps-13133324-76e6-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 98.398799ms
May 15 07:50:16.890: INFO: Pod "pod-projected-configmaps-13133324-76e6-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.168378007s
[1mSTEP[0m: Saw pod success
May 15 07:50:16.890: INFO: Pod "pod-projected-configmaps-13133324-76e6-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:50:16.959: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-configmaps-13133324-76e6-11e9-9e56-3ac139a44f02 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:50:17.192: INFO: Waiting for pod pod-projected-configmaps-13133324-76e6-11e9-9e56-3ac139a44f02 to disappear
May 15 07:50:17.291: INFO: Pod pod-projected-configmaps-13133324-76e6-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:50:17.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-rbf57" for this suite.
May 15 07:50:23.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:50:28.439: INFO: namespace: e2e-tests-projected-rbf57, resource: bindings, ignored listing per whitelist
May 15 07:50:28.635: INFO: namespace e2e-tests-projected-rbf57 deletion completed in 11.239321727s

[32m [SLOW TEST:16.617 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:50:28.635: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:50:31.520: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-42bl4" to be "success or failure"
May 15 07:50:31.619: INFO: Pod "downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 99.63661ms
May 15 07:50:33.690: INFO: Pod "downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.169813881s
May 15 07:50:35.760: INFO: Pod "downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.239772293s
[1mSTEP[0m: Saw pod success
May 15 07:50:35.760: INFO: Pod "downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:50:35.829: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:50:36.049: INFO: Waiting for pod downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02 to disappear
May 15 07:50:36.149: INFO: Pod downwardapi-volume-1d162897-76e6-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:50:36.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-42bl4" for this suite.
May 15 07:50:42.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:50:45.111: INFO: namespace: e2e-tests-projected-42bl4, resource: bindings, ignored listing per whitelist
May 15 07:50:46.696: INFO: namespace e2e-tests-projected-42bl4 deletion completed in 10.476595551s

[32m [SLOW TEST:18.061 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should provide container's memory request [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (non-root,0666,tmpfs) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:50:46.696: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
May 15 07:50:49.309: INFO: Waiting up to 5m0s for pod "pod-27b13ac6-76e6-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-wbjrm" to be "success or failure"
May 15 07:50:49.430: INFO: Pod "pod-27b13ac6-76e6-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 121.556225ms
May 15 07:50:51.501: INFO: Pod "pod-27b13ac6-76e6-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.192537453s
[1mSTEP[0m: Saw pod success
May 15 07:50:51.501: INFO: Pod "pod-27b13ac6-76e6-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:50:51.571: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-27b13ac6-76e6-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:50:52.130: INFO: Waiting for pod pod-27b13ac6-76e6-11e9-9e56-3ac139a44f02 to disappear
May 15 07:50:52.224: INFO: Pod pod-27b13ac6-76e6-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:50:52.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-wbjrm" for this suite.
May 15 07:50:58.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:51:01.234: INFO: namespace: e2e-tests-emptydir-wbjrm, resource: bindings, ignored listing per whitelist
May 15 07:51:03.346: INFO: namespace e2e-tests-emptydir-wbjrm deletion completed in 11.051389394s

[32m [SLOW TEST:16.650 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould scale a replication controller  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:51:03.346: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a replication controller
May 15 07:51:05.799: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:11.452: INFO: stderr: ""
May 15 07:51:11.452: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 15 07:51:11.453: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:12.315: INFO: stderr: ""
May 15 07:51:12.315: INFO: stdout: "update-demo-nautilus-bvv8n update-demo-nautilus-j84rs "
May 15 07:51:12.315: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-bvv8n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:13.212: INFO: stderr: ""
May 15 07:51:13.212: INFO: stdout: ""
May 15 07:51:13.212: INFO: update-demo-nautilus-bvv8n is created but not running
May 15 07:51:18.213: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:19.661: INFO: stderr: ""
May 15 07:51:19.661: INFO: stdout: "update-demo-nautilus-bvv8n update-demo-nautilus-j84rs "
May 15 07:51:19.661: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-bvv8n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:20.093: INFO: stderr: ""
May 15 07:51:20.093: INFO: stdout: "true"
May 15 07:51:20.093: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-bvv8n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:20.475: INFO: stderr: ""
May 15 07:51:20.476: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:51:20.476: INFO: validating pod update-demo-nautilus-bvv8n
May 15 07:51:21.030: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:51:21.030: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:51:21.030: INFO: update-demo-nautilus-bvv8n is verified up and running
May 15 07:51:21.030: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-j84rs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:21.596: INFO: stderr: ""
May 15 07:51:21.596: INFO: stdout: "true"
May 15 07:51:21.596: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-j84rs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:21.990: INFO: stderr: ""
May 15 07:51:21.990: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:51:21.990: INFO: validating pod update-demo-nautilus-j84rs
May 15 07:51:22.596: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:51:22.596: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:51:22.596: INFO: update-demo-nautilus-j84rs is verified up and running
[1mSTEP[0m: scaling down the replication controller
May 15 07:51:22.598: INFO: scanned /workspace for discovery docs: <nil>
May 15 07:51:22.598: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:23.370: INFO: stderr: ""
May 15 07:51:23.370: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 15 07:51:23.370: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:23.889: INFO: stderr: ""
May 15 07:51:23.889: INFO: stdout: "update-demo-nautilus-bvv8n update-demo-nautilus-j84rs "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 15 07:51:28.890: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:29.437: INFO: stderr: ""
May 15 07:51:29.437: INFO: stdout: "update-demo-nautilus-bvv8n "
May 15 07:51:29.437: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-bvv8n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:29.840: INFO: stderr: ""
May 15 07:51:29.840: INFO: stdout: "true"
May 15 07:51:29.840: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-bvv8n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:30.226: INFO: stderr: ""
May 15 07:51:30.226: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:51:30.226: INFO: validating pod update-demo-nautilus-bvv8n
May 15 07:51:30.299: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:51:30.300: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:51:30.300: INFO: update-demo-nautilus-bvv8n is verified up and running
[1mSTEP[0m: scaling up the replication controller
May 15 07:51:30.303: INFO: scanned /workspace for discovery docs: <nil>
May 15 07:51:30.303: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:30.999: INFO: stderr: ""
May 15 07:51:30.999: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 15 07:51:30.999: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:31.415: INFO: stderr: ""
May 15 07:51:31.415: INFO: stdout: "update-demo-nautilus-6s65x update-demo-nautilus-bvv8n "
May 15 07:51:31.415: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-6s65x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:32.012: INFO: stderr: ""
May 15 07:51:32.012: INFO: stdout: ""
May 15 07:51:32.012: INFO: update-demo-nautilus-6s65x is created but not running
May 15 07:51:37.012: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:37.451: INFO: stderr: ""
May 15 07:51:37.451: INFO: stdout: "update-demo-nautilus-6s65x update-demo-nautilus-bvv8n "
May 15 07:51:37.451: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-6s65x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:37.832: INFO: stderr: ""
May 15 07:51:37.832: INFO: stdout: "true"
May 15 07:51:37.832: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-6s65x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:38.213: INFO: stderr: ""
May 15 07:51:38.213: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:51:38.213: INFO: validating pod update-demo-nautilus-6s65x
May 15 07:51:38.328: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:51:38.328: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:51:38.328: INFO: update-demo-nautilus-6s65x is verified up and running
May 15 07:51:38.328: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-bvv8n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:38.720: INFO: stderr: ""
May 15 07:51:38.720: INFO: stdout: "true"
May 15 07:51:38.720: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods update-demo-nautilus-bvv8n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:39.104: INFO: stderr: ""
May 15 07:51:39.104: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 15 07:51:39.104: INFO: validating pod update-demo-nautilus-bvv8n
May 15 07:51:39.177: INFO: got data: {
  "image": "nautilus.jpg"
}

May 15 07:51:39.177: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 15 07:51:39.177: INFO: update-demo-nautilus-bvv8n is verified up and running
[1mSTEP[0m: using delete to clean up resources
May 15 07:51:39.177: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:39.748: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 15 07:51:39.748: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 15 07:51:39.748: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-fwtms'
May 15 07:51:40.290: INFO: stderr: "No resources found.\n"
May 15 07:51:40.291: INFO: stdout: ""
May 15 07:51:40.291: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pods -l name=update-demo --namespace=e2e-tests-kubectl-fwtms -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 15 07:51:40.675: INFO: stderr: ""
May 15 07:51:40.675: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:51:40.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-fwtms" for this suite.
May 15 07:52:03.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:52:07.499: INFO: namespace: e2e-tests-kubectl-fwtms, resource: bindings, ignored listing per whitelist
May 15 07:52:09.331: INFO: namespace e2e-tests-kubectl-fwtms deletion completed in 28.542707796s

[32m [SLOW TEST:65.985 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Update Demo
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should scale a replication controller  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:52:09.331: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-58faeeaa-76e6-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:52:12.537: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-594c0e99-76e6-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-6f9kg" to be "success or failure"
May 15 07:52:12.635: INFO: Pod "pod-projected-configmaps-594c0e99-76e6-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 97.49076ms
May 15 07:52:14.705: INFO: Pod "pod-projected-configmaps-594c0e99-76e6-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.167643874s
[1mSTEP[0m: Saw pod success
May 15 07:52:14.705: INFO: Pod "pod-projected-configmaps-594c0e99-76e6-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:52:14.774: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-configmaps-594c0e99-76e6-11e9-9e56-3ac139a44f02 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:52:14.998: INFO: Waiting for pod pod-projected-configmaps-594c0e99-76e6-11e9-9e56-3ac139a44f02 to disappear
May 15 07:52:15.104: INFO: Pod pod-projected-configmaps-594c0e99-76e6-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:52:15.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-6f9kg" for this suite.
May 15 07:52:21.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:52:23.374: INFO: namespace: e2e-tests-projected-6f9kg, resource: bindings, ignored listing per whitelist
May 15 07:52:26.251: INFO: namespace e2e-tests-projected-6f9kg deletion completed in 11.076274668s

[32m [SLOW TEST:16.920 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:52:26.251: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-map-6301cd54-76e6-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 07:52:28.930: INFO: Waiting up to 5m0s for pod "pod-secrets-6311774c-76e6-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-bw69r" to be "success or failure"
May 15 07:52:29.023: INFO: Pod "pod-secrets-6311774c-76e6-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 93.130654ms
May 15 07:52:31.212: INFO: Pod "pod-secrets-6311774c-76e6-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.281990544s
[1mSTEP[0m: Saw pod success
May 15 07:52:31.212: INFO: Pod "pod-secrets-6311774c-76e6-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:52:31.342: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-secrets-6311774c-76e6-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:52:31.574: INFO: Waiting for pod pod-secrets-6311774c-76e6-11e9-9e56-3ac139a44f02 to disappear
May 15 07:52:31.668: INFO: Pod pod-secrets-6311774c-76e6-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:52:31.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-bw69r" for this suite.
May 15 07:52:38.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:52:40.724: INFO: namespace: e2e-tests-secrets-bw69r, resource: bindings, ignored listing per whitelist
May 15 07:52:42.022: INFO: namespace e2e-tests-secrets-bw69r deletion completed in 10.284115805s

[32m [SLOW TEST:15.771 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl expose[0m 
  [1mshould create services for rc  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:52:42.023: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating Redis RC
May 15 07:52:44.552: INFO: namespace e2e-tests-kubectl-5gnfq
May 15 07:52:44.552: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-5gnfq'
May 15 07:52:45.240: INFO: stderr: ""
May 15 07:52:45.240: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
May 15 07:52:46.338: INFO: Selector matched 1 pods for map[app:redis]
May 15 07:52:46.338: INFO: Found 0 / 1
May 15 07:52:47.311: INFO: Selector matched 1 pods for map[app:redis]
May 15 07:52:47.311: INFO: Found 1 / 1
May 15 07:52:47.311: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 15 07:52:47.382: INFO: Selector matched 1 pods for map[app:redis]
May 15 07:52:47.382: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 15 07:52:47.382: INFO: wait on redis-master startup in e2e-tests-kubectl-5gnfq 
May 15 07:52:47.382: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 logs redis-master-22t8z redis-master --namespace=e2e-tests-kubectl-5gnfq'
May 15 07:52:47.955: INFO: stderr: ""
May 15 07:52:47.955: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 May 07:52:46.268 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 May 07:52:46.268 # Server started, Redis version 3.2.12\n1:M 15 May 07:52:46.268 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 May 07:52:46.268 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: exposing RC
May 15 07:52:47.955: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-5gnfq'
May 15 07:52:48.511: INFO: stderr: ""
May 15 07:52:48.511: INFO: stdout: "service/rm2 exposed\n"
May 15 07:52:48.607: INFO: Service rm2 in namespace e2e-tests-kubectl-5gnfq found.
[1mSTEP[0m: exposing service
May 15 07:52:50.783: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-5gnfq'
May 15 07:52:51.262: INFO: stderr: ""
May 15 07:52:51.262: INFO: stdout: "service/rm3 exposed\n"
May 15 07:52:51.364: INFO: Service rm3 in namespace e2e-tests-kubectl-5gnfq found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:52:53.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-5gnfq" for this suite.
May 15 07:53:15.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:53:17.213: INFO: namespace: e2e-tests-kubectl-5gnfq, resource: bindings, ignored listing per whitelist
May 15 07:53:20.694: INFO: namespace e2e-tests-kubectl-5gnfq deletion completed in 27.0770968s

[32m [SLOW TEST:38.672 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl expose
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create services for rc  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve a basic endpoint from pods  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:53:20.695: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating service endpoint-test2 in namespace e2e-tests-services-sr6bs
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-sr6bs to expose endpoints map[]
May 15 07:53:23.386: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-sr6bs exposes endpoints map[] (112.890212ms elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace e2e-tests-services-sr6bs
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-sr6bs to expose endpoints map[pod1:[80]]
May 15 07:53:24.949: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-sr6bs exposes endpoints map[pod1:[80]] (1.443173138s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace e2e-tests-services-sr6bs
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-sr6bs to expose endpoints map[pod2:[80] pod1:[80]]
May 15 07:53:27.734: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-sr6bs exposes endpoints map[pod1:[80] pod2:[80]] (2.705570391s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace e2e-tests-services-sr6bs
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-sr6bs to expose endpoints map[pod2:[80]]
May 15 07:53:28.056: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-sr6bs exposes endpoints map[pod2:[80]] (196.786888ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace e2e-tests-services-sr6bs
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-sr6bs to expose endpoints map[]
May 15 07:53:28.322: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-sr6bs exposes endpoints map[] (155.024074ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:53:28.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-sr6bs" for this suite.
May 15 07:53:51.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:53:55.224: INFO: namespace: e2e-tests-services-sr6bs, resource: bindings, ignored listing per whitelist
May 15 07:53:56.773: INFO: namespace e2e-tests-services-sr6bs deletion completed in 28.193479902s
[AfterEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

[32m [SLOW TEST:36.078 seconds][0m
[sig-network] Services
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should serve a basic endpoint from pods  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl replace[0m 
  [1mshould update a single-container pod's image  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:53:56.774: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
May 15 07:53:59.295: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rz8cw'
May 15 07:53:59.749: INFO: stderr: ""
May 15 07:53:59.749: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod is running
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
May 15 07:54:04.850: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rz8cw -o json'
May 15 07:54:05.273: INFO: stderr: ""
May 15 07:54:05.273: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-15T07:53:59Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-rz8cw\",\n        \"resourceVersion\": \"15090\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-rz8cw/pods/e2e-test-nginx-pod\",\n        \"uid\": \"99355b8b-76e6-11e9-8329-42010a8e0130\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-dtmxt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-dtmxt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-dtmxt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-15T07:53:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-15T07:54:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-15T07:54:00Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-15T07:53:59Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://5db5408dd9b023f6291bbae99d27f2de86860e971cbfb812017cc855898572f5\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-15T07:54:00Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.142.0.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.8.2.80\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-15T07:53:59Z\"\n    }\n}\n"
[1mSTEP[0m: replace the image in the pod
May 15 07:54:05.274: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 replace -f - --namespace=e2e-tests-kubectl-rz8cw'
May 15 07:54:05.981: INFO: stderr: ""
May 15 07:54:05.981: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
May 15 07:54:06.051: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rz8cw'
May 15 07:54:07.983: INFO: stderr: ""
May 15 07:54:07.983: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:54:07.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-rz8cw" for this suite.
May 15 07:54:14.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:54:15.100: INFO: namespace: e2e-tests-kubectl-rz8cw, resource: bindings, ignored listing per whitelist
May 15 07:54:21.023: INFO: namespace e2e-tests-kubectl-rz8cw deletion completed in 12.970379197s

[32m [SLOW TEST:24.250 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl replace
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should update a single-container pod's image  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:54:21.023: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-exec in namespace e2e-tests-container-probe-69fcj
May 15 07:54:26.259: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-69fcj
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 15 07:54:26.329: INFO: Initial restart count of pod liveness-exec is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:58:26.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-69fcj" for this suite.
May 15 07:58:33.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:58:33.826: INFO: namespace: e2e-tests-container-probe-69fcj, resource: bindings, ignored listing per whitelist
May 15 07:58:37.219: INFO: namespace e2e-tests-container-probe-69fcj deletion completed in 10.307717238s

[32m [SLOW TEST:256.196 seconds][0m
[k8s.io] Probing container
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould update pod when spec was updated and update strategy is RollingUpdate [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:58:37.219: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 07:58:40.346: INFO: Creating simple daemon set daemon-set
[1mSTEP[0m: Check that daemon pods launch on every node of the cluster.
May 15 07:58:40.658: INFO: Number of nodes with available pods: 0
May 15 07:58:40.658: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 07:58:41.798: INFO: Number of nodes with available pods: 0
May 15 07:58:41.798: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 07:58:42.800: INFO: Number of nodes with available pods: 3
May 15 07:58:42.800: INFO: Number of running nodes: 3, number of available pods: 3
[1mSTEP[0m: Update daemon pods image.
[1mSTEP[0m: Check that daemon pods images are updated.
May 15 07:58:43.441: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:43.441: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:43.441: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:44.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:44.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:44.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:45.586: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:45.586: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:45.586: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:46.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:46.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:46.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:46.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:47.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:47.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:47.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:47.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:48.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:48.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:48.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:48.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:49.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:49.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:49.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:49.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:50.586: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:50.586: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:50.586: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:50.586: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:51.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:51.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:51.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:51.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:52.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:52.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:52.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:52.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:53.586: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:53.586: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:53.586: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:53.586: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:54.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:54.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:54.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:54.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:55.586: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:55.586: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:55.586: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:55.586: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:56.584: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:56.584: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:56.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:56.584: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:57.585: INFO: Wrong image for pod: daemon-set-8f9qq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:57.585: INFO: Pod daemon-set-8f9qq is not available
May 15 07:58:57.585: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:57.585: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:58.607: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:58.607: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:58.607: INFO: Pod daemon-set-txqc8 is not available
May 15 07:58:59.585: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:59.585: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:58:59.585: INFO: Pod daemon-set-txqc8 is not available
May 15 07:59:00.591: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:00.591: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:01.585: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:01.585: INFO: Wrong image for pod: daemon-set-m8btg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:01.585: INFO: Pod daemon-set-m8btg is not available
May 15 07:59:02.674: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:02.674: INFO: Pod daemon-set-x7b6f is not available
May 15 07:59:03.585: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:03.585: INFO: Pod daemon-set-x7b6f is not available
May 15 07:59:04.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:04.584: INFO: Pod daemon-set-8jt7q is not available
May 15 07:59:05.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:05.584: INFO: Pod daemon-set-8jt7q is not available
May 15 07:59:06.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:06.584: INFO: Pod daemon-set-8jt7q is not available
May 15 07:59:07.584: INFO: Wrong image for pod: daemon-set-8jt7q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
May 15 07:59:07.584: INFO: Pod daemon-set-8jt7q is not available
May 15 07:59:08.586: INFO: Pod daemon-set-v5l64 is not available
[1mSTEP[0m: Check that daemon pods are still running on every node of the cluster.
May 15 07:59:08.798: INFO: Number of nodes with available pods: 2
May 15 07:59:08.798: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx is running more than one daemon pod
May 15 07:59:09.940: INFO: Number of nodes with available pods: 3
May 15 07:59:09.940: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-m9vlq, will wait for the garbage collector to delete the pods
May 15 07:59:10.640: INFO: Deleting DaemonSet.extensions daemon-set took: 118.892436ms
May 15 07:59:10.840: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.335335ms
May 15 07:59:18.999: INFO: Number of nodes with available pods: 0
May 15 07:59:19.000: INFO: Number of running nodes: 0, number of available pods: 0
May 15 07:59:19.167: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-m9vlq/daemonsets","resourceVersion":"16150"},"items":null}

May 15 07:59:19.331: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-m9vlq/pods","resourceVersion":"16151"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:59:20.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-m9vlq" for this suite.
May 15 07:59:26.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:59:27.018: INFO: namespace: e2e-tests-daemonsets-m9vlq, resource: bindings, ignored listing per whitelist
May 15 07:59:30.595: INFO: namespace e2e-tests-daemonsets-m9vlq deletion completed in 10.428988376s

[32m [SLOW TEST:53.376 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:59:30.595: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 07:59:33.404: INFO: Waiting up to 5m0s for pod "downwardapi-volume-600f8785-76e7-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-6945j" to be "success or failure"
May 15 07:59:33.510: INFO: Pod "downwardapi-volume-600f8785-76e7-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 106.310589ms
May 15 07:59:35.581: INFO: Pod "downwardapi-volume-600f8785-76e7-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.176858876s
[1mSTEP[0m: Saw pod success
May 15 07:59:35.581: INFO: Pod "downwardapi-volume-600f8785-76e7-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:59:35.651: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-600f8785-76e7-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 07:59:35.885: INFO: Waiting for pod downwardapi-volume-600f8785-76e7-11e9-9e56-3ac139a44f02 to disappear
May 15 07:59:35.993: INFO: Pod downwardapi-volume-600f8785-76e7-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:59:35.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-6945j" for this suite.
May 15 07:59:42.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 07:59:46.506: INFO: namespace: e2e-tests-projected-6945j, resource: bindings, ignored listing per whitelist
May 15 07:59:47.101: INFO: namespace e2e-tests-projected-6945j deletion completed in 11.036442262s

[32m [SLOW TEST:16.505 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should provide container's cpu limit [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 07:59:47.101: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-69e1db66-76e7-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 07:59:49.964: INFO: Waiting up to 5m0s for pod "pod-configmaps-69f1f2d1-76e7-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-gcw4d" to be "success or failure"
May 15 07:59:50.061: INFO: Pod "pod-configmaps-69f1f2d1-76e7-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 96.382956ms
May 15 07:59:52.131: INFO: Pod "pod-configmaps-69f1f2d1-76e7-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.166344634s
[1mSTEP[0m: Saw pod success
May 15 07:59:52.131: INFO: Pod "pod-configmaps-69f1f2d1-76e7-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 07:59:52.200: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-configmaps-69f1f2d1-76e7-11e9-9e56-3ac139a44f02 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 07:59:52.430: INFO: Waiting for pod pod-configmaps-69f1f2d1-76e7-11e9-9e56-3ac139a44f02 to disappear
May 15 07:59:52.538: INFO: Pod pod-configmaps-69f1f2d1-76e7-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 07:59:52.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-gcw4d" for this suite.
May 15 07:59:58.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:00:02.307: INFO: namespace: e2e-tests-configmap-gcw4d, resource: bindings, ignored listing per whitelist
May 15 08:00:03.951: INFO: namespace e2e-tests-configmap-gcw4d deletion completed in 11.318681051s

[32m [SLOW TEST:16.850 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRollingUpdateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:00:03.951: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:00:06.407: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 15 08:00:06.611: INFO: Pod name sample-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
May 15 08:00:08.784: INFO: Creating deployment "test-rolling-update-deployment"
May 15 08:00:08.892: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 15 08:00:09.149: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 15 08:00:09.219: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504008, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504008, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504008, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504008, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:00:11.289: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 15 08:00:11.653: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-mcp84,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mcp84/deployments/test-rolling-update-deployment,UID:753df0aa-76e7-11e9-8329-42010a8e0130,ResourceVersion:16393,Generation:1,CreationTimestamp:2019-05-15 08:00:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-15 08:00:08 +0000 UTC 2019-05-15 08:00:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-15 08:00:10 +0000 UTC 2019-05-15 08:00:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 15 08:00:11.724: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-mcp84,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mcp84/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:754284cc-76e7-11e9-8329-42010a8e0130,ResourceVersion:16385,Generation:1,CreationTimestamp:2019-05-15 08:00:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 753df0aa-76e7-11e9-8329-42010a8e0130 0xc001dfd077 0xc001dfd078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 15 08:00:11.724: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 15 08:00:11.743: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-mcp84,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mcp84/replicasets/test-rolling-update-controller,UID:73d2c62d-76e7-11e9-8329-42010a8e0130,ResourceVersion:16392,Generation:2,CreationTimestamp:2019-05-15 08:00:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 753df0aa-76e7-11e9-8329-42010a8e0130 0xc001dfcce7 0xc001dfcce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 15 08:00:11.815: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-nlpp5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-nlpp5,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-mcp84,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mcp84/pods/test-rolling-update-deployment-68b55d7bc6-nlpp5,UID:754414b9-76e7-11e9-8329-42010a8e0130,ResourceVersion:16384,Generation:0,CreationTimestamp:2019-05-15 08:00:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 754284cc-76e7-11e9-8329-42010a8e0130 0xc001d68b97 0xc001d68b98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hp7sb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hp7sb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hp7sb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d68cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d68d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:00:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:00:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:00:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:00:08 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:10.8.1.102,StartTime:2019-05-15 08:00:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-15 08:00:10 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://87e7253a6326faa547e430865cd9bff8d24b682fb623c44b9061172778285362}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:00:11.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-mcp84" for this suite.
May 15 08:00:18.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:00:18.406: INFO: namespace: e2e-tests-deployment-mcp84, resource: bindings, ignored listing per whitelist
May 15 08:00:22.656: INFO: namespace e2e-tests-deployment-mcp84 deletion completed in 10.76998701s

[32m [SLOW TEST:18.705 seconds][0m
[sig-apps] Deployment
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:00:22.656: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
May 15 08:00:25.368: INFO: Waiting up to 5m0s for pod "downward-api-7f0b7187-76e7-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-wvkqx" to be "success or failure"
May 15 08:00:25.463: INFO: Pod "downward-api-7f0b7187-76e7-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 95.765051ms
May 15 08:00:27.534: INFO: Pod "downward-api-7f0b7187-76e7-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.166043503s
[1mSTEP[0m: Saw pod success
May 15 08:00:27.534: INFO: Pod "downward-api-7f0b7187-76e7-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:00:27.603: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downward-api-7f0b7187-76e7-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:00:28.175: INFO: Waiting for pod downward-api-7f0b7187-76e7-11e9-9e56-3ac139a44f02 to disappear
May 15 08:00:28.292: INFO: Pod downward-api-7f0b7187-76e7-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:00:28.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-wvkqx" for this suite.
May 15 08:00:34.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:00:35.805: INFO: namespace: e2e-tests-downward-api-wvkqx, resource: bindings, ignored listing per whitelist
May 15 08:00:39.311: INFO: namespace e2e-tests-downward-api-wvkqx deletion completed in 10.948008068s

[32m [SLOW TEST:16.654 seconds][0m
[sig-node] Downward API
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:00:39.311: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-88e35482-76e7-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 08:00:41.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-88f2c598-76e7-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-strxw" to be "success or failure"
May 15 08:00:42.086: INFO: Pod "pod-configmaps-88f2c598-76e7-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 103.533559ms
May 15 08:00:44.156: INFO: Pod "pod-configmaps-88f2c598-76e7-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.17369908s
[1mSTEP[0m: Saw pod success
May 15 08:00:44.156: INFO: Pod "pod-configmaps-88f2c598-76e7-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:00:44.226: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-configmaps-88f2c598-76e7-11e9-9e56-3ac139a44f02 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:00:44.444: INFO: Waiting for pod pod-configmaps-88f2c598-76e7-11e9-9e56-3ac139a44f02 to disappear
May 15 08:00:44.546: INFO: Pod pod-configmaps-88f2c598-76e7-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:00:44.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-strxw" for this suite.
May 15 08:00:50.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:00:54.333: INFO: namespace: e2e-tests-configmap-strxw, resource: bindings, ignored listing per whitelist
May 15 08:00:55.711: INFO: namespace e2e-tests-configmap-strxw deletion completed in 11.094758562s

[32m [SLOW TEST:16.400 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:00:55.711: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-93065a99-76e7-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 08:00:59.291: INFO: Waiting up to 5m0s for pod "pod-secrets-9315d302-76e7-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-5pdrj" to be "success or failure"
May 15 08:00:59.395: INFO: Pod "pod-secrets-9315d302-76e7-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 103.680153ms
May 15 08:01:01.465: INFO: Pod "pod-secrets-9315d302-76e7-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.173781936s
[1mSTEP[0m: Saw pod success
May 15 08:01:01.465: INFO: Pod "pod-secrets-9315d302-76e7-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:01:01.535: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-secrets-9315d302-76e7-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:01:02.495: INFO: Waiting for pod pod-secrets-9315d302-76e7-11e9-9e56-3ac139a44f02 to disappear
May 15 08:01:02.660: INFO: Pod pod-secrets-9315d302-76e7-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:01:02.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-5pdrj" for this suite.
May 15 08:01:09.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:01:09.240: INFO: namespace: e2e-tests-secrets-5pdrj, resource: bindings, ignored listing per whitelist
May 15 08:01:13.388: INFO: namespace e2e-tests-secrets-5pdrj deletion completed in 10.646822271s

[32m [SLOW TEST:17.676 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:01:13.388: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:01:15.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d353fa6-76e7-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-j7pcv" to be "success or failure"
May 15 08:01:16.063: INFO: Pod "downwardapi-volume-9d353fa6-76e7-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 96.129965ms
May 15 08:01:18.138: INFO: Pod "downwardapi-volume-9d353fa6-76e7-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.171435952s
[1mSTEP[0m: Saw pod success
May 15 08:01:18.138: INFO: Pod "downwardapi-volume-9d353fa6-76e7-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:01:18.208: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-9d353fa6-76e7-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:01:18.427: INFO: Waiting for pod downwardapi-volume-9d353fa6-76e7-11e9-9e56-3ac139a44f02 to disappear
May 15 08:01:18.527: INFO: Pod downwardapi-volume-9d353fa6-76e7-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:01:18.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-j7pcv" for this suite.
May 15 08:01:24.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:01:28.816: INFO: namespace: e2e-tests-projected-j7pcv, resource: bindings, ignored listing per whitelist
May 15 08:01:29.629: INFO: namespace e2e-tests-projected-j7pcv deletion completed in 11.031335052s

[32m [SLOW TEST:16.241 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should provide container's memory limit [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould have monotonically increasing restart count [Slow][NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:01:29.629: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-rk25n
May 15 08:01:36.453: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-rk25n
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 15 08:01:36.524: INFO: Initial restart count of pod liveness-http is 0
May 15 08:01:46.996: INFO: Restart count of pod e2e-tests-container-probe-rk25n/liveness-http is now 1 (10.472327072s elapsed)
May 15 08:02:07.701: INFO: Restart count of pod e2e-tests-container-probe-rk25n/liveness-http is now 2 (31.177336564s elapsed)
May 15 08:02:28.408: INFO: Restart count of pod e2e-tests-container-probe-rk25n/liveness-http is now 3 (51.884128559s elapsed)
May 15 08:02:47.039: INFO: Restart count of pod e2e-tests-container-probe-rk25n/liveness-http is now 4 (1m10.514376717s elapsed)
May 15 08:03:55.512: INFO: Restart count of pod e2e-tests-container-probe-rk25n/liveness-http is now 5 (2m18.988076841s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:03:55.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-rk25n" for this suite.
May 15 08:04:02.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:04:05.028: INFO: namespace: e2e-tests-container-probe-rk25n, resource: bindings, ignored listing per whitelist
May 15 08:04:06.151: INFO: namespace e2e-tests-container-probe-rk25n deletion completed in 10.413807123s

[32m [SLOW TEST:156.522 seconds][0m
[k8s.io] Probing container
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run pod[0m 
  [1mshould create a pod from an image when restart is Never  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:04:06.151: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
May 15 08:04:08.774: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xwdht'
May 15 08:04:11.691: INFO: stderr: ""
May 15 08:04:11.691: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
May 15 08:04:11.792: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xwdht'
May 15 08:04:14.534: INFO: stderr: ""
May 15 08:04:14.534: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:04:14.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-xwdht" for this suite.
May 15 08:04:22.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:04:23.309: INFO: namespace: e2e-tests-kubectl-xwdht, resource: bindings, ignored listing per whitelist
May 15 08:04:27.212: INFO: namespace e2e-tests-kubectl-xwdht deletion completed in 12.607474912s

[32m [SLOW TEST:21.061 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run pod
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a pod from an image when restart is Never  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] ReplicationController
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:04:27.212: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating replication controller my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02
May 15 08:04:29.864: INFO: Pod name my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02: Found 1 pods out of 1
May 15 08:04:29.864: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02" are running
May 15 08:04:34.046: INFO: Pod "my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02-cmflh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 08:04:29 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 08:04:29 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 08:04:29 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-15 08:04:29 +0000 UTC Reason: Message:}])
May 15 08:04:34.046: INFO: Trying to dial the pod
May 15 08:04:39.333: INFO: Controller my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02: Got expected result from replica 1 [my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02-cmflh]: "my-hostname-basic-10b8dccb-76e8-11e9-9e56-3ac139a44f02-cmflh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:04:39.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-replication-controller-djlbg" for this suite.
May 15 08:04:45.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:04:46.272: INFO: namespace: e2e-tests-replication-controller-djlbg, resource: bindings, ignored listing per whitelist
May 15 08:04:51.405: INFO: namespace e2e-tests-replication-controller-djlbg deletion completed in 12.002280675s

[32m [SLOW TEST:24.193 seconds][0m
[sig-apps] ReplicationController
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should serve a basic image on each replica with a public image  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be submitted and removed [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:04:51.406: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up watch
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: verifying pod creation was observed
May 15 08:04:56.566: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-1f34456f-76e8-11e9-9e56-3ac139a44f02", GenerateName:"", Namespace:"e2e-tests-pods-7p86f", SelfLink:"/api/v1/namespaces/e2e-tests-pods-7p86f/pods/pod-submit-remove-1f34456f-76e8-11e9-9e56-3ac139a44f02", UID:"1f56e494-76e8-11e9-8329-42010a8e0130", ResourceVersion:"17429", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693504294, loc:(*time.Location)(0x7c9e580)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"952044839"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jlwlg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001e8f040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jlwlg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001f20888), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00254ec60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f20900)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f209a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001f209a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001f209ac)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504294, loc:(*time.Location)(0x7c9e580)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504295, loc:(*time.Location)(0x7c9e580)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504295, loc:(*time.Location)(0x7c9e580)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504294, loc:(*time.Location)(0x7c9e580)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.142.0.2", PodIP:"10.8.1.107", StartTime:(*v1.Time)(0xc0012d58e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0012d5900), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760", ContainerID:"docker://b8bdf0f4bdbbe15229c0944f51bde3660b396ba2b3830a097b78bf1e7cbcaf6d"}}, QOSClass:"BestEffort"}}
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
May 15 08:05:01.767: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[1mSTEP[0m: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:05:01.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-7p86f" for this suite.
May 15 08:05:08.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:05:09.749: INFO: namespace: e2e-tests-pods-7p86f, resource: bindings, ignored listing per whitelist
May 15 08:05:12.932: INFO: namespace e2e-tests-pods-7p86f deletion completed in 11.025431582s

[32m [SLOW TEST:21.527 seconds][0m
[k8s.io] Pods
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be submitted and removed [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe an object deletion if it stops meeting the requirements of the selector [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:05:12.932: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a watch on configmaps with a certain label
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: changing the label value of the configmap
[1mSTEP[0m: Expecting to observe a delete notification for the watched object
May 15 08:05:15.988: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wtv8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-wtv8j/configmaps/e2e-watch-test-label-changed,UID:2c176a92-76e8-11e9-8329-42010a8e0130,ResourceVersion:17511,Generation:0,CreationTimestamp:2019-05-15 08:05:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 15 08:05:15.989: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wtv8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-wtv8j/configmaps/e2e-watch-test-label-changed,UID:2c176a92-76e8-11e9-8329-42010a8e0130,ResourceVersion:17512,Generation:0,CreationTimestamp:2019-05-15 08:05:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 15 08:05:15.989: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wtv8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-wtv8j/configmaps/e2e-watch-test-label-changed,UID:2c176a92-76e8-11e9-8329-42010a8e0130,ResourceVersion:17513,Generation:0,CreationTimestamp:2019-05-15 08:05:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: Expecting not to observe a notification because the object no longer meets the selector's requirements
[1mSTEP[0m: changing the label value of the configmap back
[1mSTEP[0m: modifying the configmap a third time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe an add notification for the watched object when the label value was restored
May 15 08:05:26.523: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wtv8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-wtv8j/configmaps/e2e-watch-test-label-changed,UID:2c176a92-76e8-11e9-8329-42010a8e0130,ResourceVersion:17544,Generation:0,CreationTimestamp:2019-05-15 08:05:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 15 08:05:26.523: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wtv8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-wtv8j/configmaps/e2e-watch-test-label-changed,UID:2c176a92-76e8-11e9-8329-42010a8e0130,ResourceVersion:17548,Generation:0,CreationTimestamp:2019-05-15 08:05:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 15 08:05:26.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wtv8j,SelfLink:/api/v1/namespaces/e2e-tests-watch-wtv8j/configmaps/e2e-watch-test-label-changed,UID:2c176a92-76e8-11e9-8329-42010a8e0130,ResourceVersion:17550,Generation:0,CreationTimestamp:2019-05-15 08:05:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:05:26.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-wtv8j" for this suite.
May 15 08:05:32.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:05:33.215: INFO: namespace: e2e-tests-watch-wtv8j, resource: bindings, ignored listing per whitelist
May 15 08:05:37.095: INFO: namespace e2e-tests-watch-wtv8j deletion completed in 10.501456869s

[32m [SLOW TEST:24.163 seconds][0m
[sig-api-machinery] Watchers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Events[0m 
  [1mshould be sent by kubelets and the scheduler about pods scheduling and running  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:05:37.095: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename events
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: retrieving the pod
May 15 08:05:42.347: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-3a5fc72f-76e8-11e9-9e56-3ac139a44f02,GenerateName:,Namespace:e2e-tests-events-nvkph,SelfLink:/api/v1/namespaces/e2e-tests-events-nvkph/pods/send-events-3a5fc72f-76e8-11e9-9e56-3ac139a44f02,UID:3a654e7e-76e8-11e9-8329-42010a8e0130,ResourceVersion:17611,Generation:0,CreationTimestamp:2019-05-15 08:05:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 535663954,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gm7wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gm7wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-gm7wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0025ac560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025ac590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:05:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:05:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:05:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:05:39 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:10.8.2.87,StartTime:2019-05-15 08:05:39 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-15 08:05:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://b51241f4a3ef3a29bbbc3ad0256391b36c40947abf8d8d6356d1b86f43195a3e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

[1mSTEP[0m: checking for scheduler event about the pod
May 15 08:05:44.444: INFO: Saw scheduler event for our pod.
[1mSTEP[0m: checking for kubelet event about the pod
May 15 08:05:46.515: INFO: Saw kubelet event for our pod.
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:05:46.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-events-nvkph" for this suite.
May 15 08:06:28.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:06:32.218: INFO: namespace: e2e-tests-events-nvkph, resource: bindings, ignored listing per whitelist
May 15 08:06:32.543: INFO: namespace e2e-tests-events-nvkph deletion completed in 45.845053115s

[32m [SLOW TEST:55.448 seconds][0m
[k8s.io] [sig-node] Events
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to start watching from a specific resource version [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:06:32.543: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: creating a watch on configmaps from the resource version returned by the first update
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap after the first update
May 15 08:06:36.209: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-5k465,SelfLink:/api/v1/namespaces/e2e-tests-watch-5k465/configmaps/e2e-watch-test-resource-version,UID:5bcb118b-76e8-11e9-8329-42010a8e0130,ResourceVersion:17795,Generation:0,CreationTimestamp:2019-05-15 08:06:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 15 08:06:36.209: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-5k465,SelfLink:/api/v1/namespaces/e2e-tests-watch-5k465/configmaps/e2e-watch-test-resource-version,UID:5bcb118b-76e8-11e9-8329-42010a8e0130,ResourceVersion:17796,Generation:0,CreationTimestamp:2019-05-15 08:06:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:06:36.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-watch-5k465" for this suite.
May 15 08:06:42.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:06:47.132: INFO: namespace: e2e-tests-watch-5k465, resource: bindings, ignored listing per whitelist
May 15 08:06:47.728: INFO: namespace e2e-tests-watch-5k465 deletion completed in 11.422104479s

[32m [SLOW TEST:15.184 seconds][0m
[sig-api-machinery] Watchers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should be able to start watching from a specific resource version [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:06:47.728: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test override arguments
May 15 08:06:50.564: INFO: Waiting up to 5m0s for pod "client-containers-64a4a258-76e8-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-containers-c4wqk" to be "success or failure"
May 15 08:06:50.660: INFO: Pod "client-containers-64a4a258-76e8-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 95.593159ms
May 15 08:06:52.730: INFO: Pod "client-containers-64a4a258-76e8-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.16593139s
[1mSTEP[0m: Saw pod success
May 15 08:06:52.730: INFO: Pod "client-containers-64a4a258-76e8-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:06:52.800: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod client-containers-64a4a258-76e8-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:06:53.359: INFO: Waiting for pod client-containers-64a4a258-76e8-11e9-9e56-3ac139a44f02 to disappear
May 15 08:06:53.460: INFO: Pod client-containers-64a4a258-76e8-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:06:53.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-c4wqk" for this suite.
May 15 08:06:59.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:07:00.202: INFO: namespace: e2e-tests-containers-c4wqk, resource: bindings, ignored listing per whitelist
May 15 08:07:03.806: INFO: namespace e2e-tests-containers-c4wqk deletion completed in 10.275069612s

[32m [SLOW TEST:16.078 seconds][0m
[k8s.io] Docker Containers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl patch[0m 
  [1mshould add annotations for pods in rc  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:07:03.806: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating Redis RC
May 15 08:07:06.266: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-m2qqs'
May 15 08:07:06.916: INFO: stderr: ""
May 15 08:07:06.916: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
May 15 08:07:08.018: INFO: Selector matched 1 pods for map[app:redis]
May 15 08:07:08.018: INFO: Found 0 / 1
May 15 08:07:08.987: INFO: Selector matched 1 pods for map[app:redis]
May 15 08:07:08.987: INFO: Found 1 / 1
May 15 08:07:08.987: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
[1mSTEP[0m: patching all pods
May 15 08:07:09.057: INFO: Selector matched 1 pods for map[app:redis]
May 15 08:07:09.057: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 15 08:07:09.057: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 patch pod redis-master-drtm9 --namespace=e2e-tests-kubectl-m2qqs -p {"metadata":{"annotations":{"x":"y"}}}'
May 15 08:07:09.582: INFO: stderr: ""
May 15 08:07:09.582: INFO: stdout: "pod/redis-master-drtm9 patched\n"
[1mSTEP[0m: checking annotations
May 15 08:07:09.652: INFO: Selector matched 1 pods for map[app:redis]
May 15 08:07:09.652: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:07:09.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-m2qqs" for this suite.
May 15 08:07:31.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:07:33.202: INFO: namespace: e2e-tests-kubectl-m2qqs, resource: bindings, ignored listing per whitelist
May 15 08:07:36.905: INFO: namespace e2e-tests-kubectl-m2qqs deletion completed in 27.182370077s

[32m [SLOW TEST:33.099 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl patch
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should add annotations for pods in rc  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:07:36.905: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-81d99691-76e8-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 08:07:39.683: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-81e9856c-76e8-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-qlnz5" to be "success or failure"
May 15 08:07:39.788: INFO: Pod "pod-projected-secrets-81e9856c-76e8-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 104.190346ms
May 15 08:07:41.858: INFO: Pod "pod-projected-secrets-81e9856c-76e8-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.174260811s
[1mSTEP[0m: Saw pod success
May 15 08:07:41.858: INFO: Pod "pod-projected-secrets-81e9856c-76e8-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:07:41.927: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-secrets-81e9856c-76e8-11e9-9e56-3ac139a44f02 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:07:42.129: INFO: Waiting for pod pod-projected-secrets-81e9856c-76e8-11e9-9e56-3ac139a44f02 to disappear
May 15 08:07:42.224: INFO: Pod pod-projected-secrets-81e9856c-76e8-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:07:42.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-qlnz5" for this suite.
May 15 08:07:49.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:07:53.442: INFO: namespace: e2e-tests-projected-qlnz5, resource: bindings, ignored listing per whitelist
May 15 08:07:53.632: INFO: namespace e2e-tests-projected-qlnz5 deletion completed in 11.338598968s

[32m [SLOW TEST:16.727 seconds][0m
[sig-storage] Projected secret
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34[0m
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide host IP as an env var [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:07:53.632: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
May 15 08:07:56.329: INFO: Waiting up to 5m0s for pod "downward-api-8bd76e67-76e8-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-j7whn" to be "success or failure"
May 15 08:07:56.435: INFO: Pod "downward-api-8bd76e67-76e8-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 106.161594ms
May 15 08:07:58.512: INFO: Pod "downward-api-8bd76e67-76e8-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.183316999s
[1mSTEP[0m: Saw pod success
May 15 08:07:58.512: INFO: Pod "downward-api-8bd76e67-76e8-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:07:58.582: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downward-api-8bd76e67-76e8-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:07:58.830: INFO: Waiting for pod downward-api-8bd76e67-76e8-11e9-9e56-3ac139a44f02 to disappear
May 15 08:07:58.931: INFO: Pod downward-api-8bd76e67-76e8-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:07:58.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-j7whn" for this suite.
May 15 08:08:05.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:08:08.690: INFO: namespace: e2e-tests-downward-api-j7whn, resource: bindings, ignored listing per whitelist
May 15 08:08:11.687: INFO: namespace e2e-tests-downward-api-j7whn deletion completed in 12.685745141s

[32m [SLOW TEST:18.055 seconds][0m
[sig-node] Downward API
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide host IP as an env var [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:08:11.687: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
[1mSTEP[0m: Gathering metrics
W0515 08:08:45.750088    1545 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 15 08:08:45.750: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:08:45.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-n5h84" for this suite.
May 15 08:08:52.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:08:54.624: INFO: namespace: e2e-tests-gc-n5h84, resource: bindings, ignored listing per whitelist
May 15 08:08:57.744: INFO: namespace e2e-tests-gc-n5h84 deletion completed in 11.916885392s

[32m [SLOW TEST:46.057 seconds][0m
[sig-api-machinery] Garbage collector
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRecreateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:08:57.744: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:09:00.266: INFO: Creating deployment "test-recreate-deployment"
May 15 08:09:00.378: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 15 08:09:00.592: INFO: Waiting deployment "test-recreate-deployment" to complete
May 15 08:09:00.662: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504540, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504540, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504540, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693504540, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:09:02.813: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 15 08:09:03.302: INFO: Updating deployment test-recreate-deployment
May 15 08:09:03.302: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 15 08:09:03.684: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-jfmj4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jfmj4/deployments/test-recreate-deployment,UID:b20b9741-76e8-11e9-8329-42010a8e0130,ResourceVersion:18417,Generation:2,CreationTimestamp:2019-05-15 08:09:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-15 08:09:03 +0000 UTC 2019-05-15 08:09:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-15 08:09:03 +0000 UTC 2019-05-15 08:09:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 15 08:09:03.754: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-jfmj4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jfmj4/replicasets/test-recreate-deployment-697fbf54bf,UID:b3dd61d8-76e8-11e9-8329-42010a8e0130,ResourceVersion:18416,Generation:1,CreationTimestamp:2019-05-15 08:09:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b20b9741-76e8-11e9-8329-42010a8e0130 0xc002347317 0xc002347318}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 15 08:09:03.754: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 15 08:09:03.755: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-jfmj4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jfmj4/replicasets/test-recreate-deployment-5dfdcc846d,UID:b20e1c85-76e8-11e9-8329-42010a8e0130,ResourceVersion:18408,Generation:2,CreationTimestamp:2019-05-15 08:09:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b20b9741-76e8-11e9-8329-42010a8e0130 0xc002347257 0xc002347258}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 15 08:09:03.853: INFO: Pod "test-recreate-deployment-697fbf54bf-d24cg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-d24cg,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-jfmj4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jfmj4/pods/test-recreate-deployment-697fbf54bf-d24cg,UID:b3df3d2a-76e8-11e9-8329-42010a8e0130,ResourceVersion:18418,Generation:0,CreationTimestamp:2019-05-15 08:09:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf b3dd61d8-76e8-11e9-8329-42010a8e0130 0xc0022480d7 0xc0022480d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lttjs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lttjs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lttjs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002248160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002248180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:09:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:09:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:09:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:09:03 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:,StartTime:2019-05-15 08:09:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:09:03.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-jfmj4" for this suite.
May 15 08:09:10.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:09:12.725: INFO: namespace: e2e-tests-deployment-jfmj4, resource: bindings, ignored listing per whitelist
May 15 08:09:14.314: INFO: namespace e2e-tests-deployment-jfmj4 deletion completed in 10.390870751s

[32m [SLOW TEST:16.570 seconds][0m
[sig-apps] Deployment
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  RecreateDeployment should delete old pods and create new ones [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,default) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:09:14.314: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on node default medium
May 15 08:09:18.693: INFO: Waiting up to 5m0s for pod "pod-bcb1ac0c-76e8-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-kfwms" to be "success or failure"
May 15 08:09:18.970: INFO: Pod "pod-bcb1ac0c-76e8-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 277.532606ms
May 15 08:09:21.127: INFO: Pod "pod-bcb1ac0c-76e8-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.433963574s
[1mSTEP[0m: Saw pod success
May 15 08:09:21.127: INFO: Pod "pod-bcb1ac0c-76e8-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:09:21.289: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-bcb1ac0c-76e8-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:09:21.642: INFO: Waiting for pod pod-bcb1ac0c-76e8-11e9-9e56-3ac139a44f02 to disappear
May 15 08:09:21.740: INFO: Pod pod-bcb1ac0c-76e8-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:09:21.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-kfwms" for this suite.
May 15 08:09:28.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:09:30.106: INFO: namespace: e2e-tests-emptydir-kfwms, resource: bindings, ignored listing per whitelist
May 15 08:09:33.119: INFO: namespace e2e-tests-emptydir-kfwms deletion completed in 11.308684401s

[32m [SLOW TEST:18.805 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0666,default) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Namespaces [Serial][0m 
  [1mshould ensure that all services are removed when a namespace is deleted [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:09:33.120: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename namespaces
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a test namespace
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[1mSTEP[0m: Creating a service in the namespace
[1mSTEP[0m: Deleting the namespace
[1mSTEP[0m: Waiting for the namespace to be removed.
[1mSTEP[0m: Recreating the namespace
[1mSTEP[0m: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:09:42.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-namespaces-w8qtm" for this suite.
May 15 08:09:49.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:09:53.916: INFO: namespace: e2e-tests-namespaces-w8qtm, resource: bindings, ignored listing per whitelist
May 15 08:09:53.916: INFO: namespace e2e-tests-namespaces-w8qtm deletion completed in 10.961311577s
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-scwg9" for this suite.
May 15 08:09:53.986: INFO: Namespace e2e-tests-nsdeletetest-scwg9 was already deleted
[1mSTEP[0m: Destroying namespace "e2e-tests-nsdeletetest-b9nhb" for this suite.
May 15 08:10:00.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:10:04.214: INFO: namespace: e2e-tests-nsdeletetest-b9nhb, resource: bindings, ignored listing per whitelist
May 15 08:10:04.439: INFO: namespace e2e-tests-nsdeletetest-b9nhb deletion completed in 10.452843266s

[32m [SLOW TEST:31.320 seconds][0m
[sig-api-machinery] Namespaces [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should ensure that all services are removed when a namespace is deleted [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should delete old replica sets [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:10:04.440: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:10:07.599: INFO: Pod name cleanup-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
May 15 08:10:09.823: INFO: Creating deployment test-cleanup-deployment
[1mSTEP[0m: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 15 08:10:12.574: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-5lmlp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5lmlp/deployments/test-cleanup-deployment,UID:db9d7c93-76e8-11e9-8329-42010a8e0130,ResourceVersion:18745,Generation:1,CreationTimestamp:2019-05-15 08:10:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-15 08:10:10 +0000 UTC 2019-05-15 08:10:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-15 08:10:11 +0000 UTC 2019-05-15 08:10:10 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 15 08:10:12.645: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-5lmlp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5lmlp/replicasets/test-cleanup-deployment-7dbbfcf846,UID:dba144a0-76e8-11e9-8329-42010a8e0130,ResourceVersion:18737,Generation:1,CreationTimestamp:2019-05-15 08:10:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment db9d7c93-76e8-11e9-8329-42010a8e0130 0xc001554d77 0xc001554d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 15 08:10:12.716: INFO: Pod "test-cleanup-deployment-7dbbfcf846-4clcw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-4clcw,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-5lmlp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5lmlp/pods/test-cleanup-deployment-7dbbfcf846-4clcw,UID:dba293bd-76e8-11e9-8329-42010a8e0130,ResourceVersion:18736,Generation:0,CreationTimestamp:2019-05-15 08:10:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 dba144a0-76e8-11e9-8329-42010a8e0130 0xc001555bd7 0xc001555bd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5s68l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5s68l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5s68l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001555c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001555c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:10:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:10:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:10:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:10:10 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:10.8.1.115,StartTime:2019-05-15 08:10:10 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-15 08:10:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://de2f25560beac0cf5e30820fd7ef7692e8a97e965644cb1873e562d0e1472fcd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:10:12.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-5lmlp" for this suite.
May 15 08:10:19.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:10:20.702: INFO: namespace: e2e-tests-deployment-5lmlp, resource: bindings, ignored listing per whitelist
May 15 08:10:23.536: INFO: namespace e2e-tests-deployment-5lmlp deletion completed in 10.722995978s

[32m [SLOW TEST:19.096 seconds][0m
[sig-apps] Deployment
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  deployment should delete old replica sets [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop exec hook properly [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:10:23.536: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: delete the pod with lifecycle hook
May 15 08:10:31.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:31.190: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:33.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:33.262: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:35.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:35.260: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:37.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:37.260: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:39.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:39.261: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:41.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:41.261: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:43.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:43.260: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:45.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:45.260: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:47.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:47.261: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:49.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:49.261: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:51.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:51.260: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:53.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:53.261: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:55.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:55.260: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:57.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:57.261: INFO: Pod pod-with-prestop-exec-hook still exists
May 15 08:10:59.190: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 15 08:10:59.260: INFO: Pod pod-with-prestop-exec-hook no longer exists
[1mSTEP[0m: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:10:59.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-xntff" for this suite.
May 15 08:11:21.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:11:24.225: INFO: namespace: e2e-tests-container-lifecycle-hook-xntff, resource: bindings, ignored listing per whitelist
May 15 08:11:26.005: INFO: namespace e2e-tests-container-lifecycle-hook-xntff deletion completed in 26.554005801s

[32m [SLOW TEST:62.469 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-scheduling] SchedulerPredicates [Serial][0m 
  [1mvalidates that NodeSelector is respected if not matching  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:11:26.005: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename sched-pred
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 15 08:11:28.440: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 15 08:11:28.580: INFO: Waiting for terminating namespaces to be deleted...
May 15 08:11:28.693: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz before test
May 15 08:11:28.801: INFO: event-exporter-v0.2.3-f67d895d8-8gtbv from kube-system started at 2019-05-15 06:54:58 +0000 UTC (2 container statuses recorded)
May 15 08:11:28.801: INFO: 	Container event-exporter ready: true, restart count 0
May 15 08:11:28.801: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 08:11:28.801: INFO: prometheus-to-sd-gfglj from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 08:11:28.801: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 08:11:28.801: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz from kube-system started at <nil> (0 container statuses recorded)
May 15 08:11:28.801: INFO: fluentd-gcp-v3.2.0-mmn4z from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 08:11:28.801: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 08:11:28.801: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 08:11:28.801: INFO: l7-default-backend-fd59995cd-qmgxp from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 08:11:28.801: INFO: 	Container default-http-backend ready: true, restart count 0
May 15 08:11:28.801: INFO: kube-dns-6987857fdb-hs77r from kube-system started at 2019-05-15 06:54:58 +0000 UTC (4 container statuses recorded)
May 15 08:11:28.801: INFO: 	Container dnsmasq ready: true, restart count 0
May 15 08:11:28.801: INFO: 	Container kubedns ready: true, restart count 0
May 15 08:11:28.801: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 08:11:28.801: INFO: 	Container sidecar ready: true, restart count 0
May 15 08:11:28.801: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r before test
May 15 08:11:28.907: INFO: heapster-v1.6.0-beta.1-798666ff5c-74dbk from kube-system started at 2019-05-15 06:55:12 +0000 UTC (3 container statuses recorded)
May 15 08:11:28.907: INFO: 	Container heapster ready: true, restart count 0
May 15 08:11:28.907: INFO: 	Container heapster-nanny ready: true, restart count 0
May 15 08:11:28.907: INFO: 	Container prom-to-sd ready: true, restart count 0
May 15 08:11:28.907: INFO: metrics-server-v0.3.1-65cd4f6fd8-4f249 from kube-system started at 2019-05-15 06:55:12 +0000 UTC (2 container statuses recorded)
May 15 08:11:28.908: INFO: 	Container metrics-server ready: true, restart count 0
May 15 08:11:28.908: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 15 08:11:28.908: INFO: prometheus-to-sd-b572x from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 08:11:28.908: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 08:11:28.908: INFO: kube-dns-autoscaler-bb58c6784-j4zhb from kube-system started at 2019-05-15 06:55:12 +0000 UTC (1 container statuses recorded)
May 15 08:11:28.908: INFO: 	Container autoscaler ready: true, restart count 0
May 15 08:11:28.908: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r from kube-system started at <nil> (0 container statuses recorded)
May 15 08:11:28.908: INFO: fluentd-gcp-scaler-68b55c6dc5-596nw from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 08:11:28.908: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 15 08:11:28.908: INFO: fluentd-gcp-v3.2.0-ngtmk from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 08:11:28.908: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 08:11:28.908: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 08:11:28.908: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx before test
May 15 08:11:29.010: INFO: fluentd-gcp-v3.2.0-ljmkc from kube-system started at 2019-05-15 06:55:13 +0000 UTC (2 container statuses recorded)
May 15 08:11:29.010: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 15 08:11:29.010: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 15 08:11:29.010: INFO: prometheus-to-sd-fzxr4 from kube-system started at 2019-05-15 06:54:58 +0000 UTC (1 container statuses recorded)
May 15 08:11:29.010: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 08:11:29.010: INFO: kube-dns-6987857fdb-g4phv from kube-system started at 2019-05-15 06:55:17 +0000 UTC (4 container statuses recorded)
May 15 08:11:29.010: INFO: 	Container dnsmasq ready: true, restart count 0
May 15 08:11:29.010: INFO: 	Container kubedns ready: true, restart count 0
May 15 08:11:29.010: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 15 08:11:29.010: INFO: 	Container sidecar ready: true, restart count 0
May 15 08:11:29.010: INFO: kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Trying to schedule Pod with nonempty NodeSelector.
[1mSTEP[0m: Considering event: 
Type = [Warning], Name = [restricted-pod.159eccf8a2bf41fa], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:11:30.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-sched-pred-6wd5t" for this suite.
May 15 08:11:36.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:11:38.960: INFO: namespace: e2e-tests-sched-pred-6wd5t, resource: bindings, ignored listing per whitelist
May 15 08:11:40.965: INFO: namespace e2e-tests-sched-pred-6wd5t deletion completed in 10.361683161s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

[32m [SLOW TEST:14.960 seconds][0m
[sig-scheduling] SchedulerPredicates [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22[0m
  validates that NodeSelector is respected if not matching  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:11:40.965: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-http in namespace e2e-tests-container-probe-6hfwz
May 15 08:11:45.719: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-6hfwz
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 15 08:11:45.789: INFO: Initial restart count of pod liveness-http is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:15:47.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-6hfwz" for this suite.
May 15 08:15:54.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:15:56.256: INFO: namespace: e2e-tests-container-probe-6hfwz, resource: bindings, ignored listing per whitelist
May 15 08:15:59.357: INFO: namespace e2e-tests-container-probe-6hfwz deletion completed in 11.747310393s

[32m [SLOW TEST:258.392 seconds][0m
[k8s.io] Probing container
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:15:59.357: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:16:02.274: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ad7a9aa6-76e9-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-p2575" to be "success or failure"
May 15 08:16:02.372: INFO: Pod "downwardapi-volume-ad7a9aa6-76e9-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 98.773804ms
May 15 08:16:04.442: INFO: Pod "downwardapi-volume-ad7a9aa6-76e9-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.168607098s
[1mSTEP[0m: Saw pod success
May 15 08:16:04.442: INFO: Pod "downwardapi-volume-ad7a9aa6-76e9-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:16:04.511: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-ad7a9aa6-76e9-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:16:04.727: INFO: Waiting for pod downwardapi-volume-ad7a9aa6-76e9-11e9-9e56-3ac139a44f02 to disappear
May 15 08:16:04.828: INFO: Pod downwardapi-volume-ad7a9aa6-76e9-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:16:04.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-p2575" for this suite.
May 15 08:16:11.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:16:15.303: INFO: namespace: e2e-tests-downward-api-p2575, resource: bindings, ignored listing per whitelist
May 15 08:16:16.007: INFO: namespace e2e-tests-downward-api-p2575 deletion completed in 11.108499898s

[32m [SLOW TEST:16.650 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide podname only [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl describe[0m 
  [1mshould check if kubectl describe prints relevant information for rc and pods  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:16:16.007: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:16:18.515: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 version --client'
May 15 08:16:18.600: INFO: stderr: ""
May 15 08:16:18.600: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13+\", GitVersion:\"v1.13.5-gke.10\", GitCommit:\"f5949b3427099d4e410ef96d6e0fea3cd4794e10\", GitTreeState:\"clean\", BuildDate:\"2019-04-10T19:06:57Z\", GoVersion:\"go1.11.5b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 15 08:16:18.669: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-f94jz'
May 15 08:16:21.836: INFO: stderr: ""
May 15 08:16:21.836: INFO: stdout: "replicationcontroller/redis-master created\n"
May 15 08:16:21.836: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 create -f - --namespace=e2e-tests-kubectl-f94jz'
May 15 08:16:22.476: INFO: stderr: ""
May 15 08:16:22.477: INFO: stdout: "service/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
May 15 08:16:23.578: INFO: Selector matched 1 pods for map[app:redis]
May 15 08:16:23.578: INFO: Found 1 / 1
May 15 08:16:23.578: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 15 08:16:23.649: INFO: Selector matched 1 pods for map[app:redis]
May 15 08:16:23.649: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 15 08:16:23.649: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 describe pod redis-master-whrgp --namespace=e2e-tests-kubectl-f94jz'
May 15 08:16:24.306: INFO: stderr: ""
May 15 08:16:24.306: INFO: stdout: "Name:               redis-master-whrgp\nNamespace:          e2e-tests-kubectl-f94jz\nPriority:           0\nPriorityClassName:  <none>\nNode:               gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx/10.142.0.3\nStart Time:         Wed, 15 May 2019 08:16:21 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.8.2.94\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://b92187a76e903c5ba0ee8edf2ce1bada01c6f3e1c1a7d7b32bcc45dd673dc1e5\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 15 May 2019 08:16:22 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-pcp9f (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-pcp9f:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-pcp9f\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                          Message\n  ----    ------     ----  ----                                                          -------\n  Normal  Scheduled  3s    default-scheduler                                             Successfully assigned e2e-tests-kubectl-f94jz/redis-master-whrgp to gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx\n  Normal  Pulled     2s    kubelet, gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Created container\n  Normal  Started    2s    kubelet, gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx  Started container\n"
May 15 08:16:24.306: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 describe rc redis-master --namespace=e2e-tests-kubectl-f94jz'
May 15 08:16:25.010: INFO: stderr: ""
May 15 08:16:25.010: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-f94jz\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-whrgp\n"
May 15 08:16:25.010: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 describe service redis-master --namespace=e2e-tests-kubectl-f94jz'
May 15 08:16:26.024: INFO: stderr: ""
May 15 08:16:26.025: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-f94jz\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.11.248.61\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.8.2.94:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 15 08:16:26.096: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 describe node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz'
May 15 08:16:26.892: INFO: stderr: ""
May 15 08:16:26.892: INFO: stdout: "Name:               gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/fluentd-ds-ready=true\n                    beta.kubernetes.io/instance-type=n1-standard-2\n                    beta.kubernetes.io/os=linux\n                    cloud.google.com/gke-nodepool=default-pool\n                    cloud.google.com/gke-os-distribution=cos\n                    failure-domain.beta.kubernetes.io/region=us-east1\n                    failure-domain.beta.kubernetes.io/zone=us-east1-d\n                    kubernetes.io/hostname=gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz\nAnnotations:        container.googleapis.com/instance_id: 4226267462338218429\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 15 May 2019 06:54:57 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                          ------  -----------------                 ------------------                ------                       -------\n  FrequentUnregisterNetDevice   False   Wed, 15 May 2019 08:16:17 +0000   Wed, 15 May 2019 06:59:38 +0000   UnregisterNetDevice          node is functioning properly\n  CorruptDockerOverlay2         False   Wed, 15 May 2019 08:16:17 +0000   Wed, 15 May 2019 06:59:38 +0000   CorruptDockerOverlay2        docker overlay2 is functioning properly\n  KernelDeadlock                False   Wed, 15 May 2019 08:16:17 +0000   Wed, 15 May 2019 06:54:36 +0000   KernelHasNoDeadlock          kernel has no deadlock\n  ReadonlyFilesystem            False   Wed, 15 May 2019 08:16:17 +0000   Wed, 15 May 2019 06:54:36 +0000   FilesystemIsNotReadOnly      Filesystem is not read-only\n  FrequentKubeletRestart        False   Wed, 15 May 2019 08:16:17 +0000   Wed, 15 May 2019 06:59:38 +0000   FrequentKubeletRestart       kubelet is functioning properly\n  FrequentDockerRestart         False   Wed, 15 May 2019 08:16:17 +0000   Wed, 15 May 2019 06:59:39 +0000   FrequentDockerRestart        docker is functioning properly\n  FrequentContainerdRestart     False   Wed, 15 May 2019 08:16:17 +0000   Wed, 15 May 2019 06:59:40 +0000   FrequentContainerdRestart    containerd is functioning properly\n  NetworkUnavailable            False   Wed, 15 May 2019 06:55:15 +0000   Wed, 15 May 2019 06:55:15 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure                False   Wed, 15 May 2019 08:16:21 +0000   Wed, 15 May 2019 06:54:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure                  False   Wed, 15 May 2019 08:16:21 +0000   Wed, 15 May 2019 06:54:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure                   False   Wed, 15 May 2019 08:16:21 +0000   Wed, 15 May 2019 06:54:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                         True    Wed, 15 May 2019 08:16:21 +0000   Wed, 15 May 2019 06:54:58 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.142.0.4\n  ExternalIP:   35.237.7.196\n  InternalDNS:  gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz.c.prow-gob-internal-boskos-62.internal\n  Hostname:     gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz.c.prow-gob-internal-boskos-62.internal\nCapacity:\n attachable-volumes-gce-pd:  64\n cpu:                        2\n ephemeral-storage:          98868448Ki\n hugepages-2Mi:              0\n memory:                     7658072Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  64\n cpu:                        1930m\n ephemeral-storage:          47093746742\n hugepages-2Mi:              0\n memory:                     5778008Ki\n pods:                       110\nSystem Info:\n Machine ID:                 18175e9ce98e00960f4b5a68d2113104\n System UUID:                18175E9C-E98E-0096-0F4B-5A68D2113104\n Boot ID:                    0d62b2dd-beed-4b27-8296-8dab42fed76c\n Kernel Version:             4.14.94+\n OS Image:                   Container-Optimized OS from Google\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.3\n Kubelet Version:            v1.13.5-gke.10\n Kube-Proxy Version:         v1.13.5-gke.10\nPodCIDR:                     10.8.0.0/24\nProviderID:                  gce://prow-gob-internal-boskos-62/us-east1-d/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------  ---\n  kube-system                event-exporter-v0.2.3-f67d895d8-8gtbv                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                fluentd-gcp-v3.2.0-mmn4z                                          100m (5%)     1 (51%)     200Mi (3%)       500Mi (8%)     81m\n  kube-system                kube-dns-6987857fdb-hs77r                                         260m (13%)    0 (0%)      110Mi (1%)       170Mi (3%)     81m\n  kube-system                kube-proxy-gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz    100m (5%)     0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                l7-default-backend-fd59995cd-qmgxp                                10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)      81m\n  kube-system                prometheus-to-sd-gfglj                                            1m (0%)       3m (0%)     20Mi (0%)        20Mi (0%)      81m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        471m (24%)  1013m (52%)\n  memory                     350Mi (6%)  710Mi (12%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-gce-pd  0           0\nEvents:                      <none>\n"
May 15 08:16:26.892: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 describe namespace e2e-tests-kubectl-f94jz'
May 15 08:16:27.595: INFO: stderr: ""
May 15 08:16:27.595: INFO: stdout: "Name:         e2e-tests-kubectl-f94jz\nLabels:       e2e-framework=kubectl\n              e2e-run=7129cc3f-76de-11e9-9e56-3ac139a44f02\nAnnotations:  <none>\nStatus:       Active\n\nResource Quotas\n Name:                       gke-resource-quotas\n Resource                    Used  Hard\n --------                    ---   ---\n count/ingresses.extensions  0     100\n count/jobs.batch            0     5k\n pods                        1     1500\n services                    1     500\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:16:27.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-f94jz" for this suite.
May 15 08:16:51.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:16:56.027: INFO: namespace: e2e-tests-kubectl-f94jz, resource: bindings, ignored listing per whitelist
May 15 08:16:56.219: INFO: namespace e2e-tests-kubectl-f94jz deletion completed in 28.52413073s

[32m [SLOW TEST:40.212 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl describe
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould mount an API token into pods  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:16:56.220: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: getting the auto-created API token
[1mSTEP[0m: Creating a pod to test consume service account token
May 15 08:16:59.729: INFO: Waiting up to 5m0s for pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7" in namespace "e2e-tests-svcaccounts-q54gq" to be "success or failure"
May 15 08:16:59.826: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7": Phase="Pending", Reason="", readiness=false. Elapsed: 96.510799ms
May 15 08:17:01.896: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166584652s
May 15 08:17:03.966: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.236933509s
[1mSTEP[0m: Saw pod success
May 15 08:17:03.966: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7" satisfied condition "success or failure"
May 15 08:17:04.036: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7 container token-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:17:04.646: INFO: Waiting for pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7 to disappear
May 15 08:17:04.741: INFO: Pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-vwwk7 no longer exists
[1mSTEP[0m: Creating a pod to test consume service account root CA
May 15 08:17:04.818: INFO: Waiting up to 5m0s for pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-576dk" in namespace "e2e-tests-svcaccounts-q54gq" to be "success or failure"
May 15 08:17:04.936: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-576dk": Phase="Pending", Reason="", readiness=false. Elapsed: 117.629334ms
May 15 08:17:07.007: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-576dk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.188010147s
[1mSTEP[0m: Saw pod success
May 15 08:17:07.007: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-576dk" satisfied condition "success or failure"
May 15 08:17:07.078: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-576dk container root-ca-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:17:07.320: INFO: Waiting for pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-576dk to disappear
May 15 08:17:07.391: INFO: Pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-576dk no longer exists
[1mSTEP[0m: Creating a pod to test consume service account namespace
May 15 08:17:07.471: INFO: Waiting up to 5m0s for pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-4nhp8" in namespace "e2e-tests-svcaccounts-q54gq" to be "success or failure"
May 15 08:17:07.568: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-4nhp8": Phase="Pending", Reason="", readiness=false. Elapsed: 96.995666ms
May 15 08:17:09.638: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-4nhp8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.167656443s
[1mSTEP[0m: Saw pod success
May 15 08:17:09.639: INFO: Pod "pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-4nhp8" satisfied condition "success or failure"
May 15 08:17:09.709: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-4nhp8 container namespace-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:17:09.936: INFO: Waiting for pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-4nhp8 to disappear
May 15 08:17:10.005: INFO: Pod pod-service-account-cfbc473d-76e9-11e9-9e56-3ac139a44f02-4nhp8 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:17:10.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svcaccounts-q54gq" for this suite.
May 15 08:17:16.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:17:17.483: INFO: namespace: e2e-tests-svcaccounts-q54gq, resource: bindings, ignored listing per whitelist
May 15 08:17:22.029: INFO: namespace e2e-tests-svcaccounts-q54gq deletion completed in 11.953320034s

[32m [SLOW TEST:25.810 seconds][0m
[sig-auth] ServiceAccounts
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22[0m
  should mount an API token into pods  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow composing env vars into new env vars [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:17:22.030: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test env composition
May 15 08:17:24.682: INFO: Waiting up to 5m0s for pod "var-expansion-de9b764f-76e9-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-var-expansion-998kx" to be "success or failure"
May 15 08:17:24.786: INFO: Pod "var-expansion-de9b764f-76e9-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 103.923316ms
May 15 08:17:26.858: INFO: Pod "var-expansion-de9b764f-76e9-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.175493233s
[1mSTEP[0m: Saw pod success
May 15 08:17:26.858: INFO: Pod "var-expansion-de9b764f-76e9-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:17:26.927: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod var-expansion-de9b764f-76e9-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:17:27.140: INFO: Waiting for pod var-expansion-de9b764f-76e9-11e9-9e56-3ac139a44f02 to disappear
May 15 08:17:27.236: INFO: Pod var-expansion-de9b764f-76e9-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:17:27.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-998kx" for this suite.
May 15 08:17:33.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:17:34.207: INFO: namespace: e2e-tests-var-expansion-998kx, resource: bindings, ignored listing per whitelist
May 15 08:17:38.336: INFO: namespace e2e-tests-var-expansion-998kx deletion completed in 11.029701099s

[32m [SLOW TEST:16.306 seconds][0m
[k8s.io] Variable Expansion
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve multiport endpoints from pods  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:17:38.336: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating service multi-endpoint-test in namespace e2e-tests-services-nzqzg
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nzqzg to expose endpoints map[]
May 15 08:17:41.054: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nzqzg exposes endpoints map[] (96.479367ms elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace e2e-tests-services-nzqzg
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nzqzg to expose endpoints map[pod1:[100]]
May 15 08:17:43.612: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nzqzg exposes endpoints map[pod1:[100]] (2.443048726s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace e2e-tests-services-nzqzg
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nzqzg to expose endpoints map[pod1:[100] pod2:[101]]
May 15 08:17:46.344: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nzqzg exposes endpoints map[pod1:[100] pod2:[101]] (2.655174121s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace e2e-tests-services-nzqzg
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nzqzg to expose endpoints map[pod2:[101]]
May 15 08:17:46.588: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nzqzg exposes endpoints map[pod2:[101]] (139.523932ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace e2e-tests-services-nzqzg
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-nzqzg to expose endpoints map[]
May 15 08:17:46.755: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-nzqzg exposes endpoints map[] (69.217127ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:17:46.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-services-nzqzg" for this suite.
May 15 08:18:09.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:18:12.390: INFO: namespace: e2e-tests-services-nzqzg, resource: bindings, ignored listing per whitelist
May 15 08:18:14.203: INFO: namespace e2e-tests-services-nzqzg deletion completed in 27.25187294s
[AfterEach] [sig-network] Services
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

[32m [SLOW TEST:35.868 seconds][0m
[sig-network] Services
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should serve multiport endpoints from pods  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] KubeletManagedEtcHosts[0m 
  [1mshould test kubelet managed /etc/hosts file [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:18:14.204: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename e2e-kubelet-etc-hosts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Setting up the test
[1mSTEP[0m: Creating hostNetwork=false pod
[1mSTEP[0m: Creating hostNetwork=true pod
[1mSTEP[0m: Running the test
[1mSTEP[0m: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 15 08:18:21.342: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:21.342: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:22.014: INFO: Exec stderr: ""
May 15 08:18:22.014: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:22.014: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:22.650: INFO: Exec stderr: ""
May 15 08:18:22.650: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:22.650: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:23.777: INFO: Exec stderr: ""
May 15 08:18:23.778: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:23.778: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:24.410: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 15 08:18:24.410: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:24.410: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:25.037: INFO: Exec stderr: ""
May 15 08:18:25.037: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:25.037: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:25.668: INFO: Exec stderr: ""
[1mSTEP[0m: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 15 08:18:25.668: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:25.668: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:26.302: INFO: Exec stderr: ""
May 15 08:18:26.302: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:26.302: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:26.899: INFO: Exec stderr: ""
May 15 08:18:26.899: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:26.899: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:27.518: INFO: Exec stderr: ""
May 15 08:18:27.518: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kq6nw PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 15 08:18:27.518: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
May 15 08:18:28.123: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:18:28.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-kq6nw" for this suite.
May 15 08:19:10.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:19:11.034: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-kq6nw, resource: bindings, ignored listing per whitelist
May 15 08:19:14.324: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-kq6nw deletion completed in 46.130300277s

[32m [SLOW TEST:60.120 seconds][0m
[k8s.io] KubeletManagedEtcHosts
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould set DefaultMode on files [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:19:14.324: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:19:18.787: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-sgrpk" to be "success or failure"
May 15 08:19:18.969: INFO: Pod "downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 182.773956ms
May 15 08:19:21.129: INFO: Pod "downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.342715622s
May 15 08:19:23.199: INFO: Pod "downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.412532225s
[1mSTEP[0m: Saw pod success
May 15 08:19:23.199: INFO: Pod "downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:19:23.273: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:19:23.501: INFO: Waiting for pod downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02 to disappear
May 15 08:19:23.607: INFO: Pod downwardapi-volume-2268c02c-76ea-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:19:23.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-sgrpk" for this suite.
May 15 08:19:29.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:19:33.832: INFO: namespace: e2e-tests-projected-sgrpk, resource: bindings, ignored listing per whitelist
May 15 08:19:34.417: INFO: namespace e2e-tests-projected-sgrpk deletion completed in 10.699313113s

[32m [SLOW TEST:20.093 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should set DefaultMode on files [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for the cluster  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] DNS
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:19:34.418: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;check="$$(dig +notcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/wheezy_udp@google.com;check="$$(dig +tcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@google.com;check="$$(dig +notcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/wheezy_udp@metadata;check="$$(dig +tcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@metadata;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-sbfc7.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-sbfc7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-sbfc7.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;check="$$(dig +notcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/jessie_udp@google.com;check="$$(dig +tcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/jessie_tcp@google.com;check="$$(dig +notcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/jessie_udp@metadata;check="$$(dig +tcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/jessie_tcp@metadata;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-sbfc7.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-sbfc7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-sbfc7.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
May 15 08:19:49.559: INFO: DNS probes using e2e-tests-dns-sbfc7/dns-test-2d811814-76ea-11e9-9e56-3ac139a44f02 succeeded

[1mSTEP[0m: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:19:49.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-dns-sbfc7" for this suite.
May 15 08:19:56.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:19:58.312: INFO: namespace: e2e-tests-dns-sbfc7, resource: bindings, ignored listing per whitelist
May 15 08:20:01.332: INFO: namespace e2e-tests-dns-sbfc7 deletion completed in 11.59450082s

[32m [SLOW TEST:26.914 seconds][0m
[sig-network] DNS
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should provide DNS for the cluster  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support proportional scaling [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:20:01.332: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:20:03.944: INFO: Creating deployment "nginx-deployment"
May 15 08:20:04.064: INFO: Waiting for observed generation 1
May 15 08:20:04.216: INFO: Waiting for all required pods to come up
May 15 08:20:04.355: INFO: Pod name nginx: Found 4 pods out of 10
May 15 08:20:09.429: INFO: Pod name nginx: Found 10 pods out of 10
[1mSTEP[0m: ensuring each pod is running
May 15 08:20:09.429: INFO: Waiting for deployment "nginx-deployment" to complete
May 15 08:20:09.601: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 15 08:20:10.162: INFO: Updating deployment nginx-deployment
May 15 08:20:10.162: INFO: Waiting for observed generation 2
May 15 08:20:12.330: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 15 08:20:12.430: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 15 08:20:12.500: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 15 08:20:12.709: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 15 08:20:12.709: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 15 08:20:12.811: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 15 08:20:12.950: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 15 08:20:12.950: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 15 08:20:13.093: INFO: Updating deployment nginx-deployment
May 15 08:20:13.093: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 15 08:20:13.270: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 15 08:20:15.444: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 15 08:20:15.612: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kmg7l/deployments/nginx-deployment,UID:3da371f7-76ea-11e9-8329-42010a8e0130,ResourceVersion:21032,Generation:3,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-15 08:20:13 +0000 UTC 2019-05-15 08:20:13 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-15 08:20:13 +0000 UTC 2019-05-15 08:20:04 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 15 08:20:15.683: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kmg7l/replicasets/nginx-deployment-65bbdb5f8,UID:4146f11c-76ea-11e9-8329-42010a8e0130,ResourceVersion:21031,Generation:3,CreationTimestamp:2019-05-15 08:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3da371f7-76ea-11e9-8329-42010a8e0130 0xc0023a79c7 0xc0023a79c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 15 08:20:15.683: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 15 08:20:15.683: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-kmg7l/replicasets/nginx-deployment-555b55d965,UID:3da5f31a-76ea-11e9-8329-42010a8e0130,ResourceVersion:21023,Generation:3,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3da371f7-76ea-11e9-8329-42010a8e0130 0xc0023a78e7 0xc0023a78e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 15 08:20:15.755: INFO: Pod "nginx-deployment-555b55d965-2zl48" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2zl48,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-2zl48,UID:43159730-76ea-11e9-8329-42010a8e0130,ResourceVersion:21050,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc001b7f5e7 0xc001b7f5e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b7f650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b7f670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.756: INFO: Pod "nginx-deployment-555b55d965-5psp7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5psp7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-5psp7,UID:4315b1a2-76ea-11e9-8329-42010a8e0130,ResourceVersion:21008,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc001b7f720 0xc001b7f721}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b7fb00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b7fb80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.756: INFO: Pod "nginx-deployment-555b55d965-64ml7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-64ml7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-64ml7,UID:432671da-76ea-11e9-8329-42010a8e0130,ResourceVersion:21048,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc001b7fc50 0xc001b7fc51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b7fcb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b7fcd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.756: INFO: Pod "nginx-deployment-555b55d965-687sd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-687sd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-687sd,UID:3dc51315-76ea-11e9-8329-42010a8e0130,ResourceVersion:20895,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc001b7fd80 0xc001b7fd81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027742e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002774300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:10.8.2.102,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://8e6f11e0049f86c76abcdafc1ca482885785904ea997d0c3d087eedc0e60c0e8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.756: INFO: Pod "nginx-deployment-555b55d965-6h6td" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6h6td,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-6h6td,UID:430bbbcd-76ea-11e9-8329-42010a8e0130,ResourceVersion:20998,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc0027743c0 0xc0027743c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002774420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002774650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.756: INFO: Pod "nginx-deployment-555b55d965-8dxw4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8dxw4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-8dxw4,UID:3dc4a79a-76ea-11e9-8329-42010a8e0130,ResourceVersion:20888,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002774700 0xc002774701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027747e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002774800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:10.8.2.100,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://42301adcf8f9821896689cccdf9247ace71d18bafea955131eafcfae0b824a86}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.756: INFO: Pod "nginx-deployment-555b55d965-8kpdv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8kpdv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-8kpdv,UID:4315ab87-76ea-11e9-8329-42010a8e0130,ResourceVersion:21027,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002774920 0xc002774921}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002774a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002774a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.757: INFO: Pod "nginx-deployment-555b55d965-d6vt8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d6vt8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-d6vt8,UID:43267727-76ea-11e9-8329-42010a8e0130,ResourceVersion:21035,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002774ae0 0xc002774ae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002774c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002774c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.757: INFO: Pod "nginx-deployment-555b55d965-d7zzx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d7zzx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-d7zzx,UID:3dc51b2e-76ea-11e9-8329-42010a8e0130,ResourceVersion:20904,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002774d40 0xc002774d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002774db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002774f00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:10.8.1.125,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://03f14bb60cb36e85f6692e9cec7c1c7331e72661c5b24d8edf9088781e11cb0c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.757: INFO: Pod "nginx-deployment-555b55d965-dr829" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dr829,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-dr829,UID:3daeadbb-76ea-11e9-8329-42010a8e0130,ResourceVersion:20877,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002774fd0 0xc002774fd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002775050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:10.8.1.123,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://d78d1ce54916bb932863dc84fd36a09e0684454f37f7e195311374037e416247}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.757: INFO: Pod "nginx-deployment-555b55d965-dwh89" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dwh89,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-dwh89,UID:43261971-76ea-11e9-8329-42010a8e0130,ResourceVersion:21033,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002775200 0xc002775201}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002775280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.757: INFO: Pod "nginx-deployment-555b55d965-hfxf9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hfxf9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-hfxf9,UID:43078681-76ea-11e9-8329-42010a8e0130,ResourceVersion:20986,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc0027753c0 0xc0027753c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002775440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.758: INFO: Pod "nginx-deployment-555b55d965-mppdd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mppdd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-mppdd,UID:430c0f7f-76ea-11e9-8329-42010a8e0130,ResourceVersion:20990,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc0027754f0 0xc0027754f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027755a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.758: INFO: Pod "nginx-deployment-555b55d965-sm8kl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sm8kl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-sm8kl,UID:4317192c-76ea-11e9-8329-42010a8e0130,ResourceVersion:21037,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002775650 0xc002775651}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027756b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027756d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.758: INFO: Pod "nginx-deployment-555b55d965-srzw9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-srzw9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-srzw9,UID:3dd62f91-76ea-11e9-8329-42010a8e0130,ResourceVersion:20891,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002775810 0xc002775811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027758a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:10.8.2.101,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://74689fa9a479f5ae7807e3e34a6fa2182c90cd0f090840a228b809eb43912fe2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.758: INFO: Pod "nginx-deployment-555b55d965-wc67x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wc67x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-wc67x,UID:4326690f-76ea-11e9-8329-42010a8e0130,ResourceVersion:21040,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002775a10 0xc002775a11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002775b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.758: INFO: Pod "nginx-deployment-555b55d965-wj89h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wj89h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-wj89h,UID:3db93279-76ea-11e9-8329-42010a8e0130,ResourceVersion:20880,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc002775b90 0xc002775b91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002775fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279e090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:10.8.0.31,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://538f674c160113e6adb7d6833f17f8145bb24e7442cf8fc3989178ce89c121b1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.759: INFO: Pod "nginx-deployment-555b55d965-wjp86" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wjp86,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-wjp86,UID:3dd57844-76ea-11e9-8329-42010a8e0130,ResourceVersion:20883,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc00279e150 0xc00279e151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279e1b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279e1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:10.8.0.32,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://d5d884bdd33ffdb5145e3c6e5471389f1fc586db79e85bf54c6c495482bff491}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.759: INFO: Pod "nginx-deployment-555b55d965-z56l9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z56l9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-z56l9,UID:3db73562-76ea-11e9-8329-42010a8e0130,ResourceVersion:20898,Generation:0,CreationTimestamp:2019-05-15 08:20:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc00279e390 0xc00279e391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279e3f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279e410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:04 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:10.8.2.99,StartTime:2019-05-15 08:20:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-15 08:20:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 docker://d673fb88901d6c3329075da29c5dd5b44bccde0012304a064f6a3122708de5a1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.759: INFO: Pod "nginx-deployment-555b55d965-zz6qg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zz6qg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-555b55d965-zz6qg,UID:432628df-76ea-11e9-8329-42010a8e0130,ResourceVersion:21052,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3da5f31a-76ea-11e9-8329-42010a8e0130 0xc00279e590 0xc00279e591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279e680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279e6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.759: INFO: Pod "nginx-deployment-65bbdb5f8-5bmgk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5bmgk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-5bmgk,UID:41674b9e-76ea-11e9-8329-42010a8e0130,ResourceVersion:20953,Generation:0,CreationTimestamp:2019-05-15 08:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279e910 0xc00279e911}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279e980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279e9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:,StartTime:2019-05-15 08:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.759: INFO: Pod "nginx-deployment-65bbdb5f8-6c75g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6c75g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-6c75g,UID:4338a48d-76ea-11e9-8329-42010a8e0130,ResourceVersion:21038,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279eca0 0xc00279eca1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279ed10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279ed30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.759: INFO: Pod "nginx-deployment-65bbdb5f8-7pdnj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7pdnj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-7pdnj,UID:43115ea4-76ea-11e9-8329-42010a8e0130,ResourceVersion:21018,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279edf0 0xc00279edf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279eee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279ef00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.760: INFO: Pod "nginx-deployment-65bbdb5f8-bffg9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bffg9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-bffg9,UID:430954b4-76ea-11e9-8329-42010a8e0130,ResourceVersion:20992,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279efc0 0xc00279efc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279f030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279f050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.760: INFO: Pod "nginx-deployment-65bbdb5f8-bzknv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bzknv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-bzknv,UID:43267c77-76ea-11e9-8329-42010a8e0130,ResourceVersion:21030,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279f3d0 0xc00279f3d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279f440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279f460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.760: INFO: Pod "nginx-deployment-65bbdb5f8-j6v7n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j6v7n,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-j6v7n,UID:414d786e-76ea-11e9-8329-42010a8e0130,ResourceVersion:20961,Generation:0,CreationTimestamp:2019-05-15 08:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279f780 0xc00279f781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279f7f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279f810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:10.8.2.103,StartTime:2019-05-15 08:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.762: INFO: Pod "nginx-deployment-65bbdb5f8-jnvqw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jnvqw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-jnvqw,UID:4169c5c7-76ea-11e9-8329-42010a8e0130,ResourceVersion:20968,Generation:0,CreationTimestamp:2019-05-15 08:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279f900 0xc00279f901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279f9b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279f9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:10.8.1.128,StartTime:2019-05-15 08:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.762: INFO: Pod "nginx-deployment-65bbdb5f8-mqmlb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mqmlb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-mqmlb,UID:414878f0-76ea-11e9-8329-42010a8e0130,ResourceVersion:20966,Generation:0,CreationTimestamp:2019-05-15 08:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279fb10 0xc00279fb11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279fbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279fbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:10.8.1.127,StartTime:2019-05-15 08:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.762: INFO: Pod "nginx-deployment-65bbdb5f8-mz7sr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mz7sr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-mz7sr,UID:414d495f-76ea-11e9-8329-42010a8e0130,ResourceVersion:20959,Generation:0,CreationTimestamp:2019-05-15 08:20:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279fcb0 0xc00279fcb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279fdb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279fdd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:10 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:10.8.0.33,StartTime:2019-05-15 08:20:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.762: INFO: Pod "nginx-deployment-65bbdb5f8-rqnl5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rqnl5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-rqnl5,UID:4310b64f-76ea-11e9-8329-42010a8e0130,ResourceVersion:21003,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc00279feb0 0xc00279feb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00279ff90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00279ffb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.4,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.763: INFO: Pod "nginx-deployment-65bbdb5f8-w29hb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-w29hb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-w29hb,UID:4326821a-76ea-11e9-8329-42010a8e0130,ResourceVersion:21047,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc0022d6070 0xc0022d6071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022d6170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022d6190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.763: INFO: Pod "nginx-deployment-65bbdb5f8-x948k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x948k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-x948k,UID:432686b9-76ea-11e9-8329-42010a8e0130,ResourceVersion:21021,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc0022d6250 0xc0022d6251}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022d62c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022d62e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 15 08:20:15.763: INFO: Pod "nginx-deployment-65bbdb5f8-xhsgd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xhsgd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-kmg7l,SelfLink:/api/v1/namespaces/e2e-tests-deployment-kmg7l/pods/nginx-deployment-65bbdb5f8-xhsgd,UID:4325d6d2-76ea-11e9-8329-42010a8e0130,ResourceVersion:21028,Generation:0,CreationTimestamp:2019-05-15 08:20:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4146f11c-76ea-11e9-8329-42010a8e0130 0xc0022d63d0 0xc0022d63d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4zjkm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4zjkm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4zjkm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022d6440} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022d6460}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:20:13 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.3,PodIP:,StartTime:2019-05-15 08:20:13 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:20:15.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-kmg7l" for this suite.
May 15 08:20:24.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:20:27.904: INFO: namespace: e2e-tests-deployment-kmg7l, resource: bindings, ignored listing per whitelist
May 15 08:20:28.354: INFO: namespace e2e-tests-deployment-kmg7l deletion completed in 12.50659049s

[32m [SLOW TEST:27.022 seconds][0m
[sig-apps] Deployment
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  deployment should support proportional scaling [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume as non-root [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:20:28.354: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-4d9b3087-76ea-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 08:20:31.007: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-rz8qt" to be "success or failure"
May 15 08:20:31.235: INFO: Pod "pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 227.68816ms
May 15 08:20:33.305: INFO: Pod "pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02": Phase="Running", Reason="", readiness=true. Elapsed: 2.29785633s
May 15 08:20:35.376: INFO: Pod "pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.368739538s
[1mSTEP[0m: Saw pod success
May 15 08:20:35.376: INFO: Pod "pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:20:35.447: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:20:35.655: INFO: Waiting for pod pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02 to disappear
May 15 08:20:35.752: INFO: Pod pod-projected-configmaps-4daac5d0-76ea-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:20:35.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-rz8qt" for this suite.
May 15 08:20:42.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:20:42.320: INFO: namespace: e2e-tests-projected-rz8qt, resource: bindings, ignored listing per whitelist
May 15 08:20:48.305: INFO: namespace e2e-tests-projected-rz8qt deletion completed in 12.483496197s

[32m [SLOW TEST:19.951 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command that always fails in a pod[0m 
  [1mshould have an terminated reason [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:20:48.306: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:20:55.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubelet-test-z2x9t" for this suite.
May 15 08:21:01.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:21:05.804: INFO: namespace: e2e-tests-kubelet-test-z2x9t, resource: bindings, ignored listing per whitelist
May 15 08:21:06.196: INFO: namespace e2e-tests-kubelet-test-z2x9t deletion completed in 10.938224452s

[32m [SLOW TEST:17.891 seconds][0m
[k8s.io] Kubelet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when scheduling a busybox command that always fails in a pod
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78[0m
    should have an terminated reason [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir wrapper volumes[0m 
  [1mshould not conflict [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:21:06.197: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir-wrapper
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Cleaning up the secret
[1mSTEP[0m: Cleaning up the configmap
[1mSTEP[0m: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:21:11.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-wrapper-tdk9q" for this suite.
May 15 08:21:17.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:21:21.124: INFO: namespace: e2e-tests-emptydir-wrapper-tdk9q, resource: bindings, ignored listing per whitelist
May 15 08:21:23.110: INFO: namespace e2e-tests-emptydir-wrapper-tdk9q deletion completed in 11.403421202s

[32m [SLOW TEST:16.913 seconds][0m
[sig-storage] EmptyDir wrapper volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  should not conflict [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould use the image defaults if command and args are blank [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:21:23.110: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test use defaults
May 15 08:21:25.848: INFO: Waiting up to 5m0s for pod "client-containers-6e5b3d3c-76ea-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-containers-4rxzz" to be "success or failure"
May 15 08:21:25.950: INFO: Pod "client-containers-6e5b3d3c-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 102.527186ms
May 15 08:21:28.020: INFO: Pod "client-containers-6e5b3d3c-76ea-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.172304506s
[1mSTEP[0m: Saw pod success
May 15 08:21:28.020: INFO: Pod "client-containers-6e5b3d3c-76ea-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:21:28.090: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod client-containers-6e5b3d3c-76ea-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:21:28.314: INFO: Waiting for pod client-containers-6e5b3d3c-76ea-11e9-9e56-3ac139a44f02 to disappear
May 15 08:21:28.418: INFO: Pod client-containers-6e5b3d3c-76ea-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:21:28.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-containers-4rxzz" for this suite.
May 15 08:21:34.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:21:37.411: INFO: namespace: e2e-tests-containers-4rxzz, resource: bindings, ignored listing per whitelist
May 15 08:21:39.207: INFO: namespace e2e-tests-containers-4rxzz deletion completed in 10.718179715s

[32m [SLOW TEST:16.097 seconds][0m
[k8s.io] Docker Containers
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with projected pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:21:39.207: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-projected-qvdl
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
May 15 08:21:42.057: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-qvdl" in namespace "e2e-tests-subpath-qzc4s" to be "success or failure"
May 15 08:21:42.159: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Pending", Reason="", readiness=false. Elapsed: 102.024225ms
May 15 08:21:44.230: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.172297224s
May 15 08:21:46.300: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 4.242701684s
May 15 08:21:48.370: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 6.312853571s
May 15 08:21:50.440: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 8.383050036s
May 15 08:21:52.511: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 10.453370972s
May 15 08:21:54.580: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 12.523277916s
May 15 08:21:56.651: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 14.593921474s
May 15 08:21:58.721: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 16.66415042s
May 15 08:22:00.792: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 18.734595948s
May 15 08:22:02.865: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Running", Reason="", readiness=false. Elapsed: 20.808277595s
May 15 08:22:04.936: INFO: Pod "pod-subpath-test-projected-qvdl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.878660506s
[1mSTEP[0m: Saw pod success
May 15 08:22:04.936: INFO: Pod "pod-subpath-test-projected-qvdl" satisfied condition "success or failure"
May 15 08:22:05.005: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-subpath-test-projected-qvdl container test-container-subpath-projected-qvdl: <nil>
[1mSTEP[0m: delete the pod
May 15 08:22:05.248: INFO: Waiting for pod pod-subpath-test-projected-qvdl to disappear
May 15 08:22:05.351: INFO: Pod pod-subpath-test-projected-qvdl no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-projected-qvdl
May 15 08:22:05.351: INFO: Deleting pod "pod-subpath-test-projected-qvdl" in namespace "e2e-tests-subpath-qzc4s"
[AfterEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:22:05.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-qzc4s" for this suite.
May 15 08:22:11.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:22:16.591: INFO: namespace: e2e-tests-subpath-qzc4s, resource: bindings, ignored listing per whitelist
May 15 08:22:16.591: INFO: namespace e2e-tests-subpath-qzc4s deletion completed in 11.097019375s

[32m [SLOW TEST:37.384 seconds][0m
[sig-storage] Subpath
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with projected pod [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node with explicit kubelet port using proxy subresource  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] version v1
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:22:16.591: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:22:19.424: INFO: (0) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 106.517984ms)
May 15 08:22:19.498: INFO: (1) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 74.115008ms)
May 15 08:22:19.570: INFO: (2) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.848776ms)
May 15 08:22:19.642: INFO: (3) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.448651ms)
May 15 08:22:19.714: INFO: (4) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.850373ms)
May 15 08:22:19.786: INFO: (5) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.083909ms)
May 15 08:22:19.859: INFO: (6) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.57206ms)
May 15 08:22:19.931: INFO: (7) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.869092ms)
May 15 08:22:20.003: INFO: (8) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.103271ms)
May 15 08:22:20.075: INFO: (9) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.047135ms)
May 15 08:22:20.148: INFO: (10) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.310419ms)
May 15 08:22:20.221: INFO: (11) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 73.635653ms)
May 15 08:22:20.293: INFO: (12) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.724583ms)
May 15 08:22:20.371: INFO: (13) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 77.875709ms)
May 15 08:22:20.443: INFO: (14) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.026931ms)
May 15 08:22:20.517: INFO: (15) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 73.918227ms)
May 15 08:22:20.589: INFO: (16) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 71.884795ms)
May 15 08:22:20.662: INFO: (17) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.437873ms)
May 15 08:22:20.734: INFO: (18) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.004136ms)
May 15 08:22:20.806: INFO: (19) /api/v1/nodes/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 72.036954ms)
[AfterEach] version v1
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:22:20.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-proxy-xgtpl" for this suite.
May 15 08:22:27.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:22:29.808: INFO: namespace: e2e-tests-proxy-xgtpl, resource: bindings, ignored listing per whitelist
May 15 08:22:32.004: INFO: namespace e2e-tests-proxy-xgtpl deletion completed in 11.128618568s

[32m [SLOW TEST:15.414 seconds][0m
[sig-network] Proxy
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:22:32.005: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:22:34.671: INFO: Waiting up to 5m0s for pod "downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-29gpz" to be "success or failure"
May 15 08:22:34.765: INFO: Pod "downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 93.535906ms
May 15 08:22:36.837: INFO: Pod "downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02": Phase="Running", Reason="", readiness=true. Elapsed: 2.165824758s
May 15 08:22:38.908: INFO: Pod "downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.236980708s
[1mSTEP[0m: Saw pod success
May 15 08:22:38.908: INFO: Pod "downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:22:38.977: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:22:39.189: INFO: Waiting for pod downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02 to disappear
May 15 08:22:39.464: INFO: Pod downwardapi-volume-975d0d39-76ea-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:22:39.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-29gpz" for this suite.
May 15 08:22:45.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:22:47.957: INFO: namespace: e2e-tests-projected-29gpz, resource: bindings, ignored listing per whitelist
May 15 08:22:50.599: INFO: namespace e2e-tests-projected-29gpz deletion completed in 11.064260202s

[32m [SLOW TEST:18.594 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should provide container's cpu request [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:22:50.599: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:23:12.009: INFO: Container started at 2019-05-15 08:22:54 +0000 UTC, pod became ready at 2019-05-15 08:23:10 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:23:12.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-gnn2s" for this suite.
May 15 08:23:34.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:23:35.371: INFO: namespace: e2e-tests-container-probe-gnn2s, resource: bindings, ignored listing per whitelist
May 15 08:23:39.316: INFO: namespace e2e-tests-container-probe-gnn2s deletion completed in 27.209678074s

[32m [SLOW TEST:48.717 seconds][0m
[k8s.io] Probing container
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mvolume on default medium should have the correct mode [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:23:39.316: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir volume type on node default medium
May 15 08:23:41.941: INFO: Waiting up to 5m0s for pod "pod-bf796d52-76ea-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-gftb2" to be "success or failure"
May 15 08:23:42.036: INFO: Pod "pod-bf796d52-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 94.644378ms
May 15 08:23:44.105: INFO: Pod "pod-bf796d52-76ea-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.164525746s
[1mSTEP[0m: Saw pod success
May 15 08:23:44.105: INFO: Pod "pod-bf796d52-76ea-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:23:44.175: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-bf796d52-76ea-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:23:44.395: INFO: Waiting for pod pod-bf796d52-76ea-11e9-9e56-3ac139a44f02 to disappear
May 15 08:23:44.490: INFO: Pod pod-bf796d52-76ea-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:23:44.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-gftb2" for this suite.
May 15 08:23:50.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:23:55.898: INFO: namespace: e2e-tests-emptydir-gftb2, resource: bindings, ignored listing per whitelist
May 15 08:23:55.994: INFO: namespace e2e-tests-emptydir-gftb2 deletion completed in 11.431215288s

[32m [SLOW TEST:16.678 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:23:55.994: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-c95f8429-76ea-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 08:23:58.644: INFO: Waiting up to 5m0s for pod "pod-secrets-c96e5fb2-76ea-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-h2vfw" to be "success or failure"
May 15 08:23:58.759: INFO: Pod "pod-secrets-c96e5fb2-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 115.238875ms
May 15 08:24:00.830: INFO: Pod "pod-secrets-c96e5fb2-76ea-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.186505275s
[1mSTEP[0m: Saw pod success
May 15 08:24:00.830: INFO: Pod "pod-secrets-c96e5fb2-76ea-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:24:00.900: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-secrets-c96e5fb2-76ea-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:24:01.143: INFO: Waiting for pod pod-secrets-c96e5fb2-76ea-11e9-9e56-3ac139a44f02 to disappear
May 15 08:24:01.256: INFO: Pod pod-secrets-c96e5fb2-76ea-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:24:01.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-h2vfw" for this suite.
May 15 08:24:07.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:24:09.730: INFO: namespace: e2e-tests-secrets-h2vfw, resource: bindings, ignored listing per whitelist
May 15 08:24:12.159: INFO: namespace e2e-tests-secrets-h2vfw deletion completed in 10.833432958s

[32m [SLOW TEST:16.165 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould support remote command execution over websockets [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:24:12.160: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:24:15.090: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:24:18.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-pods-mcv4x" for this suite.
May 15 08:24:57.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:25:02.203: INFO: namespace: e2e-tests-pods-mcv4x, resource: bindings, ignored listing per whitelist
May 15 08:25:02.203: INFO: namespace e2e-tests-pods-mcv4x deletion completed in 43.497064803s

[32m [SLOW TEST:50.043 seconds][0m
[k8s.io] Pods
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should support remote command execution over websockets [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's command [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:25:02.203: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test substitution in container's command
May 15 08:25:04.888: INFO: Waiting up to 5m0s for pod "var-expansion-f0e9b95c-76ea-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-var-expansion-2zttc" to be "success or failure"
May 15 08:25:05.314: INFO: Pod "var-expansion-f0e9b95c-76ea-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 425.37981ms
May 15 08:25:07.385: INFO: Pod "var-expansion-f0e9b95c-76ea-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.496191796s
[1mSTEP[0m: Saw pod success
May 15 08:25:07.385: INFO: Pod "var-expansion-f0e9b95c-76ea-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:25:07.455: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod var-expansion-f0e9b95c-76ea-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:25:08.065: INFO: Waiting for pod var-expansion-f0e9b95c-76ea-11e9-9e56-3ac139a44f02 to disappear
May 15 08:25:08.160: INFO: Pod var-expansion-f0e9b95c-76ea-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:25:08.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-var-expansion-2zttc" for this suite.
May 15 08:25:14.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:25:15.382: INFO: namespace: e2e-tests-var-expansion-2zttc, resource: bindings, ignored listing per whitelist
May 15 08:25:19.189: INFO: namespace e2e-tests-var-expansion-2zttc deletion completed in 10.857024315s

[32m [SLOW TEST:16.986 seconds][0m
[k8s.io] Variable Expansion
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:25:19.189: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
May 15 08:25:24.873: INFO: Successfully updated pod "labelsupdatefb07288c-76ea-11e9-9e56-3ac139a44f02"
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:25:27.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-4h746" for this suite.
May 15 08:25:49.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:25:52.497: INFO: namespace: e2e-tests-downward-api-4h746, resource: bindings, ignored listing per whitelist
May 15 08:25:53.282: INFO: namespace e2e-tests-downward-api-4h746 deletion completed in 26.18275285s

[32m [SLOW TEST:34.093 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should update labels on modification [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:25:53.283: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name s-test-opt-del-0f510ef7-76eb-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating secret with name s-test-opt-upd-0f510f80-76eb-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-0f510ef7-76eb-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Updating secret s-test-opt-upd-0f510f80-76eb-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating secret with name s-test-opt-create-0f510fa4-76eb-11e9-9e56-3ac139a44f02
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:26:01.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-mvj45" for this suite.
May 15 08:26:23.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:26:24.292: INFO: namespace: e2e-tests-secrets-mvj45, resource: bindings, ignored listing per whitelist
May 15 08:26:30.547: INFO: namespace e2e-tests-secrets-mvj45 deletion completed in 28.964872226s

[32m [SLOW TEST:37.265 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] PreStop[0m 
  [1mshould call prestop when killing a pod  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:26:30.548: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename prestop
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating server pod server in namespace e2e-tests-prestop-fq4s4
[1mSTEP[0m: Waiting for pods to come up.
[1mSTEP[0m: Creating tester pod tester in namespace e2e-tests-prestop-fq4s4
[1mSTEP[0m: Deleting pre-stop pod
May 15 08:26:44.980: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
[1mSTEP[0m: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:26:45.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-prestop-fq4s4" for this suite.
May 15 08:27:23.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:27:25.256: INFO: namespace: e2e-tests-prestop-fq4s4, resource: bindings, ignored listing per whitelist
May 15 08:27:28.158: INFO: namespace e2e-tests-prestop-fq4s4 deletion completed in 43.003159383s

[32m [SLOW TEST:57.610 seconds][0m
[k8s.io] [sig-node] PreStop
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should call prestop when killing a pod  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with configmap pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:27:28.158: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-configmap-lmc7
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
May 15 08:27:31.581: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lmc7" in namespace "e2e-tests-subpath-bpjs2" to be "success or failure"
May 15 08:27:31.685: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Pending", Reason="", readiness=false. Elapsed: 103.956705ms
May 15 08:27:33.755: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.173793031s
May 15 08:27:35.825: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 4.243723051s
May 15 08:27:37.895: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 6.313952153s
May 15 08:27:39.966: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 8.384350091s
May 15 08:27:42.036: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 10.454927468s
May 15 08:27:44.106: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 12.525304876s
May 15 08:27:46.177: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 14.595468183s
May 15 08:27:48.247: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 16.665880372s
May 15 08:27:50.321: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 18.739904855s
May 15 08:27:52.391: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Running", Reason="", readiness=false. Elapsed: 20.810043162s
May 15 08:27:54.461: INFO: Pod "pod-subpath-test-configmap-lmc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.880265257s
[1mSTEP[0m: Saw pod success
May 15 08:27:54.461: INFO: Pod "pod-subpath-test-configmap-lmc7" satisfied condition "success or failure"
May 15 08:27:54.531: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-subpath-test-configmap-lmc7 container test-container-subpath-configmap-lmc7: <nil>
[1mSTEP[0m: delete the pod
May 15 08:27:54.745: INFO: Waiting for pod pod-subpath-test-configmap-lmc7 to disappear
May 15 08:27:54.843: INFO: Pod pod-subpath-test-configmap-lmc7 no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-configmap-lmc7
May 15 08:27:54.843: INFO: Deleting pod "pod-subpath-test-configmap-lmc7" in namespace "e2e-tests-subpath-bpjs2"
[AfterEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:27:54.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-bpjs2" for this suite.
May 15 08:28:01.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:28:01.901: INFO: namespace: e2e-tests-subpath-bpjs2, resource: bindings, ignored listing per whitelist
May 15 08:28:08.817: INFO: namespace e2e-tests-subpath-bpjs2 deletion completed in 13.802300487s

[32m [SLOW TEST:40.659 seconds][0m
[sig-storage] Subpath
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with configmap pod [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:28:08.818: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:28:11.359: INFO: Waiting up to 5m0s for pod "downwardapi-volume-600f90a6-76eb-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-n28zw" to be "success or failure"
May 15 08:28:11.455: INFO: Pod "downwardapi-volume-600f90a6-76eb-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 95.485006ms
May 15 08:28:13.525: INFO: Pod "downwardapi-volume-600f90a6-76eb-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.165776043s
[1mSTEP[0m: Saw pod success
May 15 08:28:13.525: INFO: Pod "downwardapi-volume-600f90a6-76eb-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:28:13.595: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downwardapi-volume-600f90a6-76eb-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:28:13.808: INFO: Waiting for pod downwardapi-volume-600f90a6-76eb-11e9-9e56-3ac139a44f02 to disappear
May 15 08:28:13.912: INFO: Pod downwardapi-volume-600f90a6-76eb-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:28:13.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-n28zw" for this suite.
May 15 08:28:20.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:28:23.612: INFO: namespace: e2e-tests-projected-n28zw, resource: bindings, ignored listing per whitelist
May 15 08:28:24.897: INFO: namespace e2e-tests-projected-n28zw deletion completed in 10.915166477s

[32m [SLOW TEST:16.080 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should provide podname only [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide pod UID as env vars [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:28:24.898: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward api env vars
May 15 08:28:28.513: INFO: Waiting up to 5m0s for pod "downward-api-69fb88ef-76eb-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-bkxrd" to be "success or failure"
May 15 08:28:28.938: INFO: Pod "downward-api-69fb88ef-76eb-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 425.430112ms
May 15 08:28:31.009: INFO: Pod "downward-api-69fb88ef-76eb-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.495642591s
[1mSTEP[0m: Saw pod success
May 15 08:28:31.009: INFO: Pod "downward-api-69fb88ef-76eb-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:28:31.079: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downward-api-69fb88ef-76eb-11e9-9e56-3ac139a44f02 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:28:31.316: INFO: Waiting for pod downward-api-69fb88ef-76eb-11e9-9e56-3ac139a44f02 to disappear
May 15 08:28:31.418: INFO: Pod downward-api-69fb88ef-76eb-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:28:31.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-bkxrd" for this suite.
May 15 08:28:37.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:28:39.767: INFO: namespace: e2e-tests-downward-api-bkxrd, resource: bindings, ignored listing per whitelist
May 15 08:28:42.656: INFO: namespace e2e-tests-downward-api-bkxrd deletion completed in 11.167932838s

[32m [SLOW TEST:17.758 seconds][0m
[sig-node] Downward API
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38[0m
  should provide pod UID as env vars [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mScaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:28:42.656: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace e2e-tests-statefulset-nj9jt
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Initializing watcher for selector baz=blah,foo=bar
[1mSTEP[0m: Creating stateful set ss in namespace e2e-tests-statefulset-nj9jt
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-nj9jt
May 15 08:28:45.884: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 15 08:28:56.004: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 15 08:28:56.074: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 08:28:57.146: INFO: stderr: ""
May 15 08:28:57.146: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 08:28:57.146: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 08:28:57.217: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 15 08:29:07.289: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 15 08:29:07.289: INFO: Waiting for statefulset status.replicas updated to 0
May 15 08:29:07.635: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998947s
May 15 08:29:08.705: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.929873638s
May 15 08:29:09.778: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.859753991s
May 15 08:29:10.848: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.787036561s
May 15 08:29:11.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.716606637s
May 15 08:29:12.990: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.646417663s
May 15 08:29:14.060: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.574839203s
May 15 08:29:15.131: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.504338519s
May 15 08:29:16.323: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.434060949s
May 15 08:29:17.491: INFO: Verifying statefulset ss doesn't scale past 1 for another 241.103735ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-nj9jt
May 15 08:29:18.739: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:29:20.197: INFO: stderr: ""
May 15 08:29:20.197: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 08:29:20.197: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 08:29:20.357: INFO: Found 1 stateful pods, waiting for 3
May 15 08:29:30.428: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 15 08:29:30.428: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 15 08:29:30.428: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Verifying that stateful set ss was scaled up in order
[1mSTEP[0m: Scale down will halt with unhealthy stateful pod
May 15 08:29:30.595: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 08:29:31.700: INFO: stderr: ""
May 15 08:29:31.700: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 08:29:31.700: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 08:29:31.700: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 08:29:32.823: INFO: stderr: ""
May 15 08:29:32.823: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 08:29:32.823: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 08:29:32.823: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 15 08:29:33.933: INFO: stderr: ""
May 15 08:29:33.933: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 15 08:29:33.933: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 15 08:29:33.933: INFO: Waiting for statefulset status.replicas updated to 0
May 15 08:29:34.003: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 15 08:29:44.145: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 15 08:29:44.146: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 15 08:29:44.146: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 15 08:29:44.371: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999328s
May 15 08:29:45.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.921194678s
May 15 08:29:46.515: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.847734583s
May 15 08:29:47.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.777132304s
May 15 08:29:48.744: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.620181085s
May 15 08:29:49.815: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.547557374s
May 15 08:29:50.886: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.47671438s
May 15 08:29:51.956: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.406134821s
May 15 08:29:53.026: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.335507138s
May 15 08:29:54.101: INFO: Verifying statefulset ss doesn't scale past 3 for another 265.688213ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-nj9jt
May 15 08:29:55.171: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:29:56.151: INFO: stderr: ""
May 15 08:29:56.151: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 08:29:56.151: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 08:29:56.152: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:29:57.134: INFO: stderr: ""
May 15 08:29:57.134: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 15 08:29:57.134: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 15 08:29:57.134: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:29:57.815: INFO: rc: 1
May 15 08:29:57.815: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc00175d9e0 exit status 1 <nil> <nil> true [0xc00000fe70 0xc00000fee8 0xc00000ff28] [0xc00000fe70 0xc00000fee8 0xc00000ff28] [0xc00000fec0 0xc00000ff20] [0x938580 0x938580] 0xc001b12300 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May 15 08:30:07.815: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:30:08.184: INFO: rc: 1
May 15 08:30:08.185: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0008401e0 exit status 1 <nil> <nil> true [0xc00000ff30 0xc00000ff60 0xc00000ff88] [0xc00000ff30 0xc00000ff60 0xc00000ff88] [0xc00000ff40 0xc00000ff80] [0x938580 0x938580] 0xc001b12600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:30:18.185: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:30:18.585: INFO: rc: 1
May 15 08:30:18.585: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000840f30 exit status 1 <nil> <nil> true [0xc00000ff90 0xc00000ffb0 0xc00000ffe0] [0xc00000ff90 0xc00000ffb0 0xc00000ffe0] [0xc00000ffa0 0xc00000ffd8] [0x938580 0x938580] 0xc001b12900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:30:28.585: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:30:28.954: INFO: rc: 1
May 15 08:30:28.955: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000841830 exit status 1 <nil> <nil> true [0xc000a82000 0xc000a82018 0xc000a82030] [0xc000a82000 0xc000a82018 0xc000a82030] [0xc000a82010 0xc000a82028] [0x938580 0x938580] 0xc001b12c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:30:38.955: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:30:39.328: INFO: rc: 1
May 15 08:30:39.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000da4120 exit status 1 <nil> <nil> true [0xc0022200e8 0xc002220100 0xc002220118] [0xc0022200e8 0xc002220100 0xc002220118] [0xc0022200f8 0xc002220110] [0x938580 0x938580] 0xc00257f9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:30:49.329: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:30:49.701: INFO: rc: 1
May 15 08:30:49.702: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000da4a20 exit status 1 <nil> <nil> true [0xc002220120 0xc002220138 0xc002220150] [0xc002220120 0xc002220138 0xc002220150] [0xc002220130 0xc002220148] [0x938580 0x938580] 0xc00257fe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:30:59.702: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:31:00.134: INFO: rc: 1
May 15 08:31:00.134: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000da51d0 exit status 1 <nil> <nil> true [0xc002220158 0xc002220170 0xc002220188] [0xc002220158 0xc002220170 0xc002220188] [0xc002220168 0xc002220180] [0x938580 0x938580] 0xc0022bc240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:31:10.135: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:31:10.508: INFO: rc: 1
May 15 08:31:10.508: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00175d200 exit status 1 <nil> <nil> true [0xc00000e168 0xc00000e560 0xc00000eb00] [0xc00000e168 0xc00000e560 0xc00000eb00] [0xc00000e2f0 0xc00000e998] [0x938580 0x938580] 0xc00255e060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:31:20.508: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:31:20.880: INFO: rc: 1
May 15 08:31:20.880: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017dea80 exit status 1 <nil> <nil> true [0xc000182000 0xc0003bf568 0xc0003bfb00] [0xc000182000 0xc0003bf568 0xc0003bfb00] [0xc0003bf550 0xc0003bfa80] [0x938580 0x938580] 0xc00257f680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:31:30.880: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:31:31.361: INFO: rc: 1
May 15 08:31:31.361: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017dfaa0 exit status 1 <nil> <nil> true [0xc0003bfb38 0xc0003bfb70 0xc0003bfbd8] [0xc0003bfb38 0xc0003bfb70 0xc0003bfbd8] [0xc0003bfb60 0xc0003bfb80] [0x938580 0x938580] 0xc00257f980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:31:41.362: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:31:41.729: INFO: rc: 1
May 15 08:31:41.729: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00246aab0 exit status 1 <nil> <nil> true [0xc002220000 0xc002220018 0xc002220030] [0xc002220000 0xc002220018 0xc002220030] [0xc002220010 0xc002220028] [0x938580 0x938580] 0xc0027f4240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:31:51.729: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:31:52.103: INFO: rc: 1
May 15 08:31:52.103: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00191a8a0 exit status 1 <nil> <nil> true [0xc000a82000 0xc000a82018 0xc000a82030] [0xc000a82000 0xc000a82018 0xc000a82030] [0xc000a82010 0xc000a82028] [0x938580 0x938580] 0xc0025c6000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:32:02.104: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:32:02.478: INFO: rc: 1
May 15 08:32:02.478: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00191b350 exit status 1 <nil> <nil> true [0xc000a82038 0xc000a82050 0xc000a82068] [0xc000a82038 0xc000a82050 0xc000a82068] [0xc000a82048 0xc000a82060] [0x938580 0x938580] 0xc0025c6300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:32:12.479: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:32:12.867: INFO: rc: 1
May 15 08:32:12.867: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00243e3c0 exit status 1 <nil> <nil> true [0xc0003bfbf8 0xc0003bfca8 0xc0003bfce8] [0xc0003bfbf8 0xc0003bfca8 0xc0003bfce8] [0xc0003bfc60 0xc0003bfcd0] [0x938580 0x938580] 0xc00257fe00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:32:22.867: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:32:23.247: INFO: rc: 1
May 15 08:32:23.247: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00191bc20 exit status 1 <nil> <nil> true [0xc000a82070 0xc000a82088 0xc000a820a0] [0xc000a82070 0xc000a82088 0xc000a820a0] [0xc000a82080 0xc000a82098] [0x938580 0x938580] 0xc0025c6600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:32:33.247: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:32:33.628: INFO: rc: 1
May 15 08:32:33.629: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002506750 exit status 1 <nil> <nil> true [0xc000a820a8 0xc000a820c0 0xc000a820d8] [0xc000a820a8 0xc000a820c0 0xc000a820d8] [0xc000a820b8 0xc000a820d0] [0x938580 0x938580] 0xc0025c6900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:32:43.629: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:32:44.007: INFO: rc: 1
May 15 08:32:44.007: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025072c0 exit status 1 <nil> <nil> true [0xc000a820e0 0xc000a820f8 0xc000a82110] [0xc000a820e0 0xc000a820f8 0xc000a82110] [0xc000a820f0 0xc000a82108] [0x938580 0x938580] 0xc0025c6cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:32:54.008: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:32:54.388: INFO: rc: 1
May 15 08:32:54.388: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002507ef0 exit status 1 <nil> <nil> true [0xc000a82118 0xc000a82130 0xc000a82148] [0xc000a82118 0xc000a82130 0xc000a82148] [0xc000a82128 0xc000a82140] [0x938580 0x938580] 0xc0025c6fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:33:04.388: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:33:04.830: INFO: rc: 1
May 15 08:33:04.830: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00121a810 exit status 1 <nil> <nil> true [0xc000a82150 0xc000a82168 0xc000a82180] [0xc000a82150 0xc000a82168 0xc000a82180] [0xc000a82160 0xc000a82178] [0x938580 0x938580] 0xc0025c72c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:33:14.831: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:33:15.207: INFO: rc: 1
May 15 08:33:15.207: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002506ba0 exit status 1 <nil> <nil> true [0xc0003bf1e0 0xc0003bfa68 0xc0003bfb38] [0xc0003bf1e0 0xc0003bfa68 0xc0003bfb38] [0xc0003bf568 0xc0003bfb00] [0x938580 0x938580] 0xc000e53020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:33:25.207: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:33:25.578: INFO: rc: 1
May 15 08:33:25.579: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002507560 exit status 1 <nil> <nil> true [0xc0003bfb58 0xc0003bfb78 0xc0003bfbf8] [0xc0003bfb58 0xc0003bfb78 0xc0003bfbf8] [0xc0003bfb70 0xc0003bfbd8] [0x938580 0x938580] 0xc0020e9ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:33:35.579: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:33:35.953: INFO: rc: 1
May 15 08:33:35.954: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017de360 exit status 1 <nil> <nil> true [0xc0003bfc30 0xc0003bfcb8 0xc0003bfd00] [0xc0003bfc30 0xc0003bfcb8 0xc0003bfd00] [0xc0003bfca8 0xc0003bfce8] [0x938580 0x938580] 0xc00257f620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:33:45.954: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:33:46.330: INFO: rc: 1
May 15 08:33:46.330: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00246aae0 exit status 1 <nil> <nil> true [0xc002220000 0xc002220018 0xc002220030] [0xc002220000 0xc002220018 0xc002220030] [0xc002220010 0xc002220028] [0x938580 0x938580] 0xc0027f45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:33:56.331: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:33:56.706: INFO: rc: 1
May 15 08:33:56.706: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017df110 exit status 1 <nil> <nil> true [0xc0003bfd40 0xc0003bfda0 0xc0003bfde0] [0xc0003bfd40 0xc0003bfda0 0xc0003bfde0] [0xc0003bfd68 0xc0003bfdc8] [0x938580 0x938580] 0xc00257f920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:34:06.706: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:34:07.080: INFO: rc: 1
May 15 08:34:07.080: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00243e990 exit status 1 <nil> <nil> true [0xc000a82000 0xc000a82018 0xc000a82030] [0xc000a82000 0xc000a82018 0xc000a82030] [0xc000a82010 0xc000a82028] [0x938580 0x938580] 0xc0025c6240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:34:17.080: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:34:17.699: INFO: rc: 1
May 15 08:34:17.699: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00246b4d0 exit status 1 <nil> <nil> true [0xc002220038 0xc002220050 0xc002220068] [0xc002220038 0xc002220050 0xc002220068] [0xc002220048 0xc002220060] [0x938580 0x938580] 0xc0027f4ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:34:27.700: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:34:28.075: INFO: rc: 1
May 15 08:34:28.075: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00246bd10 exit status 1 <nil> <nil> true [0xc002220070 0xc002220088 0xc0022200a0] [0xc002220070 0xc002220088 0xc0022200a0] [0xc002220080 0xc002220098] [0x938580 0x938580] 0xc00255e120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:34:38.075: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:34:38.450: INFO: rc: 1
May 15 08:34:38.450: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00191a870 exit status 1 <nil> <nil> true [0xc00000e010 0xc00000e2f0 0xc00000e998] [0xc00000e010 0xc00000e2f0 0xc00000e998] [0xc00000e1a8 0xc00000e770] [0x938580 0x938580] 0xc0020f6240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:34:48.450: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:34:48.825: INFO: rc: 1
May 15 08:34:48.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017dfda0 exit status 1 <nil> <nil> true [0xc0003bfdf8 0xc0003bfe28 0xc0003bfea0] [0xc0003bfdf8 0xc0003bfe28 0xc0003bfea0] [0xc0003bfe10 0xc0003bfe58] [0x938580 0x938580] 0xc00257fda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 15 08:34:58.826: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 exec --namespace=e2e-tests-statefulset-nj9jt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 15 08:34:59.199: INFO: rc: 1
May 15 08:34:59.200: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
May 15 08:34:59.200: INFO: Scaling statefulset ss to 0
[1mSTEP[0m: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 15 08:34:59.518: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nj9jt
May 15 08:34:59.617: INFO: Scaling statefulset ss to 0
May 15 08:34:59.826: INFO: Waiting for statefulset status.replicas updated to 0
May 15 08:34:59.896: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:35:00.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-statefulset-nj9jt" for this suite.
May 15 08:35:07.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:35:09.789: INFO: namespace: e2e-tests-statefulset-nj9jt, resource: bindings, ignored listing per whitelist
May 15 08:35:11.396: INFO: namespace e2e-tests-statefulset-nj9jt deletion completed in 10.656257956s

[32m [SLOW TEST:388.740 seconds][0m
[sig-apps] StatefulSet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:35:11.396: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-5bf60cc4-76ec-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 08:35:14.075: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c04ec88-76ec-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-zzxmc" to be "success or failure"
May 15 08:35:14.169: INFO: Pod "pod-projected-configmaps-5c04ec88-76ec-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 93.495165ms
May 15 08:35:16.239: INFO: Pod "pod-projected-configmaps-5c04ec88-76ec-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.163600882s
[1mSTEP[0m: Saw pod success
May 15 08:35:16.239: INFO: Pod "pod-projected-configmaps-5c04ec88-76ec-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:35:16.308: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-configmaps-5c04ec88-76ec-11e9-9e56-3ac139a44f02 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:35:17.020: INFO: Waiting for pod pod-projected-configmaps-5c04ec88-76ec-11e9-9e56-3ac139a44f02 to disappear
May 15 08:35:17.117: INFO: Pod pod-projected-configmaps-5c04ec88-76ec-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:35:17.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-zzxmc" for this suite.
May 15 08:35:23.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:35:24.104: INFO: namespace: e2e-tests-projected-zzxmc, resource: bindings, ignored listing per whitelist
May 15 08:35:27.707: INFO: namespace e2e-tests-projected-zzxmc deletion completed in 10.482160266s

[32m [SLOW TEST:16.311 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart http hook properly [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:35:27.708: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
May 15 08:35:35.097: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 15 08:35:35.199: INFO: Pod pod-with-poststart-http-hook still exists
May 15 08:35:37.199: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 15 08:35:37.273: INFO: Pod pod-with-poststart-http-hook still exists
May 15 08:35:39.199: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 15 08:35:39.269: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:35:39.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-hc8wv" for this suite.
May 15 08:36:01.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:36:05.210: INFO: namespace: e2e-tests-container-lifecycle-hook-hc8wv, resource: bindings, ignored listing per whitelist
May 15 08:36:06.969: INFO: namespace e2e-tests-container-lifecycle-hook-hc8wv deletion completed in 27.629077318s

[32m [SLOW TEST:39.261 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute poststart http hook properly [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:36:06.969: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating the pod
May 15 08:36:12.563: INFO: Successfully updated pod "labelsupdate7d10af1a-76ec-11e9-9e56-3ac139a44f02"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:36:14.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-gggc7" for this suite.
May 15 08:36:37.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:36:37.598: INFO: namespace: e2e-tests-projected-gggc7, resource: bindings, ignored listing per whitelist
May 15 08:36:41.463: INFO: namespace e2e-tests-projected-gggc7 deletion completed in 26.675926528s

[32m [SLOW TEST:34.493 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should update labels on modification [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:36:41.463: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:36:44.055: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91a65aa5-76ec-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-cxdj4" to be "success or failure"
May 15 08:36:44.162: INFO: Pod "downwardapi-volume-91a65aa5-76ec-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 106.857399ms
May 15 08:36:46.232: INFO: Pod "downwardapi-volume-91a65aa5-76ec-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.177015323s
[1mSTEP[0m: Saw pod success
May 15 08:36:46.232: INFO: Pod "downwardapi-volume-91a65aa5-76ec-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:36:46.302: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod downwardapi-volume-91a65aa5-76ec-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:36:46.518: INFO: Waiting for pod downwardapi-volume-91a65aa5-76ec-11e9-9e56-3ac139a44f02 to disappear
May 15 08:36:46.619: INFO: Pod downwardapi-volume-91a65aa5-76ec-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:36:46.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-cxdj4" for this suite.
May 15 08:36:52.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:36:57.602: INFO: namespace: e2e-tests-downward-api-cxdj4, resource: bindings, ignored listing per whitelist
May 15 08:36:57.903: INFO: namespace e2e-tests-downward-api-cxdj4 deletion completed in 11.214355831s

[32m [SLOW TEST:16.441 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide container's memory limit [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:36:57.904: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:37:00.540: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b79f21f-76ec-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-downward-api-wljdj" to be "success or failure"
May 15 08:37:00.634: INFO: Pod "downwardapi-volume-9b79f21f-76ec-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 94.48358ms
May 15 08:37:02.756: INFO: Pod "downwardapi-volume-9b79f21f-76ec-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.21609198s
[1mSTEP[0m: Saw pod success
May 15 08:37:02.756: INFO: Pod "downwardapi-volume-9b79f21f-76ec-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:37:02.827: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downwardapi-volume-9b79f21f-76ec-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:37:03.055: INFO: Waiting for pod downwardapi-volume-9b79f21f-76ec-11e9-9e56-3ac139a44f02 to disappear
May 15 08:37:03.149: INFO: Pod downwardapi-volume-9b79f21f-76ec-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:37:03.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-downward-api-wljdj" for this suite.
May 15 08:37:09.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:37:13.547: INFO: namespace: e2e-tests-downward-api-wljdj, resource: bindings, ignored listing per whitelist
May 15 08:37:14.022: INFO: namespace e2e-tests-downward-api-wljdj deletion completed in 10.802978392s

[32m [SLOW TEST:16.118 seconds][0m
[sig-storage] Downward API volume
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:37:14.022: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-a517ca8f-76ec-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 08:37:16.772: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a526c44c-76ec-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-jwnsn" to be "success or failure"
May 15 08:37:16.867: INFO: Pod "pod-projected-configmaps-a526c44c-76ec-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 94.746756ms
May 15 08:37:18.937: INFO: Pod "pod-projected-configmaps-a526c44c-76ec-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.164872215s
[1mSTEP[0m: Saw pod success
May 15 08:37:18.937: INFO: Pod "pod-projected-configmaps-a526c44c-76ec-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:37:19.007: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-configmaps-a526c44c-76ec-11e9-9e56-3ac139a44f02 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:37:19.663: INFO: Waiting for pod pod-projected-configmaps-a526c44c-76ec-11e9-9e56-3ac139a44f02 to disappear
May 15 08:37:19.756: INFO: Pod pod-projected-configmaps-a526c44c-76ec-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:37:19.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-jwnsn" for this suite.
May 15 08:37:26.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:37:29.002: INFO: namespace: e2e-tests-projected-jwnsn, resource: bindings, ignored listing per whitelist
May 15 08:37:31.326: INFO: namespace e2e-tests-projected-jwnsn deletion completed in 11.117030638s

[32m [SLOW TEST:17.304 seconds][0m
[sig-storage] Projected configMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34[0m
  should be consumable from pods in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers if init containers fail on a RestartAlways pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:37:31.326: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
May 15 08:37:33.948: INFO: PodSpec: initContainers in spec.initContainers
May 15 08:38:21.657: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-af73f8e0-76ec-11e9-9e56-3ac139a44f02", GenerateName:"", Namespace:"e2e-tests-init-container-4nc6h", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-4nc6h/pods/pod-init-af73f8e0-76ec-11e9-9e56-3ac139a44f02", UID:"af7bd6c5-76ec-11e9-8329-42010a8e0130", ResourceVersion:"25097", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693506253, loc:(*time.Location)(0x7c9e580)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"948341970"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fpgjf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000d40740), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fpgjf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fpgjf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fpgjf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0010995b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0017cb800), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001099650)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001099670)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001099678), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00109967c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506254, loc:(*time.Location)(0x7c9e580)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506254, loc:(*time.Location)(0x7c9e580)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506254, loc:(*time.Location)(0x7c9e580)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506254, loc:(*time.Location)(0x7c9e580)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.142.0.3", PodIP:"10.8.2.124", StartTime:(*v1.Time)(0xc001136320), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000173260)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0001732d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://8d6e5323987daabda5a7b96187880020c3519f61b8651bc2d02c04b2d597efca"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001136460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001136340), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:38:21.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-4nc6h" for this suite.
May 15 08:38:43.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:38:47.962: INFO: namespace: e2e-tests-init-container-4nc6h, resource: bindings, ignored listing per whitelist
May 15 08:38:48.684: INFO: namespace e2e-tests-init-container-4nc6h deletion completed in 26.955594942s

[32m [SLOW TEST:77.357 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:38:48.684: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name s-test-opt-del-dd832c74-76ec-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating secret with name s-test-opt-upd-dd832cd3-76ec-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-dd832c74-76ec-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Updating secret s-test-opt-upd-dd832cd3-76ec-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating secret with name s-test-opt-create-dd832d04-76ec-11e9-9e56-3ac139a44f02
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:38:56.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-q7wfh" for this suite.
May 15 08:39:22.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:39:25.497: INFO: namespace: e2e-tests-projected-q7wfh, resource: bindings, ignored listing per whitelist
May 15 08:39:28.018: INFO: namespace e2e-tests-projected-q7wfh deletion completed in 31.352231091s

[32m [SLOW TEST:39.334 seconds][0m
[sig-storage] Projected secret
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:39:28.018: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod liveness-exec in namespace e2e-tests-container-probe-m7dtl
May 15 08:39:32.773: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-m7dtl
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 15 08:39:32.843: INFO: Initial restart count of pod liveness-exec is 0
May 15 08:40:20.537: INFO: Restart count of pod e2e-tests-container-probe-m7dtl/liveness-exec is now 1 (47.693869723s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:40:20.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-probe-m7dtl" for this suite.
May 15 08:40:27.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:40:28.298: INFO: namespace: e2e-tests-container-probe-m7dtl, resource: bindings, ignored listing per whitelist
May 15 08:40:33.248: INFO: namespace e2e-tests-container-probe-m7dtl deletion completed in 12.496059365s

[32m [SLOW TEST:65.230 seconds][0m
[k8s.io] Probing container
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume as non-root [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:40:33.251: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-1bdec49d-76ed-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 08:40:36.068: INFO: Waiting up to 5m0s for pod "pod-configmaps-1bef47b8-76ed-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-gxtpq" to be "success or failure"
May 15 08:40:36.170: INFO: Pod "pod-configmaps-1bef47b8-76ed-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 102.814762ms
May 15 08:40:38.243: INFO: Pod "pod-configmaps-1bef47b8-76ed-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.175512429s
[1mSTEP[0m: Saw pod success
May 15 08:40:38.243: INFO: Pod "pod-configmaps-1bef47b8-76ed-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:40:38.313: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-configmaps-1bef47b8-76ed-11e9-9e56-3ac139a44f02 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:40:38.536: INFO: Waiting for pod pod-configmaps-1bef47b8-76ed-11e9-9e56-3ac139a44f02 to disappear
May 15 08:40:38.634: INFO: Pod pod-configmaps-1bef47b8-76ed-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:40:38.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-gxtpq" for this suite.
May 15 08:40:44.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:40:47.952: INFO: namespace: e2e-tests-configmap-gxtpq, resource: bindings, ignored listing per whitelist
May 15 08:40:49.094: INFO: namespace e2e-tests-configmap-gxtpq deletion completed in 10.389122571s

[32m [SLOW TEST:15.844 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:40:49.094: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 15 08:40:51.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2548d53c-76ed-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-5zth8" to be "success or failure"
May 15 08:40:51.834: INFO: Pod "downwardapi-volume-2548d53c-76ed-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 98.874857ms
May 15 08:40:53.904: INFO: Pod "downwardapi-volume-2548d53c-76ed-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.168922629s
[1mSTEP[0m: Saw pod success
May 15 08:40:53.905: INFO: Pod "downwardapi-volume-2548d53c-76ed-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:40:53.974: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod downwardapi-volume-2548d53c-76ed-11e9-9e56-3ac139a44f02 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:40:54.205: INFO: Waiting for pod downwardapi-volume-2548d53c-76ed-11e9-9e56-3ac139a44f02 to disappear
May 15 08:40:54.308: INFO: Pod downwardapi-volume-2548d53c-76ed-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:40:54.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-5zth8" for this suite.
May 15 08:41:00.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:41:02.399: INFO: namespace: e2e-tests-projected-5zth8, resource: bindings, ignored listing per whitelist
May 15 08:41:04.802: INFO: namespace e2e-tests-projected-5zth8 deletion completed in 10.423680725s

[32m [SLOW TEST:15.708 seconds][0m
[sig-storage] Projected downwardAPI
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0666,tmpfs) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:41:04.803: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0666 on tmpfs
May 15 08:41:07.538: INFO: Waiting up to 5m0s for pod "pod-2eb36389-76ed-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-gllvp" to be "success or failure"
May 15 08:41:07.637: INFO: Pod "pod-2eb36389-76ed-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 98.925115ms
May 15 08:41:09.708: INFO: Pod "pod-2eb36389-76ed-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.169800594s
[1mSTEP[0m: Saw pod success
May 15 08:41:09.708: INFO: Pod "pod-2eb36389-76ed-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:41:09.777: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-2eb36389-76ed-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 08:41:10.003: INFO: Waiting for pod pod-2eb36389-76ed-11e9-9e56-3ac139a44f02 to disappear
May 15 08:41:10.098: INFO: Pod pod-2eb36389-76ed-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:41:10.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-gllvp" for this suite.
May 15 08:41:16.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:41:19.756: INFO: namespace: e2e-tests-emptydir-gllvp, resource: bindings, ignored listing per whitelist
May 15 08:41:20.898: INFO: namespace e2e-tests-emptydir-gllvp deletion completed in 10.730576354s

[32m [SLOW TEST:16.096 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run job[0m 
  [1mshould create a job from an image when restart is OnFailure  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:41:20.898: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
May 15 08:41:23.492: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-khbqs'
May 15 08:41:26.410: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 15 08:41:26.410: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
[1mSTEP[0m: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
May 15 08:41:26.517: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-khbqs'
May 15 08:41:27.233: INFO: stderr: ""
May 15 08:41:27.233: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:41:27.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-khbqs" for this suite.
May 15 08:41:49.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:41:51.032: INFO: namespace: e2e-tests-kubectl-khbqs, resource: bindings, ignored listing per whitelist
May 15 08:41:54.106: INFO: namespace e2e-tests-kubectl-khbqs deletion completed in 26.769771962s

[32m [SLOW TEST:33.208 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run job
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create a job from an image when restart is OnFailure  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Subpath[0m [90mAtomic writer volumes[0m 
  [1mshould support subpaths with secret pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:41:54.107: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename subpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
[1mSTEP[0m: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating pod pod-subpath-test-secret-dskz
[1mSTEP[0m: Creating a pod to test atomic-volume-subpath
May 15 08:41:56.853: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-dskz" in namespace "e2e-tests-subpath-jxw7l" to be "success or failure"
May 15 08:41:56.947: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Pending", Reason="", readiness=false. Elapsed: 93.128006ms
May 15 08:41:59.018: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.164260606s
May 15 08:42:01.088: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 4.234602104s
May 15 08:42:03.164: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 6.310139986s
May 15 08:42:05.233: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 8.379968728s
May 15 08:42:07.304: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 10.450172766s
May 15 08:42:09.374: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 12.520253079s
May 15 08:42:11.444: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 14.590495837s
May 15 08:42:13.514: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 16.660552351s
May 15 08:42:15.588: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 18.734564233s
May 15 08:42:17.744: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Running", Reason="", readiness=false. Elapsed: 20.890237161s
May 15 08:42:19.817: INFO: Pod "pod-subpath-test-secret-dskz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.964029056s
[1mSTEP[0m: Saw pod success
May 15 08:42:19.818: INFO: Pod "pod-subpath-test-secret-dskz" satisfied condition "success or failure"
May 15 08:42:19.887: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-subpath-test-secret-dskz container test-container-subpath-secret-dskz: <nil>
[1mSTEP[0m: delete the pod
May 15 08:42:20.113: INFO: Waiting for pod pod-subpath-test-secret-dskz to disappear
May 15 08:42:20.222: INFO: Pod pod-subpath-test-secret-dskz no longer exists
[1mSTEP[0m: Deleting pod pod-subpath-test-secret-dskz
May 15 08:42:20.223: INFO: Deleting pod "pod-subpath-test-secret-dskz" in namespace "e2e-tests-subpath-jxw7l"
[AfterEach] [sig-storage] Subpath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:42:20.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-subpath-jxw7l" for this suite.
May 15 08:42:26.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:42:29.237: INFO: namespace: e2e-tests-subpath-jxw7l, resource: bindings, ignored listing per whitelist
May 15 08:42:31.557: INFO: namespace e2e-tests-subpath-jxw7l deletion completed in 11.192238818s

[32m [SLOW TEST:37.450 seconds][0m
[sig-storage] Subpath
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  Atomic writer volumes
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34[0m
    should support subpaths with secret pod [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support rollover [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:42:31.557: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:42:34.810: INFO: Pod name rollover-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
May 15 08:42:36.988: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 15 08:42:39.105: INFO: Creating deployment "test-rollover-deployment"
May 15 08:42:39.341: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 15 08:42:39.411: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 15 08:42:39.597: INFO: Ensure that both replica sets have 1 created replica
May 15 08:42:39.738: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 15 08:42:39.915: INFO: Updating deployment test-rollover-deployment
May 15 08:42:39.915: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 15 08:42:40.002: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 15 08:42:40.141: INFO: Make sure deployment "test-rollover-deployment" is complete
May 15 08:42:40.280: INFO: all replica sets need to contain the pod-template-hash label
May 15 08:42:40.280: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:42:42.420: INFO: all replica sets need to contain the pod-template-hash label
May 15 08:42:42.420: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506561, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:42:44.421: INFO: all replica sets need to contain the pod-template-hash label
May 15 08:42:44.421: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506561, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:42:46.420: INFO: all replica sets need to contain the pod-template-hash label
May 15 08:42:46.420: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506561, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:42:48.420: INFO: all replica sets need to contain the pod-template-hash label
May 15 08:42:48.420: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506561, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:42:50.420: INFO: all replica sets need to contain the pod-template-hash label
May 15 08:42:50.420: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506561, loc:(*time.Location)(0x7c9e580)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693506559, loc:(*time.Location)(0x7c9e580)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 15 08:42:52.421: INFO: 
May 15 08:42:52.421: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 15 08:42:52.703: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-5qfz7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5qfz7/deployments/test-rollover-deployment,UID:655f26e0-76ed-11e9-8329-42010a8e0130,ResourceVersion:26143,Generation:2,CreationTimestamp:2019-05-15 08:42:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-15 08:42:39 +0000 UTC 2019-05-15 08:42:39 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-15 08:42:51 +0000 UTC 2019-05-15 08:42:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 15 08:42:52.774: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-5qfz7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5qfz7/replicasets/test-rollover-deployment-6b7f9d6597,UID:65cc56bf-76ed-11e9-8329-42010a8e0130,ResourceVersion:26136,Generation:2,CreationTimestamp:2019-05-15 08:42:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 655f26e0-76ed-11e9-8329-42010a8e0130 0xc001fd0117 0xc001fd0118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 15 08:42:52.774: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 15 08:42:52.774: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-5qfz7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5qfz7/replicasets/test-rollover-controller,UID:62b17b43-76ed-11e9-8329-42010a8e0130,ResourceVersion:26142,Generation:2,CreationTimestamp:2019-05-15 08:42:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 655f26e0-76ed-11e9-8329-42010a8e0130 0xc002819f87 0xc002819f88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 15 08:42:52.774: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-5qfz7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5qfz7/replicasets/test-rollover-deployment-6586df867b,UID:65696615-76ed-11e9-8329-42010a8e0130,ResourceVersion:26093,Generation:2,CreationTimestamp:2019-05-15 08:42:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 655f26e0-76ed-11e9-8329-42010a8e0130 0xc001fd0047 0xc001fd0048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 15 08:42:52.844: INFO: Pod "test-rollover-deployment-6b7f9d6597-4fxlt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-4fxlt,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-5qfz7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5qfz7/pods/test-rollover-deployment-6b7f9d6597-4fxlt,UID:65d289aa-76ed-11e9-8329-42010a8e0130,ResourceVersion:26105,Generation:0,CreationTimestamp:2019-05-15 08:42:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 65cc56bf-76ed-11e9-8329-42010a8e0130 0xc001fd1347 0xc001fd1348}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kkzfg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kkzfg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-kkzfg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fd13c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fd13e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:42:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:42:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:42:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-15 08:42:39 +0000 UTC  }],Message:,Reason:,HostIP:10.142.0.2,PodIP:10.8.1.156,StartTime:2019-05-15 08:42:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-15 08:42:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://cf98a0eb0b7727199b315fd1d8b4f7353166df6279e588e6de99fe309a6b7887}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:42:52.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-deployment-5qfz7" for this suite.
May 15 08:42:59.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:43:02.400: INFO: namespace: e2e-tests-deployment-5qfz7, resource: bindings, ignored listing per whitelist
May 15 08:43:04.220: INFO: namespace e2e-tests-deployment-5qfz7 deletion completed in 11.305850702s

[32m [SLOW TEST:32.662 seconds][0m
[sig-apps] Deployment
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  deployment should support rollover [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould rollback without unnecessary restarts [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:43:04.220: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:43:07.229: INFO: Create a RollingUpdate DaemonSet
May 15 08:43:07.329: INFO: Check that daemon pods launch on every node of the cluster
May 15 08:43:07.507: INFO: Number of nodes with available pods: 0
May 15 08:43:07.507: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:43:08.650: INFO: Number of nodes with available pods: 1
May 15 08:43:08.650: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r is running more than one daemon pod
May 15 08:43:09.648: INFO: Number of nodes with available pods: 3
May 15 08:43:09.648: INFO: Number of running nodes: 3, number of available pods: 3
May 15 08:43:09.648: INFO: Update the DaemonSet to trigger a rollout
May 15 08:43:09.837: INFO: Updating DaemonSet daemon-set
May 15 08:43:13.047: INFO: Roll back the DaemonSet before rollout is complete
May 15 08:43:13.191: INFO: Updating DaemonSet daemon-set
May 15 08:43:13.191: INFO: Make sure DaemonSet rollback is complete
May 15 08:43:13.261: INFO: Wrong image for pod: daemon-set-7kf6j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 15 08:43:13.261: INFO: Pod daemon-set-7kf6j is not available
May 15 08:43:14.401: INFO: Wrong image for pod: daemon-set-7kf6j. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
May 15 08:43:14.401: INFO: Pod daemon-set-7kf6j is not available
May 15 08:43:15.402: INFO: Pod daemon-set-8rggm is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-f6h4x, will wait for the garbage collector to delete the pods
May 15 08:43:15.933: INFO: Deleting DaemonSet.extensions daemon-set took: 96.962465ms
May 15 08:43:16.033: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.377913ms
May 15 08:44:48.085: INFO: Number of nodes with available pods: 0
May 15 08:44:48.085: INFO: Number of running nodes: 0, number of available pods: 0
May 15 08:44:48.185: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-f6h4x/daemonsets","resourceVersion":"26580"},"items":null}

May 15 08:44:48.254: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-f6h4x/pods","resourceVersion":"26580"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:44:48.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-f6h4x" for this suite.
May 15 08:44:54.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:45:00.297: INFO: namespace: e2e-tests-daemonsets-f6h4x, resource: bindings, ignored listing per whitelist
May 15 08:45:00.696: INFO: namespace e2e-tests-daemonsets-f6h4x deletion completed in 11.968549506s

[32m [SLOW TEST:116.476 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should rollback without unnecessary restarts [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a read only busybox container[0m 
  [1mshould not write to root filesystem [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:45:00.696: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:45:05.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubelet-test-2tzzz" for this suite.
May 15 08:45:50.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:45:51.599: INFO: namespace: e2e-tests-kubelet-test-2tzzz, resource: bindings, ignored listing per whitelist
May 15 08:45:55.015: INFO: namespace e2e-tests-kubelet-test-2tzzz deletion completed in 49.053064514s

[32m [SLOW TEST:54.319 seconds][0m
[k8s.io] Kubelet
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when scheduling a read only busybox container
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186[0m
    should not write to root filesystem [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart exec hook properly [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:45:55.016: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
May 15 08:46:02.340: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:02.446: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:04.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:04.517: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:06.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:06.517: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:08.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:08.517: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:10.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:10.516: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:12.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:12.517: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:14.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:14.516: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:16.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:16.517: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:18.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:18.516: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:20.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:20.517: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:22.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:22.516: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:24.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:24.518: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:26.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:26.517: INFO: Pod pod-with-poststart-exec-hook still exists
May 15 08:46:28.447: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 15 08:46:28.518: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:46:28.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-container-lifecycle-hook-cjjsc" for this suite.
May 15 08:46:50.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:46:54.406: INFO: namespace: e2e-tests-container-lifecycle-hook-cjjsc, resource: bindings, ignored listing per whitelist
May 15 08:46:54.707: INFO: namespace e2e-tests-container-lifecycle-hook-cjjsc deletion completed in 26.118008315s

[32m [SLOW TEST:59.691 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  when create a pod with lifecycle hook
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:46:54.707: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the rc1
[1mSTEP[0m: create the rc2
[1mSTEP[0m: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
[1mSTEP[0m: delete the rc simpletest-rc-to-be-deleted
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
W0515 08:47:08.784318    1545 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 15 08:47:08.784: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:47:08.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-bjzvr" for this suite.
May 15 08:47:15.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:47:17.751: INFO: namespace: e2e-tests-gc-bjzvr, resource: bindings, ignored listing per whitelist
May 15 08:47:20.396: INFO: namespace e2e-tests-gc-bjzvr deletion completed in 11.541265657s

[32m [SLOW TEST:25.689 seconds][0m
[sig-api-machinery] Garbage collector
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run default[0m 
  [1mshould create an rc or deployment from an image  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:47:20.396: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: running the image docker.io/library/nginx:1.14-alpine
May 15 08:47:22.844: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pgzbr'
May 15 08:47:23.343: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 15 08:47:23.344: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
May 15 08:47:25.575: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.231.193.88 --kubeconfig=/tmp/gke-kubecfg325943844 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-pgzbr'
May 15 08:47:26.141: INFO: stderr: ""
May 15 08:47:26.141: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:47:26.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-kubectl-pgzbr" for this suite.
May 15 08:47:50.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:47:54.587: INFO: namespace: e2e-tests-kubectl-pgzbr, resource: bindings, ignored listing per whitelist
May 15 08:47:55.281: INFO: namespace e2e-tests-kubectl-pgzbr deletion completed in 29.06360927s

[32m [SLOW TEST:34.884 seconds][0m
[sig-cli] Kubectl client
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22[0m
  [k8s.io] Kubectl run default
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
    should create an rc or deployment from an image  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:47:55.281: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-234e76e7-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-234e774d-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-234e76e7-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Updating configmap cm-test-opt-upd-234e774d-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-234e776b-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:48:03.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-4n896" for this suite.
May 15 08:48:26.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:48:30.724: INFO: namespace: e2e-tests-configmap-4n896, resource: bindings, ignored listing per whitelist
May 15 08:48:30.926: INFO: namespace e2e-tests-configmap-4n896 deletion completed in 27.212155997s

[32m [SLOW TEST:35.645 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Daemon set [Serial][0m 
  [1mshould run and stop complex daemon [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:48:30.927: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename daemonsets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:48:34.409: INFO: Creating daemon "daemon-set" with a node selector
[1mSTEP[0m: Initially, daemon pods should not be running on any nodes.
May 15 08:48:35.040: INFO: Number of nodes with available pods: 0
May 15 08:48:35.040: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Change node label to blue, check that daemon pod is launched.
May 15 08:48:35.389: INFO: Number of nodes with available pods: 0
May 15 08:48:35.389: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:36.459: INFO: Number of nodes with available pods: 0
May 15 08:48:36.459: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:37.458: INFO: Number of nodes with available pods: 1
May 15 08:48:37.458: INFO: Number of running nodes: 1, number of available pods: 1
[1mSTEP[0m: Update the node label to green, and wait for daemons to be unscheduled
May 15 08:48:37.770: INFO: Number of nodes with available pods: 0
May 15 08:48:37.770: INFO: Number of running nodes: 0, number of available pods: 0
[1mSTEP[0m: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 15 08:48:37.958: INFO: Number of nodes with available pods: 0
May 15 08:48:37.958: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:39.028: INFO: Number of nodes with available pods: 0
May 15 08:48:39.028: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:40.028: INFO: Number of nodes with available pods: 0
May 15 08:48:40.028: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:41.028: INFO: Number of nodes with available pods: 0
May 15 08:48:41.028: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:42.029: INFO: Number of nodes with available pods: 0
May 15 08:48:42.029: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:43.028: INFO: Number of nodes with available pods: 0
May 15 08:48:43.028: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:44.028: INFO: Number of nodes with available pods: 0
May 15 08:48:44.028: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:45.027: INFO: Number of nodes with available pods: 0
May 15 08:48:45.027: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:46.029: INFO: Number of nodes with available pods: 0
May 15 08:48:46.029: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:47.028: INFO: Number of nodes with available pods: 0
May 15 08:48:47.028: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:48.046: INFO: Number of nodes with available pods: 0
May 15 08:48:48.046: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:49.028: INFO: Number of nodes with available pods: 0
May 15 08:48:49.028: INFO: Node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz is running more than one daemon pod
May 15 08:48:50.028: INFO: Number of nodes with available pods: 1
May 15 08:48:50.028: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
[1mSTEP[0m: Deleting DaemonSet "daemon-set"
[1mSTEP[0m: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-k7c87, will wait for the garbage collector to delete the pods
May 15 08:48:50.819: INFO: Deleting DaemonSet.extensions daemon-set took: 102.920465ms
May 15 08:48:50.919: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.426692ms
May 15 08:48:57.951: INFO: Number of nodes with available pods: 0
May 15 08:48:57.951: INFO: Number of running nodes: 0, number of available pods: 0
May 15 08:48:58.062: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k7c87/daemonsets","resourceVersion":"27609"},"items":null}

May 15 08:48:58.132: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k7c87/pods","resourceVersion":"27609"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:48:58.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-daemonsets-k7c87" for this suite.
May 15 08:49:04.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:49:08.934: INFO: namespace: e2e-tests-daemonsets-k7c87, resource: bindings, ignored listing per whitelist
May 15 08:49:09.026: INFO: namespace e2e-tests-daemonsets-k7c87 deletion completed in 10.308229709s

[32m [SLOW TEST:38.100 seconds][0m
[sig-apps] Daemon set [Serial]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  should run and stop complex daemon [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:49:09.026: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating secret with name secret-test-4f385985-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 08:49:11.701: INFO: Waiting up to 5m0s for pod "pod-secrets-4f479fa1-76ee-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-secrets-747dm" to be "success or failure"
May 15 08:49:11.811: INFO: Pod "pod-secrets-4f479fa1-76ee-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 109.132822ms
May 15 08:49:13.881: INFO: Pod "pod-secrets-4f479fa1-76ee-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.179566638s
[1mSTEP[0m: Saw pod success
May 15 08:49:13.881: INFO: Pod "pod-secrets-4f479fa1-76ee-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:49:13.951: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-secrets-4f479fa1-76ee-11e9-9e56-3ac139a44f02 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:49:14.160: INFO: Waiting for pod pod-secrets-4f479fa1-76ee-11e9-9e56-3ac139a44f02 to disappear
May 15 08:49:14.256: INFO: Pod pod-secrets-4f479fa1-76ee-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:49:14.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-secrets-747dm" for this suite.
May 15 08:49:22.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:49:24.855: INFO: namespace: e2e-tests-secrets-747dm, resource: bindings, ignored listing per whitelist
May 15 08:49:26.502: INFO: namespace e2e-tests-secrets-747dm deletion completed in 12.175943932s

[32m [SLOW TEST:17.476 seconds][0m
[sig-storage] Secrets
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34[0m
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not be blocked by dependency circle [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:49:26.502: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:49:29.358: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"59c2310f-76ee-11e9-8329-42010a8e0130", Controller:(*bool)(0xc00190b546), BlockOwnerDeletion:(*bool)(0xc00190b547)}}
May 15 08:49:29.477: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"59a9de6a-76ee-11e9-8329-42010a8e0130", Controller:(*bool)(0xc001ad856e), BlockOwnerDeletion:(*bool)(0xc001ad856f)}}
May 15 08:49:29.911: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"59b5d6a3-76ee-11e9-8329-42010a8e0130", Controller:(*bool)(0xc001ba324e), BlockOwnerDeletion:(*bool)(0xc001ba324f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:49:35.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-w7gld" for this suite.
May 15 08:49:41.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:49:42.298: INFO: namespace: e2e-tests-gc-w7gld, resource: bindings, ignored listing per whitelist
May 15 08:49:45.988: INFO: namespace e2e-tests-gc-w7gld deletion completed in 10.688062305s

[32m [SLOW TEST:19.486 seconds][0m
[sig-api-machinery] Garbage collector
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should not be blocked by dependency circle [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:49:45.988: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-655d768d-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 08:49:48.843: INFO: Waiting up to 5m0s for pod "pod-configmaps-656c3238-76ee-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-rcx5g" to be "success or failure"
May 15 08:49:48.942: INFO: Pod "pod-configmaps-656c3238-76ee-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 99.400959ms
May 15 08:49:51.014: INFO: Pod "pod-configmaps-656c3238-76ee-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.17064166s
[1mSTEP[0m: Saw pod success
May 15 08:49:51.014: INFO: Pod "pod-configmaps-656c3238-76ee-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:49:51.084: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-configmaps-656c3238-76ee-11e9-9e56-3ac139a44f02 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:49:51.299: INFO: Waiting for pod pod-configmaps-656c3238-76ee-11e9-9e56-3ac139a44f02 to disappear
May 15 08:49:51.402: INFO: Pod pod-configmaps-656c3238-76ee-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:49:51.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-rcx5g" for this suite.
May 15 08:49:57.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:50:00.792: INFO: namespace: e2e-tests-configmap-rcx5g, resource: bindings, ignored listing per whitelist
May 15 08:50:01.540: INFO: namespace e2e-tests-configmap-rcx5g deletion completed in 10.067033176s

[32m [SLOW TEST:15.551 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete RS created by deployment when not orphaning [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:50:01.540: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for all rs to be garbage collected
[1mSTEP[0m: Gathering metrics
W0515 08:50:04.865077    1545 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 15 08:50:04.865: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:50:04.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-gc-rrd45" for this suite.
May 15 08:50:11.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:50:12.673: INFO: namespace: e2e-tests-gc-rrd45, resource: bindings, ignored listing per whitelist
May 15 08:50:15.803: INFO: namespace e2e-tests-gc-rrd45 deletion completed in 10.868010122s

[32m [SLOW TEST:14.263 seconds][0m
[sig-api-machinery] Garbage collector
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  should delete RS created by deployment when not orphaning [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:50:15.803: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating configMap with name configmap-test-volume-7712acfd-76ee-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume configMaps
May 15 08:50:18.578: INFO: Waiting up to 5m0s for pod "pod-configmaps-7722250d-76ee-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-configmap-q86bb" to be "success or failure"
May 15 08:50:18.683: INFO: Pod "pod-configmaps-7722250d-76ee-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 105.009218ms
May 15 08:50:20.753: INFO: Pod "pod-configmaps-7722250d-76ee-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.175295518s
[1mSTEP[0m: Saw pod success
May 15 08:50:20.753: INFO: Pod "pod-configmaps-7722250d-76ee-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 08:50:20.823: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-configmaps-7722250d-76ee-11e9-9e56-3ac139a44f02 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 08:50:21.045: INFO: Waiting for pod pod-configmaps-7722250d-76ee-11e9-9e56-3ac139a44f02 to disappear
May 15 08:50:21.145: INFO: Pod pod-configmaps-7722250d-76ee-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:50:21.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-configmap-q86bb" for this suite.
May 15 08:50:27.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:50:31.779: INFO: namespace: e2e-tests-configmap-q86bb, resource: bindings, ignored listing per whitelist
May 15 08:50:32.902: INFO: namespace e2e-tests-configmap-q86bb deletion completed in 11.686630496s

[32m [SLOW TEST:17.099 seconds][0m
[sig-storage] ConfigMap
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33[0m
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] CustomResourceDefinition resources[0m [90mSimple CustomResourceDefinition[0m 
  [1mcreating/deleting custom resource definition objects works  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:50:32.903: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename custom-resource-definition
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 15 08:50:35.499: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:50:36.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-custom-resource-definition-kcfdz" for this suite.
May 15 08:50:42.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:50:43.795: INFO: namespace: e2e-tests-custom-resource-definition-kcfdz, resource: bindings, ignored listing per whitelist
May 15 08:50:47.716: INFO: namespace e2e-tests-custom-resource-definition-kcfdz deletion completed in 11.508738991s

[32m [SLOW TEST:14.813 seconds][0m
[sig-api-machinery] CustomResourceDefinition resources
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22[0m
  Simple CustomResourceDefinition
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35[0m
    creating/deleting custom resource definition objects works  [Conformance]
    [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir wrapper volumes[0m 
  [1mshould not cause race condition when used for configmaps [Serial] [Slow] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:50:47.716: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir-wrapper
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating 50 configmaps
[1mSTEP[0m: Creating RC which spawns configmap-volume pods
May 15 08:50:54.598: INFO: Pod name wrapped-volume-race-8c7e75b4-76ee-11e9-9e56-3ac139a44f02: Found 3 pods out of 5
May 15 08:50:59.700: INFO: Pod name wrapped-volume-race-8c7e75b4-76ee-11e9-9e56-3ac139a44f02: Found 5 pods out of 5
[1mSTEP[0m: Ensuring each pod is running
[1mSTEP[0m: deleting ReplicationController wrapped-volume-race-8c7e75b4-76ee-11e9-9e56-3ac139a44f02 in namespace e2e-tests-emptydir-wrapper-sfxbs, will wait for the garbage collector to delete the pods
May 15 08:52:42.674: INFO: Deleting ReplicationController wrapped-volume-race-8c7e75b4-76ee-11e9-9e56-3ac139a44f02 took: 107.083098ms
May 15 08:52:42.775: INFO: Terminating ReplicationController wrapped-volume-race-8c7e75b4-76ee-11e9-9e56-3ac139a44f02 pods took: 100.446719ms
[1mSTEP[0m: Creating RC which spawns configmap-volume pods
May 15 08:53:19.876: INFO: Pod name wrapped-volume-race-e317429a-76ee-11e9-9e56-3ac139a44f02: Found 2 pods out of 5
May 15 08:53:24.949: INFO: Pod name wrapped-volume-race-e317429a-76ee-11e9-9e56-3ac139a44f02: Found 5 pods out of 5
[1mSTEP[0m: Ensuring each pod is running
[1mSTEP[0m: deleting ReplicationController wrapped-volume-race-e317429a-76ee-11e9-9e56-3ac139a44f02 in namespace e2e-tests-emptydir-wrapper-sfxbs, will wait for the garbage collector to delete the pods
May 15 08:55:29.896: INFO: Deleting ReplicationController wrapped-volume-race-e317429a-76ee-11e9-9e56-3ac139a44f02 took: 113.067527ms
May 15 08:55:30.096: INFO: Terminating ReplicationController wrapped-volume-race-e317429a-76ee-11e9-9e56-3ac139a44f02 pods took: 200.493097ms
[1mSTEP[0m: Creating RC which spawns configmap-volume pods
May 15 08:56:08.309: INFO: Pod name wrapped-volume-race-476b1a87-76ef-11e9-9e56-3ac139a44f02: Found 3 pods out of 5
May 15 08:56:13.382: INFO: Pod name wrapped-volume-race-476b1a87-76ef-11e9-9e56-3ac139a44f02: Found 5 pods out of 5
[1mSTEP[0m: Ensuring each pod is running
[1mSTEP[0m: deleting ReplicationController wrapped-volume-race-476b1a87-76ef-11e9-9e56-3ac139a44f02 in namespace e2e-tests-emptydir-wrapper-sfxbs, will wait for the garbage collector to delete the pods
May 15 08:58:08.805: INFO: Deleting ReplicationController wrapped-volume-race-476b1a87-76ef-11e9-9e56-3ac139a44f02 took: 605.651487ms
May 15 08:58:08.905: INFO: Terminating ReplicationController wrapped-volume-race-476b1a87-76ef-11e9-9e56-3ac139a44f02 pods took: 100.359373ms
[1mSTEP[0m: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:58:54.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-wrapper-sfxbs" for this suite.
May 15 08:59:00.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:59:03.026: INFO: namespace: e2e-tests-emptydir-wrapper-sfxbs, resource: bindings, ignored listing per whitelist
May 15 08:59:07.610: INFO: namespace e2e-tests-emptydir-wrapper-sfxbs deletion completed in 13.446999512s

[32m [SLOW TEST:499.894 seconds][0m
[sig-storage] EmptyDir wrapper volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[0m[sig-storage] HostPath[0m 
  [1mshould give a volume the correct mode [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] HostPath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:59:07.610: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename hostpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test hostPath mode
May 15 08:59:10.201: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-k48xg" to be "success or failure"
May 15 08:59:10.297: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 96.579694ms
May 15 08:59:12.368: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167364638s
May 15 08:59:14.438: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.237578579s
[1mSTEP[0m: Saw pod success
May 15 08:59:14.438: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 15 08:59:14.509: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-host-path-test container test-container-1: <nil>
[1mSTEP[0m: delete the pod
May 15 08:59:14.727: INFO: Waiting for pod pod-host-path-test to disappear
May 15 08:59:14.821: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:59:14.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-hostpath-k48xg" for this suite.
May 15 08:59:23.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 08:59:23.501: INFO: namespace: e2e-tests-hostpath-k48xg, resource: bindings, ignored listing per whitelist
May 15 08:59:27.631: INFO: namespace e2e-tests-hostpath-k48xg deletion completed in 12.7394151s

[32m [SLOW TEST:20.021 seconds][0m
[sig-storage] HostPath
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34[0m
  should give a volume the correct mode [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Service endpoints latency[0m 
  [1mshould not be very high  [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 08:59:27.631: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename svc-latency
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-2q6c2
I0515 08:59:30.265517    1545 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-2q6c2, replica count: 1
I0515 08:59:31.416329    1545 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0515 08:59:32.416662    1545 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 15 08:59:32.732: INFO: Created: latency-svc-r4fsb
May 15 08:59:32.756: INFO: Got endpoints: latency-svc-r4fsb [139.796749ms]
May 15 08:59:32.867: INFO: Created: latency-svc-rvlqq
May 15 08:59:32.888: INFO: Got endpoints: latency-svc-rvlqq [131.417278ms]
May 15 08:59:32.917: INFO: Created: latency-svc-4x5j6
May 15 08:59:32.944: INFO: Created: latency-svc-hxrbb
May 15 08:59:32.979: INFO: Got endpoints: latency-svc-4x5j6 [222.11143ms]
May 15 08:59:32.986: INFO: Created: latency-svc-9wjtr
May 15 08:59:32.996: INFO: Got endpoints: latency-svc-hxrbb [239.246609ms]
May 15 08:59:33.015: INFO: Created: latency-svc-qbslt
May 15 08:59:33.036: INFO: Created: latency-svc-zmxcg
May 15 08:59:33.097: INFO: Got endpoints: latency-svc-9wjtr [340.020561ms]
May 15 08:59:33.097: INFO: Got endpoints: latency-svc-qbslt [339.965372ms]
May 15 08:59:33.102: INFO: Created: latency-svc-g5qch
May 15 08:59:33.127: INFO: Created: latency-svc-vn4r2
May 15 08:59:33.135: INFO: Got endpoints: latency-svc-zmxcg [378.529827ms]
May 15 08:59:33.169: INFO: Created: latency-svc-jbb7d
May 15 08:59:33.200: INFO: Got endpoints: latency-svc-vn4r2 [443.064835ms]
May 15 08:59:33.237: INFO: Created: latency-svc-7wk2x
May 15 08:59:33.240: INFO: Got endpoints: latency-svc-g5qch [483.227559ms]
May 15 08:59:33.296: INFO: Got endpoints: latency-svc-jbb7d [539.081207ms]
May 15 08:59:33.318: INFO: Created: latency-svc-n4brf
May 15 08:59:33.330: INFO: Created: latency-svc-bjtbs
May 15 08:59:33.370: INFO: Created: latency-svc-6rmrj
May 15 08:59:33.385: INFO: Created: latency-svc-5nwfp
May 15 08:59:33.387: INFO: Got endpoints: latency-svc-7wk2x [630.548683ms]
May 15 08:59:33.409: INFO: Created: latency-svc-p97m7
May 15 08:59:33.410: INFO: Got endpoints: latency-svc-bjtbs [652.536877ms]
May 15 08:59:33.410: INFO: Got endpoints: latency-svc-6rmrj [652.616468ms]
May 15 08:59:33.410: INFO: Got endpoints: latency-svc-n4brf [652.767646ms]
May 15 08:59:33.421: INFO: Got endpoints: latency-svc-5nwfp [663.853657ms]
May 15 08:59:33.426: INFO: Created: latency-svc-b4bvl
May 15 08:59:33.443: INFO: Created: latency-svc-9bs89
May 15 08:59:33.456: INFO: Created: latency-svc-qpqn5
May 15 08:59:33.456: INFO: Created: latency-svc-48md2
May 15 08:59:33.475: INFO: Got endpoints: latency-svc-p97m7 [717.99724ms]
May 15 08:59:33.475: INFO: Got endpoints: latency-svc-b4bvl [586.898802ms]
May 15 08:59:33.492: INFO: Created: latency-svc-5qvcp
May 15 08:59:33.515: INFO: Created: latency-svc-wtvvf
May 15 08:59:33.518: INFO: Got endpoints: latency-svc-qpqn5 [421.251927ms]
May 15 08:59:33.518: INFO: Got endpoints: latency-svc-9bs89 [539.079758ms]
May 15 08:59:33.518: INFO: Got endpoints: latency-svc-48md2 [522.303525ms]
May 15 08:59:33.527: INFO: Got endpoints: latency-svc-5qvcp [429.80837ms]
May 15 08:59:33.533: INFO: Created: latency-svc-r8vzj
May 15 08:59:33.543: INFO: Got endpoints: latency-svc-wtvvf [407.247371ms]
May 15 08:59:33.563: INFO: Got endpoints: latency-svc-r8vzj [362.614558ms]
May 15 08:59:33.573: INFO: Created: latency-svc-2wfsp
May 15 08:59:33.596: INFO: Created: latency-svc-xbb2v
May 15 08:59:33.617: INFO: Created: latency-svc-hxrtz
May 15 08:59:33.632: INFO: Created: latency-svc-d2q9b
May 15 08:59:33.639: INFO: Got endpoints: latency-svc-2wfsp [398.818266ms]
May 15 08:59:33.656: INFO: Created: latency-svc-ttjz7
May 15 08:59:33.665: INFO: Got endpoints: latency-svc-xbb2v [369.466141ms]
May 15 08:59:33.665: INFO: Got endpoints: latency-svc-hxrtz [277.893823ms]
May 15 08:59:33.676: INFO: Got endpoints: latency-svc-d2q9b [266.673517ms]
May 15 08:59:33.683: INFO: Created: latency-svc-k8t8x
May 15 08:59:33.700: INFO: Created: latency-svc-jqwkj
May 15 08:59:33.719: INFO: Created: latency-svc-9xgqg
May 15 08:59:33.723: INFO: Got endpoints: latency-svc-jqwkj [302.511676ms]
May 15 08:59:33.723: INFO: Got endpoints: latency-svc-k8t8x [313.900115ms]
May 15 08:59:33.726: INFO: Got endpoints: latency-svc-ttjz7 [316.154697ms]
May 15 08:59:33.745: INFO: Created: latency-svc-xtlvh
May 15 08:59:33.761: INFO: Got endpoints: latency-svc-9xgqg [285.794434ms]
May 15 08:59:33.771: INFO: Got endpoints: latency-svc-xtlvh [296.055144ms]
May 15 08:59:33.779: INFO: Created: latency-svc-8wnhg
May 15 08:59:33.806: INFO: Created: latency-svc-m7bjl
May 15 08:59:33.825: INFO: Created: latency-svc-brpql
May 15 08:59:33.829: INFO: Got endpoints: latency-svc-8wnhg [311.034045ms]
May 15 08:59:33.846: INFO: Got endpoints: latency-svc-m7bjl [327.935878ms]
May 15 08:59:33.855: INFO: Created: latency-svc-kfqcf
May 15 08:59:33.855: INFO: Created: latency-svc-hpg5d
May 15 08:59:33.872: INFO: Got endpoints: latency-svc-brpql [353.581688ms]
May 15 08:59:33.881: INFO: Created: latency-svc-c4wpl
May 15 08:59:33.910: INFO: Got endpoints: latency-svc-kfqcf [382.910177ms]
May 15 08:59:33.951: INFO: Got endpoints: latency-svc-hpg5d [408.482804ms]
May 15 08:59:33.951: INFO: Created: latency-svc-xz6vl
May 15 08:59:33.986: INFO: Got endpoints: latency-svc-c4wpl [423.056792ms]
May 15 08:59:34.007: INFO: Created: latency-svc-74bqc
May 15 08:59:34.078: INFO: Created: latency-svc-jltc4
May 15 08:59:34.078: INFO: Created: latency-svc-984wg
May 15 08:59:34.154: INFO: Created: latency-svc-fltx8
May 15 08:59:34.157: INFO: Got endpoints: latency-svc-xz6vl [517.99758ms]
May 15 08:59:34.157: INFO: Got endpoints: latency-svc-74bqc [491.631114ms]
May 15 08:59:34.224: INFO: Created: latency-svc-6n725
May 15 08:59:34.235: INFO: Got endpoints: latency-svc-984wg [569.619265ms]
May 15 08:59:34.235: INFO: Got endpoints: latency-svc-jltc4 [558.807503ms]
May 15 08:59:34.297: INFO: Created: latency-svc-4rf8l
May 15 08:59:34.298: INFO: Got endpoints: latency-svc-fltx8 [574.559988ms]
May 15 08:59:34.319: INFO: Created: latency-svc-6725d
May 15 08:59:34.326: INFO: Got endpoints: latency-svc-6n725 [602.800133ms]
May 15 08:59:34.331: INFO: Created: latency-svc-hls76
May 15 08:59:34.352: INFO: Created: latency-svc-bjll9
May 15 08:59:34.357: INFO: Got endpoints: latency-svc-4rf8l [631.075185ms]
May 15 08:59:34.387: INFO: Got endpoints: latency-svc-6725d [615.490279ms]
May 15 08:59:34.387: INFO: Got endpoints: latency-svc-hls76 [625.941574ms]
May 15 08:59:34.391: INFO: Created: latency-svc-8fgld
May 15 08:59:34.407: INFO: Got endpoints: latency-svc-bjll9 [577.260563ms]
May 15 08:59:34.409: INFO: Created: latency-svc-9pk7f
May 15 08:59:34.423: INFO: Got endpoints: latency-svc-8fgld [577.125122ms]
May 15 08:59:34.433: INFO: Created: latency-svc-fxx99
May 15 08:59:34.444: INFO: Created: latency-svc-w8tl5
May 15 08:59:34.444: INFO: Created: latency-svc-tnc8w
May 15 08:59:34.451: INFO: Got endpoints: latency-svc-9pk7f [578.671634ms]
May 15 08:59:34.470: INFO: Got endpoints: latency-svc-fxx99 [560.656383ms]
May 15 08:59:34.479: INFO: Created: latency-svc-xtsgb
May 15 08:59:34.493: INFO: Created: latency-svc-2hrcc
May 15 08:59:34.505: INFO: Got endpoints: latency-svc-w8tl5 [519.41751ms]
May 15 08:59:34.505: INFO: Got endpoints: latency-svc-tnc8w [554.062711ms]
May 15 08:59:34.513: INFO: Created: latency-svc-cfvsx
May 15 08:59:34.534: INFO: Created: latency-svc-vn7w5
May 15 08:59:34.536: INFO: Got endpoints: latency-svc-xtsgb [378.517898ms]
May 15 08:59:34.547: INFO: Got endpoints: latency-svc-cfvsx [311.797916ms]
May 15 08:59:34.554: INFO: Got endpoints: latency-svc-2hrcc [396.777231ms]
May 15 08:59:34.556: INFO: Created: latency-svc-kgnvl
May 15 08:59:34.576: INFO: Created: latency-svc-smp99
May 15 08:59:34.586: INFO: Got endpoints: latency-svc-vn7w5 [351.275717ms]
May 15 08:59:34.595: INFO: Created: latency-svc-lvpt9
May 15 08:59:34.598: INFO: Got endpoints: latency-svc-kgnvl [300.091293ms]
May 15 08:59:34.617: INFO: Got endpoints: latency-svc-smp99 [290.636902ms]
May 15 08:59:34.617: INFO: Created: latency-svc-5l7lw
May 15 08:59:34.634: INFO: Got endpoints: latency-svc-lvpt9 [276.717896ms]
May 15 08:59:34.641: INFO: Created: latency-svc-qvqjf
May 15 08:59:34.652: INFO: Created: latency-svc-4xjgr
May 15 08:59:34.664: INFO: Got endpoints: latency-svc-5l7lw [277.174741ms]
May 15 08:59:34.664: INFO: Created: latency-svc-vrm5n
May 15 08:59:34.677: INFO: Got endpoints: latency-svc-qvqjf [289.673889ms]
May 15 08:59:34.682: INFO: Created: latency-svc-b97vg
May 15 08:59:34.702: INFO: Created: latency-svc-mpcwh
May 15 08:59:34.714: INFO: Got endpoints: latency-svc-4xjgr [290.540499ms]
May 15 08:59:34.728: INFO: Created: latency-svc-n7mp5
May 15 08:59:34.730: INFO: Got endpoints: latency-svc-vrm5n [323.367956ms]
May 15 08:59:34.730: INFO: Got endpoints: latency-svc-b97vg [279.384119ms]
May 15 08:59:34.731: INFO: Created: latency-svc-fxvh8
May 15 08:59:34.753: INFO: Got endpoints: latency-svc-n7mp5 [247.174892ms]
May 15 08:59:34.753: INFO: Got endpoints: latency-svc-mpcwh [282.157878ms]
May 15 08:59:34.753: INFO: Got endpoints: latency-svc-fxvh8 [247.244002ms]
May 15 08:59:34.757: INFO: Created: latency-svc-r57qv
May 15 08:59:34.773: INFO: Created: latency-svc-kbpmz
May 15 08:59:34.787: INFO: Created: latency-svc-qqjph
May 15 08:59:34.795: INFO: Got endpoints: latency-svc-r57qv [259.595668ms]
May 15 08:59:34.808: INFO: Created: latency-svc-5g82n
May 15 08:59:34.831: INFO: Created: latency-svc-t7nct
May 15 08:59:34.842: INFO: Created: latency-svc-wlhwq
May 15 08:59:34.853: INFO: Got endpoints: latency-svc-kbpmz [306.402923ms]
May 15 08:59:34.854: INFO: Created: latency-svc-ckl5f
May 15 08:59:34.856: INFO: Created: latency-svc-sbm7w
May 15 08:59:34.881: INFO: Created: latency-svc-k59dc
May 15 08:59:34.886: INFO: Got endpoints: latency-svc-qqjph [222.179343ms]
May 15 08:59:34.891: INFO: Created: latency-svc-xtbrs
May 15 08:59:34.918: INFO: Created: latency-svc-xdc7q
May 15 08:59:34.931: INFO: Created: latency-svc-78pbn
May 15 08:59:34.942: INFO: Created: latency-svc-mjm9k
May 15 08:59:34.955: INFO: Created: latency-svc-2ftsx
May 15 08:59:34.962: INFO: Got endpoints: latency-svc-5g82n [408.137516ms]
May 15 08:59:34.974: INFO: Created: latency-svc-vprzr
May 15 08:59:34.991: INFO: Created: latency-svc-7w9lg
May 15 08:59:35.001: INFO: Got endpoints: latency-svc-t7nct [414.193185ms]
May 15 08:59:35.003: INFO: Created: latency-svc-7qf4p
May 15 08:59:35.010: INFO: Created: latency-svc-mnh9t
May 15 08:59:35.024: INFO: Got endpoints: latency-svc-wlhwq [425.339156ms]
May 15 08:59:35.048: INFO: Created: latency-svc-9n9lm
May 15 08:59:35.076: INFO: Got endpoints: latency-svc-ckl5f [458.832823ms]
May 15 08:59:35.093: INFO: Created: latency-svc-vltml
May 15 08:59:35.109: INFO: Created: latency-svc-c89vj
May 15 08:59:35.124: INFO: Got endpoints: latency-svc-sbm7w [490.028859ms]
May 15 08:59:35.161: INFO: Created: latency-svc-pjfct
May 15 08:59:35.173: INFO: Got endpoints: latency-svc-k59dc [496.167908ms]
May 15 08:59:35.207: INFO: Created: latency-svc-4tj6s
May 15 08:59:35.222: INFO: Got endpoints: latency-svc-xtbrs [508.112216ms]
May 15 08:59:35.253: INFO: Created: latency-svc-djsvk
May 15 08:59:35.272: INFO: Got endpoints: latency-svc-xdc7q [542.056953ms]
May 15 08:59:35.321: INFO: Created: latency-svc-x4ndh
May 15 08:59:35.323: INFO: Got endpoints: latency-svc-78pbn [592.631291ms]
May 15 08:59:35.363: INFO: Created: latency-svc-zmsd8
May 15 08:59:35.379: INFO: Got endpoints: latency-svc-mjm9k [626.633186ms]
May 15 08:59:35.403: INFO: Created: latency-svc-jvgqb
May 15 08:59:35.422: INFO: Got endpoints: latency-svc-2ftsx [669.553016ms]
May 15 08:59:35.459: INFO: Created: latency-svc-jnnw9
May 15 08:59:35.472: INFO: Got endpoints: latency-svc-vprzr [718.743925ms]
May 15 08:59:35.501: INFO: Created: latency-svc-dsw8v
May 15 08:59:35.524: INFO: Got endpoints: latency-svc-7w9lg [728.217282ms]
May 15 08:59:35.555: INFO: Created: latency-svc-kqgtw
May 15 08:59:35.573: INFO: Got endpoints: latency-svc-7qf4p [719.351737ms]
May 15 08:59:35.612: INFO: Created: latency-svc-tb7rr
May 15 08:59:35.623: INFO: Got endpoints: latency-svc-mnh9t [736.288433ms]
May 15 08:59:35.660: INFO: Created: latency-svc-lr2b6
May 15 08:59:35.672: INFO: Got endpoints: latency-svc-9n9lm [710.097945ms]
May 15 08:59:35.744: INFO: Created: latency-svc-rh4vh
May 15 08:59:35.746: INFO: Got endpoints: latency-svc-vltml [745.367054ms]
May 15 08:59:35.763: INFO: Created: latency-svc-nmxqq
May 15 08:59:35.774: INFO: Got endpoints: latency-svc-c89vj [750.150551ms]
May 15 08:59:35.847: INFO: Created: latency-svc-9ptzf
May 15 08:59:35.851: INFO: Got endpoints: latency-svc-pjfct [774.632407ms]
May 15 08:59:35.865: INFO: Created: latency-svc-gklqx
May 15 08:59:35.872: INFO: Got endpoints: latency-svc-4tj6s [747.690708ms]
May 15 08:59:35.932: INFO: Got endpoints: latency-svc-djsvk [758.81078ms]
May 15 08:59:35.940: INFO: Created: latency-svc-fksxq
May 15 08:59:35.957: INFO: Created: latency-svc-65ddp
May 15 08:59:35.972: INFO: Got endpoints: latency-svc-x4ndh [749.55489ms]
May 15 08:59:36.014: INFO: Created: latency-svc-l25m2
May 15 08:59:36.023: INFO: Got endpoints: latency-svc-zmsd8 [750.442847ms]
May 15 08:59:36.053: INFO: Created: latency-svc-r7xsg
May 15 08:59:36.071: INFO: Got endpoints: latency-svc-jvgqb [748.293506ms]
May 15 08:59:36.103: INFO: Created: latency-svc-6xw94
May 15 08:59:36.122: INFO: Got endpoints: latency-svc-jnnw9 [742.535221ms]
May 15 08:59:36.164: INFO: Created: latency-svc-7f2jg
May 15 08:59:36.176: INFO: Got endpoints: latency-svc-dsw8v [753.273423ms]
May 15 08:59:36.205: INFO: Created: latency-svc-mlcss
May 15 08:59:36.222: INFO: Got endpoints: latency-svc-kqgtw [750.384827ms]
May 15 08:59:36.259: INFO: Created: latency-svc-wqqhn
May 15 08:59:36.271: INFO: Got endpoints: latency-svc-tb7rr [747.302748ms]
May 15 08:59:36.312: INFO: Created: latency-svc-rf4wk
May 15 08:59:36.324: INFO: Got endpoints: latency-svc-lr2b6 [751.351393ms]
May 15 08:59:36.354: INFO: Created: latency-svc-dwkjt
May 15 08:59:36.379: INFO: Got endpoints: latency-svc-rh4vh [755.84812ms]
May 15 08:59:36.402: INFO: Created: latency-svc-qncqg
May 15 08:59:36.421: INFO: Got endpoints: latency-svc-nmxqq [748.687126ms]
May 15 08:59:36.458: INFO: Created: latency-svc-zjgbf
May 15 08:59:36.473: INFO: Got endpoints: latency-svc-9ptzf [726.597187ms]
May 15 08:59:36.504: INFO: Created: latency-svc-9bvc7
May 15 08:59:36.523: INFO: Got endpoints: latency-svc-gklqx [748.550441ms]
May 15 08:59:36.552: INFO: Created: latency-svc-ztd2z
May 15 08:59:36.572: INFO: Got endpoints: latency-svc-fksxq [721.214305ms]
May 15 08:59:36.605: INFO: Created: latency-svc-s7ztl
May 15 08:59:36.622: INFO: Got endpoints: latency-svc-65ddp [750.172869ms]
May 15 08:59:36.655: INFO: Created: latency-svc-p9wbp
May 15 08:59:36.679: INFO: Got endpoints: latency-svc-l25m2 [747.38049ms]
May 15 08:59:36.710: INFO: Created: latency-svc-twvdf
May 15 08:59:36.722: INFO: Got endpoints: latency-svc-r7xsg [749.853376ms]
May 15 08:59:36.763: INFO: Created: latency-svc-p9bwb
May 15 08:59:36.773: INFO: Got endpoints: latency-svc-6xw94 [750.678974ms]
May 15 08:59:36.809: INFO: Created: latency-svc-tlxfh
May 15 08:59:36.824: INFO: Got endpoints: latency-svc-7f2jg [753.165732ms]
May 15 08:59:36.855: INFO: Created: latency-svc-7dvzr
May 15 08:59:36.871: INFO: Got endpoints: latency-svc-mlcss [748.72664ms]
May 15 08:59:36.916: INFO: Created: latency-svc-t7cfp
May 15 08:59:36.924: INFO: Got endpoints: latency-svc-wqqhn [748.31502ms]
May 15 08:59:36.951: INFO: Created: latency-svc-xjl9w
May 15 08:59:36.971: INFO: Got endpoints: latency-svc-rf4wk [748.749079ms]
May 15 08:59:37.004: INFO: Created: latency-svc-xjjz7
May 15 08:59:37.021: INFO: Got endpoints: latency-svc-dwkjt [750.324989ms]
May 15 08:59:37.063: INFO: Created: latency-svc-fvm8k
May 15 08:59:37.071: INFO: Got endpoints: latency-svc-qncqg [746.672473ms]
May 15 08:59:37.104: INFO: Created: latency-svc-kj54g
May 15 08:59:37.122: INFO: Got endpoints: latency-svc-zjgbf [743.506435ms]
May 15 08:59:37.151: INFO: Created: latency-svc-hk4gw
May 15 08:59:37.171: INFO: Got endpoints: latency-svc-9bvc7 [750.097557ms]
May 15 08:59:37.209: INFO: Created: latency-svc-wdvw5
May 15 08:59:37.221: INFO: Got endpoints: latency-svc-ztd2z [748.064772ms]
May 15 08:59:37.251: INFO: Created: latency-svc-mqgdk
May 15 08:59:37.272: INFO: Got endpoints: latency-svc-s7ztl [749.043492ms]
May 15 08:59:37.299: INFO: Created: latency-svc-tvg89
May 15 08:59:37.323: INFO: Got endpoints: latency-svc-p9wbp [751.119475ms]
May 15 08:59:37.352: INFO: Created: latency-svc-s2dgf
May 15 08:59:37.373: INFO: Got endpoints: latency-svc-twvdf [750.521003ms]
May 15 08:59:37.404: INFO: Created: latency-svc-bmrgr
May 15 08:59:37.421: INFO: Got endpoints: latency-svc-p9bwb [741.745331ms]
May 15 08:59:37.454: INFO: Created: latency-svc-758w8
May 15 08:59:37.471: INFO: Got endpoints: latency-svc-tlxfh [749.434649ms]
May 15 08:59:37.503: INFO: Created: latency-svc-spr5j
May 15 08:59:37.522: INFO: Got endpoints: latency-svc-7dvzr [748.641404ms]
May 15 08:59:37.553: INFO: Created: latency-svc-4j9hf
May 15 08:59:37.572: INFO: Got endpoints: latency-svc-t7cfp [747.90729ms]
May 15 08:59:37.623: INFO: Created: latency-svc-x64hx
May 15 08:59:37.638: INFO: Got endpoints: latency-svc-xjl9w [767.218018ms]
May 15 08:59:37.670: INFO: Created: latency-svc-lzhwb
May 15 08:59:37.677: INFO: Got endpoints: latency-svc-xjjz7 [752.588064ms]
May 15 08:59:37.726: INFO: Created: latency-svc-tz6kh
May 15 08:59:37.727: INFO: Got endpoints: latency-svc-fvm8k [756.063695ms]
May 15 08:59:37.759: INFO: Created: latency-svc-q2mcf
May 15 08:59:37.772: INFO: Got endpoints: latency-svc-kj54g [750.03558ms]
May 15 08:59:37.808: INFO: Created: latency-svc-tb86f
May 15 08:59:37.822: INFO: Got endpoints: latency-svc-hk4gw [750.679727ms]
May 15 08:59:37.853: INFO: Created: latency-svc-4kxz4
May 15 08:59:37.873: INFO: Got endpoints: latency-svc-wdvw5 [750.5618ms]
May 15 08:59:37.904: INFO: Created: latency-svc-ddwdk
May 15 08:59:37.923: INFO: Got endpoints: latency-svc-mqgdk [752.096344ms]
May 15 08:59:37.955: INFO: Created: latency-svc-7bbgd
May 15 08:59:37.971: INFO: Got endpoints: latency-svc-tvg89 [749.970639ms]
May 15 08:59:38.005: INFO: Created: latency-svc-tjpks
May 15 08:59:38.023: INFO: Got endpoints: latency-svc-s2dgf [750.972623ms]
May 15 08:59:38.054: INFO: Created: latency-svc-6rdwv
May 15 08:59:38.072: INFO: Got endpoints: latency-svc-bmrgr [749.22368ms]
May 15 08:59:38.106: INFO: Created: latency-svc-xbtdn
May 15 08:59:38.124: INFO: Got endpoints: latency-svc-758w8 [751.694573ms]
May 15 08:59:38.156: INFO: Created: latency-svc-zm2pm
May 15 08:59:38.173: INFO: Got endpoints: latency-svc-spr5j [751.823318ms]
May 15 08:59:38.208: INFO: Created: latency-svc-nl8rl
May 15 08:59:38.224: INFO: Got endpoints: latency-svc-4j9hf [752.588004ms]
May 15 08:59:38.258: INFO: Created: latency-svc-f6lgz
May 15 08:59:38.271: INFO: Got endpoints: latency-svc-x64hx [749.148305ms]
May 15 08:59:38.304: INFO: Created: latency-svc-plfmz
May 15 08:59:38.322: INFO: Got endpoints: latency-svc-lzhwb [749.597317ms]
May 15 08:59:38.354: INFO: Created: latency-svc-bx86s
May 15 08:59:38.374: INFO: Got endpoints: latency-svc-tz6kh [735.402469ms]
May 15 08:59:38.414: INFO: Created: latency-svc-zsfpg
May 15 08:59:38.428: INFO: Got endpoints: latency-svc-q2mcf [750.814204ms]
May 15 08:59:38.460: INFO: Created: latency-svc-8qp46
May 15 08:59:38.474: INFO: Got endpoints: latency-svc-tb86f [746.656432ms]
May 15 08:59:38.505: INFO: Created: latency-svc-klr8p
May 15 08:59:38.522: INFO: Got endpoints: latency-svc-4kxz4 [750.003071ms]
May 15 08:59:38.557: INFO: Created: latency-svc-n9gh2
May 15 08:59:38.571: INFO: Got endpoints: latency-svc-ddwdk [749.259975ms]
May 15 08:59:38.601: INFO: Created: latency-svc-q5t6k
May 15 08:59:38.622: INFO: Got endpoints: latency-svc-7bbgd [749.474864ms]
May 15 08:59:38.651: INFO: Created: latency-svc-klwz2
May 15 08:59:38.672: INFO: Got endpoints: latency-svc-tjpks [748.346407ms]
May 15 08:59:38.707: INFO: Created: latency-svc-xwqvg
May 15 08:59:38.722: INFO: Got endpoints: latency-svc-6rdwv [750.929644ms]
May 15 08:59:38.751: INFO: Created: latency-svc-n967p
May 15 08:59:38.772: INFO: Got endpoints: latency-svc-xbtdn [748.781452ms]
May 15 08:59:38.802: INFO: Created: latency-svc-8mvmk
May 15 08:59:38.821: INFO: Got endpoints: latency-svc-zm2pm [748.45206ms]
May 15 08:59:38.851: INFO: Created: latency-svc-s6qw9
May 15 08:59:38.871: INFO: Got endpoints: latency-svc-nl8rl [747.074528ms]
May 15 08:59:38.908: INFO: Created: latency-svc-s2rjj
May 15 08:59:38.922: INFO: Got endpoints: latency-svc-f6lgz [749.120904ms]
May 15 08:59:38.950: INFO: Created: latency-svc-npcs5
May 15 08:59:38.971: INFO: Got endpoints: latency-svc-plfmz [746.879068ms]
May 15 08:59:39.000: INFO: Created: latency-svc-qsdmv
May 15 08:59:39.022: INFO: Got endpoints: latency-svc-bx86s [750.017859ms]
May 15 08:59:39.049: INFO: Created: latency-svc-6c88f
May 15 08:59:39.072: INFO: Got endpoints: latency-svc-zsfpg [750.177662ms]
May 15 08:59:39.102: INFO: Created: latency-svc-vbpzt
May 15 08:59:39.121: INFO: Got endpoints: latency-svc-8qp46 [747.828134ms]
May 15 08:59:39.154: INFO: Created: latency-svc-s7jdf
May 15 08:59:39.172: INFO: Got endpoints: latency-svc-klr8p [744.168311ms]
May 15 08:59:39.204: INFO: Created: latency-svc-vpz9n
May 15 08:59:39.222: INFO: Got endpoints: latency-svc-n9gh2 [748.238715ms]
May 15 08:59:39.254: INFO: Created: latency-svc-29vf7
May 15 08:59:39.272: INFO: Got endpoints: latency-svc-q5t6k [750.658886ms]
May 15 08:59:39.302: INFO: Created: latency-svc-mqdbb
May 15 08:59:39.323: INFO: Got endpoints: latency-svc-klwz2 [751.791747ms]
May 15 08:59:39.353: INFO: Created: latency-svc-s92gh
May 15 08:59:39.371: INFO: Got endpoints: latency-svc-xwqvg [748.819051ms]
May 15 08:59:39.401: INFO: Created: latency-svc-pqs9p
May 15 08:59:39.516: INFO: Got endpoints: latency-svc-n967p [843.85462ms]
May 15 08:59:39.556: INFO: Got endpoints: latency-svc-8mvmk [833.98772ms]
May 15 08:59:39.594: INFO: Got endpoints: latency-svc-s6qw9 [822.540221ms]
May 15 08:59:39.726: INFO: Got endpoints: latency-svc-s2rjj [904.839604ms]
May 15 08:59:39.726: INFO: Got endpoints: latency-svc-npcs5 [854.571632ms]
May 15 08:59:39.726: INFO: Got endpoints: latency-svc-qsdmv [803.958087ms]
May 15 08:59:39.733: INFO: Created: latency-svc-qqbtt
May 15 08:59:39.745: INFO: Created: latency-svc-7wkc4
May 15 08:59:39.751: INFO: Got endpoints: latency-svc-6c88f [779.890413ms]
May 15 08:59:39.757: INFO: Created: latency-svc-qrrpj
May 15 08:59:39.762: INFO: Created: latency-svc-hbqmr
May 15 08:59:39.771: INFO: Got endpoints: latency-svc-vbpzt [749.027129ms]
May 15 08:59:39.815: INFO: Created: latency-svc-lwt2v
May 15 08:59:39.828: INFO: Created: latency-svc-5jc2v
May 15 08:59:39.837: INFO: Created: latency-svc-52hhn
May 15 08:59:39.840: INFO: Got endpoints: latency-svc-s7jdf [767.872651ms]
May 15 08:59:39.857: INFO: Created: latency-svc-q2nk4
May 15 08:59:39.865: INFO: Created: latency-svc-9vc2c
May 15 08:59:39.873: INFO: Got endpoints: latency-svc-vpz9n [751.247329ms]
May 15 08:59:39.948: INFO: Got endpoints: latency-svc-29vf7 [775.505127ms]
May 15 08:59:39.956: INFO: Created: latency-svc-mzzfq
May 15 08:59:39.968: INFO: Created: latency-svc-4sq7v
May 15 08:59:40.004: INFO: Got endpoints: latency-svc-mqdbb [781.630378ms]
May 15 08:59:40.031: INFO: Got endpoints: latency-svc-s92gh [758.572354ms]
May 15 08:59:40.036: INFO: Created: latency-svc-mtjs6
May 15 08:59:40.071: INFO: Got endpoints: latency-svc-pqs9p [748.155906ms]
May 15 08:59:40.086: INFO: Created: latency-svc-fqmpk
May 15 08:59:40.110: INFO: Created: latency-svc-4gqjh
May 15 08:59:40.121: INFO: Got endpoints: latency-svc-qqbtt [749.381042ms]
May 15 08:59:40.149: INFO: Created: latency-svc-mdwz5
May 15 08:59:40.171: INFO: Got endpoints: latency-svc-7wkc4 [654.785367ms]
May 15 08:59:40.207: INFO: Created: latency-svc-cx2ts
May 15 08:59:40.235: INFO: Got endpoints: latency-svc-qrrpj [678.536549ms]
May 15 08:59:40.281: INFO: Created: latency-svc-jmw69
May 15 08:59:40.288: INFO: Got endpoints: latency-svc-hbqmr [693.521953ms]
May 15 08:59:40.328: INFO: Created: latency-svc-s8hds
May 15 08:59:40.333: INFO: Got endpoints: latency-svc-lwt2v [606.882013ms]
May 15 08:59:40.374: INFO: Got endpoints: latency-svc-5jc2v [647.46267ms]
May 15 08:59:40.383: INFO: Created: latency-svc-trx8x
May 15 08:59:40.432: INFO: Got endpoints: latency-svc-52hhn [705.342534ms]
May 15 08:59:40.456: INFO: Created: latency-svc-svtwl
May 15 08:59:40.482: INFO: Created: latency-svc-q2s75
May 15 08:59:40.486: INFO: Got endpoints: latency-svc-q2nk4 [735.01234ms]
May 15 08:59:40.525: INFO: Got endpoints: latency-svc-9vc2c [754.391864ms]
May 15 08:59:40.543: INFO: Created: latency-svc-jfhq6
May 15 08:59:40.586: INFO: Got endpoints: latency-svc-mzzfq [745.589262ms]
May 15 08:59:40.593: INFO: Created: latency-svc-vldrv
May 15 08:59:40.635: INFO: Created: latency-svc-nqxjg
May 15 08:59:40.640: INFO: Got endpoints: latency-svc-4sq7v [766.731933ms]
May 15 08:59:40.687: INFO: Got endpoints: latency-svc-mtjs6 [739.862834ms]
May 15 08:59:40.694: INFO: Created: latency-svc-xp6c2
May 15 08:59:40.744: INFO: Created: latency-svc-v5wlr
May 15 08:59:40.745: INFO: Got endpoints: latency-svc-fqmpk [741.089698ms]
May 15 08:59:40.774: INFO: Got endpoints: latency-svc-4gqjh [742.948451ms]
May 15 08:59:40.822: INFO: Got endpoints: latency-svc-mdwz5 [750.970938ms]
May 15 08:59:40.870: INFO: Got endpoints: latency-svc-cx2ts [749.355585ms]
May 15 08:59:40.922: INFO: Got endpoints: latency-svc-jmw69 [751.110489ms]
May 15 08:59:40.971: INFO: Got endpoints: latency-svc-s8hds [736.481567ms]
May 15 08:59:41.021: INFO: Got endpoints: latency-svc-trx8x [733.388744ms]
May 15 08:59:41.071: INFO: Got endpoints: latency-svc-svtwl [737.880614ms]
May 15 08:59:41.122: INFO: Got endpoints: latency-svc-q2s75 [748.412562ms]
May 15 08:59:41.172: INFO: Got endpoints: latency-svc-jfhq6 [740.28219ms]
May 15 08:59:41.222: INFO: Got endpoints: latency-svc-vldrv [736.232431ms]
May 15 08:59:41.273: INFO: Got endpoints: latency-svc-nqxjg [747.64566ms]
May 15 08:59:41.322: INFO: Got endpoints: latency-svc-xp6c2 [735.72412ms]
May 15 08:59:41.373: INFO: Got endpoints: latency-svc-v5wlr [732.728285ms]
May 15 08:59:41.373: INFO: Latencies: [131.417278ms 222.11143ms 222.179343ms 239.246609ms 247.174892ms 247.244002ms 259.595668ms 266.673517ms 276.717896ms 277.174741ms 277.893823ms 279.384119ms 282.157878ms 285.794434ms 289.673889ms 290.540499ms 290.636902ms 296.055144ms 300.091293ms 302.511676ms 306.402923ms 311.034045ms 311.797916ms 313.900115ms 316.154697ms 323.367956ms 327.935878ms 339.965372ms 340.020561ms 351.275717ms 353.581688ms 362.614558ms 369.466141ms 378.517898ms 378.529827ms 382.910177ms 396.777231ms 398.818266ms 407.247371ms 408.137516ms 408.482804ms 414.193185ms 421.251927ms 423.056792ms 425.339156ms 429.80837ms 443.064835ms 458.832823ms 483.227559ms 490.028859ms 491.631114ms 496.167908ms 508.112216ms 517.99758ms 519.41751ms 522.303525ms 539.079758ms 539.081207ms 542.056953ms 554.062711ms 558.807503ms 560.656383ms 569.619265ms 574.559988ms 577.125122ms 577.260563ms 578.671634ms 586.898802ms 592.631291ms 602.800133ms 606.882013ms 615.490279ms 625.941574ms 626.633186ms 630.548683ms 631.075185ms 647.46267ms 652.536877ms 652.616468ms 652.767646ms 654.785367ms 663.853657ms 669.553016ms 678.536549ms 693.521953ms 705.342534ms 710.097945ms 717.99724ms 718.743925ms 719.351737ms 721.214305ms 726.597187ms 728.217282ms 732.728285ms 733.388744ms 735.01234ms 735.402469ms 735.72412ms 736.232431ms 736.288433ms 736.481567ms 737.880614ms 739.862834ms 740.28219ms 741.089698ms 741.745331ms 742.535221ms 742.948451ms 743.506435ms 744.168311ms 745.367054ms 745.589262ms 746.656432ms 746.672473ms 746.879068ms 747.074528ms 747.302748ms 747.38049ms 747.64566ms 747.690708ms 747.828134ms 747.90729ms 748.064772ms 748.155906ms 748.238715ms 748.293506ms 748.31502ms 748.346407ms 748.412562ms 748.45206ms 748.550441ms 748.641404ms 748.687126ms 748.72664ms 748.749079ms 748.781452ms 748.819051ms 749.027129ms 749.043492ms 749.120904ms 749.148305ms 749.22368ms 749.259975ms 749.355585ms 749.381042ms 749.434649ms 749.474864ms 749.55489ms 749.597317ms 749.853376ms 749.970639ms 750.003071ms 750.017859ms 750.03558ms 750.097557ms 750.150551ms 750.172869ms 750.177662ms 750.324989ms 750.384827ms 750.442847ms 750.521003ms 750.5618ms 750.658886ms 750.678974ms 750.679727ms 750.814204ms 750.929644ms 750.970938ms 750.972623ms 751.110489ms 751.119475ms 751.247329ms 751.351393ms 751.694573ms 751.791747ms 751.823318ms 752.096344ms 752.588004ms 752.588064ms 753.165732ms 753.273423ms 754.391864ms 755.84812ms 756.063695ms 758.572354ms 758.81078ms 766.731933ms 767.218018ms 767.872651ms 774.632407ms 775.505127ms 779.890413ms 781.630378ms 803.958087ms 822.540221ms 833.98772ms 843.85462ms 854.571632ms 904.839604ms]
May 15 08:59:41.373: INFO: 50 %ile: 736.481567ms
May 15 08:59:41.373: INFO: 90 %ile: 753.165732ms
May 15 08:59:41.373: INFO: 99 %ile: 854.571632ms
May 15 08:59:41.373: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 08:59:41.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-svc-latency-2q6c2" for this suite.
May 15 08:59:59.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 09:00:01.666: INFO: namespace: e2e-tests-svc-latency-2q6c2, resource: bindings, ignored listing per whitelist
May 15 09:00:04.190: INFO: namespace e2e-tests-svc-latency-2q6c2 deletion completed in 22.747148494s

[32m [SLOW TEST:36.559 seconds][0m
[sig-network] Service endpoints latency
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  should not be very high  [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mshould support (root,0777,default) [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 09:00:04.191: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating a pod to test emptydir 0777 on node default medium
May 15 09:00:06.749: INFO: Waiting up to 5m0s for pod "pod-d5b837be-76ef-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-emptydir-kxzdx" to be "success or failure"
May 15 09:00:06.850: INFO: Pod "pod-d5b837be-76ef-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 100.508557ms
May 15 09:00:08.920: INFO: Pod "pod-d5b837be-76ef-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.170692709s
[1mSTEP[0m: Saw pod success
May 15 09:00:08.920: INFO: Pod "pod-d5b837be-76ef-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 09:00:08.990: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx pod pod-d5b837be-76ef-11e9-9e56-3ac139a44f02 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 15 09:00:09.203: INFO: Waiting for pod pod-d5b837be-76ef-11e9-9e56-3ac139a44f02 to disappear
May 15 09:00:09.295: INFO: Pod pod-d5b837be-76ef-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 09:00:09.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-emptydir-kxzdx" for this suite.
May 15 09:00:15.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 09:00:16.494: INFO: namespace: e2e-tests-emptydir-kxzdx, resource: bindings, ignored listing per whitelist
May 15 09:00:20.625: INFO: namespace e2e-tests-emptydir-kxzdx deletion completed in 11.258774698s

[32m [SLOW TEST:16.434 seconds][0m
[sig-storage] EmptyDir volumes
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40[0m
  should support (root,0777,default) [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 09:00:20.625: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-df8f5d6a-76ef-11e9-9e56-3ac139a44f02
[1mSTEP[0m: Creating a pod to test consume secrets
May 15 09:00:23.357: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02" in namespace "e2e-tests-projected-cmg46" to be "success or failure"
May 15 09:00:23.457: INFO: Pod "pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 100.05167ms
May 15 09:00:25.527: INFO: Pod "pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.169877204s
May 15 09:00:27.597: INFO: Pod "pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.240119833s
[1mSTEP[0m: Saw pod success
May 15 09:00:27.597: INFO: Pod "pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02" satisfied condition "success or failure"
May 15 09:00:27.666: INFO: Trying to get logs from node gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r pod pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02 container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 15 09:00:27.879: INFO: Waiting for pod pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02 to disappear
May 15 09:00:27.984: INFO: Pod pod-projected-secrets-df9de175-76ef-11e9-9e56-3ac139a44f02 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 09:00:27.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-projected-cmg46" for this suite.
May 15 09:00:34.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 09:00:35.899: INFO: namespace: e2e-tests-projected-cmg46, resource: bindings, ignored listing per whitelist
May 15 09:00:39.091: INFO: namespace e2e-tests-projected-cmg46 deletion completed in 11.035613809s

[32m [SLOW TEST:18.467 seconds][0m
[sig-storage] Projected secret
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34[0m
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartAlways pod [Conformance][0m
  [37m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
[1mSTEP[0m: Creating a kubernetes client
May 15 09:00:39.092: INFO: >>> kubeConfig: /tmp/gke-kubecfg325943844
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[1mSTEP[0m: creating the pod
May 15 09:00:41.537: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 15 09:00:45.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[1mSTEP[0m: Destroying namespace "e2e-tests-init-container-pmgzm" for this suite.
May 15 09:01:08.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 15 09:01:08.502: INFO: namespace: e2e-tests-init-container-pmgzm, resource: bindings, ignored listing per whitelist
May 15 09:01:12.092: INFO: namespace e2e-tests-init-container-pmgzm deletion completed in 26.338042444s

[32m [SLOW TEST:33.000 seconds][0m
[k8s.io] InitContainer [NodeConformance]
[90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694[0m
  should invoke init containers on a RestartAlways pod [Conformance]
  [90m/workspace/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699[0m
[90m------------------------------[0m
May 15 09:01:12.092: INFO: Running AfterSuite actions on all nodes
May 15 09:01:12.117: INFO: Running AfterSuite actions on node 1
May 15 09:01:12.117: INFO: Skipping dumping logs from cluster

[1m[32mRan 201 of 2161 Specs in 7534.734 seconds[0m
[1m[32mSUCCESS![0m -- [32m[1m201 Passed[0m | [91m[1m0 Failed[0m | [33m[1m0 Pending[0m | [36m[1m1960 Skipped[0m PASS

Ginkgo ran 1 suite in 2h5m35.750525044s
Test Suite Passed
2019/05/15 09:01:12 process.go:155: Step './hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\] --minStartupPods=8 --num-nodes=3 --report-dir=/logs/artifacts --disable-log-dump=true' finished in 2h5m36.220524834s
2019/05/15 09:01:12 process.go:153: Running: bash -c 
function log_dump_custom_get_instances() {
  if [[ $1 == "master" ]]; then
    return 0
  fi

  gcloud compute instances list '--project=prow-gob-internal-boskos-62' '--filter=(metadata.created-by:*zones/us-east1-d/instanceGroupManagers/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-grp)' '--format=get(name)'
}
export -f log_dump_custom_get_instances
# Set below vars that log-dump.sh expects in order to use scp with gcloud.
export PROJECT=prow-gob-internal-boskos-62
export ZONE='us-east1-d'
export KUBERNETES_PROVIDER=gke
export KUBE_NODE_OS_DISTRIBUTION='gci'
./cluster/log-dump/log-dump.sh '/logs/artifacts'
Checking for custom logdump instances, if any
Using 'use_custom_instance_list' with gke, skipping check for LOG_DUMP_SSH_KEY and LOG_DUMP_SSH_USER
Dumping logs from master locally to '/logs/artifacts'
No masters found?
Dumping logs from nodes locally to '/logs/artifacts'
Dumping logs for nodes provided by log_dump_custom_get_instances() function
WARNING: --filter : operator evaluation is changing for consistency across Google APIs.  metadata.created-by:*zones/us-east1-d/instanceGroupManagers/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-grp currently matches but will not match in the near future.  Run `gcloud topic filters` for details.
Changing logfiles to be world-readable for download
Changing logfiles to be world-readable for download
Changing logfiles to be world-readable for download
Copying 'kube-proxy.log fluentd.log node-problem-detector.log kubelet.cov' from gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-vscx
Copying 'kube-proxy.log fluentd.log node-problem-detector.log kubelet.cov' from gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-pf6r
Copying 'kube-proxy.log fluentd.log node-problem-detector.log kubelet.cov' from gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-68wz

Specify --start=132879 in the next get-serial-port-output invocation to get only the new output starting from here.

Specify --start=152042 in the next get-serial-port-output invocation to get only the new output starting from here.

Specify --start=81545 in the next get-serial-port-output invocation to get only the new output starting from here.
scp: /var/log/fluentd.log*: No such file or directory
scp: /var/log/node-problem-detector.log*: No such file or directory
scp: /var/log/kubelet.cov*: No such file or directory
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
scp: /var/log/fluentd.log*: No such file or directory
scp: /var/log/node-problem-detector.log*: No such file or directory
scp: /var/log/kubelet.cov*: No such file or directory
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
scp: /var/log/fluentd.log*: No such file or directory
scp: /var/log/node-problem-detector.log*: No such file or directory
scp: /var/log/kubelet.cov*: No such file or directory
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
2019/05/15 09:02:05 process.go:155: Step 'bash -c 
function log_dump_custom_get_instances() {
  if [[ $1 == "master" ]]; then
    return 0
  fi

  gcloud compute instances list '--project=prow-gob-internal-boskos-62' '--filter=(metadata.created-by:*zones/us-east1-d/instanceGroupManagers/gke-e2e-a9ed4389fc-72cc1-default-pool-f216a26d-grp)' '--format=get(name)'
}
export -f log_dump_custom_get_instances
# Set below vars that log-dump.sh expects in order to use scp with gcloud.
export PROJECT=prow-gob-internal-boskos-62
export ZONE='us-east1-d'
export KUBERNETES_PROVIDER=gke
export KUBE_NODE_OS_DISTRIBUTION='gci'
./cluster/log-dump/log-dump.sh '/logs/artifacts'
' finished in 53.208851672s
2019/05/15 09:02:05 e2e.go:444: Listing resources...
2019/05/15 09:02:05 process.go:153: Running: ./cluster/gce/list-resources.sh
Listed 0 items.

To show all fields of the firewall, please show in JSON format: --format=json
To show all fields in table format, please see the examples in --help.

Listed 0 items.
Listed 0 items.
Listed 0 items.
2019/05/15 09:02:15 process.go:155: Step './cluster/gce/list-resources.sh' finished in 10.571405342s
2019/05/15 09:02:15 process.go:153: Running: gcloud container clusters delete -q e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --zone=us-east1-d
Deleting cluster e2e-a9ed4389fc-72cc1...
...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.
Deleted [https://container.googleapis.com/v1/projects/prow-gob-internal-boskos-62/zones/us-east1-d/clusters/e2e-a9ed4389fc-72cc1].
2019/05/15 09:04:50 process.go:155: Step 'gcloud container clusters delete -q e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62 --zone=us-east1-d' finished in 2m34.871712229s
2019/05/15 09:04:50 process.go:153: Running: gcloud compute firewall-rules describe e2e-ports-f216a26d --project=prow-gob-internal-boskos-62 --format=value(name)
2019/05/15 09:04:51 process.go:155: Step 'gcloud compute firewall-rules describe e2e-ports-f216a26d --project=prow-gob-internal-boskos-62 --format=value(name)' finished in 904.564288ms
2019/05/15 09:04:51 gke.go:610: Found rules for firewall 'e2e-ports-f216a26d', deleting them
2019/05/15 09:04:51 process.go:153: Running: gcloud compute firewall-rules delete -q e2e-ports-f216a26d --project=prow-gob-internal-boskos-62
Deleted [https://www.googleapis.com/compute/v1/projects/prow-gob-internal-boskos-62/global/firewalls/e2e-ports-f216a26d].
2019/05/15 09:05:04 process.go:155: Step 'gcloud compute firewall-rules delete -q e2e-ports-f216a26d --project=prow-gob-internal-boskos-62' finished in 12.265017246s
2019/05/15 09:05:04 process.go:153: Running: gcloud compute networks delete -q e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62
Deleted [https://www.googleapis.com/compute/v1/projects/prow-gob-internal-boskos-62/global/networks/e2e-a9ed4389fc-72cc1].
2019/05/15 09:06:04 process.go:155: Step 'gcloud compute networks delete -q e2e-a9ed4389fc-72cc1 --project=prow-gob-internal-boskos-62' finished in 59.375757907s
2019/05/15 09:06:04 e2e.go:277: Sleeping for 30 seconds...
2019/05/15 09:06:34 e2e.go:444: Listing resources...
2019/05/15 09:06:34 process.go:153: Running: ./cluster/gce/list-resources.sh
Listed 0 items.
Listed 0 items.
Listed 0 items.
Listed 0 items.
Listed 0 items.

To show all fields of the firewall, please show in JSON format: --format=json
To show all fields in table format, please see the examples in --help.

Listed 0 items.
Listed 0 items.
Listed 0 items.
2019/05/15 09:06:44 process.go:155: Step './cluster/gce/list-resources.sh' finished in 9.756967345s
2019/05/15 09:06:44 process.go:153: Running: diff -sw -U0 -F^\[.*\]$ /logs/artifacts/gcp-resources-before.txt /logs/artifacts/gcp-resources-after.txt
2019/05/15 09:06:44 process.go:155: Step 'diff -sw -U0 -F^\[.*\]$ /logs/artifacts/gcp-resources-before.txt /logs/artifacts/gcp-resources-after.txt' finished in 45.427286ms
2019/05/15 09:06:44 process.go:96: Saved XML output to /logs/artifacts/junit_runner.xml.
+ EXIT_VALUE=0
+ set +o xtrace
