I0614 11:56:38.761094      18 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-059955192
I0614 11:56:38.763412      18 e2e.go:224] Starting e2e run "77367325-8e9b-11e9-82a6-0255ac100014" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1560513397 - Will randomize all specs
Will run 201 of 1946 specs

Jun 14 11:56:38.871: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 11:56:38.874: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jun 14 11:56:38.897: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 14 11:56:38.917: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 14 11:56:38.917: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Jun 14 11:56:38.917: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jun 14 11:56:38.922: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'icagent' (0 seconds elapsed)
Jun 14 11:56:38.922: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'storage-driver' (0 seconds elapsed)
Jun 14 11:56:38.922: INFO: e2e test version: v1.13.0
Jun 14 11:56:38.924: INFO: kube-apiserver version: v1.13.6-r0-CCE2.0.23.B001
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:56:38.924: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename var-expansion
Jun 14 11:56:38.984: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jun 14 11:56:38.998: INFO: Waiting up to 5m0s for pod "var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014" in namespace "e2e-tests-var-expansion-n8sg4" to be "success or failure"
Jun 14 11:56:39.000: INFO: Pod "var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.779864ms
Jun 14 11:56:41.002: INFO: Pod "var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004207038s
Jun 14 11:56:43.005: INFO: Pod "var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006718812s
Jun 14 11:56:45.008: INFO: Pod "var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009421172s
Jun 14 11:56:47.010: INFO: Pod "var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.01193433s
STEP: Saw pod success
Jun 14 11:56:47.010: INFO: Pod "var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 11:56:47.012: INFO: Trying to get logs from node 192.168.0.235 pod var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 11:56:47.050: INFO: Waiting for pod var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014 to disappear
Jun 14 11:56:47.052: INFO: Pod var-expansion-77a46e63-8e9b-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 11:56:47.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-n8sg4" for this suite.
Jun 14 11:56:53.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:56:53.070: INFO: namespace: e2e-tests-var-expansion-n8sg4, resource: bindings, ignored listing per whitelist
Jun 14 11:56:53.115: INFO: namespace e2e-tests-var-expansion-n8sg4 deletion completed in 6.06185989s

• [SLOW TEST:14.192 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:56:53.116: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 11:56:59.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-jd2rd" for this suite.
Jun 14 11:57:05.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:57:05.314: INFO: namespace: e2e-tests-namespaces-jd2rd, resource: bindings, ignored listing per whitelist
Jun 14 11:57:05.327: INFO: namespace e2e-tests-namespaces-jd2rd deletion completed in 6.064416654s
STEP: Destroying namespace "e2e-tests-nsdeletetest-bs9t6" for this suite.
Jun 14 11:57:05.328: INFO: Namespace e2e-tests-nsdeletetest-bs9t6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-5cvsz" for this suite.
Jun 14 11:57:11.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:57:11.351: INFO: namespace: e2e-tests-nsdeletetest-5cvsz, resource: bindings, ignored listing per whitelist
Jun 14 11:57:11.387: INFO: namespace e2e-tests-nsdeletetest-5cvsz deletion completed in 6.058501258s

• [SLOW TEST:18.271 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:57:11.387: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-8afcc823-8e9b-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 11:57:11.452: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-8l7mp" to be "success or failure"
Jun 14 11:57:11.454: INFO: Pod "pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076991ms
Jun 14 11:57:13.457: INFO: Pod "pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004570045s
Jun 14 11:57:15.459: INFO: Pod "pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006754918s
Jun 14 11:57:17.462: INFO: Pod "pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009207241s
STEP: Saw pod success
Jun 14 11:57:17.462: INFO: Pod "pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 11:57:17.463: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 14 11:57:17.482: INFO: Waiting for pod pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014 to disappear
Jun 14 11:57:17.484: INFO: Pod pod-projected-secrets-8afd9530-8e9b-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 11:57:17.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8l7mp" for this suite.
Jun 14 11:57:23.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:57:23.540: INFO: namespace: e2e-tests-projected-8l7mp, resource: bindings, ignored listing per whitelist
Jun 14 11:57:23.544: INFO: namespace e2e-tests-projected-8l7mp deletion completed in 6.058514506s

• [SLOW TEST:12.157 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:57:23.544: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jun 14 11:57:29.616: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-923bf9c8-8e9b-11e9-82a6-0255ac100014,GenerateName:,Namespace:e2e-tests-events-vxhxc,SelfLink:/api/v1/namespaces/e2e-tests-events-vxhxc/pods/send-events-923bf9c8-8e9b-11e9-82a6-0255ac100014,UID:924d1bb4-8e9b-11e9-a0dc-fa163eff1b62,ResourceVersion:32027,Generation:0,CreationTimestamp:2019-06-14 11:57:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 599000112,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vprrc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vprrc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-vprrc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011cc240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011cc260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc000744150} {timeout 0xc000744160}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 11:57:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 11:57:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 11:57:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 11:57:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:172.16.0.54,StartTime:2019-06-14 11:57:23 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-06-14 11:57:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ce4d8e27833b737caa7827a5e55dfbf8ec1e8d6c7d3b25007889b13a0b38bd91}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jun 14 11:57:31.620: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jun 14 11:57:33.623: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 11:57:33.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-vxhxc" for this suite.
Jun 14 11:58:11.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:58:11.684: INFO: namespace: e2e-tests-events-vxhxc, resource: bindings, ignored listing per whitelist
Jun 14 11:58:11.685: INFO: namespace e2e-tests-events-vxhxc deletion completed in 38.053812347s

• [SLOW TEST:48.141 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:58:11.685: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jun 14 11:58:11.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 cluster-info'
Jun 14 11:58:12.085: INFO: stderr: ""
Jun 14 11:58:12.085: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.247.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.247.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 11:58:12.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sqfvh" for this suite.
Jun 14 11:58:18.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:58:18.119: INFO: namespace: e2e-tests-kubectl-sqfvh, resource: bindings, ignored listing per whitelist
Jun 14 11:58:18.144: INFO: namespace e2e-tests-kubectl-sqfvh deletion completed in 6.056291551s

• [SLOW TEST:6.458 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:58:18.144: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jun 14 11:58:18.196: INFO: Waiting up to 5m0s for pod "var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014" in namespace "e2e-tests-var-expansion-fhs9f" to be "success or failure"
Jun 14 11:58:18.198: INFO: Pod "var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114194ms
Jun 14 11:58:20.200: INFO: Pod "var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004429176s
Jun 14 11:58:22.202: INFO: Pod "var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006626299s
STEP: Saw pod success
Jun 14 11:58:22.202: INFO: Pod "var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 11:58:22.204: INFO: Trying to get logs from node 192.168.0.235 pod var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 11:58:22.217: INFO: Waiting for pod var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014 to disappear
Jun 14 11:58:22.218: INFO: Pod var-expansion-b2c603ea-8e9b-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 11:58:22.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-fhs9f" for this suite.
Jun 14 11:58:28.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:58:28.239: INFO: namespace: e2e-tests-var-expansion-fhs9f, resource: bindings, ignored listing per whitelist
Jun 14 11:58:28.277: INFO: namespace e2e-tests-var-expansion-fhs9f deletion completed in 6.05687012s

• [SLOW TEST:10.133 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:58:28.277: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 11:58:30.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zvltc" for this suite.
Jun 14 11:59:20.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 11:59:20.417: INFO: namespace: e2e-tests-kubelet-test-zvltc, resource: bindings, ignored listing per whitelist
Jun 14 11:59:20.458: INFO: namespace e2e-tests-kubelet-test-zvltc deletion completed in 50.104545535s

• [SLOW TEST:52.181 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 11:59:20.458: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-b2x7t
Jun 14 11:59:32.515: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-b2x7t
STEP: checking the pod's current state and verifying that restartCount is present
Jun 14 11:59:32.516: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:03:32.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-b2x7t" for this suite.
Jun 14 12:03:38.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:03:38.993: INFO: namespace: e2e-tests-container-probe-b2x7t, resource: bindings, ignored listing per whitelist
Jun 14 12:03:38.998: INFO: namespace e2e-tests-container-probe-b2x7t deletion completed in 6.056366032s

• [SLOW TEST:258.540 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:03:38.998: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 14 12:03:39.060: INFO: Waiting up to 5m0s for pod "pod-7205d1ff-8e9c-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-6f6j2" to be "success or failure"
Jun 14 12:03:39.061: INFO: Pod "pod-7205d1ff-8e9c-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.831188ms
Jun 14 12:03:41.067: INFO: Pod "pod-7205d1ff-8e9c-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007532041s
STEP: Saw pod success
Jun 14 12:03:41.067: INFO: Pod "pod-7205d1ff-8e9c-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:03:41.069: INFO: Trying to get logs from node 192.168.0.235 pod pod-7205d1ff-8e9c-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:03:41.114: INFO: Waiting for pod pod-7205d1ff-8e9c-11e9-82a6-0255ac100014 to disappear
Jun 14 12:03:41.116: INFO: Pod pod-7205d1ff-8e9c-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:03:41.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6f6j2" for this suite.
Jun 14 12:03:47.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:03:47.134: INFO: namespace: e2e-tests-emptydir-6f6j2, resource: bindings, ignored listing per whitelist
Jun 14 12:03:47.175: INFO: namespace e2e-tests-emptydir-6f6j2 deletion completed in 6.056912516s

• [SLOW TEST:8.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:03:47.175: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-tr9c2
Jun 14 12:03:51.228: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-tr9c2
STEP: checking the pod's current state and verifying that restartCount is present
Jun 14 12:03:51.229: INFO: Initial restart count of pod liveness-http is 0
Jun 14 12:04:05.250: INFO: Restart count of pod e2e-tests-container-probe-tr9c2/liveness-http is now 1 (14.021353469s elapsed)
Jun 14 12:04:25.283: INFO: Restart count of pod e2e-tests-container-probe-tr9c2/liveness-http is now 2 (34.054156479s elapsed)
Jun 14 12:04:45.314: INFO: Restart count of pod e2e-tests-container-probe-tr9c2/liveness-http is now 3 (54.084945513s elapsed)
Jun 14 12:05:05.344: INFO: Restart count of pod e2e-tests-container-probe-tr9c2/liveness-http is now 4 (1m14.114674239s elapsed)
Jun 14 12:06:15.451: INFO: Restart count of pod e2e-tests-container-probe-tr9c2/liveness-http is now 5 (2m24.221904462s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:06:15.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tr9c2" for this suite.
Jun 14 12:06:21.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:06:21.490: INFO: namespace: e2e-tests-container-probe-tr9c2, resource: bindings, ignored listing per whitelist
Jun 14 12:06:21.522: INFO: namespace e2e-tests-container-probe-tr9c2 deletion completed in 6.060131371s

• [SLOW TEST:154.347 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:06:21.522: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jun 14 12:06:21.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 api-versions'
Jun 14 12:06:21.638: INFO: stderr: ""
Jun 14 12:06:21.638: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nrbac.cce.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:06:21.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w27v5" for this suite.
Jun 14 12:06:27.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:06:27.673: INFO: namespace: e2e-tests-kubectl-w27v5, resource: bindings, ignored listing per whitelist
Jun 14 12:06:27.723: INFO: namespace e2e-tests-kubectl-w27v5 deletion completed in 6.081869256s

• [SLOW TEST:6.201 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:06:27.723: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-sts4
STEP: Creating a pod to test atomic-volume-subpath
Jun 14 12:06:27.784: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sts4" in namespace "e2e-tests-subpath-7pcs6" to be "success or failure"
Jun 14 12:06:27.787: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.278434ms
Jun 14 12:06:29.790: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005797377s
Jun 14 12:06:31.796: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 4.011683687s
Jun 14 12:06:33.798: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 6.014243145s
Jun 14 12:06:35.800: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 8.016458356s
Jun 14 12:06:37.802: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 10.01849957s
Jun 14 12:06:39.805: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 12.021037882s
Jun 14 12:06:41.811: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 14.027269401s
Jun 14 12:06:43.814: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 16.029626015s
Jun 14 12:06:45.816: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 18.03215455s
Jun 14 12:06:47.819: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 20.034823856s
Jun 14 12:06:49.821: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Running", Reason="", readiness=false. Elapsed: 22.037382362s
Jun 14 12:06:51.827: INFO: Pod "pod-subpath-test-projected-sts4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043353016s
STEP: Saw pod success
Jun 14 12:06:51.827: INFO: Pod "pod-subpath-test-projected-sts4" satisfied condition "success or failure"
Jun 14 12:06:51.829: INFO: Trying to get logs from node 192.168.0.235 pod pod-subpath-test-projected-sts4 container test-container-subpath-projected-sts4: <nil>
STEP: delete the pod
Jun 14 12:06:51.849: INFO: Waiting for pod pod-subpath-test-projected-sts4 to disappear
Jun 14 12:06:51.852: INFO: Pod pod-subpath-test-projected-sts4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-sts4
Jun 14 12:06:51.852: INFO: Deleting pod "pod-subpath-test-projected-sts4" in namespace "e2e-tests-subpath-7pcs6"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:06:51.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7pcs6" for this suite.
Jun 14 12:06:57.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:06:57.870: INFO: namespace: e2e-tests-subpath-7pcs6, resource: bindings, ignored listing per whitelist
Jun 14 12:06:57.914: INFO: namespace e2e-tests-subpath-7pcs6 deletion completed in 6.057929959s

• [SLOW TEST:30.191 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:06:57.914: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 14 12:07:02.507: INFO: Successfully updated pod "annotationupdatee8952eef-8e9c-11e9-82a6-0255ac100014"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:07:04.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rzzp4" for this suite.
Jun 14 12:07:26.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:07:26.537: INFO: namespace: e2e-tests-projected-rzzp4, resource: bindings, ignored listing per whitelist
Jun 14 12:07:26.580: INFO: namespace e2e-tests-projected-rzzp4 deletion completed in 22.058480107s

• [SLOW TEST:28.666 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:07:26.580: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:07:26.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7tzsj" for this suite.
Jun 14 12:07:32.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:07:32.692: INFO: namespace: e2e-tests-kubelet-test-7tzsj, resource: bindings, ignored listing per whitelist
Jun 14 12:07:32.703: INFO: namespace e2e-tests-kubelet-test-7tzsj deletion completed in 6.057030083s

• [SLOW TEST:6.123 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:07:32.703: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-5zhnt
Jun 14 12:07:34.762: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-5zhnt
STEP: checking the pod's current state and verifying that restartCount is present
Jun 14 12:07:34.763: INFO: Initial restart count of pod liveness-exec is 0
Jun 14 12:08:26.846: INFO: Restart count of pod e2e-tests-container-probe-5zhnt/liveness-exec is now 1 (52.082506647s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:08:26.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5zhnt" for this suite.
Jun 14 12:08:32.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:08:32.894: INFO: namespace: e2e-tests-container-probe-5zhnt, resource: bindings, ignored listing per whitelist
Jun 14 12:08:32.915: INFO: namespace e2e-tests-container-probe-5zhnt deletion completed in 6.058408278s

• [SLOW TEST:60.212 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:08:32.915: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-21353776-8e9d-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:08:32.974: INFO: Waiting up to 5m0s for pod "pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-spclg" to be "success or failure"
Jun 14 12:08:32.976: INFO: Pod "pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.75505ms
Jun 14 12:08:34.982: INFO: Pod "pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007152921s
Jun 14 12:08:36.984: INFO: Pod "pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009686222s
STEP: Saw pod success
Jun 14 12:08:36.984: INFO: Pod "pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:08:36.986: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:08:37.002: INFO: Waiting for pod pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:08:37.003: INFO: Pod pod-configmaps-2135e84b-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:08:37.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-spclg" for this suite.
Jun 14 12:08:43.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:08:43.020: INFO: namespace: e2e-tests-configmap-spclg, resource: bindings, ignored listing per whitelist
Jun 14 12:08:43.062: INFO: namespace e2e-tests-configmap-spclg deletion completed in 6.057268798s

• [SLOW TEST:10.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:08:43.062: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jun 14 12:08:43.107: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-059955192 proxy --unix-socket=/tmp/kubectl-proxy-unix738779383/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:08:43.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qtdfm" for this suite.
Jun 14 12:08:49.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:08:49.198: INFO: namespace: e2e-tests-kubectl-qtdfm, resource: bindings, ignored listing per whitelist
Jun 14 12:08:49.211: INFO: namespace e2e-tests-kubectl-qtdfm deletion completed in 6.058286214s

• [SLOW TEST:6.149 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:08:49.211: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:08:49.289: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"2aff8649-8e9d-11e9-a0dc-fa163eff1b62", Controller:(*bool)(0xc0026ea576), BlockOwnerDeletion:(*bool)(0xc0026ea577)}}
Jun 14 12:08:49.295: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"2afd65ac-8e9d-11e9-a0dc-fa163eff1b62", Controller:(*bool)(0xc001fc8746), BlockOwnerDeletion:(*bool)(0xc001fc8747)}}
Jun 14 12:08:49.300: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"2afe2f8b-8e9d-11e9-a0dc-fa163eff1b62", Controller:(*bool)(0xc0026df886), BlockOwnerDeletion:(*bool)(0xc0026df887)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:08:54.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-d9vf7" for this suite.
Jun 14 12:09:00.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:09:00.321: INFO: namespace: e2e-tests-gc-d9vf7, resource: bindings, ignored listing per whitelist
Jun 14 12:09:00.368: INFO: namespace e2e-tests-gc-d9vf7 deletion completed in 6.058829101s

• [SLOW TEST:11.156 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:09:00.368: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 14 12:09:00.412: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:09:03.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ptt2v" for this suite.
Jun 14 12:09:09.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:09:09.560: INFO: namespace: e2e-tests-init-container-ptt2v, resource: bindings, ignored listing per whitelist
Jun 14 12:09:09.571: INFO: namespace e2e-tests-init-container-ptt2v deletion completed in 6.065149096s

• [SLOW TEST:9.204 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:09:09.571: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-370e38fe-8e9d-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:09:09.627: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-370ecfb4-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-xbjxd" to be "success or failure"
Jun 14 12:09:09.629: INFO: Pod "pod-projected-configmaps-370ecfb4-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.705488ms
Jun 14 12:09:11.631: INFO: Pod "pod-projected-configmaps-370ecfb4-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004083945s
STEP: Saw pod success
Jun 14 12:09:11.631: INFO: Pod "pod-projected-configmaps-370ecfb4-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:09:11.633: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-configmaps-370ecfb4-8e9d-11e9-82a6-0255ac100014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:09:11.644: INFO: Waiting for pod pod-projected-configmaps-370ecfb4-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:09:11.646: INFO: Pod pod-projected-configmaps-370ecfb4-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:09:11.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xbjxd" for this suite.
Jun 14 12:09:17.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:09:17.681: INFO: namespace: e2e-tests-projected-xbjxd, resource: bindings, ignored listing per whitelist
Jun 14 12:09:17.727: INFO: namespace e2e-tests-projected-xbjxd deletion completed in 6.079291758s

• [SLOW TEST:8.156 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:09:17.727: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:09:17.778: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3bea427d-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-p9qkf" to be "success or failure"
Jun 14 12:09:17.780: INFO: Pod "downwardapi-volume-3bea427d-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.636007ms
Jun 14 12:09:19.782: INFO: Pod "downwardapi-volume-3bea427d-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004072153s
STEP: Saw pod success
Jun 14 12:09:19.782: INFO: Pod "downwardapi-volume-3bea427d-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:09:19.784: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-3bea427d-8e9d-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:09:19.836: INFO: Waiting for pod downwardapi-volume-3bea427d-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:09:19.838: INFO: Pod downwardapi-volume-3bea427d-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:09:19.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p9qkf" for this suite.
Jun 14 12:09:25.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:09:25.889: INFO: namespace: e2e-tests-downward-api-p9qkf, resource: bindings, ignored listing per whitelist
Jun 14 12:09:25.896: INFO: namespace e2e-tests-downward-api-p9qkf deletion completed in 6.05659175s

• [SLOW TEST:8.169 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:09:25.896: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 14 12:09:25.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-c48xv'
Jun 14 12:09:26.185: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 14 12:09:26.185: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jun 14 12:09:26.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-c48xv'
Jun 14 12:09:26.244: INFO: stderr: ""
Jun 14 12:09:26.244: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:09:26.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c48xv" for this suite.
Jun 14 12:09:48.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:09:48.280: INFO: namespace: e2e-tests-kubectl-c48xv, resource: bindings, ignored listing per whitelist
Jun 14 12:09:48.310: INFO: namespace e2e-tests-kubectl-c48xv deletion completed in 22.063574003s

• [SLOW TEST:22.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:09:48.310: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 14 12:09:48.361: INFO: Waiting up to 5m0s for pod "downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-bxzfn" to be "success or failure"
Jun 14 12:09:48.363: INFO: Pod "downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.72569ms
Jun 14 12:09:50.369: INFO: Pod "downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007574651s
Jun 14 12:09:52.371: INFO: Pod "downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010071334s
STEP: Saw pod success
Jun 14 12:09:52.371: INFO: Pod "downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:09:52.373: INFO: Trying to get logs from node 192.168.0.235 pod downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 12:09:52.388: INFO: Waiting for pod downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:09:52.391: INFO: Pod downward-api-4e24e519-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:09:52.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bxzfn" for this suite.
Jun 14 12:09:58.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:09:58.405: INFO: namespace: e2e-tests-downward-api-bxzfn, resource: bindings, ignored listing per whitelist
Jun 14 12:09:58.451: INFO: namespace e2e-tests-downward-api-bxzfn deletion completed in 6.058367858s

• [SLOW TEST:10.141 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:09:58.451: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-7qp5c;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-7qp5c;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7qp5c.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 145.6.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.6.145_udp@PTR;check="$$(dig +tcp +noall +answer +search 145.6.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.6.145_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-7qp5c;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-7qp5c.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-7qp5c.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7qp5c.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 145.6.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.6.145_udp@PTR;check="$$(dig +tcp +noall +answer +search 145.6.247.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.247.6.145_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 14 12:10:22.953: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:22.983: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:22.984: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:22.986: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7qp5c from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:22.988: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:22.990: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:22.992: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:22.993: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:23.001: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:23.013: INFO: Lookups using e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7qp5c jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c jessie_udp@dns-test-service.e2e-tests-dns-7qp5c.svc jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc]

Jun 14 12:10:28.016: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.043: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.045: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.047: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7qp5c from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.048: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.050: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.052: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.054: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.055: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:28.066: INFO: Lookups using e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7qp5c jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c jessie_udp@dns-test-service.e2e-tests-dns-7qp5c.svc jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc]

Jun 14 12:10:33.022: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.072: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.074: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.076: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7qp5c from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.078: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.079: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.081: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.083: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.085: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc from pod e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014: the server could not find the requested resource (get pods dns-test-5431de53-8e9d-11e9-82a6-0255ac100014)
Jun 14 12:10:33.096: INFO: Lookups using e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-7qp5c jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c jessie_udp@dns-test-service.e2e-tests-dns-7qp5c.svc jessie_tcp@dns-test-service.e2e-tests-dns-7qp5c.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-7qp5c.svc]

Jun 14 12:10:38.065: INFO: DNS probes using e2e-tests-dns-7qp5c/dns-test-5431de53-8e9d-11e9-82a6-0255ac100014 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:10:38.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-7qp5c" for this suite.
Jun 14 12:10:44.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:10:44.137: INFO: namespace: e2e-tests-dns-7qp5c, resource: bindings, ignored listing per whitelist
Jun 14 12:10:44.179: INFO: namespace e2e-tests-dns-7qp5c deletion completed in 6.070591581s

• [SLOW TEST:45.728 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:10:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 14 12:10:44.222: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:10:49.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-l9hlb" for this suite.
Jun 14 12:11:11.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:11:11.292: INFO: namespace: e2e-tests-init-container-l9hlb, resource: bindings, ignored listing per whitelist
Jun 14 12:11:11.321: INFO: namespace e2e-tests-init-container-l9hlb deletion completed in 22.05841919s

• [SLOW TEST:27.142 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:11:11.321: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-zltmc
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zltmc to expose endpoints map[]
Jun 14 12:11:11.378: INFO: Get endpoints failed (1.903863ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jun 14 12:11:12.380: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zltmc exposes endpoints map[] (1.004189101s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-zltmc
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zltmc to expose endpoints map[pod1:[100]]
Jun 14 12:11:14.399: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zltmc exposes endpoints map[pod1:[100]] (2.011049896s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-zltmc
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zltmc to expose endpoints map[pod1:[100] pod2:[101]]
Jun 14 12:11:18.433: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zltmc exposes endpoints map[pod1:[100] pod2:[101]] (4.031109569s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-zltmc
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zltmc to expose endpoints map[pod2:[101]]
Jun 14 12:11:19.451: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zltmc exposes endpoints map[pod2:[101]] (1.007292367s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-zltmc
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zltmc to expose endpoints map[]
Jun 14 12:11:20.459: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zltmc exposes endpoints map[] (1.00407214s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:11:20.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-zltmc" for this suite.
Jun 14 12:11:42.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:11:42.537: INFO: namespace: e2e-tests-services-zltmc, resource: bindings, ignored listing per whitelist
Jun 14 12:11:42.546: INFO: namespace e2e-tests-services-zltmc deletion completed in 22.067827053s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:31.225 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:11:42.546: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-923dc755-8e9d-11e9-82a6-0255ac100014
STEP: Creating configMap with name cm-test-opt-upd-923dc77d-8e9d-11e9-82a6-0255ac100014
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-923dc755-8e9d-11e9-82a6-0255ac100014
STEP: Updating configmap cm-test-opt-upd-923dc77d-8e9d-11e9-82a6-0255ac100014
STEP: Creating configMap with name cm-test-opt-create-923dc78d-8e9d-11e9-82a6-0255ac100014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:11:48.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pwdnd" for this suite.
Jun 14 12:12:10.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:12:10.714: INFO: namespace: e2e-tests-configmap-pwdnd, resource: bindings, ignored listing per whitelist
Jun 14 12:12:10.739: INFO: namespace e2e-tests-configmap-pwdnd deletion completed in 22.067132634s

• [SLOW TEST:28.193 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:12:10.739: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a30a0a2f-8e9d-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:12:10.844: INFO: Waiting up to 5m0s for pod "pod-secrets-a31242cf-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-475tk" to be "success or failure"
Jun 14 12:12:10.845: INFO: Pod "pod-secrets-a31242cf-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.397733ms
Jun 14 12:12:12.859: INFO: Pod "pod-secrets-a31242cf-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015148263s
STEP: Saw pod success
Jun 14 12:12:12.859: INFO: Pod "pod-secrets-a31242cf-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:12:12.861: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-a31242cf-8e9d-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:12:12.874: INFO: Waiting for pod pod-secrets-a31242cf-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:12:12.876: INFO: Pod pod-secrets-a31242cf-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:12:12.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-475tk" for this suite.
Jun 14 12:12:18.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:12:18.909: INFO: namespace: e2e-tests-secrets-475tk, resource: bindings, ignored listing per whitelist
Jun 14 12:12:18.939: INFO: namespace e2e-tests-secrets-475tk deletion completed in 6.061704896s
STEP: Destroying namespace "e2e-tests-secret-namespace-zdg6b" for this suite.
Jun 14 12:12:24.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:12:24.956: INFO: namespace: e2e-tests-secret-namespace-zdg6b, resource: bindings, ignored listing per whitelist
Jun 14 12:12:24.996: INFO: namespace e2e-tests-secret-namespace-zdg6b deletion completed in 6.057226483s

• [SLOW TEST:14.257 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:12:24.996: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 14 12:12:25.051: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 14 12:12:25.055: INFO: Waiting for terminating namespaces to be deleted...
Jun 14 12:12:25.056: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.19 before test
Jun 14 12:12:25.065: INFO: storage-driver-pz5nn from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.065: INFO: 	Container storage-driver ready: true, restart count 0
Jun 14 12:12:25.065: INFO: coredns-7d456d978c-xkjtl from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.065: INFO: 	Container coredns ready: true, restart count 0
Jun 14 12:12:25.065: INFO: icagent-pbhr4 from kube-system started at 2019-06-14 08:59:55 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.065: INFO: 	Container icagent ready: true, restart count 0
Jun 14 12:12:25.065: INFO: web-terminal-78fcf4fd59-smd5z from default started at 2019-06-14 09:17:03 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.065: INFO: 	Container web-terminal ready: true, restart count 0
Jun 14 12:12:25.065: INFO: sonobuoy-e2e-job-99d77d11689f4bcf from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 12:12:25.065: INFO: 	Container e2e ready: true, restart count 0
Jun 14 12:12:25.065: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 14 12:12:25.065: INFO: sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-8q7tm from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 12:12:25.065: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 14 12:12:25.065: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 14 12:12:25.065: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.235 before test
Jun 14 12:12:25.070: INFO: storage-driver-m898l from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.070: INFO: 	Container storage-driver ready: true, restart count 0
Jun 14 12:12:25.070: INFO: coredns-7d456d978c-vklzn from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.070: INFO: 	Container coredns ready: true, restart count 0
Jun 14 12:12:25.070: INFO: icagent-qzxb7 from kube-system started at 2019-06-14 08:59:56 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.070: INFO: 	Container icagent ready: true, restart count 0
Jun 14 12:12:25.070: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-14 11:55:55 +0000 UTC (1 container statuses recorded)
Jun 14 12:12:25.070: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 14 12:12:25.070: INFO: sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-t2dvh from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 12:12:25.070: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 14 12:12:25.070: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-acc2979f-8e9d-11e9-82a6-0255ac100014 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-acc2979f-8e9d-11e9-82a6-0255ac100014 off the node 192.168.0.235
STEP: verifying the node doesn't have the label kubernetes.io/e2e-acc2979f-8e9d-11e9-82a6-0255ac100014
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:12:31.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-f555p" for this suite.
Jun 14 12:12:39.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:12:39.176: INFO: namespace: e2e-tests-sched-pred-f555p, resource: bindings, ignored listing per whitelist
Jun 14 12:12:39.189: INFO: namespace e2e-tests-sched-pred-f555p deletion completed in 8.057319968s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:14.193 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:12:39.189: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0614 12:12:49.270636      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 14 12:12:49.270: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:12:49.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-65j87" for this suite.
Jun 14 12:12:55.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:12:55.311: INFO: namespace: e2e-tests-gc-65j87, resource: bindings, ignored listing per whitelist
Jun 14 12:12:55.333: INFO: namespace e2e-tests-gc-65j87 deletion completed in 6.061472503s

• [SLOW TEST:16.144 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:12:55.334: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bd9e9a0e-8e9d-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:12:55.398: INFO: Waiting up to 5m0s for pod "pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-mp6k2" to be "success or failure"
Jun 14 12:12:55.399: INFO: Pod "pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.643404ms
Jun 14 12:12:57.402: INFO: Pod "pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004028542s
Jun 14 12:12:59.404: INFO: Pod "pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006290216s
STEP: Saw pod success
Jun 14 12:12:59.404: INFO: Pod "pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:12:59.406: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:12:59.425: INFO: Waiting for pod pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:12:59.427: INFO: Pod pod-secrets-bda08930-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:12:59.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mp6k2" for this suite.
Jun 14 12:13:05.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:13:05.452: INFO: namespace: e2e-tests-secrets-mp6k2, resource: bindings, ignored listing per whitelist
Jun 14 12:13:05.491: INFO: namespace e2e-tests-secrets-mp6k2 deletion completed in 6.062435621s

• [SLOW TEST:10.157 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:13:05.491: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c3ac0d92-8e9d-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:13:05.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-7bpjp" to be "success or failure"
Jun 14 12:13:05.545: INFO: Pod "pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429445ms
Jun 14 12:13:07.548: INFO: Pod "pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004764951s
Jun 14 12:13:09.550: INFO: Pod "pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007510989s
STEP: Saw pod success
Jun 14 12:13:09.550: INFO: Pod "pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:13:09.552: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:13:09.567: INFO: Waiting for pod pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:13:09.569: INFO: Pod pod-configmaps-c3aca722-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:13:09.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7bpjp" for this suite.
Jun 14 12:13:15.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:13:15.586: INFO: namespace: e2e-tests-configmap-7bpjp, resource: bindings, ignored listing per whitelist
Jun 14 12:13:15.632: INFO: namespace e2e-tests-configmap-7bpjp deletion completed in 6.061112277s

• [SLOW TEST:10.140 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:13:15.632: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c9b7903c-8e9d-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:13:15.686: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-8g9jh" to be "success or failure"
Jun 14 12:13:15.688: INFO: Pod "pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.834365ms
Jun 14 12:13:17.690: INFO: Pod "pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004243367s
Jun 14 12:13:19.693: INFO: Pod "pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006665s
STEP: Saw pod success
Jun 14 12:13:19.693: INFO: Pod "pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:13:19.694: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:13:19.708: INFO: Waiting for pod pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014 to disappear
Jun 14 12:13:19.709: INFO: Pod pod-projected-configmaps-c9b83113-8e9d-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:13:19.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8g9jh" for this suite.
Jun 14 12:13:25.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:13:25.752: INFO: namespace: e2e-tests-projected-8g9jh, resource: bindings, ignored listing per whitelist
Jun 14 12:13:25.770: INFO: namespace e2e-tests-projected-8g9jh deletion completed in 6.05923366s

• [SLOW TEST:10.138 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:13:25.770: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:14:25.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-f7lk7" for this suite.
Jun 14 12:14:47.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:14:47.858: INFO: namespace: e2e-tests-container-probe-f7lk7, resource: bindings, ignored listing per whitelist
Jun 14 12:14:47.888: INFO: namespace e2e-tests-container-probe-f7lk7 deletion completed in 22.05705905s

• [SLOW TEST:82.118 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:14:47.888: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:14:47.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 version --client'
Jun 14 12:14:47.980: INFO: stderr: ""
Jun 14 12:14:47.980: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jun 14 12:14:47.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-84zrb'
Jun 14 12:14:48.141: INFO: stderr: ""
Jun 14 12:14:48.141: INFO: stdout: "replicationcontroller/redis-master created\n"
Jun 14 12:14:48.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-84zrb'
Jun 14 12:14:48.260: INFO: stderr: ""
Jun 14 12:14:48.260: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 14 12:14:49.263: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:14:49.263: INFO: Found 0 / 1
Jun 14 12:14:50.266: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:14:50.266: INFO: Found 0 / 1
Jun 14 12:14:51.263: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:14:51.263: INFO: Found 0 / 1
Jun 14 12:14:52.263: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:14:52.263: INFO: Found 0 / 1
Jun 14 12:14:53.263: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:14:53.263: INFO: Found 1 / 1
Jun 14 12:14:53.263: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 14 12:14:53.265: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:14:53.265: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 14 12:14:53.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 describe pod redis-master-qxwdk --namespace=e2e-tests-kubectl-84zrb'
Jun 14 12:14:53.325: INFO: stderr: ""
Jun 14 12:14:53.325: INFO: stdout: "Name:               redis-master-qxwdk\nNamespace:          e2e-tests-kubectl-84zrb\nPriority:           0\nPriorityClassName:  <none>\nNode:               192.168.0.235/192.168.0.235\nStart Time:         Fri, 14 Jun 2019 12:14:48 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 172.16.0.58\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://c283a55fc1a37dd850e8b7d7f30c4ea16712fd284f3886ccb42ab22e46da7d32\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 14 Jun 2019 12:14:52 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-kgn5g (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-kgn5g:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-kgn5g\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason                 Age              From                    Message\n  ----    ------                 ----             ----                    -------\n  Normal  Scheduled              5s               default-scheduler       Successfully assigned e2e-tests-kubectl-84zrb/redis-master-qxwdk to 192.168.0.235\n  Normal  Pulling                4s               kubelet, 192.168.0.235  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled                 2s               kubelet, 192.168.0.235  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  SuccessfulMountVolume  1s (x2 over 5s)  kubelet, 192.168.0.235  Successfully mounted volumes for pod \"redis-master-qxwdk_e2e-tests-kubectl-84zrb(00ce4ad7-8e9e-11e9-8a76-fa163e95400d)\"\n  Normal  SuccessfulCreate       1s               kubelet, 192.168.0.235  Created container\n  Normal  Started                1s               kubelet, 192.168.0.235  Started container\n"
Jun 14 12:14:53.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 describe rc redis-master --namespace=e2e-tests-kubectl-84zrb'
Jun 14 12:14:53.391: INFO: stderr: ""
Jun 14 12:14:53.391: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-84zrb\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-qxwdk\n"
Jun 14 12:14:53.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 describe service redis-master --namespace=e2e-tests-kubectl-84zrb'
Jun 14 12:14:53.450: INFO: stderr: ""
Jun 14 12:14:53.450: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-84zrb\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.247.55.14\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.16.0.58:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jun 14 12:14:53.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 describe node 192.168.0.19'
Jun 14 12:14:53.519: INFO: stderr: ""
Jun 14 12:14:53.519: INFO: stdout: "Name:               192.168.0.19\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/is-baremetal=false\n                    failure-domain.beta.kubernetes.io/region=ap-southeast-1\n                    failure-domain.beta.kubernetes.io/zone=ap-southeast-1a\n                    kubernetes.io/availablezone=ap-southeast-1a\n                    kubernetes.io/hostname=192.168.0.19\n                    os.architecture=amd64\n                    os.name=EulerOS_2.0_SP5\n                    os.version=3.10.0-862.14.0.1.h147.eulerosv2r7.x86_64\nAnnotations:        huawei.com/gpu-status: []\n                    node.alpha.kubernetes.io/ttl: 0\nCreationTimestamp:  Fri, 14 Jun 2019 08:58:57 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 14 Jun 2019 12:14:34 +0000   Fri, 14 Jun 2019 08:58:56 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 14 Jun 2019 12:14:34 +0000   Fri, 14 Jun 2019 08:58:56 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 14 Jun 2019 12:14:34 +0000   Fri, 14 Jun 2019 08:58:56 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 14 Jun 2019 12:14:34 +0000   Fri, 14 Jun 2019 08:59:06 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.0.19\n  Hostname:    192.168.0.19\nCapacity:\n cpu:                4\n ephemeral-storage:  10251540Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7992528Ki\n pods:               110\nAllocatable:\n cpu:                3920m\n ephemeral-storage:  9447819249\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6264016Ki\n pods:               110\nSystem Info:\n Machine ID:                 43a79cdc-8f31-4533-b303-7a148da9bc18\n System UUID:                013ABABB-CDF3-4D87-8462-6A9F6BA3D55A\n Boot ID:                    f37576c9-1bd9-427d-91b3-1cd995ecd9b5\n Kernel Version:             3.10.0-862.14.0.1.h147.eulerosv2r7.x86_64\n OS Image:                   EulerOS 2.0 (SP5)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.0\n Kubelet Version:            v1.13.4-r0-CCE2.0.23.B001\n Kube-Proxy Version:         v1.13.4-r0-CCE2.0.23.B001\nProviderID:                  85ce72f2-8e81-11e9-9da5-0255ac101a8d\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    web-terminal-78fcf4fd59-smd5z                              100m (2%)     200m (5%)   256Mi (4%)       512Mi (8%)     177m\n  heptio-sonobuoy            sonobuoy-e2e-job-99d77d11689f4bcf                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         18m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-8q7tm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         18m\n  kube-system                coredns-7d456d978c-xkjtl                                   500m (12%)    500m (12%)  512Mi (8%)       512Mi (8%)     3h15m\n  kube-system                icagent-pbhr4                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h14m\n  kube-system                storage-driver-pz5nn                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h15m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                600m (15%)   700m (17%)\n  memory             768Mi (12%)  1Gi (16%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:              <none>\n"
Jun 14 12:14:53.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 describe namespace e2e-tests-kubectl-84zrb'
Jun 14 12:14:53.577: INFO: stderr: ""
Jun 14 12:14:53.577: INFO: stdout: "Name:         e2e-tests-kubectl-84zrb\nLabels:       e2e-framework=kubectl\n              e2e-run=77367325-8e9b-11e9-82a6-0255ac100014\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:14:53.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-84zrb" for this suite.
Jun 14 12:15:15.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:15:15.616: INFO: namespace: e2e-tests-kubectl-84zrb, resource: bindings, ignored listing per whitelist
Jun 14 12:15:15.638: INFO: namespace e2e-tests-kubectl-84zrb deletion completed in 22.058831801s

• [SLOW TEST:27.750 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:15:15.639: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:15:15.696: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jun 14 12:15:15.704: INFO: Number of nodes with available pods: 0
Jun 14 12:15:15.704: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:15:16.708: INFO: Number of nodes with available pods: 0
Jun 14 12:15:16.708: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:15:17.708: INFO: Number of nodes with available pods: 1
Jun 14 12:15:17.708: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:15:18.708: INFO: Number of nodes with available pods: 1
Jun 14 12:15:18.708: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:15:19.716: INFO: Number of nodes with available pods: 1
Jun 14 12:15:19.716: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:15:20.708: INFO: Number of nodes with available pods: 2
Jun 14 12:15:20.708: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jun 14 12:15:20.728: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:20.728: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:21.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:21.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:22.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:22.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:23.738: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:23.738: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:24.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:24.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:25.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:25.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:26.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:26.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:27.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:27.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:28.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:28.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:29.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:29.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:30.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:30.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:31.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:31.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:32.734: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:32.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:33.734: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:33.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:34.738: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:34.738: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:35.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:35.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:36.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:36.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:37.734: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:37.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:38.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:38.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:39.734: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:39.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:40.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:40.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:41.734: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:41.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:42.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:42.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:43.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:43.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:44.734: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:44.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:45.738: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:45.738: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:46.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:46.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:47.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:47.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:48.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:48.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:49.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:49.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:50.735: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:50.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:51.734: INFO: Wrong image for pod: daemon-set-4tqzd. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:51.734: INFO: Pod daemon-set-4tqzd is not available
Jun 14 12:15:51.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:52.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:53.735: INFO: Pod daemon-set-dlx58 is not available
Jun 14 12:15:53.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:54.735: INFO: Pod daemon-set-dlx58 is not available
Jun 14 12:15:54.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:55.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:56.738: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:57.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:58.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:15:59.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:00.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:01.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:02.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:03.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:04.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:05.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:06.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:07.737: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:08.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:09.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:10.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:11.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:12.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:13.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:14.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:15.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:16.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:17.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:18.738: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:19.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:20.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:21.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:22.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:23.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:24.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:25.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:25.735: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:26.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:26.735: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:27.736: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:27.736: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:28.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:28.735: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:29.737: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:29.737: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:30.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:30.735: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:31.741: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:31.741: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:32.735: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:32.735: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:33.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:33.734: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:34.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:34.734: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:35.734: INFO: Wrong image for pod: daemon-set-wmbpl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 14 12:16:35.734: INFO: Pod daemon-set-wmbpl is not available
Jun 14 12:16:36.734: INFO: Pod daemon-set-228sz is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jun 14 12:16:36.740: INFO: Number of nodes with available pods: 1
Jun 14 12:16:36.740: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:16:37.744: INFO: Number of nodes with available pods: 1
Jun 14 12:16:37.744: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:16:38.744: INFO: Number of nodes with available pods: 1
Jun 14 12:16:38.744: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:16:39.747: INFO: Number of nodes with available pods: 1
Jun 14 12:16:39.747: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:16:40.745: INFO: Number of nodes with available pods: 2
Jun 14 12:16:40.745: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-t46g8, will wait for the garbage collector to delete the pods
Jun 14 12:16:40.811: INFO: Deleting DaemonSet.extensions daemon-set took: 4.629572ms
Jun 14 12:16:40.911: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.126767ms
Jun 14 12:16:44.713: INFO: Number of nodes with available pods: 0
Jun 14 12:16:44.713: INFO: Number of running nodes: 0, number of available pods: 0
Jun 14 12:16:44.715: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-t46g8/daemonsets","resourceVersion":"36153"},"items":null}

Jun 14 12:16:44.717: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-t46g8/pods","resourceVersion":"36153"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:16:44.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-t46g8" for this suite.
Jun 14 12:16:50.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:16:50.787: INFO: namespace: e2e-tests-daemonsets-t46g8, resource: bindings, ignored listing per whitelist
Jun 14 12:16:50.788: INFO: namespace e2e-tests-daemonsets-t46g8 deletion completed in 6.065289915s

• [SLOW TEST:95.150 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:16:50.788: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 14 12:16:50.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-nj6lw'
Jun 14 12:16:50.920: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 14 12:16:50.920: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jun 14 12:16:52.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-nj6lw'
Jun 14 12:16:52.988: INFO: stderr: ""
Jun 14 12:16:52.988: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:16:52.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nj6lw" for this suite.
Jun 14 12:16:59.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:16:59.036: INFO: namespace: e2e-tests-kubectl-nj6lw, resource: bindings, ignored listing per whitelist
Jun 14 12:16:59.051: INFO: namespace e2e-tests-kubectl-nj6lw deletion completed in 6.060840971s

• [SLOW TEST:8.263 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:16:59.051: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4ee20af6-8e9e-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:16:59.100: INFO: Waiting up to 5m0s for pod "pod-secrets-4ee2b55d-8e9e-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-j2f5x" to be "success or failure"
Jun 14 12:16:59.102: INFO: Pod "pod-secrets-4ee2b55d-8e9e-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.719924ms
Jun 14 12:17:01.108: INFO: Pod "pod-secrets-4ee2b55d-8e9e-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007714355s
STEP: Saw pod success
Jun 14 12:17:01.108: INFO: Pod "pod-secrets-4ee2b55d-8e9e-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:17:01.110: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-4ee2b55d-8e9e-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:17:01.126: INFO: Waiting for pod pod-secrets-4ee2b55d-8e9e-11e9-82a6-0255ac100014 to disappear
Jun 14 12:17:01.128: INFO: Pod pod-secrets-4ee2b55d-8e9e-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:17:01.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j2f5x" for this suite.
Jun 14 12:17:07.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:17:07.163: INFO: namespace: e2e-tests-secrets-j2f5x, resource: bindings, ignored listing per whitelist
Jun 14 12:17:07.192: INFO: namespace e2e-tests-secrets-j2f5x deletion completed in 6.063017729s

• [SLOW TEST:8.141 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:17:07.192: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jun 14 12:17:07.244: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jun 14 12:17:07.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:07.375: INFO: stderr: ""
Jun 14 12:17:07.375: INFO: stdout: "service/redis-slave created\n"
Jun 14 12:17:07.375: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jun 14 12:17:07.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:07.518: INFO: stderr: ""
Jun 14 12:17:07.518: INFO: stdout: "service/redis-master created\n"
Jun 14 12:17:07.520: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jun 14 12:17:07.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:07.656: INFO: stderr: ""
Jun 14 12:17:07.656: INFO: stdout: "service/frontend created\n"
Jun 14 12:17:07.656: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jun 14 12:17:07.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:07.780: INFO: stderr: ""
Jun 14 12:17:07.780: INFO: stdout: "deployment.extensions/frontend created\n"
Jun 14 12:17:07.780: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jun 14 12:17:07.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:07.896: INFO: stderr: ""
Jun 14 12:17:07.896: INFO: stdout: "deployment.extensions/redis-master created\n"
Jun 14 12:17:07.896: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jun 14 12:17:07.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:08.015: INFO: stderr: ""
Jun 14 12:17:08.015: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jun 14 12:17:08.015: INFO: Waiting for all frontend pods to be Running.
Jun 14 12:17:33.066: INFO: Waiting for frontend to serve content.
Jun 14 12:17:34.115: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jun 14 12:17:39.124: INFO: Trying to add a new entry to the guestbook.
Jun 14 12:17:39.161: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jun 14 12:17:39.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:39.276: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:17:39.276: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jun 14 12:17:39.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:39.343: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:17:39.343: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 14 12:17:39.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:39.410: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:17:39.410: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 14 12:17:39.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:39.469: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:17:39.469: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 14 12:17:39.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:39.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:17:39.529: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 14 12:17:39.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tr787'
Jun 14 12:17:39.594: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:17:39.594: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:17:39.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tr787" for this suite.
Jun 14 12:18:17.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:18:17.697: INFO: namespace: e2e-tests-kubectl-tr787, resource: bindings, ignored listing per whitelist
Jun 14 12:18:17.701: INFO: namespace e2e-tests-kubectl-tr787 deletion completed in 38.104513306s

• [SLOW TEST:70.508 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:18:17.701: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 14 12:18:17.752: INFO: PodSpec: initContainers in spec.initContainers
Jun 14 12:19:06.210: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7dc497d0-8e9e-11e9-82a6-0255ac100014", GenerateName:"", Namespace:"e2e-tests-init-container-x6tc7", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-x6tc7/pods/pod-init-7dc497d0-8e9e-11e9-82a6-0255ac100014", UID:"7dd75278-8e9e-11e9-a0dc-fa163eff1b62", ResourceVersion:"36756", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63696111497, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"752369790"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vwqcz", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0021de000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vwqcz", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vwqcz", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vwqcz", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001ff6088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.0.235", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0017502a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ff6110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ff6130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001ff6138), DNSConfig:(*v1.PodDNSConfig)(0xc002580050), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001ff6147)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696111497, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696111497, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696111497, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696111497, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.235", PodIP:"172.16.0.54", StartTime:(*v1.Time)(0xc0021b0260), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f8c070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f8c0e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c37804d8a75759877076cb104bfc6cf8597ad1acf394b6d41b3e6b1c222ca469"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0021b03e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0021b0320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:19:06.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-x6tc7" for this suite.
Jun 14 12:19:28.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:19:28.263: INFO: namespace: e2e-tests-init-container-x6tc7, resource: bindings, ignored listing per whitelist
Jun 14 12:19:28.277: INFO: namespace e2e-tests-init-container-x6tc7 deletion completed in 22.05982052s

• [SLOW TEST:70.576 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:19:28.277: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:19:28.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7d5375e-8e9e-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-nv77s" to be "success or failure"
Jun 14 12:19:28.334: INFO: Pod "downwardapi-volume-a7d5375e-8e9e-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.716372ms
Jun 14 12:19:30.336: INFO: Pod "downwardapi-volume-a7d5375e-8e9e-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004321993s
STEP: Saw pod success
Jun 14 12:19:30.336: INFO: Pod "downwardapi-volume-a7d5375e-8e9e-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:19:30.338: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-a7d5375e-8e9e-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:19:30.357: INFO: Waiting for pod downwardapi-volume-a7d5375e-8e9e-11e9-82a6-0255ac100014 to disappear
Jun 14 12:19:30.359: INFO: Pod downwardapi-volume-a7d5375e-8e9e-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:19:30.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nv77s" for this suite.
Jun 14 12:19:36.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:19:36.377: INFO: namespace: e2e-tests-projected-nv77s, resource: bindings, ignored listing per whitelist
Jun 14 12:19:36.418: INFO: namespace e2e-tests-projected-nv77s deletion completed in 6.05685589s

• [SLOW TEST:8.141 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:19:36.418: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-8gpv
STEP: Creating a pod to test atomic-volume-subpath
Jun 14 12:19:36.469: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-8gpv" in namespace "e2e-tests-subpath-zcw77" to be "success or failure"
Jun 14 12:19:36.471: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026329ms
Jun 14 12:19:38.477: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008017764s
Jun 14 12:19:40.479: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010447409s
Jun 14 12:19:42.482: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013087547s
Jun 14 12:19:44.484: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01541333s
Jun 14 12:19:46.486: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017820159s
Jun 14 12:19:48.492: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 12.023492672s
Jun 14 12:19:50.495: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Pending", Reason="", readiness=false. Elapsed: 14.025927075s
Jun 14 12:19:52.497: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 16.028358741s
Jun 14 12:19:54.499: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 18.030686067s
Jun 14 12:19:56.502: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 20.032938245s
Jun 14 12:19:58.507: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 22.038327438s
Jun 14 12:20:00.509: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 24.040743067s
Jun 14 12:20:02.512: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 26.042965164s
Jun 14 12:20:04.514: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 28.044989312s
Jun 14 12:20:06.517: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 30.048320753s
Jun 14 12:20:08.524: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Running", Reason="", readiness=false. Elapsed: 32.05498414s
Jun 14 12:20:10.527: INFO: Pod "pod-subpath-test-downwardapi-8gpv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.057923306s
STEP: Saw pod success
Jun 14 12:20:10.527: INFO: Pod "pod-subpath-test-downwardapi-8gpv" satisfied condition "success or failure"
Jun 14 12:20:10.528: INFO: Trying to get logs from node 192.168.0.19 pod pod-subpath-test-downwardapi-8gpv container test-container-subpath-downwardapi-8gpv: <nil>
STEP: delete the pod
Jun 14 12:20:10.543: INFO: Waiting for pod pod-subpath-test-downwardapi-8gpv to disappear
Jun 14 12:20:10.544: INFO: Pod pod-subpath-test-downwardapi-8gpv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-8gpv
Jun 14 12:20:10.545: INFO: Deleting pod "pod-subpath-test-downwardapi-8gpv" in namespace "e2e-tests-subpath-zcw77"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:20:10.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zcw77" for this suite.
Jun 14 12:20:16.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:20:16.575: INFO: namespace: e2e-tests-subpath-zcw77, resource: bindings, ignored listing per whitelist
Jun 14 12:20:16.609: INFO: namespace e2e-tests-subpath-zcw77 deletion completed in 6.060626815s

• [SLOW TEST:40.191 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:20:16.609: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 14 12:20:16.653: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 14 12:20:16.656: INFO: Waiting for terminating namespaces to be deleted...
Jun 14 12:20:16.658: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.19 before test
Jun 14 12:20:16.662: INFO: web-terminal-78fcf4fd59-smd5z from default started at 2019-06-14 09:17:03 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.662: INFO: 	Container web-terminal ready: true, restart count 0
Jun 14 12:20:16.662: INFO: sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-8q7tm from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 12:20:16.662: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 14 12:20:16.662: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 14 12:20:16.662: INFO: icagent-pbhr4 from kube-system started at 2019-06-14 08:59:55 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.662: INFO: 	Container icagent ready: true, restart count 0
Jun 14 12:20:16.662: INFO: sonobuoy-e2e-job-99d77d11689f4bcf from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 12:20:16.662: INFO: 	Container e2e ready: true, restart count 0
Jun 14 12:20:16.662: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 14 12:20:16.662: INFO: storage-driver-pz5nn from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.662: INFO: 	Container storage-driver ready: true, restart count 0
Jun 14 12:20:16.662: INFO: coredns-7d456d978c-xkjtl from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.662: INFO: 	Container coredns ready: true, restart count 0
Jun 14 12:20:16.662: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.235 before test
Jun 14 12:20:16.668: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-14 11:55:55 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.668: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 14 12:20:16.668: INFO: sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-t2dvh from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 12:20:16.668: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 14 12:20:16.668: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 14 12:20:16.668: INFO: storage-driver-m898l from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.668: INFO: 	Container storage-driver ready: true, restart count 0
Jun 14 12:20:16.668: INFO: coredns-7d456d978c-vklzn from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.668: INFO: 	Container coredns ready: true, restart count 0
Jun 14 12:20:16.668: INFO: icagent-qzxb7 from kube-system started at 2019-06-14 08:59:56 +0000 UTC (1 container statuses recorded)
Jun 14 12:20:16.668: INFO: 	Container icagent ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 192.168.0.19
STEP: verifying the node has the label node 192.168.0.235
Jun 14 12:20:16.689: INFO: Pod web-terminal-78fcf4fd59-smd5z requesting resource cpu=100m on Node 192.168.0.19
Jun 14 12:20:16.689: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.0.235
Jun 14 12:20:16.689: INFO: Pod sonobuoy-e2e-job-99d77d11689f4bcf requesting resource cpu=0m on Node 192.168.0.19
Jun 14 12:20:16.689: INFO: Pod sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-8q7tm requesting resource cpu=0m on Node 192.168.0.19
Jun 14 12:20:16.689: INFO: Pod sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-t2dvh requesting resource cpu=0m on Node 192.168.0.235
Jun 14 12:20:16.689: INFO: Pod coredns-7d456d978c-vklzn requesting resource cpu=500m on Node 192.168.0.235
Jun 14 12:20:16.689: INFO: Pod coredns-7d456d978c-xkjtl requesting resource cpu=500m on Node 192.168.0.19
Jun 14 12:20:16.689: INFO: Pod icagent-pbhr4 requesting resource cpu=0m on Node 192.168.0.19
Jun 14 12:20:16.689: INFO: Pod icagent-qzxb7 requesting resource cpu=0m on Node 192.168.0.235
Jun 14 12:20:16.689: INFO: Pod storage-driver-m898l requesting resource cpu=0m on Node 192.168.0.235
Jun 14 12:20:16.689: INFO: Pod storage-driver-pz5nn requesting resource cpu=0m on Node 192.168.0.19
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a8f8d6-8e9e-11e9-82a6-0255ac100014.15a80ff53b73d1de], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-6vbj6/filler-pod-c4a8f8d6-8e9e-11e9-82a6-0255ac100014 to 192.168.0.19]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a8f8d6-8e9e-11e9-82a6-0255ac100014.15a80ff54682a7dd], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-c4a8f8d6-8e9e-11e9-82a6-0255ac100014_e2e-tests-sched-pred-6vbj6(c4bbccae-8e9e-11e9-a0dc-fa163eff1b62)"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a8f8d6-8e9e-11e9-82a6-0255ac100014.15a80ff576e367cd], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a8f8d6-8e9e-11e9-82a6-0255ac100014.15a80ff587e3aaa0], Reason = [SuccessfulCreate], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a8f8d6-8e9e-11e9-82a6-0255ac100014.15a80ff59079d080], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a9d9cd-8e9e-11e9-82a6-0255ac100014.15a80ff53ba70abb], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-6vbj6/filler-pod-c4a9d9cd-8e9e-11e9-82a6-0255ac100014 to 192.168.0.235]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a9d9cd-8e9e-11e9-82a6-0255ac100014.15a80ff544af2809], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volumes for pod "filler-pod-c4a9d9cd-8e9e-11e9-82a6-0255ac100014_e2e-tests-sched-pred-6vbj6(c4bc8101-8e9e-11e9-a0dc-fa163eff1b62)"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a9d9cd-8e9e-11e9-82a6-0255ac100014.15a80ff5744f7620], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a9d9cd-8e9e-11e9-82a6-0255ac100014.15a80ff583e7ffab], Reason = [SuccessfulCreate], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c4a9d9cd-8e9e-11e9-82a6-0255ac100014.15a80ff58c90c1ad], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a80ff62ac1b568], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 192.168.0.19
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 192.168.0.235
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:20:21.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6vbj6" for this suite.
Jun 14 12:20:27.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:20:27.818: INFO: namespace: e2e-tests-sched-pred-6vbj6, resource: bindings, ignored listing per whitelist
Jun 14 12:20:27.818: INFO: namespace e2e-tests-sched-pred-6vbj6 deletion completed in 6.057498935s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.209 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:20:27.818: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jun 14 12:20:27.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:28.150: INFO: stderr: ""
Jun 14 12:20:28.150: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 14 12:20:28.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:28.205: INFO: stderr: ""
Jun 14 12:20:28.205: INFO: stdout: "update-demo-nautilus-gtkwr update-demo-nautilus-n4mst "
Jun 14 12:20:28.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-gtkwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:28.254: INFO: stderr: ""
Jun 14 12:20:28.254: INFO: stdout: ""
Jun 14 12:20:28.254: INFO: update-demo-nautilus-gtkwr is created but not running
Jun 14 12:20:33.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:33.306: INFO: stderr: ""
Jun 14 12:20:33.306: INFO: stdout: "update-demo-nautilus-gtkwr update-demo-nautilus-n4mst "
Jun 14 12:20:33.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-gtkwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:33.357: INFO: stderr: ""
Jun 14 12:20:33.357: INFO: stdout: "true"
Jun 14 12:20:33.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-gtkwr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:33.408: INFO: stderr: ""
Jun 14 12:20:33.408: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 12:20:33.408: INFO: validating pod update-demo-nautilus-gtkwr
Jun 14 12:20:33.437: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 12:20:33.437: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 12:20:33.437: INFO: update-demo-nautilus-gtkwr is verified up and running
Jun 14 12:20:33.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-n4mst -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:33.487: INFO: stderr: ""
Jun 14 12:20:33.487: INFO: stdout: "true"
Jun 14 12:20:33.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-n4mst -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:33.536: INFO: stderr: ""
Jun 14 12:20:33.536: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 12:20:33.536: INFO: validating pod update-demo-nautilus-n4mst
Jun 14 12:20:33.548: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 12:20:33.548: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 12:20:33.548: INFO: update-demo-nautilus-n4mst is verified up and running
STEP: using delete to clean up resources
Jun 14 12:20:33.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:33.604: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:20:33.604: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 14 12:20:33.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-gmqcw'
Jun 14 12:20:33.668: INFO: stderr: "No resources found.\n"
Jun 14 12:20:33.668: INFO: stdout: ""
Jun 14 12:20:33.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -l name=update-demo --namespace=e2e-tests-kubectl-gmqcw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 14 12:20:33.720: INFO: stderr: ""
Jun 14 12:20:33.720: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:20:33.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gmqcw" for this suite.
Jun 14 12:20:55.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:20:55.768: INFO: namespace: e2e-tests-kubectl-gmqcw, resource: bindings, ignored listing per whitelist
Jun 14 12:20:55.782: INFO: namespace e2e-tests-kubectl-gmqcw deletion completed in 22.060060217s

• [SLOW TEST:27.965 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:20:55.783: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jun 14 12:20:57.868: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:21:21.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-s6lsg" for this suite.
Jun 14 12:21:27.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:21:27.925: INFO: namespace: e2e-tests-namespaces-s6lsg, resource: bindings, ignored listing per whitelist
Jun 14 12:21:27.972: INFO: namespace e2e-tests-namespaces-s6lsg deletion completed in 6.06488192s
STEP: Destroying namespace "e2e-tests-nsdeletetest-kkbz2" for this suite.
Jun 14 12:21:27.974: INFO: Namespace e2e-tests-nsdeletetest-kkbz2 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-hn7m8" for this suite.
Jun 14 12:21:33.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:21:34.023: INFO: namespace: e2e-tests-nsdeletetest-hn7m8, resource: bindings, ignored listing per whitelist
Jun 14 12:21:34.035: INFO: namespace e2e-tests-nsdeletetest-hn7m8 deletion completed in 6.061112227s

• [SLOW TEST:38.253 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:21:34.035: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 14 12:21:34.084: INFO: Waiting up to 5m0s for pod "pod-f2c985ae-8e9e-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-4fwns" to be "success or failure"
Jun 14 12:21:34.086: INFO: Pod "pod-f2c985ae-8e9e-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.692334ms
Jun 14 12:21:36.088: INFO: Pod "pod-f2c985ae-8e9e-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004253485s
STEP: Saw pod success
Jun 14 12:21:36.088: INFO: Pod "pod-f2c985ae-8e9e-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:21:36.090: INFO: Trying to get logs from node 192.168.0.235 pod pod-f2c985ae-8e9e-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:21:36.154: INFO: Waiting for pod pod-f2c985ae-8e9e-11e9-82a6-0255ac100014 to disappear
Jun 14 12:21:36.155: INFO: Pod pod-f2c985ae-8e9e-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:21:36.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4fwns" for this suite.
Jun 14 12:21:42.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:21:42.172: INFO: namespace: e2e-tests-emptydir-4fwns, resource: bindings, ignored listing per whitelist
Jun 14 12:21:42.215: INFO: namespace e2e-tests-emptydir-4fwns deletion completed in 6.058362691s

• [SLOW TEST:8.180 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:21:42.215: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bmnp7
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-bmnp7
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-bmnp7
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-bmnp7
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-bmnp7
Jun 14 12:21:46.275: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-bmnp7, name: ss-0, uid: f970b6cf-8e9e-11e9-8a76-fa163e95400d, status phase: Pending. Waiting for statefulset controller to delete.
Jun 14 12:21:46.474: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-bmnp7, name: ss-0, uid: f970b6cf-8e9e-11e9-8a76-fa163e95400d, status phase: Failed. Waiting for statefulset controller to delete.
Jun 14 12:21:46.479: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-bmnp7, name: ss-0, uid: f970b6cf-8e9e-11e9-8a76-fa163e95400d, status phase: Failed. Waiting for statefulset controller to delete.
Jun 14 12:21:46.483: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-bmnp7
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-bmnp7
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-bmnp7 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 14 12:21:50.502: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bmnp7
Jun 14 12:21:50.504: INFO: Scaling statefulset ss to 0
Jun 14 12:22:00.517: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 12:22:00.519: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:22:00.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bmnp7" for this suite.
Jun 14 12:22:06.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:22:06.563: INFO: namespace: e2e-tests-statefulset-bmnp7, resource: bindings, ignored listing per whitelist
Jun 14 12:22:06.590: INFO: namespace e2e-tests-statefulset-bmnp7 deletion completed in 6.061612889s

• [SLOW TEST:24.375 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:22:06.590: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:22:06.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 version'
Jun 14 12:22:06.689: INFO: stderr: ""
Jun 14 12:22:06.689: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13+\", GitVersion:\"v1.13.6-r0-CCE2.0.23.B001\", GitCommit:\"a9f08ba0e70597fbf4eb449f13af301e6a3dcaf5\", GitTreeState:\"clean\", BuildDate:\"2019-05-31T09:38:52Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:22:06.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-stnhn" for this suite.
Jun 14 12:22:12.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:22:12.726: INFO: namespace: e2e-tests-kubectl-stnhn, resource: bindings, ignored listing per whitelist
Jun 14 12:22:12.750: INFO: namespace e2e-tests-kubectl-stnhn deletion completed in 6.058798687s

• [SLOW TEST:6.160 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:22:12.750: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-r7rv9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 14 12:22:12.799: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 14 12:22:36.845: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.61:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-r7rv9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:22:36.845: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:22:36.944: INFO: Found all expected endpoints: [netserver-0]
Jun 14 12:22:36.946: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.22:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-r7rv9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:22:36.946: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:22:37.009: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:22:37.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-r7rv9" for this suite.
Jun 14 12:22:59.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:22:59.059: INFO: namespace: e2e-tests-pod-network-test-r7rv9, resource: bindings, ignored listing per whitelist
Jun 14 12:22:59.071: INFO: namespace e2e-tests-pod-network-test-r7rv9 deletion completed in 22.058918848s

• [SLOW TEST:46.321 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:22:59.071: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2579cea0-8e9f-11e9-82a6-0255ac100014
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-2579cea0-8e9f-11e9-82a6-0255ac100014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:24:05.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsd8m" for this suite.
Jun 14 12:24:27.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:24:27.393: INFO: namespace: e2e-tests-projected-fsd8m, resource: bindings, ignored listing per whitelist
Jun 14 12:24:27.435: INFO: namespace e2e-tests-projected-fsd8m deletion completed in 22.063556633s

• [SLOW TEST:88.364 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:24:27.435: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-rptc2
Jun 14 12:24:31.490: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-rptc2
STEP: checking the pod's current state and verifying that restartCount is present
Jun 14 12:24:31.492: INFO: Initial restart count of pod liveness-http is 0
Jun 14 12:24:51.524: INFO: Restart count of pod e2e-tests-container-probe-rptc2/liveness-http is now 1 (20.031740109s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:24:51.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rptc2" for this suite.
Jun 14 12:24:57.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:24:57.578: INFO: namespace: e2e-tests-container-probe-rptc2, resource: bindings, ignored listing per whitelist
Jun 14 12:24:57.606: INFO: namespace e2e-tests-container-probe-rptc2 deletion completed in 6.07146057s

• [SLOW TEST:30.171 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:24:57.606: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 14 12:24:57.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ss76g'
Jun 14 12:24:57.725: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 14 12:24:57.725: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jun 14 12:24:59.732: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-8xdkg]
Jun 14 12:24:59.732: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-8xdkg" in namespace "e2e-tests-kubectl-ss76g" to be "running and ready"
Jun 14 12:24:59.734: INFO: Pod "e2e-test-nginx-rc-8xdkg": Phase="Pending", Reason="", readiness=false. Elapsed: 1.655457ms
Jun 14 12:25:01.736: INFO: Pod "e2e-test-nginx-rc-8xdkg": Phase="Running", Reason="", readiness=true. Elapsed: 2.004079021s
Jun 14 12:25:01.737: INFO: Pod "e2e-test-nginx-rc-8xdkg" satisfied condition "running and ready"
Jun 14 12:25:01.737: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-8xdkg]
Jun 14 12:25:01.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ss76g'
Jun 14 12:25:01.813: INFO: stderr: ""
Jun 14 12:25:01.813: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jun 14 12:25:01.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ss76g'
Jun 14 12:25:01.876: INFO: stderr: ""
Jun 14 12:25:01.876: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:25:01.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ss76g" for this suite.
Jun 14 12:25:07.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:25:07.933: INFO: namespace: e2e-tests-kubectl-ss76g, resource: bindings, ignored listing per whitelist
Jun 14 12:25:07.944: INFO: namespace e2e-tests-kubectl-ss76g deletion completed in 6.066015802s

• [SLOW TEST:10.338 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:25:07.944: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-s6sdr.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-s6sdr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s6sdr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-s6sdr.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-s6sdr.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s6sdr.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 14 12:25:12.053: INFO: DNS probes using e2e-tests-dns-s6sdr/dns-test-7249917f-8e9f-11e9-82a6-0255ac100014 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:25:12.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-s6sdr" for this suite.
Jun 14 12:25:18.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:25:18.091: INFO: namespace: e2e-tests-dns-s6sdr, resource: bindings, ignored listing per whitelist
Jun 14 12:25:18.125: INFO: namespace e2e-tests-dns-s6sdr deletion completed in 6.060179331s

• [SLOW TEST:10.181 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:25:18.125: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-hzr6
STEP: Creating a pod to test atomic-volume-subpath
Jun 14 12:25:18.186: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hzr6" in namespace "e2e-tests-subpath-c7hjw" to be "success or failure"
Jun 14 12:25:18.188: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.73871ms
Jun 14 12:25:20.191: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004223898s
Jun 14 12:25:22.193: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 4.006609261s
Jun 14 12:25:24.196: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 6.00906029s
Jun 14 12:25:26.198: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 8.01152779s
Jun 14 12:25:28.203: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 10.016845881s
Jun 14 12:25:30.206: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 12.019287618s
Jun 14 12:25:32.208: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 14.021777016s
Jun 14 12:25:34.210: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 16.023956533s
Jun 14 12:25:36.213: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 18.026279664s
Jun 14 12:25:38.218: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 20.031729991s
Jun 14 12:25:40.221: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Running", Reason="", readiness=false. Elapsed: 22.034144561s
Jun 14 12:25:42.223: INFO: Pod "pod-subpath-test-configmap-hzr6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.036582034s
STEP: Saw pod success
Jun 14 12:25:42.223: INFO: Pod "pod-subpath-test-configmap-hzr6" satisfied condition "success or failure"
Jun 14 12:25:42.225: INFO: Trying to get logs from node 192.168.0.19 pod pod-subpath-test-configmap-hzr6 container test-container-subpath-configmap-hzr6: <nil>
STEP: delete the pod
Jun 14 12:25:42.253: INFO: Waiting for pod pod-subpath-test-configmap-hzr6 to disappear
Jun 14 12:25:42.255: INFO: Pod pod-subpath-test-configmap-hzr6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hzr6
Jun 14 12:25:42.255: INFO: Deleting pod "pod-subpath-test-configmap-hzr6" in namespace "e2e-tests-subpath-c7hjw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:25:42.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-c7hjw" for this suite.
Jun 14 12:25:48.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:25:48.273: INFO: namespace: e2e-tests-subpath-c7hjw, resource: bindings, ignored listing per whitelist
Jun 14 12:25:48.322: INFO: namespace e2e-tests-subpath-c7hjw deletion completed in 6.063663693s

• [SLOW TEST:30.197 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:25:48.323: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 14 12:25:48.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-d6nnq'
Jun 14 12:25:48.433: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 14 12:25:48.434: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jun 14 12:25:48.437: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jun 14 12:25:48.444: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jun 14 12:25:48.450: INFO: scanned /root for discovery docs: <nil>
Jun 14 12:25:48.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-d6nnq'
Jun 14 12:26:04.207: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 14 12:26:04.207: INFO: stdout: "Created e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad\nScaling up e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jun 14 12:26:04.207: INFO: stdout: "Created e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad\nScaling up e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jun 14 12:26:04.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-d6nnq'
Jun 14 12:26:04.261: INFO: stderr: ""
Jun 14 12:26:04.261: INFO: stdout: "e2e-test-nginx-rc-5rhck e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad-jss4p "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jun 14 12:26:09.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-d6nnq'
Jun 14 12:26:09.316: INFO: stderr: ""
Jun 14 12:26:09.316: INFO: stdout: "e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad-jss4p "
Jun 14 12:26:09.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad-jss4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6nnq'
Jun 14 12:26:09.365: INFO: stderr: ""
Jun 14 12:26:09.365: INFO: stdout: "true"
Jun 14 12:26:09.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad-jss4p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-d6nnq'
Jun 14 12:26:09.415: INFO: stderr: ""
Jun 14 12:26:09.415: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jun 14 12:26:09.415: INFO: e2e-test-nginx-rc-df04a6952df522489e4b18ea94903dad-jss4p is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jun 14 12:26:09.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-d6nnq'
Jun 14 12:26:09.469: INFO: stderr: ""
Jun 14 12:26:09.469: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:26:09.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d6nnq" for this suite.
Jun 14 12:26:15.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:26:15.495: INFO: namespace: e2e-tests-kubectl-d6nnq, resource: bindings, ignored listing per whitelist
Jun 14 12:26:15.534: INFO: namespace e2e-tests-kubectl-d6nnq deletion completed in 6.062361963s

• [SLOW TEST:27.211 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:26:15.534: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 14 12:26:19.625: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 14 12:26:19.627: INFO: Pod pod-with-poststart-http-hook still exists
Jun 14 12:26:21.627: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 14 12:26:21.630: INFO: Pod pod-with-poststart-http-hook still exists
Jun 14 12:26:23.627: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 14 12:26:23.630: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:26:23.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-fnvrg" for this suite.
Jun 14 12:26:45.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:26:45.648: INFO: namespace: e2e-tests-container-lifecycle-hook-fnvrg, resource: bindings, ignored listing per whitelist
Jun 14 12:26:45.688: INFO: namespace e2e-tests-container-lifecycle-hook-fnvrg deletion completed in 22.056262549s

• [SLOW TEST:30.154 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:26:45.688: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 14 12:26:45.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xtfmt'
Jun 14 12:26:45.795: INFO: stderr: ""
Jun 14 12:26:45.795: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jun 14 12:26:50.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xtfmt -o json'
Jun 14 12:26:50.900: INFO: stderr: ""
Jun 14 12:26:50.900: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-06-14T12:26:45Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-xtfmt\",\n        \"resourceVersion\": \"38622\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-xtfmt/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ac8d5fd1-8e9f-11e9-8a76-fa163e95400d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-bt7c2\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsConfig\": {\n            \"options\": [\n                {\n                    \"name\": \"timeout\",\n                    \"value\": \"2\"\n                },\n                {\n                    \"name\": \"single-request-reopen\",\n                    \"value\": \"\"\n                }\n            ]\n        },\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.0.235\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-bt7c2\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-bt7c2\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-14T12:26:45Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-14T12:26:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-14T12:26:47Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-14T12:26:45Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://cc91d036edf1409c3644157ace4a2ed2389e070a0e30fcab2532e94fa0c0f246\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-06-14T12:26:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.0.235\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.0.56\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-06-14T12:26:45Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jun 14 12:26:50.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 replace -f - --namespace=e2e-tests-kubectl-xtfmt'
Jun 14 12:26:51.043: INFO: stderr: ""
Jun 14 12:26:51.043: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jun 14 12:26:51.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xtfmt'
Jun 14 12:26:52.695: INFO: stderr: ""
Jun 14 12:26:52.695: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:26:52.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xtfmt" for this suite.
Jun 14 12:26:58.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:26:58.719: INFO: namespace: e2e-tests-kubectl-xtfmt, resource: bindings, ignored listing per whitelist
Jun 14 12:26:58.756: INFO: namespace e2e-tests-kubectl-xtfmt deletion completed in 6.059234118s

• [SLOW TEST:13.068 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:26:58.756: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 14 12:26:58.807: INFO: Waiting up to 5m0s for pod "pod-b4564bb5-8e9f-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-hvwl5" to be "success or failure"
Jun 14 12:26:58.809: INFO: Pod "pod-b4564bb5-8e9f-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.983105ms
Jun 14 12:27:00.811: INFO: Pod "pod-b4564bb5-8e9f-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004319947s
Jun 14 12:27:02.817: INFO: Pod "pod-b4564bb5-8e9f-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009857901s
STEP: Saw pod success
Jun 14 12:27:02.817: INFO: Pod "pod-b4564bb5-8e9f-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:27:02.818: INFO: Trying to get logs from node 192.168.0.235 pod pod-b4564bb5-8e9f-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:27:02.830: INFO: Waiting for pod pod-b4564bb5-8e9f-11e9-82a6-0255ac100014 to disappear
Jun 14 12:27:02.833: INFO: Pod pod-b4564bb5-8e9f-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:27:02.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hvwl5" for this suite.
Jun 14 12:27:08.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:27:08.870: INFO: namespace: e2e-tests-emptydir-hvwl5, resource: bindings, ignored listing per whitelist
Jun 14 12:27:08.891: INFO: namespace e2e-tests-emptydir-hvwl5 deletion completed in 6.056479445s

• [SLOW TEST:10.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:27:08.892: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:27:08.944: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba60984c-8e9f-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-rsn78" to be "success or failure"
Jun 14 12:27:08.947: INFO: Pod "downwardapi-volume-ba60984c-8e9f-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.639222ms
Jun 14 12:27:10.950: INFO: Pod "downwardapi-volume-ba60984c-8e9f-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005243863s
STEP: Saw pod success
Jun 14 12:27:10.950: INFO: Pod "downwardapi-volume-ba60984c-8e9f-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:27:10.951: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-ba60984c-8e9f-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:27:11.005: INFO: Waiting for pod downwardapi-volume-ba60984c-8e9f-11e9-82a6-0255ac100014 to disappear
Jun 14 12:27:11.006: INFO: Pod downwardapi-volume-ba60984c-8e9f-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:27:11.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rsn78" for this suite.
Jun 14 12:27:17.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:27:17.051: INFO: namespace: e2e-tests-projected-rsn78, resource: bindings, ignored listing per whitelist
Jun 14 12:27:17.068: INFO: namespace e2e-tests-projected-rsn78 deletion completed in 6.059796762s

• [SLOW TEST:8.176 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:27:17.068: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jun 14 12:27:17.127: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q8c5k,SelfLink:/api/v1/namespaces/e2e-tests-watch-q8c5k/configmaps/e2e-watch-test-label-changed,UID:bf53b301-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38761,Generation:0,CreationTimestamp:2019-06-14 12:27:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 14 12:27:17.127: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q8c5k,SelfLink:/api/v1/namespaces/e2e-tests-watch-q8c5k/configmaps/e2e-watch-test-label-changed,UID:bf53b301-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38762,Generation:0,CreationTimestamp:2019-06-14 12:27:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 14 12:27:17.127: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q8c5k,SelfLink:/api/v1/namespaces/e2e-tests-watch-q8c5k/configmaps/e2e-watch-test-label-changed,UID:bf53b301-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38763,Generation:0,CreationTimestamp:2019-06-14 12:27:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jun 14 12:27:27.151: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q8c5k,SelfLink:/api/v1/namespaces/e2e-tests-watch-q8c5k/configmaps/e2e-watch-test-label-changed,UID:bf53b301-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38793,Generation:0,CreationTimestamp:2019-06-14 12:27:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 14 12:27:27.151: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q8c5k,SelfLink:/api/v1/namespaces/e2e-tests-watch-q8c5k/configmaps/e2e-watch-test-label-changed,UID:bf53b301-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38794,Generation:0,CreationTimestamp:2019-06-14 12:27:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jun 14 12:27:27.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q8c5k,SelfLink:/api/v1/namespaces/e2e-tests-watch-q8c5k/configmaps/e2e-watch-test-label-changed,UID:bf53b301-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38795,Generation:0,CreationTimestamp:2019-06-14 12:27:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:27:27.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-q8c5k" for this suite.
Jun 14 12:27:33.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:27:33.197: INFO: namespace: e2e-tests-watch-q8c5k, resource: bindings, ignored listing per whitelist
Jun 14 12:27:33.214: INFO: namespace e2e-tests-watch-q8c5k deletion completed in 6.060307181s

• [SLOW TEST:16.146 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:27:33.214: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c8e0f168-8e9f-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:27:33.274: INFO: Waiting up to 5m0s for pod "pod-secrets-c8e1fa45-8e9f-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-djz88" to be "success or failure"
Jun 14 12:27:33.276: INFO: Pod "pod-secrets-c8e1fa45-8e9f-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.727894ms
Jun 14 12:27:35.279: INFO: Pod "pod-secrets-c8e1fa45-8e9f-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004356532s
STEP: Saw pod success
Jun 14 12:27:35.279: INFO: Pod "pod-secrets-c8e1fa45-8e9f-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:27:35.280: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-c8e1fa45-8e9f-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:27:35.298: INFO: Waiting for pod pod-secrets-c8e1fa45-8e9f-11e9-82a6-0255ac100014 to disappear
Jun 14 12:27:35.299: INFO: Pod pod-secrets-c8e1fa45-8e9f-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:27:35.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-djz88" for this suite.
Jun 14 12:27:41.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:27:41.342: INFO: namespace: e2e-tests-secrets-djz88, resource: bindings, ignored listing per whitelist
Jun 14 12:27:41.359: INFO: namespace e2e-tests-secrets-djz88 deletion completed in 6.058165972s

• [SLOW TEST:8.146 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:27:41.360: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:27:41.415: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jun 14 12:27:41.422: INFO: Pod name sample-pod: Found 0 pods out of 1
Jun 14 12:27:46.424: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 14 12:27:46.424: INFO: Creating deployment "test-rolling-update-deployment"
Jun 14 12:27:46.428: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jun 14 12:27:46.432: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jun 14 12:27:48.440: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jun 14 12:27:48.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696112066, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696112066, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696112066, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696112066, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 12:27:50.444: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 14 12:27:50.449: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-t8nwn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t8nwn/deployments/test-rolling-update-deployment,UID:d0cc3c1a-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38921,Generation:1,CreationTimestamp:2019-06-14 12:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-14 12:27:46 +0000 UTC 2019-06-14 12:27:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-14 12:27:49 +0000 UTC 2019-06-14 12:27:46 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun 14 12:27:50.452: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-t8nwn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t8nwn/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:d0b4f8f2-8e9f-11e9-8a76-fa163e95400d,ResourceVersion:38914,Generation:1,CreationTimestamp:2019-06-14 12:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d0cc3c1a-8e9f-11e9-a0dc-fa163eff1b62 0xc002c87ce7 0xc002c87ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 14 12:27:50.452: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jun 14 12:27:50.452: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-t8nwn,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t8nwn/replicasets/test-rolling-update-controller,UID:cdcfda8c-8e9f-11e9-a0dc-fa163eff1b62,ResourceVersion:38920,Generation:2,CreationTimestamp:2019-06-14 12:27:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d0cc3c1a-8e9f-11e9-a0dc-fa163eff1b62 0xc002c87b47 0xc002c87b48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 14 12:27:50.454: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-gswst" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-gswst,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-t8nwn,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t8nwn/pods/test-rolling-update-deployment-68b55d7bc6-gswst,UID:d0b57f57-8e9f-11e9-8a76-fa163e95400d,ResourceVersion:38913,Generation:0,CreationTimestamp:2019-06-14 12:27:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 d0b4f8f2-8e9f-11e9-8a76-fa163e95400d 0xc001ade0e7 0xc001ade0e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l49zn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l49zn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-l49zn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ade200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ade230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016971d0} {timeout 0xc0016971e0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:27:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:27:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:27:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:27:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:172.16.0.27,StartTime:2019-06-14 12:27:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-14 12:27:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://be7ec1c5afc3f9dab2ea383c1a016298dfd0e666170e45ccce3d89801ccc2d3c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:27:50.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-t8nwn" for this suite.
Jun 14 12:27:56.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:27:56.468: INFO: namespace: e2e-tests-deployment-t8nwn, resource: bindings, ignored listing per whitelist
Jun 14 12:27:56.514: INFO: namespace e2e-tests-deployment-t8nwn deletion completed in 6.058271385s

• [SLOW TEST:15.154 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:27:56.514: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-pcznt
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jun 14 12:27:56.575: INFO: Found 0 stateful pods, waiting for 3
Jun 14 12:28:06.582: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:28:06.582: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:28:06.582: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:28:06.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-pcznt ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 12:28:06.718: INFO: stderr: ""
Jun 14 12:28:06.718: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 12:28:06.718: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun 14 12:28:16.745: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jun 14 12:28:26.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-pcznt ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 12:28:26.877: INFO: stderr: ""
Jun 14 12:28:26.877: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 12:28:26.877: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 12:28:36.894: INFO: Waiting for StatefulSet e2e-tests-statefulset-pcznt/ss2 to complete update
Jun 14 12:28:36.894: INFO: Waiting for Pod e2e-tests-statefulset-pcznt/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 14 12:28:36.894: INFO: Waiting for Pod e2e-tests-statefulset-pcznt/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 14 12:28:46.902: INFO: Waiting for StatefulSet e2e-tests-statefulset-pcznt/ss2 to complete update
Jun 14 12:28:46.902: INFO: Waiting for Pod e2e-tests-statefulset-pcznt/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jun 14 12:28:56.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-pcznt ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 12:28:57.028: INFO: stderr: ""
Jun 14 12:28:57.028: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 12:28:57.028: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 12:29:07.058: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jun 14 12:29:17.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-pcznt ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 12:29:17.185: INFO: stderr: ""
Jun 14 12:29:17.185: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 12:29:17.185: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 12:29:27.201: INFO: Waiting for StatefulSet e2e-tests-statefulset-pcznt/ss2 to complete update
Jun 14 12:29:27.201: INFO: Waiting for Pod e2e-tests-statefulset-pcznt/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 14 12:29:37.209: INFO: Deleting all statefulset in ns e2e-tests-statefulset-pcznt
Jun 14 12:29:37.211: INFO: Scaling statefulset ss2 to 0
Jun 14 12:30:07.226: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 12:30:07.228: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:30:07.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-pcznt" for this suite.
Jun 14 12:30:13.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:30:13.256: INFO: namespace: e2e-tests-statefulset-pcznt, resource: bindings, ignored listing per whitelist
Jun 14 12:30:13.302: INFO: namespace e2e-tests-statefulset-pcznt deletion completed in 6.063662144s

• [SLOW TEST:136.788 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:30:13.302: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:30:13.346: INFO: Creating deployment "nginx-deployment"
Jun 14 12:30:13.351: INFO: Waiting for observed generation 1
Jun 14 12:30:15.359: INFO: Waiting for all required pods to come up
Jun 14 12:30:15.362: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jun 14 12:30:21.368: INFO: Waiting for deployment "nginx-deployment" to complete
Jun 14 12:30:21.373: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jun 14 12:30:21.382: INFO: Updating deployment nginx-deployment
Jun 14 12:30:21.382: INFO: Waiting for observed generation 2
Jun 14 12:30:23.386: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jun 14 12:30:23.389: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jun 14 12:30:23.395: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun 14 12:30:23.401: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jun 14 12:30:23.401: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jun 14 12:30:23.403: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun 14 12:30:23.406: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jun 14 12:30:23.406: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jun 14 12:30:23.413: INFO: Updating deployment nginx-deployment
Jun 14 12:30:23.413: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jun 14 12:30:23.416: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jun 14 12:30:25.421: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 14 12:30:25.425: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5rt4p/deployments/nginx-deployment,UID:285ee62d-8ea0-11e9-a0dc-fa163eff1b62,ResourceVersion:39727,Generation:3,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-06-14 12:30:23 +0000 UTC 2019-06-14 12:30:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-14 12:30:23 +0000 UTC 2019-06-14 12:30:13 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jun 14 12:30:25.434: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5rt4p/replicasets/nginx-deployment-65bbdb5f8,UID:2d0e95dd-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39722,Generation:3,CreationTimestamp:2019-06-14 12:30:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 285ee62d-8ea0-11e9-a0dc-fa163eff1b62 0xc002cc1e47 0xc002cc1e48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 14 12:30:25.434: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jun 14 12:30:25.434: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5rt4p/replicasets/nginx-deployment-555b55d965,UID:28456fbb-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39726,Generation:3,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 285ee62d-8ea0-11e9-a0dc-fa163eff1b62 0xc002cc1d77 0xc002cc1d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jun 14 12:30:25.437: INFO: Pod "nginx-deployment-555b55d965-4wwgv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4wwgv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-4wwgv,UID:2e512b58-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39717,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1b7b7 0xc002d1b7b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d1b830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d1b850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{timeout 0xc001697230} {single-request-reopen 0xc001697240}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-6t7xg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6t7xg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-6t7xg,UID:2e4cfac1-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39725,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1b8c0 0xc002d1b8c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d1b930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d1b950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697250} {timeout 0xc001697260}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-7cqq8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7cqq8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-7cqq8,UID:2e495357-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39685,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1ba07 0xc002d1ba08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d1ba80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d1baa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697270} {timeout 0xc001697280}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-7gmrr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7gmrr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-7gmrr,UID:2e50ee34-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39716,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1bb10 0xc002d1bb11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d1bb80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d1bba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697290} {timeout 0xc0016972a0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-9cznt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9cznt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-9cznt,UID:284ef83e-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39610,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1bc10 0xc002d1bc11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d1bc80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d1bca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016972b0} {timeout 0xc0016972c0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:172.16.0.56,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7ebd5a0fc39e4a0b4dfeb0ac340fc3e1cfa7518e436181f85ed19069589bba48}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-c67hl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-c67hl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-c67hl,UID:2e4ce0b7-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39699,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1bd60 0xc002d1bd61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d1bdd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d1bdf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016972e0} {timeout 0xc0016972f0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-clmz8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-clmz8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-clmz8,UID:284a1e57-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39607,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1be60 0xc002d1be61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d1bed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d1bef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{timeout 0xc001697300} {single-request-reopen 0xc001697310}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:172.16.0.54,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c8bbec30c23ec5d8ac4d1ff9ef0ebfa83763c7014545714a08d25fda1bf33a7d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-czj7s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-czj7s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-czj7s,UID:284a27e4-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39597,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc002d1bfb0 0xc002d1bfb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a4020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a4040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{timeout 0xc001697330} {single-request-reopen 0xc001697350}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:172.16.0.22,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://175c1e163fdb56d935b731901516cdd45f3ff0387e924a40fc432f6cae2c5091}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-dbg2v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dbg2v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-dbg2v,UID:2e50e7e0-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39734,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a4250 0xc0019a4251}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a4310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a4330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697370} {timeout 0xc0016973b0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-dxhrp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dxhrp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-dxhrp,UID:2e514caf-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39719,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a43e7 0xc0019a43e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a4510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a4530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016973d0} {timeout 0xc0016973e0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-f65dt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f65dt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-f65dt,UID:2e46a5b9-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39732,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a45a0 0xc0019a45a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a4610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a46a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697400} {timeout 0xc001697410}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-f875x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f875x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-f875x,UID:28487c96-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39593,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a4757 0xc0019a4758}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a47d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a47f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697420} {timeout 0xc001697430}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:172.16.0.21,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c95c0ab5d8517e766bb8fb99f417126f1a76586361ade804992e7f5b18028eab}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-hddht" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hddht,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-hddht,UID:2e50daa7-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39714,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a4920 0xc0019a4921}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a4990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a49b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697450} {timeout 0xc001697460}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.438: INFO: Pod "nginx-deployment-555b55d965-kqd88" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kqd88,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-kqd88,UID:284f1c58-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39612,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a4a20 0xc0019a4a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a4a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a4c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697470} {timeout 0xc001697490}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:172.16.0.55,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://bc2cce5eeba631a053ebfd11d5567139cae857c860bfbee568dd57ad5cb84208}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-555b55d965-kx96m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kx96m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-kx96m,UID:2e4cbc5a-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39724,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a4ce0 0xc0019a4ce1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a4d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a4d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016974b0} {timeout 0xc0016974d0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-555b55d965-p5plw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p5plw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-p5plw,UID:2e4980e5-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39707,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a4fa7 0xc0019a4fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a5180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a51a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016974f0} {timeout 0xc001697510}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-555b55d965-pkrhn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pkrhn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-pkrhn,UID:28475a4d-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39619,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a5257 0xc0019a5258}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a52d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a52f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697520} {timeout 0xc001697530}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:172.16.0.57,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://705fd9b3cbbb072970b87d3868e19728678e485b208c0004ce5a0720bd61ed85}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-555b55d965-ps56x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ps56x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-ps56x,UID:2e4cf149-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39701,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a53b0 0xc0019a53b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a54e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a5580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697540} {timeout 0xc001697550}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-555b55d965-x2krw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-x2krw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-x2krw,UID:284f198a-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39591,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a56d0 0xc0019a56d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a5770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a5790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697560} {timeout 0xc001697570}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:172.16.0.23,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://4de7de9a7cd45d03362a18749ba3f283d19b6e5c2a0d7d22a9e529ca8b587d8d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-555b55d965-xdh9p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xdh9p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-555b55d965-xdh9p,UID:28488172-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39604,Generation:0,CreationTimestamp:2019-06-14 12:30:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 28456fbb-8ea0-11e9-8a76-fa163e95400d 0xc0019a5a20 0xc0019a5a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a5a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a5ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{timeout 0xc001697580} {single-request-reopen 0xc001697590}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:13 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:172.16.0.24,StartTime:2019-06-14 12:30:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-14 12:30:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://491ddc73d95a80aed9ad4d06212a90102a38bcdae0406236c72e8d8a8d6b861c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-65bbdb5f8-2jjm5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2jjm5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-2jjm5,UID:2e497a23-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39689,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0019a5c80 0xc0019a5c81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a5d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a5d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016975a0} {timeout 0xc0016975b0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-65bbdb5f8-5lcs7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5lcs7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-5lcs7,UID:2d0f275e-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39644,Generation:0,CreationTimestamp:2019-06-14 12:30:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0019a5da0 0xc0019a5da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a5e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a5e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016975c0} {timeout 0xc0016975d0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-65bbdb5f8-5mttt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5mttt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-5mttt,UID:2e4daa33-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39702,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0019a5f00 0xc0019a5f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019a5f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019a5fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016975e0} {timeout 0xc0016975f0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-65bbdb5f8-d6pwl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-d6pwl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-d6pwl,UID:2d177363-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39729,Generation:0,CreationTimestamp:2019-06-14 12:30:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f8030 0xc0015f8031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f80c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f80e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697600} {timeout 0xc001697610}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:,StartTime:2019-06-14 12:30:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-65bbdb5f8-dgzsq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dgzsq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-dgzsq,UID:2d164b93-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39670,Generation:0,CreationTimestamp:2019-06-14 12:30:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f81a0 0xc0015f81a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f82a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697620} {timeout 0xc001697630}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:,StartTime:2019-06-14 12:30:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-65bbdb5f8-dwffg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dwffg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-dwffg,UID:2e4da005-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39703,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f83a0 0xc0015f83a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697640} {timeout 0xc001697650}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.439: INFO: Pod "nginx-deployment-65bbdb5f8-j4jfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j4jfj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-j4jfj,UID:2e514249-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39718,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f84f0 0xc0015f84f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697660} {timeout 0xc001697670}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.440: INFO: Pod "nginx-deployment-65bbdb5f8-pcwtg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pcwtg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-pcwtg,UID:2d1013f2-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39649,Generation:0,CreationTimestamp:2019-06-14 12:30:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f8680 0xc0015f8681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697680} {timeout 0xc001697690}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.440: INFO: Pod "nginx-deployment-65bbdb5f8-qjtqh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qjtqh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-qjtqh,UID:2e46b7f5-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39686,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f88e0 0xc0015f88e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016976a0} {timeout 0xc0016976b0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.440: INFO: Pod "nginx-deployment-65bbdb5f8-vgrzg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vgrzg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-vgrzg,UID:2e496ee5-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39690,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f8da0 0xc0015f8da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016976d0} {timeout 0xc0016976e0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.440: INFO: Pod "nginx-deployment-65bbdb5f8-wtzx8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wtzx8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-wtzx8,UID:2d100e64-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39667,Generation:0,CreationTimestamp:2019-06-14 12:30:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f8f00 0xc0015f8f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f9280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f92a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0016976f0} {timeout 0xc001697700}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:21 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:,StartTime:2019-06-14 12:30:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.440: INFO: Pod "nginx-deployment-65bbdb5f8-x5xh2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x5xh2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-x5xh2,UID:2e4d9d74-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39731,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f9360 0xc0015f9361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f93e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f9400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697720} {timeout 0xc001697740}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:,StartTime:2019-06-14 12:30:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 14 12:30:25.440: INFO: Pod "nginx-deployment-65bbdb5f8-x9nnx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x9nnx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-5rt4p,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5rt4p/pods/nginx-deployment-65bbdb5f8-x9nnx,UID:2e4d8fa0-8ea0-11e9-8a76-fa163e95400d,ResourceVersion:39706,Generation:0,CreationTimestamp:2019-06-14 12:30:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 2d0e95dd-8ea0-11e9-8a76-fa163e95400d 0xc0015f9500 0xc0015f9501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fc9bf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fc9bf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-fc9bf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f9580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f95a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc001697760} {timeout 0xc001697780}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:30:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:30:25.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5rt4p" for this suite.
Jun 14 12:30:33.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:30:33.494: INFO: namespace: e2e-tests-deployment-5rt4p, resource: bindings, ignored listing per whitelist
Jun 14 12:30:33.509: INFO: namespace e2e-tests-deployment-5rt4p deletion completed in 8.066981409s

• [SLOW TEST:20.207 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:30:33.509: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vzms5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 14 12:30:33.596: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 14 12:30:57.647: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.53:8080/dial?request=hostName&protocol=http&host=172.16.0.27&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-vzms5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:30:57.647: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:30:57.738: INFO: Waiting for endpoints: map[]
Jun 14 12:30:57.740: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.53:8080/dial?request=hostName&protocol=http&host=172.16.0.52&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-vzms5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:30:57.740: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:30:57.798: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:30:57.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vzms5" for this suite.
Jun 14 12:31:19.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:31:19.854: INFO: namespace: e2e-tests-pod-network-test-vzms5, resource: bindings, ignored listing per whitelist
Jun 14 12:31:19.859: INFO: namespace e2e-tests-pod-network-test-vzms5 deletion completed in 22.058209065s

• [SLOW TEST:46.350 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:31:19.859: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:31:19.912: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ff7e690-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-c9qp6" to be "success or failure"
Jun 14 12:31:19.913: INFO: Pod "downwardapi-volume-4ff7e690-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.325381ms
Jun 14 12:31:21.919: INFO: Pod "downwardapi-volume-4ff7e690-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007011927s
STEP: Saw pod success
Jun 14 12:31:21.919: INFO: Pod "downwardapi-volume-4ff7e690-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:31:21.921: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-4ff7e690-8ea0-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:31:21.978: INFO: Waiting for pod downwardapi-volume-4ff7e690-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:31:21.979: INFO: Pod downwardapi-volume-4ff7e690-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:31:21.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c9qp6" for this suite.
Jun 14 12:31:27.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:31:28.041: INFO: namespace: e2e-tests-downward-api-c9qp6, resource: bindings, ignored listing per whitelist
Jun 14 12:31:28.047: INFO: namespace e2e-tests-downward-api-c9qp6 deletion completed in 6.065067291s

• [SLOW TEST:8.187 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:31:28.047: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:31:28.090: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:31:34.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-qvdlt" for this suite.
Jun 14 12:31:40.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:31:40.180: INFO: namespace: e2e-tests-custom-resource-definition-qvdlt, resource: bindings, ignored listing per whitelist
Jun 14 12:31:40.191: INFO: namespace e2e-tests-custom-resource-definition-qvdlt deletion completed in 6.057490694s

• [SLOW TEST:12.144 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:31:40.191: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zhp7l
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jun 14 12:31:40.252: INFO: Found 0 stateful pods, waiting for 3
Jun 14 12:31:50.258: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:31:50.258: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:31:50.258: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun 14 12:31:50.291: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jun 14 12:32:00.322: INFO: Updating stateful set ss2
Jun 14 12:32:00.326: INFO: Waiting for Pod e2e-tests-statefulset-zhp7l/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jun 14 12:32:10.358: INFO: Found 1 stateful pods, waiting for 3
Jun 14 12:32:20.364: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:32:20.364: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:32:20.364: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jun 14 12:32:20.383: INFO: Updating stateful set ss2
Jun 14 12:32:20.386: INFO: Waiting for Pod e2e-tests-statefulset-zhp7l/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 14 12:32:30.411: INFO: Updating stateful set ss2
Jun 14 12:32:30.418: INFO: Waiting for StatefulSet e2e-tests-statefulset-zhp7l/ss2 to complete update
Jun 14 12:32:30.418: INFO: Waiting for Pod e2e-tests-statefulset-zhp7l/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 14 12:32:40.426: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zhp7l
Jun 14 12:32:40.427: INFO: Scaling statefulset ss2 to 0
Jun 14 12:32:50.440: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 12:32:50.442: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:32:50.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zhp7l" for this suite.
Jun 14 12:32:56.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:32:56.463: INFO: namespace: e2e-tests-statefulset-zhp7l, resource: bindings, ignored listing per whitelist
Jun 14 12:32:56.510: INFO: namespace e2e-tests-statefulset-zhp7l deletion completed in 6.058775245s

• [SLOW TEST:76.320 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:32:56.511: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 14 12:33:01.083: INFO: Successfully updated pod "labelsupdate89932140-8ea0-11e9-82a6-0255ac100014"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:33:03.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-29zx5" for this suite.
Jun 14 12:33:19.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:33:19.126: INFO: namespace: e2e-tests-projected-29zx5, resource: bindings, ignored listing per whitelist
Jun 14 12:33:19.153: INFO: namespace e2e-tests-projected-29zx5 deletion completed in 16.057121887s

• [SLOW TEST:22.643 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:33:19.153: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 14 12:33:19.217: INFO: Waiting up to 5m0s for pod "pod-9712c9dd-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-fcvkf" to be "success or failure"
Jun 14 12:33:19.219: INFO: Pod "pod-9712c9dd-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.22926ms
Jun 14 12:33:21.225: INFO: Pod "pod-9712c9dd-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008002451s
Jun 14 12:33:23.227: INFO: Pod "pod-9712c9dd-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010657837s
STEP: Saw pod success
Jun 14 12:33:23.227: INFO: Pod "pod-9712c9dd-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:33:23.229: INFO: Trying to get logs from node 192.168.0.235 pod pod-9712c9dd-8ea0-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:33:23.246: INFO: Waiting for pod pod-9712c9dd-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:33:23.248: INFO: Pod pod-9712c9dd-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:33:23.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fcvkf" for this suite.
Jun 14 12:33:29.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:33:29.306: INFO: namespace: e2e-tests-emptydir-fcvkf, resource: bindings, ignored listing per whitelist
Jun 14 12:33:29.311: INFO: namespace e2e-tests-emptydir-fcvkf deletion completed in 6.059598585s

• [SLOW TEST:10.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:33:29.311: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jun 14 12:33:29.377: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-dqfkt,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqfkt/configmaps/e2e-watch-test-resource-version,UID:9d3419c9-8ea0-11e9-a0dc-fa163eff1b62,ResourceVersion:40634,Generation:0,CreationTimestamp:2019-06-14 12:33:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 14 12:33:29.377: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-dqfkt,SelfLink:/api/v1/namespaces/e2e-tests-watch-dqfkt/configmaps/e2e-watch-test-resource-version,UID:9d3419c9-8ea0-11e9-a0dc-fa163eff1b62,ResourceVersion:40635,Generation:0,CreationTimestamp:2019-06-14 12:33:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:33:29.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-dqfkt" for this suite.
Jun 14 12:33:35.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:33:35.430: INFO: namespace: e2e-tests-watch-dqfkt, resource: bindings, ignored listing per whitelist
Jun 14 12:33:35.437: INFO: namespace e2e-tests-watch-dqfkt deletion completed in 6.057648651s

• [SLOW TEST:6.126 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:33:35.437: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jun 14 12:33:35.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:35.848: INFO: stderr: ""
Jun 14 12:33:35.848: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 14 12:33:35.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:35.909: INFO: stderr: ""
Jun 14 12:33:35.909: INFO: stdout: "update-demo-nautilus-2nf7f update-demo-nautilus-w9l2q "
Jun 14 12:33:35.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-2nf7f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:35.959: INFO: stderr: ""
Jun 14 12:33:35.959: INFO: stdout: ""
Jun 14 12:33:35.959: INFO: update-demo-nautilus-2nf7f is created but not running
Jun 14 12:33:40.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:41.021: INFO: stderr: ""
Jun 14 12:33:41.021: INFO: stdout: "update-demo-nautilus-2nf7f update-demo-nautilus-w9l2q "
Jun 14 12:33:41.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-2nf7f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:41.072: INFO: stderr: ""
Jun 14 12:33:41.072: INFO: stdout: "true"
Jun 14 12:33:41.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-2nf7f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:41.123: INFO: stderr: ""
Jun 14 12:33:41.123: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 12:33:41.123: INFO: validating pod update-demo-nautilus-2nf7f
Jun 14 12:33:41.136: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 12:33:41.136: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 12:33:41.136: INFO: update-demo-nautilus-2nf7f is verified up and running
Jun 14 12:33:41.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-w9l2q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:41.185: INFO: stderr: ""
Jun 14 12:33:41.185: INFO: stdout: "true"
Jun 14 12:33:41.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-w9l2q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:33:41.235: INFO: stderr: ""
Jun 14 12:33:41.236: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 12:33:41.236: INFO: validating pod update-demo-nautilus-w9l2q
Jun 14 12:33:41.251: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 12:33:41.251: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 12:33:41.251: INFO: update-demo-nautilus-w9l2q is verified up and running
STEP: rolling-update to new replication controller
Jun 14 12:33:41.252: INFO: scanned /root for discovery docs: <nil>
Jun 14 12:33:41.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:34:04.528: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 14 12:34:04.528: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 14 12:34:04.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:34:04.588: INFO: stderr: ""
Jun 14 12:34:04.588: INFO: stdout: "update-demo-kitten-8qzlc update-demo-kitten-x9w8q "
Jun 14 12:34:04.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-kitten-8qzlc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:34:04.647: INFO: stderr: ""
Jun 14 12:34:04.647: INFO: stdout: "true"
Jun 14 12:34:04.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-kitten-8qzlc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:34:04.702: INFO: stderr: ""
Jun 14 12:34:04.702: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 14 12:34:04.702: INFO: validating pod update-demo-kitten-8qzlc
Jun 14 12:34:04.714: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 14 12:34:04.714: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 14 12:34:04.714: INFO: update-demo-kitten-8qzlc is verified up and running
Jun 14 12:34:04.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-kitten-x9w8q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:34:04.766: INFO: stderr: ""
Jun 14 12:34:04.766: INFO: stdout: "true"
Jun 14 12:34:04.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-kitten-x9w8q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2xjjv'
Jun 14 12:34:04.820: INFO: stderr: ""
Jun 14 12:34:04.821: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 14 12:34:04.821: INFO: validating pod update-demo-kitten-x9w8q
Jun 14 12:34:04.832: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 14 12:34:04.832: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 14 12:34:04.832: INFO: update-demo-kitten-x9w8q is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:34:04.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2xjjv" for this suite.
Jun 14 12:34:26.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:34:26.885: INFO: namespace: e2e-tests-kubectl-2xjjv, resource: bindings, ignored listing per whitelist
Jun 14 12:34:26.898: INFO: namespace e2e-tests-kubectl-2xjjv deletion completed in 22.063730981s

• [SLOW TEST:51.461 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:34:26.898: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bf736fb2-8ea0-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:34:26.953: INFO: Waiting up to 5m0s for pod "pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-zsskq" to be "success or failure"
Jun 14 12:34:26.955: INFO: Pod "pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.974727ms
Jun 14 12:34:28.957: INFO: Pod "pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004353929s
Jun 14 12:34:30.960: INFO: Pod "pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007039825s
STEP: Saw pod success
Jun 14 12:34:30.960: INFO: Pod "pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:34:30.962: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014 container secret-env-test: <nil>
STEP: delete the pod
Jun 14 12:34:30.976: INFO: Waiting for pod pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:34:30.978: INFO: Pod pod-secrets-bf74067c-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:34:30.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zsskq" for this suite.
Jun 14 12:34:36.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:34:37.027: INFO: namespace: e2e-tests-secrets-zsskq, resource: bindings, ignored listing per whitelist
Jun 14 12:34:37.043: INFO: namespace e2e-tests-secrets-zsskq deletion completed in 6.062868713s

• [SLOW TEST:10.145 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:34:37.043: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c580f635-8ea0-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:34:37.108: INFO: Waiting up to 5m0s for pod "pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-fhffq" to be "success or failure"
Jun 14 12:34:37.109: INFO: Pod "pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.419606ms
Jun 14 12:34:39.112: INFO: Pod "pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003790035s
Jun 14 12:34:41.114: INFO: Pod "pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006346703s
STEP: Saw pod success
Jun 14 12:34:41.114: INFO: Pod "pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:34:41.116: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:34:41.129: INFO: Waiting for pod pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:34:41.131: INFO: Pod pod-secrets-c581c426-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:34:41.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fhffq" for this suite.
Jun 14 12:34:47.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:34:47.176: INFO: namespace: e2e-tests-secrets-fhffq, resource: bindings, ignored listing per whitelist
Jun 14 12:34:47.193: INFO: namespace e2e-tests-secrets-fhffq deletion completed in 6.060743641s

• [SLOW TEST:10.150 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:34:47.193: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:35:14.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-dz5md" for this suite.
Jun 14 12:35:20.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:35:20.431: INFO: namespace: e2e-tests-container-runtime-dz5md, resource: bindings, ignored listing per whitelist
Jun 14 12:35:20.446: INFO: namespace e2e-tests-container-runtime-dz5md deletion completed in 6.055863693s

• [SLOW TEST:33.252 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:35:20.446: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qm8v9/configmap-test-df5e37d6-8ea0-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:35:20.500: INFO: Waiting up to 5m0s for pod "pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-qm8v9" to be "success or failure"
Jun 14 12:35:20.502: INFO: Pod "pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.512294ms
Jun 14 12:35:22.505: INFO: Pod "pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004185567s
Jun 14 12:35:24.507: INFO: Pod "pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006840518s
STEP: Saw pod success
Jun 14 12:35:24.507: INFO: Pod "pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:35:24.509: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014 container env-test: <nil>
STEP: delete the pod
Jun 14 12:35:24.523: INFO: Waiting for pod pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:35:24.524: INFO: Pod pod-configmaps-df5effcc-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:35:24.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qm8v9" for this suite.
Jun 14 12:35:30.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:35:30.600: INFO: namespace: e2e-tests-configmap-qm8v9, resource: bindings, ignored listing per whitelist
Jun 14 12:35:30.615: INFO: namespace e2e-tests-configmap-qm8v9 deletion completed in 6.088415099s

• [SLOW TEST:10.169 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:35:30.615: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 14 12:35:30.674: INFO: Waiting up to 5m0s for pod "downward-api-e56edfe6-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-f6jc5" to be "success or failure"
Jun 14 12:35:30.677: INFO: Pod "downward-api-e56edfe6-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.117295ms
Jun 14 12:35:32.679: INFO: Pod "downward-api-e56edfe6-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005711356s
STEP: Saw pod success
Jun 14 12:35:32.679: INFO: Pod "downward-api-e56edfe6-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:35:32.681: INFO: Trying to get logs from node 192.168.0.19 pod downward-api-e56edfe6-8ea0-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 12:35:32.699: INFO: Waiting for pod downward-api-e56edfe6-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:35:32.705: INFO: Pod downward-api-e56edfe6-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:35:32.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f6jc5" for this suite.
Jun 14 12:35:38.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:35:38.754: INFO: namespace: e2e-tests-downward-api-f6jc5, resource: bindings, ignored listing per whitelist
Jun 14 12:35:38.777: INFO: namespace e2e-tests-downward-api-f6jc5 deletion completed in 6.069866707s

• [SLOW TEST:8.162 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:35:38.777: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:35:38.833: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-72r9l" to be "success or failure"
Jun 14 12:35:38.834: INFO: Pod "downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.47837ms
Jun 14 12:35:40.837: INFO: Pod "downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00418101s
Jun 14 12:35:42.840: INFO: Pod "downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006589861s
STEP: Saw pod success
Jun 14 12:35:42.840: INFO: Pod "downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:35:42.841: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:35:42.858: INFO: Waiting for pod downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:35:42.860: INFO: Pod downwardapi-volume-ea4c1021-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:35:42.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-72r9l" for this suite.
Jun 14 12:35:48.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:35:48.889: INFO: namespace: e2e-tests-downward-api-72r9l, resource: bindings, ignored listing per whitelist
Jun 14 12:35:48.922: INFO: namespace e2e-tests-downward-api-72r9l deletion completed in 6.059898233s

• [SLOW TEST:10.145 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:35:48.922: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 14 12:35:48.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-29bm2'
Jun 14 12:35:49.035: INFO: stderr: ""
Jun 14 12:35:49.035: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jun 14 12:35:49.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-29bm2'
Jun 14 12:35:56.355: INFO: stderr: ""
Jun 14 12:35:56.355: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:35:56.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-29bm2" for this suite.
Jun 14 12:36:02.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:36:02.401: INFO: namespace: e2e-tests-kubectl-29bm2, resource: bindings, ignored listing per whitelist
Jun 14 12:36:02.419: INFO: namespace e2e-tests-kubectl-29bm2 deletion completed in 6.061081252s

• [SLOW TEST:13.497 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:36:02.419: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:36:02.475: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f86327b3-8ea0-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-vmj4c" to be "success or failure"
Jun 14 12:36:02.480: INFO: Pod "downwardapi-volume-f86327b3-8ea0-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.643416ms
Jun 14 12:36:04.482: INFO: Pod "downwardapi-volume-f86327b3-8ea0-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007140646s
STEP: Saw pod success
Jun 14 12:36:04.482: INFO: Pod "downwardapi-volume-f86327b3-8ea0-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:36:04.484: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-f86327b3-8ea0-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:36:04.507: INFO: Waiting for pod downwardapi-volume-f86327b3-8ea0-11e9-82a6-0255ac100014 to disappear
Jun 14 12:36:04.509: INFO: Pod downwardapi-volume-f86327b3-8ea0-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:36:04.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vmj4c" for this suite.
Jun 14 12:36:10.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:36:10.569: INFO: namespace: e2e-tests-projected-vmj4c, resource: bindings, ignored listing per whitelist
Jun 14 12:36:10.585: INFO: namespace e2e-tests-projected-vmj4c deletion completed in 6.073566163s

• [SLOW TEST:8.166 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:36:10.585: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jun 14 12:36:12.643: INFO: Pod pod-hostip-fd409904-8ea0-11e9-82a6-0255ac100014 has hostIP: 192.168.0.235
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:36:12.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tfwqb" for this suite.
Jun 14 12:36:34.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:36:34.688: INFO: namespace: e2e-tests-pods-tfwqb, resource: bindings, ignored listing per whitelist
Jun 14 12:36:34.704: INFO: namespace e2e-tests-pods-tfwqb deletion completed in 22.05980662s

• [SLOW TEST:24.120 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:36:34.705: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0ba313ff-8ea1-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:36:34.776: INFO: Waiting up to 5m0s for pod "pod-secrets-0ba3d1d2-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-p6s5m" to be "success or failure"
Jun 14 12:36:34.777: INFO: Pod "pod-secrets-0ba3d1d2-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.671588ms
Jun 14 12:36:36.781: INFO: Pod "pod-secrets-0ba3d1d2-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005733323s
STEP: Saw pod success
Jun 14 12:36:36.781: INFO: Pod "pod-secrets-0ba3d1d2-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:36:36.783: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-0ba3d1d2-8ea1-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:36:36.801: INFO: Waiting for pod pod-secrets-0ba3d1d2-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:36:36.802: INFO: Pod pod-secrets-0ba3d1d2-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:36:36.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p6s5m" for this suite.
Jun 14 12:36:42.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:36:42.838: INFO: namespace: e2e-tests-secrets-p6s5m, resource: bindings, ignored listing per whitelist
Jun 14 12:36:42.868: INFO: namespace e2e-tests-secrets-p6s5m deletion completed in 6.063450599s

• [SLOW TEST:8.163 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:36:42.868: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jun 14 12:36:42.923: INFO: Waiting up to 5m0s for pod "client-containers-107f7332-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-containers-mhmsx" to be "success or failure"
Jun 14 12:36:42.925: INFO: Pod "client-containers-107f7332-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.554787ms
Jun 14 12:36:44.927: INFO: Pod "client-containers-107f7332-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004243951s
Jun 14 12:36:46.930: INFO: Pod "client-containers-107f7332-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006957877s
Jun 14 12:36:48.932: INFO: Pod "client-containers-107f7332-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009360978s
STEP: Saw pod success
Jun 14 12:36:48.932: INFO: Pod "client-containers-107f7332-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:36:48.934: INFO: Trying to get logs from node 192.168.0.235 pod client-containers-107f7332-8ea1-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:36:48.949: INFO: Waiting for pod client-containers-107f7332-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:36:48.951: INFO: Pod client-containers-107f7332-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:36:48.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mhmsx" for this suite.
Jun 14 12:36:54.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:36:55.006: INFO: namespace: e2e-tests-containers-mhmsx, resource: bindings, ignored listing per whitelist
Jun 14 12:36:55.008: INFO: namespace e2e-tests-containers-mhmsx deletion completed in 6.055687907s

• [SLOW TEST:12.141 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:36:55.008: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 14 12:36:55.060: INFO: Waiting up to 5m0s for pod "pod-17bb7c48-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-v2cxr" to be "success or failure"
Jun 14 12:36:55.062: INFO: Pod "pod-17bb7c48-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.306164ms
Jun 14 12:36:57.064: INFO: Pod "pod-17bb7c48-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00347196s
STEP: Saw pod success
Jun 14 12:36:57.064: INFO: Pod "pod-17bb7c48-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:36:57.066: INFO: Trying to get logs from node 192.168.0.235 pod pod-17bb7c48-8ea1-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:36:57.080: INFO: Waiting for pod pod-17bb7c48-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:36:57.085: INFO: Pod pod-17bb7c48-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:36:57.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v2cxr" for this suite.
Jun 14 12:37:03.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:37:03.115: INFO: namespace: e2e-tests-emptydir-v2cxr, resource: bindings, ignored listing per whitelist
Jun 14 12:37:03.147: INFO: namespace e2e-tests-emptydir-v2cxr deletion completed in 6.05996448s

• [SLOW TEST:8.139 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:37:03.147: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-1c947adc-8ea1-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:37:03.198: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1c9529bb-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-hp699" to be "success or failure"
Jun 14 12:37:03.200: INFO: Pod "pod-projected-secrets-1c9529bb-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03253ms
Jun 14 12:37:05.202: INFO: Pod "pod-projected-secrets-1c9529bb-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004325975s
STEP: Saw pod success
Jun 14 12:37:05.202: INFO: Pod "pod-projected-secrets-1c9529bb-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:37:05.204: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-secrets-1c9529bb-8ea1-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:37:05.217: INFO: Waiting for pod pod-projected-secrets-1c9529bb-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:37:05.218: INFO: Pod pod-projected-secrets-1c9529bb-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:37:05.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hp699" for this suite.
Jun 14 12:37:11.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:37:11.239: INFO: namespace: e2e-tests-projected-hp699, resource: bindings, ignored listing per whitelist
Jun 14 12:37:11.295: INFO: namespace e2e-tests-projected-hp699 deletion completed in 6.074243405s

• [SLOW TEST:8.147 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:37:11.295: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 14 12:37:11.357: INFO: Waiting up to 5m0s for pod "pod-2172349e-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-8pxt5" to be "success or failure"
Jun 14 12:37:11.359: INFO: Pod "pod-2172349e-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.502171ms
Jun 14 12:37:13.365: INFO: Pod "pod-2172349e-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007301737s
STEP: Saw pod success
Jun 14 12:37:13.365: INFO: Pod "pod-2172349e-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:37:13.366: INFO: Trying to get logs from node 192.168.0.235 pod pod-2172349e-8ea1-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:37:13.382: INFO: Waiting for pod pod-2172349e-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:37:13.384: INFO: Pod pod-2172349e-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:37:13.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8pxt5" for this suite.
Jun 14 12:37:19.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:37:19.400: INFO: namespace: e2e-tests-emptydir-8pxt5, resource: bindings, ignored listing per whitelist
Jun 14 12:37:19.441: INFO: namespace e2e-tests-emptydir-8pxt5 deletion completed in 6.055557612s

• [SLOW TEST:8.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:37:19.441: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 14 12:37:19.488: INFO: Waiting up to 5m0s for pod "pod-264adbf9-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-w4qkm" to be "success or failure"
Jun 14 12:37:19.493: INFO: Pod "pod-264adbf9-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.171273ms
Jun 14 12:37:21.495: INFO: Pod "pod-264adbf9-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007545706s
STEP: Saw pod success
Jun 14 12:37:21.496: INFO: Pod "pod-264adbf9-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:37:21.497: INFO: Trying to get logs from node 192.168.0.235 pod pod-264adbf9-8ea1-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:37:21.550: INFO: Waiting for pod pod-264adbf9-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:37:21.552: INFO: Pod pod-264adbf9-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:37:21.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w4qkm" for this suite.
Jun 14 12:37:27.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:37:27.614: INFO: namespace: e2e-tests-emptydir-w4qkm, resource: bindings, ignored listing per whitelist
Jun 14 12:37:27.628: INFO: namespace e2e-tests-emptydir-w4qkm deletion completed in 6.072330878s

• [SLOW TEST:8.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:37:27.628: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:37:27.708: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jun 14 12:37:27.714: INFO: Number of nodes with available pods: 0
Jun 14 12:37:27.714: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jun 14 12:37:27.936: INFO: Number of nodes with available pods: 0
Jun 14 12:37:27.936: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:28.939: INFO: Number of nodes with available pods: 0
Jun 14 12:37:28.939: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:29.940: INFO: Number of nodes with available pods: 0
Jun 14 12:37:29.940: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:30.939: INFO: Number of nodes with available pods: 1
Jun 14 12:37:30.939: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jun 14 12:37:30.949: INFO: Number of nodes with available pods: 1
Jun 14 12:37:30.949: INFO: Number of running nodes: 0, number of available pods: 1
Jun 14 12:37:31.952: INFO: Number of nodes with available pods: 0
Jun 14 12:37:31.952: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jun 14 12:37:31.959: INFO: Number of nodes with available pods: 0
Jun 14 12:37:31.959: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:32.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:32.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:33.964: INFO: Number of nodes with available pods: 0
Jun 14 12:37:33.964: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:34.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:34.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:35.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:35.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:36.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:36.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:37.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:37.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:38.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:38.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:39.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:39.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:40.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:40.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:41.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:41.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:42.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:42.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:43.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:43.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:44.964: INFO: Number of nodes with available pods: 0
Jun 14 12:37:44.964: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:45.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:45.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:46.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:46.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:47.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:47.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:48.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:48.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:49.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:49.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:50.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:50.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:51.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:51.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:52.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:52.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:53.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:53.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:54.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:54.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:55.964: INFO: Number of nodes with available pods: 0
Jun 14 12:37:55.964: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:56.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:56.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:57.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:57.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:58.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:58.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:37:59.961: INFO: Number of nodes with available pods: 0
Jun 14 12:37:59.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:00.961: INFO: Number of nodes with available pods: 0
Jun 14 12:38:00.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:01.961: INFO: Number of nodes with available pods: 0
Jun 14 12:38:01.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:02.961: INFO: Number of nodes with available pods: 0
Jun 14 12:38:02.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:03.961: INFO: Number of nodes with available pods: 0
Jun 14 12:38:03.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:04.961: INFO: Number of nodes with available pods: 0
Jun 14 12:38:04.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:05.962: INFO: Number of nodes with available pods: 0
Jun 14 12:38:05.962: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:06.965: INFO: Number of nodes with available pods: 0
Jun 14 12:38:06.965: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:07.961: INFO: Number of nodes with available pods: 0
Jun 14 12:38:07.961: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:38:08.961: INFO: Number of nodes with available pods: 1
Jun 14 12:38:08.961: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nk9m2, will wait for the garbage collector to delete the pods
Jun 14 12:38:09.022: INFO: Deleting DaemonSet.extensions daemon-set took: 5.624586ms
Jun 14 12:38:09.122: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.125253ms
Jun 14 12:38:46.727: INFO: Number of nodes with available pods: 0
Jun 14 12:38:46.727: INFO: Number of running nodes: 0, number of available pods: 0
Jun 14 12:38:46.728: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nk9m2/daemonsets","resourceVersion":"41969"},"items":null}

Jun 14 12:38:46.730: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nk9m2/pods","resourceVersion":"41969"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:38:46.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nk9m2" for this suite.
Jun 14 12:38:52.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:38:52.980: INFO: namespace: e2e-tests-daemonsets-nk9m2, resource: bindings, ignored listing per whitelist
Jun 14 12:38:53.020: INFO: namespace e2e-tests-daemonsets-nk9m2 deletion completed in 6.063853085s

• [SLOW TEST:85.392 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:38:53.020: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:38:53.076: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e1282ef-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-xq4v8" to be "success or failure"
Jun 14 12:38:53.077: INFO: Pod "downwardapi-volume-5e1282ef-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.486819ms
Jun 14 12:38:55.080: INFO: Pod "downwardapi-volume-5e1282ef-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004034927s
STEP: Saw pod success
Jun 14 12:38:55.080: INFO: Pod "downwardapi-volume-5e1282ef-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:38:55.082: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-5e1282ef-8ea1-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:38:55.096: INFO: Waiting for pod downwardapi-volume-5e1282ef-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:38:55.098: INFO: Pod downwardapi-volume-5e1282ef-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:38:55.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xq4v8" for this suite.
Jun 14 12:39:01.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:39:01.122: INFO: namespace: e2e-tests-downward-api-xq4v8, resource: bindings, ignored listing per whitelist
Jun 14 12:39:01.160: INFO: namespace e2e-tests-downward-api-xq4v8 deletion completed in 6.060486738s

• [SLOW TEST:8.140 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:39:01.160: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 14 12:39:03.729: INFO: Successfully updated pod "annotationupdate62ec3145-8ea1-11e9-82a6-0255ac100014"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:39:05.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d5s8r" for this suite.
Jun 14 12:39:27.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:39:27.765: INFO: namespace: e2e-tests-downward-api-d5s8r, resource: bindings, ignored listing per whitelist
Jun 14 12:39:27.800: INFO: namespace e2e-tests-downward-api-d5s8r deletion completed in 22.057700606s

• [SLOW TEST:26.640 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:39:27.800: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-72ccf92d-8ea1-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:39:27.852: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-z479w" to be "success or failure"
Jun 14 12:39:27.854: INFO: Pod "pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.871161ms
Jun 14 12:39:29.860: INFO: Pod "pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007460104s
Jun 14 12:39:31.862: INFO: Pod "pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009987272s
STEP: Saw pod success
Jun 14 12:39:31.862: INFO: Pod "pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:39:31.864: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:39:31.880: INFO: Waiting for pod pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:39:31.882: INFO: Pod pod-projected-secrets-72cdd177-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:39:31.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z479w" for this suite.
Jun 14 12:39:37.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:39:37.917: INFO: namespace: e2e-tests-projected-z479w, resource: bindings, ignored listing per whitelist
Jun 14 12:39:37.943: INFO: namespace e2e-tests-projected-z479w deletion completed in 6.058816667s

• [SLOW TEST:10.143 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:39:37.943: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-slghm
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-slghm
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-slghm
Jun 14 12:39:38.000: INFO: Found 0 stateful pods, waiting for 1
Jun 14 12:39:48.006: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jun 14 12:39:48.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 12:39:48.138: INFO: stderr: ""
Jun 14 12:39:48.138: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 12:39:48.138: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 12:39:48.143: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 14 12:39:58.149: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 12:39:58.149: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 12:39:58.157: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999807s
Jun 14 12:39:59.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998033058s
Jun 14 12:40:00.162: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995220538s
Jun 14 12:40:01.165: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992729237s
Jun 14 12:40:02.167: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.990151401s
Jun 14 12:40:03.170: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.987601992s
Jun 14 12:40:04.173: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.984847802s
Jun 14 12:40:05.176: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.982298937s
Jun 14 12:40:06.178: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.979456826s
Jun 14 12:40:07.181: INFO: Verifying statefulset ss doesn't scale past 1 for another 976.972733ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-slghm
Jun 14 12:40:08.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 12:40:08.300: INFO: stderr: ""
Jun 14 12:40:08.300: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 12:40:08.300: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 12:40:08.302: INFO: Found 1 stateful pods, waiting for 3
Jun 14 12:40:18.308: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:40:18.308: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 12:40:18.308: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jun 14 12:40:18.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 12:40:18.410: INFO: stderr: ""
Jun 14 12:40:18.410: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 12:40:18.410: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 12:40:18.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 12:40:18.531: INFO: stderr: ""
Jun 14 12:40:18.531: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 12:40:18.531: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 12:40:18.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 12:40:18.646: INFO: stderr: ""
Jun 14 12:40:18.646: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 12:40:18.646: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 12:40:18.646: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 12:40:18.648: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jun 14 12:40:28.656: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 12:40:28.656: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 12:40:28.656: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 12:40:28.665: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999794s
Jun 14 12:40:29.668: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996423922s
Jun 14 12:40:30.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99357028s
Jun 14 12:40:31.674: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990395829s
Jun 14 12:40:32.677: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987572906s
Jun 14 12:40:33.680: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984738366s
Jun 14 12:40:34.683: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.98174271s
Jun 14 12:40:35.686: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978618648s
Jun 14 12:40:36.689: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975655933s
Jun 14 12:40:37.692: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.806436ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-slghm
Jun 14 12:40:38.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 12:40:38.806: INFO: stderr: ""
Jun 14 12:40:38.806: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 12:40:38.806: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 12:40:38.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 12:40:38.912: INFO: stderr: ""
Jun 14 12:40:38.912: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 12:40:38.912: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 12:40:38.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-slghm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 12:40:39.018: INFO: stderr: ""
Jun 14 12:40:39.018: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 12:40:39.018: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 12:40:39.018: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 14 12:40:59.031: INFO: Deleting all statefulset in ns e2e-tests-statefulset-slghm
Jun 14 12:40:59.036: INFO: Scaling statefulset ss to 0
Jun 14 12:40:59.041: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 12:40:59.043: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:40:59.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-slghm" for this suite.
Jun 14 12:41:05.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:41:05.082: INFO: namespace: e2e-tests-statefulset-slghm, resource: bindings, ignored listing per whitelist
Jun 14 12:41:05.120: INFO: namespace e2e-tests-statefulset-slghm deletion completed in 6.066988259s

• [SLOW TEST:87.177 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:41:05.120: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jun 14 12:41:05.186: INFO: Waiting up to 5m0s for pod "client-containers-acd1a718-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-containers-ql4vc" to be "success or failure"
Jun 14 12:41:05.188: INFO: Pod "client-containers-acd1a718-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.595543ms
Jun 14 12:41:07.190: INFO: Pod "client-containers-acd1a718-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003985248s
STEP: Saw pod success
Jun 14 12:41:07.190: INFO: Pod "client-containers-acd1a718-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:41:07.192: INFO: Trying to get logs from node 192.168.0.235 pod client-containers-acd1a718-8ea1-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:41:07.231: INFO: Waiting for pod client-containers-acd1a718-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:41:07.233: INFO: Pod client-containers-acd1a718-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:41:07.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ql4vc" for this suite.
Jun 14 12:41:13.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:41:13.248: INFO: namespace: e2e-tests-containers-ql4vc, resource: bindings, ignored listing per whitelist
Jun 14 12:41:13.293: INFO: namespace e2e-tests-containers-ql4vc deletion completed in 6.05883728s

• [SLOW TEST:8.173 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:41:13.293: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-x24tr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 14 12:41:13.345: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 14 12:41:31.392: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.28:8080/dial?request=hostName&protocol=udp&host=172.16.0.27&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-x24tr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:41:31.392: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:41:31.482: INFO: Waiting for endpoints: map[]
Jun 14 12:41:31.484: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.28:8080/dial?request=hostName&protocol=udp&host=172.16.0.62&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-x24tr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:41:31.484: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:41:31.543: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:41:31.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-x24tr" for this suite.
Jun 14 12:41:53.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:41:53.574: INFO: namespace: e2e-tests-pod-network-test-x24tr, resource: bindings, ignored listing per whitelist
Jun 14 12:41:53.603: INFO: namespace e2e-tests-pod-network-test-x24tr deletion completed in 22.057445019s

• [SLOW TEST:40.309 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:41:53.603: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:41:53.654: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9b510e1-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-czrxv" to be "success or failure"
Jun 14 12:41:53.656: INFO: Pod "downwardapi-volume-c9b510e1-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.250336ms
Jun 14 12:41:55.659: INFO: Pod "downwardapi-volume-c9b510e1-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004579306s
STEP: Saw pod success
Jun 14 12:41:55.659: INFO: Pod "downwardapi-volume-c9b510e1-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:41:55.661: INFO: Trying to get logs from node 192.168.0.19 pod downwardapi-volume-c9b510e1-8ea1-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:41:55.699: INFO: Waiting for pod downwardapi-volume-c9b510e1-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:41:55.700: INFO: Pod downwardapi-volume-c9b510e1-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:41:55.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-czrxv" for this suite.
Jun 14 12:42:01.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:42:01.741: INFO: namespace: e2e-tests-downward-api-czrxv, resource: bindings, ignored listing per whitelist
Jun 14 12:42:01.767: INFO: namespace e2e-tests-downward-api-czrxv deletion completed in 6.064736112s

• [SLOW TEST:8.164 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:42:01.767: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jun 14 12:42:02.337: INFO: Waiting up to 5m0s for pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24" in namespace "e2e-tests-svcaccounts-hxxng" to be "success or failure"
Jun 14 12:42:02.339: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24": Phase="Pending", Reason="", readiness=false. Elapsed: 1.75122ms
Jun 14 12:42:04.341: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004391652s
Jun 14 12:42:06.344: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006947569s
STEP: Saw pod success
Jun 14 12:42:06.344: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24" satisfied condition "success or failure"
Jun 14 12:42:06.346: INFO: Trying to get logs from node 192.168.0.235 pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24 container token-test: <nil>
STEP: delete the pod
Jun 14 12:42:06.361: INFO: Waiting for pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24 to disappear
Jun 14 12:42:06.363: INFO: Pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-2nl24 no longer exists
STEP: Creating a pod to test consume service account root CA
Jun 14 12:42:06.368: INFO: Waiting up to 5m0s for pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c" in namespace "e2e-tests-svcaccounts-hxxng" to be "success or failure"
Jun 14 12:42:06.370: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.579956ms
Jun 14 12:42:08.373: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004304124s
Jun 14 12:42:10.375: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006508468s
STEP: Saw pod success
Jun 14 12:42:10.375: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c" satisfied condition "success or failure"
Jun 14 12:42:10.377: INFO: Trying to get logs from node 192.168.0.235 pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c container root-ca-test: <nil>
STEP: delete the pod
Jun 14 12:42:10.399: INFO: Waiting for pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c to disappear
Jun 14 12:42:10.400: INFO: Pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-w659c no longer exists
STEP: Creating a pod to test consume service account namespace
Jun 14 12:42:10.404: INFO: Waiting up to 5m0s for pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4" in namespace "e2e-tests-svcaccounts-hxxng" to be "success or failure"
Jun 14 12:42:10.406: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.620835ms
Jun 14 12:42:12.412: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007702708s
Jun 14 12:42:14.414: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010247373s
STEP: Saw pod success
Jun 14 12:42:14.414: INFO: Pod "pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4" satisfied condition "success or failure"
Jun 14 12:42:14.416: INFO: Trying to get logs from node 192.168.0.235 pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4 container namespace-test: <nil>
STEP: delete the pod
Jun 14 12:42:14.434: INFO: Waiting for pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4 to disappear
Jun 14 12:42:14.435: INFO: Pod pod-service-account-cee1c61c-8ea1-11e9-82a6-0255ac100014-rkhs4 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:42:14.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-hxxng" for this suite.
Jun 14 12:42:20.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:42:20.472: INFO: namespace: e2e-tests-svcaccounts-hxxng, resource: bindings, ignored listing per whitelist
Jun 14 12:42:20.495: INFO: namespace e2e-tests-svcaccounts-hxxng deletion completed in 6.05755771s

• [SLOW TEST:18.728 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:42:20.495: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 14 12:42:20.553: INFO: Waiting up to 5m0s for pod "downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-p6ffb" to be "success or failure"
Jun 14 12:42:20.555: INFO: Pod "downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.588969ms
Jun 14 12:42:22.560: INFO: Pod "downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007549195s
Jun 14 12:42:24.564: INFO: Pod "downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010581426s
STEP: Saw pod success
Jun 14 12:42:24.564: INFO: Pod "downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:42:24.566: INFO: Trying to get logs from node 192.168.0.19 pod downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 12:42:24.610: INFO: Waiting for pod downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014 to disappear
Jun 14 12:42:24.612: INFO: Pod downward-api-d9bc7b72-8ea1-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:42:24.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p6ffb" for this suite.
Jun 14 12:42:30.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:42:30.648: INFO: namespace: e2e-tests-downward-api-p6ffb, resource: bindings, ignored listing per whitelist
Jun 14 12:42:30.683: INFO: namespace e2e-tests-downward-api-p6ffb deletion completed in 6.061743524s

• [SLOW TEST:10.188 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:42:30.683: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0614 12:43:10.782637      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 14 12:43:10.782: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:43:10.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6stnq" for this suite.
Jun 14 12:43:16.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:43:16.810: INFO: namespace: e2e-tests-gc-6stnq, resource: bindings, ignored listing per whitelist
Jun 14 12:43:16.848: INFO: namespace e2e-tests-gc-6stnq deletion completed in 6.06384541s

• [SLOW TEST:46.165 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:43:16.848: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0614 12:43:47.425605      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 14 12:43:47.425: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:43:47.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zh884" for this suite.
Jun 14 12:43:53.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:43:53.468: INFO: namespace: e2e-tests-gc-zh884, resource: bindings, ignored listing per whitelist
Jun 14 12:43:53.485: INFO: namespace e2e-tests-gc-zh884 deletion completed in 6.057832257s

• [SLOW TEST:36.637 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:43:53.485: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jun 14 12:43:53.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-sn7v4'
Jun 14 12:43:53.795: INFO: stderr: ""
Jun 14 12:43:53.795: INFO: stdout: "pod/pause created\n"
Jun 14 12:43:53.795: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jun 14 12:43:53.795: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-sn7v4" to be "running and ready"
Jun 14 12:43:53.798: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.512796ms
Jun 14 12:43:55.801: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005903331s
Jun 14 12:43:57.806: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.011596796s
Jun 14 12:43:57.806: INFO: Pod "pause" satisfied condition "running and ready"
Jun 14 12:43:57.807: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jun 14 12:43:57.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-sn7v4'
Jun 14 12:43:57.871: INFO: stderr: ""
Jun 14 12:43:57.871: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jun 14 12:43:57.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pod pause -L testing-label --namespace=e2e-tests-kubectl-sn7v4'
Jun 14 12:43:57.919: INFO: stderr: ""
Jun 14 12:43:57.919: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jun 14 12:43:57.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 label pods pause testing-label- --namespace=e2e-tests-kubectl-sn7v4'
Jun 14 12:43:57.976: INFO: stderr: ""
Jun 14 12:43:57.976: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jun 14 12:43:57.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pod pause -L testing-label --namespace=e2e-tests-kubectl-sn7v4'
Jun 14 12:43:58.025: INFO: stderr: ""
Jun 14 12:43:58.025: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jun 14 12:43:58.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sn7v4'
Jun 14 12:43:58.080: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 12:43:58.080: INFO: stdout: "pod \"pause\" force deleted\n"
Jun 14 12:43:58.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-sn7v4'
Jun 14 12:43:58.133: INFO: stderr: "No resources found.\n"
Jun 14 12:43:58.133: INFO: stdout: ""
Jun 14 12:43:58.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -l name=pause --namespace=e2e-tests-kubectl-sn7v4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 14 12:43:58.182: INFO: stderr: ""
Jun 14 12:43:58.182: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:43:58.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sn7v4" for this suite.
Jun 14 12:44:04.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:44:04.211: INFO: namespace: e2e-tests-kubectl-sn7v4, resource: bindings, ignored listing per whitelist
Jun 14 12:44:04.243: INFO: namespace e2e-tests-kubectl-sn7v4 deletion completed in 6.058493403s

• [SLOW TEST:10.759 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:44:04.243: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 14 12:44:04.296: INFO: Waiting up to 5m0s for pod "pod-17939832-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-njltj" to be "success or failure"
Jun 14 12:44:04.297: INFO: Pod "pod-17939832-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.650042ms
Jun 14 12:44:06.299: INFO: Pod "pod-17939832-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003851418s
Jun 14 12:44:08.305: INFO: Pod "pod-17939832-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009724327s
STEP: Saw pod success
Jun 14 12:44:08.305: INFO: Pod "pod-17939832-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:44:08.307: INFO: Trying to get logs from node 192.168.0.235 pod pod-17939832-8ea2-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:44:08.320: INFO: Waiting for pod pod-17939832-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:44:08.321: INFO: Pod pod-17939832-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:44:08.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-njltj" for this suite.
Jun 14 12:44:14.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:44:14.345: INFO: namespace: e2e-tests-emptydir-njltj, resource: bindings, ignored listing per whitelist
Jun 14 12:44:14.379: INFO: namespace e2e-tests-emptydir-njltj deletion completed in 6.055988086s

• [SLOW TEST:10.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:44:14.379: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:44:14.430: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:44:18.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-l2bhr" for this suite.
Jun 14 12:45:08.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:45:08.518: INFO: namespace: e2e-tests-pods-l2bhr, resource: bindings, ignored listing per whitelist
Jun 14 12:45:08.564: INFO: namespace e2e-tests-pods-l2bhr deletion completed in 50.057053509s

• [SLOW TEST:54.185 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:45:08.564: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014
Jun 14 12:45:08.620: INFO: Pod name my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014: Found 0 pods out of 1
Jun 14 12:45:13.622: INFO: Pod name my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014: Found 1 pods out of 1
Jun 14 12:45:13.622: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014" are running
Jun 14 12:45:13.624: INFO: Pod "my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014-f82fn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:45:08 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:45:10 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:45:10 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:45:08 +0000 UTC Reason: Message:}])
Jun 14 12:45:13.624: INFO: Trying to dial the pod
Jun 14 12:45:18.637: INFO: Controller my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014: Got expected result from replica 1 [my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014-f82fn]: "my-hostname-basic-3dea73c5-8ea2-11e9-82a6-0255ac100014-f82fn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:45:18.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-wcxgh" for this suite.
Jun 14 12:45:24.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:45:24.694: INFO: namespace: e2e-tests-replication-controller-wcxgh, resource: bindings, ignored listing per whitelist
Jun 14 12:45:24.696: INFO: namespace e2e-tests-replication-controller-wcxgh deletion completed in 6.057014251s

• [SLOW TEST:16.132 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:45:24.696: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jun 14 12:45:33.773: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:45:34.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-q259b" for this suite.
Jun 14 12:45:56.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:45:56.839: INFO: namespace: e2e-tests-replicaset-q259b, resource: bindings, ignored listing per whitelist
Jun 14 12:45:56.849: INFO: namespace e2e-tests-replicaset-q259b deletion completed in 22.064613085s

• [SLOW TEST:32.153 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:45:56.850: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jun 14 12:45:56.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-f7vn5'
Jun 14 12:45:57.026: INFO: stderr: ""
Jun 14 12:45:57.026: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 14 12:45:58.028: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:45:58.028: INFO: Found 0 / 1
Jun 14 12:45:59.028: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:45:59.028: INFO: Found 0 / 1
Jun 14 12:46:00.029: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:46:00.029: INFO: Found 1 / 1
Jun 14 12:46:00.029: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jun 14 12:46:00.031: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:46:00.031: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 14 12:46:00.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 patch pod redis-master-f8t7h --namespace=e2e-tests-kubectl-f7vn5 -p {"metadata":{"annotations":{"x":"y"}}}'
Jun 14 12:46:00.091: INFO: stderr: ""
Jun 14 12:46:00.091: INFO: stdout: "pod/redis-master-f8t7h patched\n"
STEP: checking annotations
Jun 14 12:46:00.093: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 12:46:00.093: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:46:00.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f7vn5" for this suite.
Jun 14 12:46:22.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:46:22.131: INFO: namespace: e2e-tests-kubectl-f7vn5, resource: bindings, ignored listing per whitelist
Jun 14 12:46:22.150: INFO: namespace e2e-tests-kubectl-f7vn5 deletion completed in 22.055863348s

• [SLOW TEST:25.301 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:46:22.151: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:46:22.201: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-lzkrw" to be "success or failure"
Jun 14 12:46:22.203: INFO: Pod "downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.510919ms
Jun 14 12:46:24.208: INFO: Pod "downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006922174s
Jun 14 12:46:26.210: INFO: Pod "downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009215481s
STEP: Saw pod success
Jun 14 12:46:26.210: INFO: Pod "downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:46:26.212: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:46:26.225: INFO: Waiting for pod downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:46:26.227: INFO: Pod downwardapi-volume-69c64746-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:46:26.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lzkrw" for this suite.
Jun 14 12:46:32.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:46:32.241: INFO: namespace: e2e-tests-downward-api-lzkrw, resource: bindings, ignored listing per whitelist
Jun 14 12:46:32.327: INFO: namespace e2e-tests-downward-api-lzkrw deletion completed in 6.098165934s

• [SLOW TEST:10.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:46:32.328: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-6fd7864e-8ea2-11e9-82a6-0255ac100014
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:46:36.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6kfx2" for this suite.
Jun 14 12:46:58.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:46:58.439: INFO: namespace: e2e-tests-configmap-6kfx2, resource: bindings, ignored listing per whitelist
Jun 14 12:46:58.457: INFO: namespace e2e-tests-configmap-6kfx2 deletion completed in 22.057933823s

• [SLOW TEST:26.130 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:46:58.457: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:46:58.507: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jun 14 12:47:03.510: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 14 12:47:03.510: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 14 12:47:03.521: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-xnbh7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xnbh7/deployments/test-cleanup-deployment,UID:827b4dd5-8ea2-11e9-a0dc-fa163eff1b62,ResourceVersion:44014,Generation:1,CreationTimestamp:2019-06-14 12:47:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jun 14 12:47:03.523: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:47:03.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xnbh7" for this suite.
Jun 14 12:47:09.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:47:09.589: INFO: namespace: e2e-tests-deployment-xnbh7, resource: bindings, ignored listing per whitelist
Jun 14 12:47:09.593: INFO: namespace e2e-tests-deployment-xnbh7 deletion completed in 6.063078247s

• [SLOW TEST:11.136 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:47:09.594: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:47:09.641: INFO: Creating ReplicaSet my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014
Jun 14 12:47:09.650: INFO: Pod name my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014: Found 0 pods out of 1
Jun 14 12:47:14.652: INFO: Pod name my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014: Found 1 pods out of 1
Jun 14 12:47:14.653: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014" is running
Jun 14 12:47:14.654: INFO: Pod "my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014-97659" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:47:09 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:47:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:47:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-14 12:47:09 +0000 UTC Reason: Message:}])
Jun 14 12:47:14.654: INFO: Trying to dial the pod
Jun 14 12:47:19.670: INFO: Controller my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014: Got expected result from replica 1 [my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014-97659]: "my-hostname-basic-860ddf12-8ea2-11e9-82a6-0255ac100014-97659", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:47:19.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-fqjk6" for this suite.
Jun 14 12:47:25.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:47:25.714: INFO: namespace: e2e-tests-replicaset-fqjk6, resource: bindings, ignored listing per whitelist
Jun 14 12:47:25.733: INFO: namespace e2e-tests-replicaset-fqjk6 deletion completed in 6.060603113s

• [SLOW TEST:16.139 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:47:25.733: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 14 12:47:28.306: INFO: Successfully updated pod "labelsupdate8fabf67f-8ea2-11e9-82a6-0255ac100014"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:47:30.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nl9j2" for this suite.
Jun 14 12:47:52.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:47:52.345: INFO: namespace: e2e-tests-downward-api-nl9j2, resource: bindings, ignored listing per whitelist
Jun 14 12:47:52.390: INFO: namespace e2e-tests-downward-api-nl9j2 deletion completed in 22.0674281s

• [SLOW TEST:26.657 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:47:52.390: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 14 12:47:52.450: INFO: Waiting up to 5m0s for pod "downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-rxw7c" to be "success or failure"
Jun 14 12:47:52.452: INFO: Pod "downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.841972ms
Jun 14 12:47:54.454: INFO: Pod "downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004435597s
Jun 14 12:47:56.457: INFO: Pod "downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006820367s
STEP: Saw pod success
Jun 14 12:47:56.457: INFO: Pod "downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:47:56.458: INFO: Trying to get logs from node 192.168.0.235 pod downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 12:47:56.479: INFO: Waiting for pod downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:47:56.480: INFO: Pod downward-api-9f90c4bb-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:47:56.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rxw7c" for this suite.
Jun 14 12:48:02.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:48:02.527: INFO: namespace: e2e-tests-downward-api-rxw7c, resource: bindings, ignored listing per whitelist
Jun 14 12:48:02.551: INFO: namespace e2e-tests-downward-api-rxw7c deletion completed in 6.068955542s

• [SLOW TEST:10.161 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:48:02.551: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jun 14 12:48:02.605: INFO: Waiting up to 5m0s for pod "pod-a59eb7e9-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-tfp95" to be "success or failure"
Jun 14 12:48:02.607: INFO: Pod "pod-a59eb7e9-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.67101ms
Jun 14 12:48:04.610: INFO: Pod "pod-a59eb7e9-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004208569s
STEP: Saw pod success
Jun 14 12:48:04.610: INFO: Pod "pod-a59eb7e9-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:48:04.611: INFO: Trying to get logs from node 192.168.0.235 pod pod-a59eb7e9-8ea2-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:48:04.624: INFO: Waiting for pod pod-a59eb7e9-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:48:04.625: INFO: Pod pod-a59eb7e9-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:48:04.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tfp95" for this suite.
Jun 14 12:48:10.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:48:10.653: INFO: namespace: e2e-tests-emptydir-tfp95, resource: bindings, ignored listing per whitelist
Jun 14 12:48:10.686: INFO: namespace e2e-tests-emptydir-tfp95 deletion completed in 6.058805822s

• [SLOW TEST:8.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:48:10.686: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:48:10.750: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aa786fde-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-42qpm" to be "success or failure"
Jun 14 12:48:10.753: INFO: Pod "downwardapi-volume-aa786fde-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.438365ms
Jun 14 12:48:12.759: INFO: Pod "downwardapi-volume-aa786fde-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009023799s
STEP: Saw pod success
Jun 14 12:48:12.759: INFO: Pod "downwardapi-volume-aa786fde-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:48:12.760: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-aa786fde-8ea2-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:48:12.778: INFO: Waiting for pod downwardapi-volume-aa786fde-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:48:12.779: INFO: Pod downwardapi-volume-aa786fde-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:48:12.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-42qpm" for this suite.
Jun 14 12:48:18.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:48:18.812: INFO: namespace: e2e-tests-projected-42qpm, resource: bindings, ignored listing per whitelist
Jun 14 12:48:18.837: INFO: namespace e2e-tests-projected-42qpm deletion completed in 6.056089744s

• [SLOW TEST:8.151 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:48:18.837: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:48:18.893: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af53969c-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-hnpwj" to be "success or failure"
Jun 14 12:48:18.894: INFO: Pod "downwardapi-volume-af53969c-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.584982ms
Jun 14 12:48:20.897: INFO: Pod "downwardapi-volume-af53969c-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003801962s
STEP: Saw pod success
Jun 14 12:48:20.897: INFO: Pod "downwardapi-volume-af53969c-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:48:20.898: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-af53969c-8ea2-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:48:20.914: INFO: Waiting for pod downwardapi-volume-af53969c-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:48:20.915: INFO: Pod downwardapi-volume-af53969c-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:48:20.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hnpwj" for this suite.
Jun 14 12:48:26.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:48:26.975: INFO: namespace: e2e-tests-downward-api-hnpwj, resource: bindings, ignored listing per whitelist
Jun 14 12:48:26.978: INFO: namespace e2e-tests-downward-api-hnpwj deletion completed in 6.060569493s

• [SLOW TEST:8.141 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:48:26.978: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jun 14 12:48:27.035: INFO: Waiting up to 5m0s for pod "client-containers-b42d7faa-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-containers-f7mth" to be "success or failure"
Jun 14 12:48:27.037: INFO: Pod "client-containers-b42d7faa-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.571555ms
Jun 14 12:48:29.039: INFO: Pod "client-containers-b42d7faa-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003881112s
STEP: Saw pod success
Jun 14 12:48:29.039: INFO: Pod "client-containers-b42d7faa-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:48:29.041: INFO: Trying to get logs from node 192.168.0.235 pod client-containers-b42d7faa-8ea2-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:48:29.052: INFO: Waiting for pod client-containers-b42d7faa-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:48:29.053: INFO: Pod client-containers-b42d7faa-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:48:29.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-f7mth" for this suite.
Jun 14 12:48:35.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:48:35.075: INFO: namespace: e2e-tests-containers-f7mth, resource: bindings, ignored listing per whitelist
Jun 14 12:48:35.111: INFO: namespace e2e-tests-containers-f7mth deletion completed in 6.056210699s

• [SLOW TEST:8.134 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:48:35.112: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b90675b0-8ea2-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:48:35.167: INFO: Waiting up to 5m0s for pod "pod-configmaps-b9073ae4-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-ntw8k" to be "success or failure"
Jun 14 12:48:35.169: INFO: Pod "pod-configmaps-b9073ae4-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.626746ms
Jun 14 12:48:37.171: INFO: Pod "pod-configmaps-b9073ae4-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003898063s
STEP: Saw pod success
Jun 14 12:48:37.171: INFO: Pod "pod-configmaps-b9073ae4-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:48:37.173: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-b9073ae4-8ea2-11e9-82a6-0255ac100014 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:48:37.203: INFO: Waiting for pod pod-configmaps-b9073ae4-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:48:37.205: INFO: Pod pod-configmaps-b9073ae4-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:48:37.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ntw8k" for this suite.
Jun 14 12:48:43.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:48:43.232: INFO: namespace: e2e-tests-configmap-ntw8k, resource: bindings, ignored listing per whitelist
Jun 14 12:48:43.270: INFO: namespace e2e-tests-configmap-ntw8k deletion completed in 6.062960844s

• [SLOW TEST:8.158 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:48:43.270: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 14 12:48:45.833: INFO: Successfully updated pod "pod-update-activedeadlineseconds-bde352a6-8ea2-11e9-82a6-0255ac100014"
Jun 14 12:48:45.833: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-bde352a6-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-pods-j8s8h" to be "terminated due to deadline exceeded"
Jun 14 12:48:45.835: INFO: Pod "pod-update-activedeadlineseconds-bde352a6-8ea2-11e9-82a6-0255ac100014": Phase="Running", Reason="", readiness=true. Elapsed: 1.603586ms
Jun 14 12:48:47.837: INFO: Pod "pod-update-activedeadlineseconds-bde352a6-8ea2-11e9-82a6-0255ac100014": Phase="Running", Reason="", readiness=true. Elapsed: 2.003956964s
Jun 14 12:48:49.839: INFO: Pod "pod-update-activedeadlineseconds-bde352a6-8ea2-11e9-82a6-0255ac100014": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.006409868s
Jun 14 12:48:49.839: INFO: Pod "pod-update-activedeadlineseconds-bde352a6-8ea2-11e9-82a6-0255ac100014" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:48:49.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j8s8h" for this suite.
Jun 14 12:48:55.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:48:55.855: INFO: namespace: e2e-tests-pods-j8s8h, resource: bindings, ignored listing per whitelist
Jun 14 12:48:55.897: INFO: namespace e2e-tests-pods-j8s8h deletion completed in 6.055650566s

• [SLOW TEST:12.627 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:48:55.897: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-lmrhw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-lmrhw
STEP: Deleting pre-stop pod
Jun 14 12:49:12.994: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:49:13.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-lmrhw" for this suite.
Jun 14 12:49:51.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:49:51.020: INFO: namespace: e2e-tests-prestop-lmrhw, resource: bindings, ignored listing per whitelist
Jun 14 12:49:51.067: INFO: namespace e2e-tests-prestop-lmrhw deletion completed in 38.064453713s

• [SLOW TEST:55.169 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:49:51.067: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jun 14 12:49:51.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 --namespace=e2e-tests-kubectl-75ndf run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jun 14 12:49:53.662: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jun 14 12:49:53.662: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:49:55.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-75ndf" for this suite.
Jun 14 12:50:07.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:50:07.708: INFO: namespace: e2e-tests-kubectl-75ndf, resource: bindings, ignored listing per whitelist
Jun 14 12:50:07.731: INFO: namespace e2e-tests-kubectl-75ndf deletion completed in 12.062920931s

• [SLOW TEST:16.664 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:50:07.731: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:50:07.786: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f03b82f7-8ea2-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-2bvgf" to be "success or failure"
Jun 14 12:50:07.788: INFO: Pod "downwardapi-volume-f03b82f7-8ea2-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.983135ms
Jun 14 12:50:09.791: INFO: Pod "downwardapi-volume-f03b82f7-8ea2-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004539509s
STEP: Saw pod success
Jun 14 12:50:09.791: INFO: Pod "downwardapi-volume-f03b82f7-8ea2-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:50:09.792: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-f03b82f7-8ea2-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:50:09.833: INFO: Waiting for pod downwardapi-volume-f03b82f7-8ea2-11e9-82a6-0255ac100014 to disappear
Jun 14 12:50:09.834: INFO: Pod downwardapi-volume-f03b82f7-8ea2-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:50:09.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2bvgf" for this suite.
Jun 14 12:50:15.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:50:15.861: INFO: namespace: e2e-tests-projected-2bvgf, resource: bindings, ignored listing per whitelist
Jun 14 12:50:15.896: INFO: namespace e2e-tests-projected-2bvgf deletion completed in 6.059279834s

• [SLOW TEST:8.165 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:50:15.896: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 14 12:50:15.955: INFO: Number of nodes with available pods: 0
Jun 14 12:50:15.955: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:50:16.960: INFO: Number of nodes with available pods: 0
Jun 14 12:50:16.960: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 12:50:17.959: INFO: Number of nodes with available pods: 2
Jun 14 12:50:17.959: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jun 14 12:50:17.970: INFO: Number of nodes with available pods: 2
Jun 14 12:50:17.970: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-jc469, will wait for the garbage collector to delete the pods
Jun 14 12:50:19.045: INFO: Deleting DaemonSet.extensions daemon-set took: 16.543029ms
Jun 14 12:50:19.146: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.138201ms
Jun 14 12:52:06.755: INFO: Number of nodes with available pods: 0
Jun 14 12:52:06.755: INFO: Number of running nodes: 0, number of available pods: 0
Jun 14 12:52:06.757: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jc469/daemonsets","resourceVersion":"45198"},"items":null}

Jun 14 12:52:06.758: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jc469/pods","resourceVersion":"45198"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:52:06.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jc469" for this suite.
Jun 14 12:52:12.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:52:12.800: INFO: namespace: e2e-tests-daemonsets-jc469, resource: bindings, ignored listing per whitelist
Jun 14 12:52:12.824: INFO: namespace e2e-tests-daemonsets-jc469 deletion completed in 6.059719068s

• [SLOW TEST:116.929 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:52:12.824: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3acad4b7-8ea3-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 12:52:12.877: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-44c2f" to be "success or failure"
Jun 14 12:52:12.878: INFO: Pod "pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.501959ms
Jun 14 12:52:14.881: INFO: Pod "pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004128106s
Jun 14 12:52:16.887: INFO: Pod "pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010114756s
STEP: Saw pod success
Jun 14 12:52:16.887: INFO: Pod "pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:52:16.889: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 14 12:52:16.901: INFO: Waiting for pod pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014 to disappear
Jun 14 12:52:16.903: INFO: Pod pod-projected-secrets-3acb6f3d-8ea3-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:52:16.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-44c2f" for this suite.
Jun 14 12:52:22.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:52:22.956: INFO: namespace: e2e-tests-projected-44c2f, resource: bindings, ignored listing per whitelist
Jun 14 12:52:22.961: INFO: namespace e2e-tests-projected-44c2f deletion completed in 6.056596932s

• [SLOW TEST:10.137 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:52:22.961: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:52:23.009: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:52:27.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ffs56" for this suite.
Jun 14 12:53:07.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:53:07.051: INFO: namespace: e2e-tests-pods-ffs56, resource: bindings, ignored listing per whitelist
Jun 14 12:53:07.093: INFO: namespace e2e-tests-pods-ffs56 deletion completed in 40.056290467s

• [SLOW TEST:44.132 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:53:07.093: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:53:07.150: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jun 14 12:53:12.157: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 14 12:53:12.157: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jun 14 12:53:14.159: INFO: Creating deployment "test-rollover-deployment"
Jun 14 12:53:14.165: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jun 14 12:53:16.169: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jun 14 12:53:16.173: INFO: Ensure that both replica sets have 1 created replica
Jun 14 12:53:16.176: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jun 14 12:53:16.181: INFO: Updating deployment test-rollover-deployment
Jun 14 12:53:16.181: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jun 14 12:53:18.186: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jun 14 12:53:18.190: INFO: Make sure deployment "test-rollover-deployment" is complete
Jun 14 12:53:18.194: INFO: all replica sets need to contain the pod-template-hash label
Jun 14 12:53:18.194: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113596, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 12:53:20.198: INFO: all replica sets need to contain the pod-template-hash label
Jun 14 12:53:20.198: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113598, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 12:53:22.201: INFO: all replica sets need to contain the pod-template-hash label
Jun 14 12:53:22.202: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113598, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 12:53:24.199: INFO: all replica sets need to contain the pod-template-hash label
Jun 14 12:53:24.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113598, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 12:53:26.199: INFO: all replica sets need to contain the pod-template-hash label
Jun 14 12:53:26.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113598, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 12:53:28.198: INFO: all replica sets need to contain the pod-template-hash label
Jun 14 12:53:28.198: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113598, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696113594, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 12:53:30.199: INFO: 
Jun 14 12:53:30.199: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 14 12:53:30.204: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-fkj5b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fkj5b/deployments/test-rollover-deployment,UID:5f67ccc6-8ea3-11e9-a0dc-fa163eff1b62,ResourceVersion:45538,Generation:2,CreationTimestamp:2019-06-14 12:53:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-14 12:53:14 +0000 UTC 2019-06-14 12:53:14 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-14 12:53:28 +0000 UTC 2019-06-14 12:53:14 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun 14 12:53:30.206: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-fkj5b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fkj5b/replicasets/test-rollover-deployment-6b7f9d6597,UID:607fbf6b-8ea3-11e9-8a76-fa163e95400d,ResourceVersion:45531,Generation:2,CreationTimestamp:2019-06-14 12:53:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f67ccc6-8ea3-11e9-a0dc-fa163eff1b62 0xc0021d0a47 0xc0021d0a48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 14 12:53:30.207: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jun 14 12:53:30.207: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-fkj5b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fkj5b/replicasets/test-rollover-controller,UID:5b3958b7-8ea3-11e9-a0dc-fa163eff1b62,ResourceVersion:45537,Generation:2,CreationTimestamp:2019-06-14 12:53:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f67ccc6-8ea3-11e9-a0dc-fa163eff1b62 0xc0021d0847 0xc0021d0848}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 14 12:53:30.207: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-fkj5b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fkj5b/replicasets/test-rollover-deployment-6586df867b,UID:5f4d9a19-8ea3-11e9-8a76-fa163e95400d,ResourceVersion:45486,Generation:2,CreationTimestamp:2019-06-14 12:53:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5f67ccc6-8ea3-11e9-a0dc-fa163eff1b62 0xc0021d0907 0xc0021d0908}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 14 12:53:30.209: INFO: Pod "test-rollover-deployment-6b7f9d6597-brphr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-brphr,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-fkj5b,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fkj5b/pods/test-rollover-deployment-6b7f9d6597-brphr,UID:6083cd98-8ea3-11e9-8a76-fa163e95400d,ResourceVersion:45498,Generation:0,CreationTimestamp:2019-06-14 12:53:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 607fbf6b-8ea3-11e9-8a76-fa163e95400d 0xc0021d1f27 0xc0021d1f28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fcc8j {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fcc8j,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fcc8j true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021d1fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021d1fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc000fa0dd0} {timeout 0xc000fa0de0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:53:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:53:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:53:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 12:53:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.19,PodIP:172.16.0.30,StartTime:2019-06-14 12:53:16 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-14 12:53:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://780cac771715dd375e4590bce33f25cf6cbe240df27d151d38fa265beb806920}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:53:30.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fkj5b" for this suite.
Jun 14 12:53:36.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:53:36.256: INFO: namespace: e2e-tests-deployment-fkj5b, resource: bindings, ignored listing per whitelist
Jun 14 12:53:36.267: INFO: namespace e2e-tests-deployment-fkj5b deletion completed in 6.056889979s

• [SLOW TEST:29.174 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:53:36.267: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jun 14 12:53:36.319: INFO: Waiting up to 5m0s for pod "client-containers-6c876438-8ea3-11e9-82a6-0255ac100014" in namespace "e2e-tests-containers-c7pg5" to be "success or failure"
Jun 14 12:53:36.320: INFO: Pod "client-containers-6c876438-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.762943ms
Jun 14 12:53:38.322: INFO: Pod "client-containers-6c876438-8ea3-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003775199s
STEP: Saw pod success
Jun 14 12:53:38.322: INFO: Pod "client-containers-6c876438-8ea3-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:53:38.324: INFO: Trying to get logs from node 192.168.0.235 pod client-containers-6c876438-8ea3-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:53:38.338: INFO: Waiting for pod client-containers-6c876438-8ea3-11e9-82a6-0255ac100014 to disappear
Jun 14 12:53:38.339: INFO: Pod client-containers-6c876438-8ea3-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:53:38.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-c7pg5" for this suite.
Jun 14 12:53:44.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:53:44.374: INFO: namespace: e2e-tests-containers-c7pg5, resource: bindings, ignored listing per whitelist
Jun 14 12:53:44.398: INFO: namespace e2e-tests-containers-c7pg5 deletion completed in 6.057092367s

• [SLOW TEST:8.131 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:53:44.398: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jun 14 12:53:44.961: INFO: created pod pod-service-account-defaultsa
Jun 14 12:53:44.961: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jun 14 12:53:44.964: INFO: created pod pod-service-account-mountsa
Jun 14 12:53:44.964: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jun 14 12:53:44.969: INFO: created pod pod-service-account-nomountsa
Jun 14 12:53:44.969: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jun 14 12:53:44.973: INFO: created pod pod-service-account-defaultsa-mountspec
Jun 14 12:53:44.973: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jun 14 12:53:44.980: INFO: created pod pod-service-account-mountsa-mountspec
Jun 14 12:53:44.980: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jun 14 12:53:44.988: INFO: created pod pod-service-account-nomountsa-mountspec
Jun 14 12:53:44.988: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jun 14 12:53:44.996: INFO: created pod pod-service-account-defaultsa-nomountspec
Jun 14 12:53:44.996: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jun 14 12:53:45.004: INFO: created pod pod-service-account-mountsa-nomountspec
Jun 14 12:53:45.004: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jun 14 12:53:45.019: INFO: created pod pod-service-account-nomountsa-nomountspec
Jun 14 12:53:45.019: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:53:45.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-5mscb" for this suite.
Jun 14 12:53:51.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:53:51.071: INFO: namespace: e2e-tests-svcaccounts-5mscb, resource: bindings, ignored listing per whitelist
Jun 14 12:53:51.084: INFO: namespace e2e-tests-svcaccounts-5mscb deletion completed in 6.060065009s

• [SLOW TEST:6.686 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:53:51.084: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0614 12:53:52.162865      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 14 12:53:52.162: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:53:52.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-m2kv8" for this suite.
Jun 14 12:53:58.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:53:58.239: INFO: namespace: e2e-tests-gc-m2kv8, resource: bindings, ignored listing per whitelist
Jun 14 12:53:58.242: INFO: namespace e2e-tests-gc-m2kv8 deletion completed in 6.077742106s

• [SLOW TEST:7.158 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:53:58.242: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-79a00f7c-8ea3-11e9-82a6-0255ac100014
STEP: Creating configMap with name cm-test-opt-upd-79a00fb8-8ea3-11e9-82a6-0255ac100014
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-79a00f7c-8ea3-11e9-82a6-0255ac100014
STEP: Updating configmap cm-test-opt-upd-79a00fb8-8ea3-11e9-82a6-0255ac100014
STEP: Creating configMap with name cm-test-opt-create-79a00fc8-8ea3-11e9-82a6-0255ac100014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:55:22.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bmn9v" for this suite.
Jun 14 12:55:44.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:55:44.651: INFO: namespace: e2e-tests-projected-bmn9v, resource: bindings, ignored listing per whitelist
Jun 14 12:55:44.684: INFO: namespace e2e-tests-projected-bmn9v deletion completed in 22.061742518s

• [SLOW TEST:106.442 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:55:44.684: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b9127ac5-8ea3-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:55:44.739: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b9131333-8ea3-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-bn6xj" to be "success or failure"
Jun 14 12:55:44.741: INFO: Pod "pod-projected-configmaps-b9131333-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.385014ms
Jun 14 12:55:46.746: INFO: Pod "pod-projected-configmaps-b9131333-8ea3-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006915676s
STEP: Saw pod success
Jun 14 12:55:46.746: INFO: Pod "pod-projected-configmaps-b9131333-8ea3-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:55:46.748: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-configmaps-b9131333-8ea3-11e9-82a6-0255ac100014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:55:46.760: INFO: Waiting for pod pod-projected-configmaps-b9131333-8ea3-11e9-82a6-0255ac100014 to disappear
Jun 14 12:55:46.762: INFO: Pod pod-projected-configmaps-b9131333-8ea3-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:55:46.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bn6xj" for this suite.
Jun 14 12:55:52.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:55:52.815: INFO: namespace: e2e-tests-projected-bn6xj, resource: bindings, ignored listing per whitelist
Jun 14 12:55:52.819: INFO: namespace e2e-tests-projected-bn6xj deletion completed in 6.055494294s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:55:52.819: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-bdeb2e1a-8ea3-11e9-82a6-0255ac100014
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-bdeb2e1a-8ea3-11e9-82a6-0255ac100014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:55:56.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9h4wq" for this suite.
Jun 14 12:56:18.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:56:18.935: INFO: namespace: e2e-tests-configmap-9h4wq, resource: bindings, ignored listing per whitelist
Jun 14 12:56:18.960: INFO: namespace e2e-tests-configmap-9h4wq deletion completed in 22.059589536s

• [SLOW TEST:26.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:56:18.960: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-cd80beda-8ea3-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:56:19.016: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-bmx88" to be "success or failure"
Jun 14 12:56:19.018: INFO: Pod "pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.96699ms
Jun 14 12:56:21.029: INFO: Pod "pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012342158s
Jun 14 12:56:23.032: INFO: Pod "pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015087848s
STEP: Saw pod success
Jun 14 12:56:23.032: INFO: Pod "pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:56:23.033: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:56:23.047: INFO: Waiting for pod pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014 to disappear
Jun 14 12:56:23.049: INFO: Pod pod-projected-configmaps-cd815cb1-8ea3-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:56:23.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bmx88" for this suite.
Jun 14 12:56:29.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:56:29.083: INFO: namespace: e2e-tests-projected-bmx88, resource: bindings, ignored listing per whitelist
Jun 14 12:56:29.113: INFO: namespace e2e-tests-projected-bmx88 deletion completed in 6.062380493s

• [SLOW TEST:10.153 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:56:29.113: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-dlc59/configmap-test-d38d15a6-8ea3-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:56:29.164: INFO: Waiting up to 5m0s for pod "pod-configmaps-d38db65c-8ea3-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-dlc59" to be "success or failure"
Jun 14 12:56:29.166: INFO: Pod "pod-configmaps-d38db65c-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.749294ms
Jun 14 12:56:31.168: INFO: Pod "pod-configmaps-d38db65c-8ea3-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004118507s
STEP: Saw pod success
Jun 14 12:56:31.168: INFO: Pod "pod-configmaps-d38db65c-8ea3-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:56:31.170: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-d38db65c-8ea3-11e9-82a6-0255ac100014 container env-test: <nil>
STEP: delete the pod
Jun 14 12:56:31.226: INFO: Waiting for pod pod-configmaps-d38db65c-8ea3-11e9-82a6-0255ac100014 to disappear
Jun 14 12:56:31.227: INFO: Pod pod-configmaps-d38db65c-8ea3-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:56:31.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dlc59" for this suite.
Jun 14 12:56:37.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:56:37.244: INFO: namespace: e2e-tests-configmap-dlc59, resource: bindings, ignored listing per whitelist
Jun 14 12:56:37.289: INFO: namespace e2e-tests-configmap-dlc59 deletion completed in 6.058598843s

• [SLOW TEST:8.176 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:56:37.289: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 14 12:56:39.859: INFO: Successfully updated pod "pod-update-d86c6efb-8ea3-11e9-82a6-0255ac100014"
STEP: verifying the updated pod is in kubernetes
Jun 14 12:56:39.864: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:56:39.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8g5vj" for this suite.
Jun 14 12:57:01.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:57:01.880: INFO: namespace: e2e-tests-pods-8g5vj, resource: bindings, ignored listing per whitelist
Jun 14 12:57:01.924: INFO: namespace e2e-tests-pods-8g5vj deletion completed in 22.0582457s

• [SLOW TEST:24.635 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:57:01.924: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 14 12:57:01.986: INFO: Waiting up to 5m0s for pod "downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-57k8w" to be "success or failure"
Jun 14 12:57:01.987: INFO: Pod "downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.646685ms
Jun 14 12:57:03.990: INFO: Pod "downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00399987s
Jun 14 12:57:05.992: INFO: Pod "downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006786575s
STEP: Saw pod success
Jun 14 12:57:05.992: INFO: Pod "downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:57:05.994: INFO: Trying to get logs from node 192.168.0.235 pod downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 12:57:06.018: INFO: Waiting for pod downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014 to disappear
Jun 14 12:57:06.022: INFO: Pod downward-api-e71d3fa9-8ea3-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:57:06.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-57k8w" for this suite.
Jun 14 12:57:12.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:57:12.080: INFO: namespace: e2e-tests-downward-api-57k8w, resource: bindings, ignored listing per whitelist
Jun 14 12:57:12.097: INFO: namespace e2e-tests-downward-api-57k8w deletion completed in 6.072317025s

• [SLOW TEST:10.173 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:57:12.097: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jun 14 12:57:12.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k8xb7,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8xb7/configmaps/e2e-watch-test-watch-closed,UID:ed41b91b-8ea3-11e9-a0dc-fa163eff1b62,ResourceVersion:46487,Generation:0,CreationTimestamp:2019-06-14 12:57:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 14 12:57:12.152: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k8xb7,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8xb7/configmaps/e2e-watch-test-watch-closed,UID:ed41b91b-8ea3-11e9-a0dc-fa163eff1b62,ResourceVersion:46488,Generation:0,CreationTimestamp:2019-06-14 12:57:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jun 14 12:57:12.160: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k8xb7,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8xb7/configmaps/e2e-watch-test-watch-closed,UID:ed41b91b-8ea3-11e9-a0dc-fa163eff1b62,ResourceVersion:46489,Generation:0,CreationTimestamp:2019-06-14 12:57:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 14 12:57:12.160: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k8xb7,SelfLink:/api/v1/namespaces/e2e-tests-watch-k8xb7/configmaps/e2e-watch-test-watch-closed,UID:ed41b91b-8ea3-11e9-a0dc-fa163eff1b62,ResourceVersion:46490,Generation:0,CreationTimestamp:2019-06-14 12:57:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:57:12.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-k8xb7" for this suite.
Jun 14 12:57:18.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:57:18.195: INFO: namespace: e2e-tests-watch-k8xb7, resource: bindings, ignored listing per whitelist
Jun 14 12:57:18.220: INFO: namespace e2e-tests-watch-k8xb7 deletion completed in 6.058106297s

• [SLOW TEST:6.123 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:57:18.220: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 12:57:18.275: INFO: (0) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.976348ms)
Jun 14 12:57:18.277: INFO: (1) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.127948ms)
Jun 14 12:57:18.280: INFO: (2) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.269884ms)
Jun 14 12:57:18.282: INFO: (3) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.095117ms)
Jun 14 12:57:18.284: INFO: (4) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.081494ms)
Jun 14 12:57:18.286: INFO: (5) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.100947ms)
Jun 14 12:57:18.288: INFO: (6) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.085832ms)
Jun 14 12:57:18.290: INFO: (7) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.043317ms)
Jun 14 12:57:18.292: INFO: (8) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.974406ms)
Jun 14 12:57:18.294: INFO: (9) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.041269ms)
Jun 14 12:57:18.296: INFO: (10) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.957305ms)
Jun 14 12:57:18.298: INFO: (11) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.996717ms)
Jun 14 12:57:18.300: INFO: (12) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.942354ms)
Jun 14 12:57:18.302: INFO: (13) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.991045ms)
Jun 14 12:57:18.304: INFO: (14) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.990487ms)
Jun 14 12:57:18.306: INFO: (15) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.094576ms)
Jun 14 12:57:18.308: INFO: (16) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.928041ms)
Jun 14 12:57:18.310: INFO: (17) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.00225ms)
Jun 14 12:57:18.312: INFO: (18) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.910621ms)
Jun 14 12:57:18.314: INFO: (19) /api/v1/nodes/192.168.0.19/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.101757ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:57:18.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-4vgv4" for this suite.
Jun 14 12:57:24.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:57:24.347: INFO: namespace: e2e-tests-proxy-4vgv4, resource: bindings, ignored listing per whitelist
Jun 14 12:57:24.372: INFO: namespace e2e-tests-proxy-4vgv4 deletion completed in 6.056038257s

• [SLOW TEST:6.152 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:57:24.372: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-j66xr in namespace e2e-tests-proxy-8cmz6
I0614 12:57:24.438110      18 runners.go:184] Created replication controller with name: proxy-service-j66xr, namespace: e2e-tests-proxy-8cmz6, replica count: 1
I0614 12:57:25.488373      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0614 12:57:26.488530      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0614 12:57:27.488680      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0614 12:57:28.488828      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0614 12:57:29.489011      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0614 12:57:30.489162      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0614 12:57:31.489312      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0614 12:57:32.489477      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0614 12:57:33.489621      18 runners.go:184] proxy-service-j66xr Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 14 12:57:33.495: INFO: setup took 9.076032856s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 6.180573ms)
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 6.084973ms)
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 6.146774ms)
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 6.090338ms)
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.213264ms)
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 6.501344ms)
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 6.503178ms)
Jun 14 12:57:33.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 6.659212ms)
Jun 14 12:57:33.502: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 7.499432ms)
Jun 14 12:57:33.505: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 10.009865ms)
Jun 14 12:57:33.505: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 10.028345ms)
Jun 14 12:57:33.508: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 13.595105ms)
Jun 14 12:57:33.508: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 13.555805ms)
Jun 14 12:57:33.509: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 14.192405ms)
Jun 14 12:57:33.509: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 14.168375ms)
Jun 14 12:57:33.511: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 16.154387ms)
Jun 14 12:57:33.514: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 3.091614ms)
Jun 14 12:57:33.514: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 3.150229ms)
Jun 14 12:57:33.515: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 3.466535ms)
Jun 14 12:57:33.515: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 3.72092ms)
Jun 14 12:57:33.516: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.417292ms)
Jun 14 12:57:33.516: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.668298ms)
Jun 14 12:57:33.516: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 4.548259ms)
Jun 14 12:57:33.516: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.58749ms)
Jun 14 12:57:33.516: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 5.204315ms)
Jun 14 12:57:33.516: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 5.122515ms)
Jun 14 12:57:33.517: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 5.582276ms)
Jun 14 12:57:33.517: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.072781ms)
Jun 14 12:57:33.517: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 6.039835ms)
Jun 14 12:57:33.517: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 5.904328ms)
Jun 14 12:57:33.517: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 6.150158ms)
Jun 14 12:57:33.517: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 5.941097ms)
Jun 14 12:57:33.521: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 3.84081ms)
Jun 14 12:57:33.521: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 3.983796ms)
Jun 14 12:57:33.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.300141ms)
Jun 14 12:57:33.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 4.241408ms)
Jun 14 12:57:33.522: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.471165ms)
Jun 14 12:57:33.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.242807ms)
Jun 14 12:57:33.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.431284ms)
Jun 14 12:57:33.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.479788ms)
Jun 14 12:57:33.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.446994ms)
Jun 14 12:57:33.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.577926ms)
Jun 14 12:57:33.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 5.819845ms)
Jun 14 12:57:33.523: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 5.991431ms)
Jun 14 12:57:33.524: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.79664ms)
Jun 14 12:57:33.524: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 7.167947ms)
Jun 14 12:57:33.525: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 7.411492ms)
Jun 14 12:57:33.525: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 7.859852ms)
Jun 14 12:57:33.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.934211ms)
Jun 14 12:57:33.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.837414ms)
Jun 14 12:57:33.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 5.015148ms)
Jun 14 12:57:33.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.027753ms)
Jun 14 12:57:33.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.183257ms)
Jun 14 12:57:33.530: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 5.132414ms)
Jun 14 12:57:33.531: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.217149ms)
Jun 14 12:57:33.531: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 5.36464ms)
Jun 14 12:57:33.531: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 5.334522ms)
Jun 14 12:57:33.531: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.439905ms)
Jun 14 12:57:33.531: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.323804ms)
Jun 14 12:57:33.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 6.40239ms)
Jun 14 12:57:33.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 7.115034ms)
Jun 14 12:57:33.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 6.962101ms)
Jun 14 12:57:33.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 7.069248ms)
Jun 14 12:57:33.532: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 7.128139ms)
Jun 14 12:57:33.536: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 3.828489ms)
Jun 14 12:57:33.536: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 3.756067ms)
Jun 14 12:57:33.536: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 3.840951ms)
Jun 14 12:57:33.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 5.222631ms)
Jun 14 12:57:33.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 5.101992ms)
Jun 14 12:57:33.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.258027ms)
Jun 14 12:57:33.538: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 5.494157ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.696343ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.534637ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 6.00488ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 6.274644ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 6.3371ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 6.243971ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.147089ms)
Jun 14 12:57:33.539: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 6.275103ms)
Jun 14 12:57:33.540: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 6.706985ms)
Jun 14 12:57:33.542: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 2.090285ms)
Jun 14 12:57:33.543: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 3.01396ms)
Jun 14 12:57:33.543: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 3.607722ms)
Jun 14 12:57:33.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 3.884676ms)
Jun 14 12:57:33.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 4.031026ms)
Jun 14 12:57:33.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.13433ms)
Jun 14 12:57:33.544: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.303904ms)
Jun 14 12:57:33.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 5.052719ms)
Jun 14 12:57:33.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 5.793507ms)
Jun 14 12:57:33.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 5.570013ms)
Jun 14 12:57:33.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 5.695474ms)
Jun 14 12:57:33.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.504576ms)
Jun 14 12:57:33.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 5.773308ms)
Jun 14 12:57:33.545: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 5.551138ms)
Jun 14 12:57:33.546: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.710868ms)
Jun 14 12:57:33.546: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 5.731189ms)
Jun 14 12:57:33.549: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.511623ms)
Jun 14 12:57:33.550: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 4.473521ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.706957ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 4.665342ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 4.808006ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.676912ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.668778ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 4.661594ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.846155ms)
Jun 14 12:57:33.551: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.993271ms)
Jun 14 12:57:33.553: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 7.156827ms)
Jun 14 12:57:33.553: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 6.923584ms)
Jun 14 12:57:33.553: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 7.079537ms)
Jun 14 12:57:33.553: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 7.230857ms)
Jun 14 12:57:33.553: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 6.931662ms)
Jun 14 12:57:33.553: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 7.324285ms)
Jun 14 12:57:33.556: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 2.908161ms)
Jun 14 12:57:33.557: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 3.992994ms)
Jun 14 12:57:33.558: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 4.317144ms)
Jun 14 12:57:33.558: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.50654ms)
Jun 14 12:57:33.558: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.798679ms)
Jun 14 12:57:33.558: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.909913ms)
Jun 14 12:57:33.558: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.815175ms)
Jun 14 12:57:33.558: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.808218ms)
Jun 14 12:57:33.558: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 5.079353ms)
Jun 14 12:57:33.559: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 5.219487ms)
Jun 14 12:57:33.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 6.497027ms)
Jun 14 12:57:33.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 6.450367ms)
Jun 14 12:57:33.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.617818ms)
Jun 14 12:57:33.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 6.864911ms)
Jun 14 12:57:33.560: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 7.012905ms)
Jun 14 12:57:33.561: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 7.436269ms)
Jun 14 12:57:33.567: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.817614ms)
Jun 14 12:57:33.567: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.0675ms)
Jun 14 12:57:33.567: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 6.258203ms)
Jun 14 12:57:33.567: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 6.30356ms)
Jun 14 12:57:33.567: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 6.47316ms)
Jun 14 12:57:33.567: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 6.43494ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 6.876944ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 6.860921ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 6.902717ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 7.013939ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 6.990846ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 7.151812ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 7.060934ms)
Jun 14 12:57:33.568: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 7.100834ms)
Jun 14 12:57:33.569: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 7.840349ms)
Jun 14 12:57:33.570: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 8.544199ms)
Jun 14 12:57:33.573: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.3455ms)
Jun 14 12:57:33.577: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 7.412118ms)
Jun 14 12:57:33.577: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 7.458065ms)
Jun 14 12:57:33.577: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 7.65305ms)
Jun 14 12:57:33.577: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 7.470931ms)
Jun 14 12:57:33.577: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 7.463347ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 7.68741ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 7.919569ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 7.84313ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 7.687673ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 7.727063ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 7.874485ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 7.90027ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 7.992163ms)
Jun 14 12:57:33.578: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 7.830077ms)
Jun 14 12:57:33.579: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 9.101214ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 4.510747ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.832319ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.843503ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.891894ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 5.032229ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 4.972191ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 5.005814ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.100658ms)
Jun 14 12:57:33.584: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.223417ms)
Jun 14 12:57:33.585: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 5.452807ms)
Jun 14 12:57:33.585: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 5.6886ms)
Jun 14 12:57:33.585: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 5.953014ms)
Jun 14 12:57:33.585: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.763541ms)
Jun 14 12:57:33.585: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 5.811435ms)
Jun 14 12:57:33.585: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 6.00945ms)
Jun 14 12:57:33.585: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.920594ms)
Jun 14 12:57:33.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 3.490378ms)
Jun 14 12:57:33.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 3.899771ms)
Jun 14 12:57:33.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 3.985272ms)
Jun 14 12:57:33.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.00744ms)
Jun 14 12:57:33.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 4.049437ms)
Jun 14 12:57:33.591: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 5.957008ms)
Jun 14 12:57:33.591: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.83494ms)
Jun 14 12:57:33.591: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 6.113934ms)
Jun 14 12:57:33.591: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.981506ms)
Jun 14 12:57:33.591: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.900317ms)
Jun 14 12:57:33.591: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 6.066721ms)
Jun 14 12:57:33.592: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 6.654712ms)
Jun 14 12:57:33.592: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 6.79386ms)
Jun 14 12:57:33.592: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 6.77417ms)
Jun 14 12:57:33.592: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.765784ms)
Jun 14 12:57:33.592: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 6.846581ms)
Jun 14 12:57:33.598: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.877043ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.911377ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.455463ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.360925ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 6.022624ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.729442ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 5.815621ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 5.860133ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 5.811647ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 6.731018ms)
Jun 14 12:57:33.599: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 6.519907ms)
Jun 14 12:57:33.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 7.689127ms)
Jun 14 12:57:33.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 8.014343ms)
Jun 14 12:57:33.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 8.239577ms)
Jun 14 12:57:33.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 8.125429ms)
Jun 14 12:57:33.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 8.711329ms)
Jun 14 12:57:33.606: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.965279ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 5.341111ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.211601ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 5.449612ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 5.331911ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.770596ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 5.766532ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.871092ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 5.904426ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 5.821448ms)
Jun 14 12:57:33.607: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 6.040638ms)
Jun 14 12:57:33.608: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 6.307042ms)
Jun 14 12:57:33.608: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 6.859739ms)
Jun 14 12:57:33.608: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 7.05491ms)
Jun 14 12:57:33.608: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 6.87625ms)
Jun 14 12:57:33.608: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 7.058714ms)
Jun 14 12:57:33.611: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 2.776133ms)
Jun 14 12:57:33.612: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 3.61159ms)
Jun 14 12:57:33.612: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 3.60359ms)
Jun 14 12:57:33.612: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.840893ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 3.994921ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 4.074903ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 4.127275ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.196334ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.327157ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.367009ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.245382ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 4.794871ms)
Jun 14 12:57:33.613: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 5.006438ms)
Jun 14 12:57:33.614: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 4.950628ms)
Jun 14 12:57:33.614: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 4.999124ms)
Jun 14 12:57:33.614: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 5.123975ms)
Jun 14 12:57:33.616: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 2.721274ms)
Jun 14 12:57:33.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 3.864344ms)
Jun 14 12:57:33.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 4.311591ms)
Jun 14 12:57:33.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 4.256827ms)
Jun 14 12:57:33.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.382198ms)
Jun 14 12:57:33.618: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.440672ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 4.89469ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 4.516863ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 4.508862ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 4.443338ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.845653ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.90298ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 4.745583ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 5.153517ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 5.218796ms)
Jun 14 12:57:33.619: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 5.231411ms)
Jun 14 12:57:33.622: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 2.570841ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 3.198113ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 3.363134ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 3.242069ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 3.574375ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 3.531221ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 3.513877ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.668681ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 3.5473ms)
Jun 14 12:57:33.623: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.594574ms)
Jun 14 12:57:33.624: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 4.457823ms)
Jun 14 12:57:33.624: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 4.533699ms)
Jun 14 12:57:33.624: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 5.031889ms)
Jun 14 12:57:33.625: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 5.129249ms)
Jun 14 12:57:33.625: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 5.241963ms)
Jun 14 12:57:33.625: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 5.335369ms)
Jun 14 12:57:33.628: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 3.022341ms)
Jun 14 12:57:33.628: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 3.474444ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 3.814263ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 4.165343ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 3.933391ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.966319ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 4.160973ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.866115ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 3.996402ms)
Jun 14 12:57:33.629: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.162498ms)
Jun 14 12:57:33.630: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 4.845159ms)
Jun 14 12:57:33.630: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 5.48325ms)
Jun 14 12:57:33.630: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 5.532273ms)
Jun 14 12:57:33.630: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 5.673258ms)
Jun 14 12:57:33.630: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 5.354727ms)
Jun 14 12:57:33.630: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 5.346319ms)
Jun 14 12:57:33.634: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.686049ms)
Jun 14 12:57:33.634: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 3.890867ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 4.156533ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 4.043343ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 4.143953ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 4.496088ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 4.414835ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 4.465934ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 4.356081ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 4.625715ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 4.594368ms)
Jun 14 12:57:33.635: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 4.824133ms)
Jun 14 12:57:33.636: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 5.2804ms)
Jun 14 12:57:33.636: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 5.359584ms)
Jun 14 12:57:33.636: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 5.350773ms)
Jun 14 12:57:33.636: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 5.384828ms)
Jun 14 12:57:33.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:1080/proxy/rewri... (200; 2.677225ms)
Jun 14 12:57:33.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 2.676154ms)
Jun 14 12:57:33.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:460/proxy/: tls baz (200; 2.852229ms)
Jun 14 12:57:33.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:462/proxy/: tls qux (200; 2.808949ms)
Jun 14 12:57:33.639: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 2.854113ms)
Jun 14 12:57:33.640: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:162/proxy/: bar (200; 3.424411ms)
Jun 14 12:57:33.642: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/https:proxy-service-j66xr-8zxsk:443/proxy/... (200; 5.927776ms)
Jun 14 12:57:33.643: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/http:proxy-service-j66xr-8zxsk:1080/proxy/... (200; 7.029752ms)
Jun 14 12:57:33.644: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk:160/proxy/: foo (200; 7.851195ms)
Jun 14 12:57:33.644: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname2/proxy/: bar (200; 8.425998ms)
Jun 14 12:57:33.645: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname1/proxy/: tls baz (200; 9.101611ms)
Jun 14 12:57:33.646: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname2/proxy/: bar (200; 9.757748ms)
Jun 14 12:57:33.646: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-8cmz6/pods/proxy-service-j66xr-8zxsk/proxy/rewriteme"... (200; 9.882106ms)
Jun 14 12:57:33.646: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/proxy-service-j66xr:portname1/proxy/: foo (200; 10.420424ms)
Jun 14 12:57:33.647: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/https:proxy-service-j66xr:tlsportname2/proxy/: tls qux (200; 10.835681ms)
Jun 14 12:57:33.647: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-8cmz6/services/http:proxy-service-j66xr:portname1/proxy/: foo (200; 10.875591ms)
STEP: deleting ReplicationController proxy-service-j66xr in namespace e2e-tests-proxy-8cmz6, will wait for the garbage collector to delete the pods
Jun 14 12:57:33.718: INFO: Deleting ReplicationController proxy-service-j66xr took: 9.75014ms
Jun 14 12:57:33.818: INFO: Terminating ReplicationController proxy-service-j66xr pods took: 100.118779ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:57:46.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8cmz6" for this suite.
Jun 14 12:57:52.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:57:52.476: INFO: namespace: e2e-tests-proxy-8cmz6, resource: bindings, ignored listing per whitelist
Jun 14 12:57:52.493: INFO: namespace e2e-tests-proxy-8cmz6 deletion completed in 6.065558365s

• [SLOW TEST:28.121 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:57:52.493: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 12:57:52.551: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-fql72" to be "success or failure"
Jun 14 12:57:52.553: INFO: Pod "downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.901926ms
Jun 14 12:57:54.556: INFO: Pod "downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004434934s
Jun 14 12:57:56.561: INFO: Pod "downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009881051s
STEP: Saw pod success
Jun 14 12:57:56.561: INFO: Pod "downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:57:56.562: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 12:57:56.573: INFO: Waiting for pod downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014 to disappear
Jun 14 12:57:56.575: INFO: Pod downwardapi-volume-05416212-8ea4-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:57:56.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fql72" for this suite.
Jun 14 12:58:02.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:58:02.620: INFO: namespace: e2e-tests-projected-fql72, resource: bindings, ignored listing per whitelist
Jun 14 12:58:02.641: INFO: namespace e2e-tests-projected-fql72 deletion completed in 6.064025462s

• [SLOW TEST:10.148 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:58:02.641: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jun 14 12:58:10.715: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:10.715: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:10.770: INFO: Exec stderr: ""
Jun 14 12:58:10.770: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:10.770: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:10.819: INFO: Exec stderr: ""
Jun 14 12:58:10.819: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:10.819: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:10.868: INFO: Exec stderr: ""
Jun 14 12:58:10.868: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:10.868: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:10.917: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jun 14 12:58:10.917: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:10.917: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:10.975: INFO: Exec stderr: ""
Jun 14 12:58:10.975: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:10.975: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:11.029: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jun 14 12:58:11.029: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:11.029: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:11.084: INFO: Exec stderr: ""
Jun 14 12:58:11.084: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:11.084: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:11.135: INFO: Exec stderr: ""
Jun 14 12:58:11.135: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:11.135: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:11.188: INFO: Exec stderr: ""
Jun 14 12:58:11.188: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-4ccjj PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 12:58:11.188: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 12:58:11.240: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:58:11.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-4ccjj" for this suite.
Jun 14 12:59:01.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:59:01.268: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-4ccjj, resource: bindings, ignored listing per whitelist
Jun 14 12:59:01.304: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-4ccjj deletion completed in 50.061259213s

• [SLOW TEST:58.663 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:59:01.304: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2e4579fb-8ea4-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 12:59:01.369: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2e463689-8ea4-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-flf5p" to be "success or failure"
Jun 14 12:59:01.370: INFO: Pod "pod-projected-configmaps-2e463689-8ea4-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.680671ms
Jun 14 12:59:03.376: INFO: Pod "pod-projected-configmaps-2e463689-8ea4-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007586408s
STEP: Saw pod success
Jun 14 12:59:03.376: INFO: Pod "pod-projected-configmaps-2e463689-8ea4-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:59:03.378: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-configmaps-2e463689-8ea4-11e9-82a6-0255ac100014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 12:59:03.390: INFO: Waiting for pod pod-projected-configmaps-2e463689-8ea4-11e9-82a6-0255ac100014 to disappear
Jun 14 12:59:03.392: INFO: Pod pod-projected-configmaps-2e463689-8ea4-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:59:03.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-flf5p" for this suite.
Jun 14 12:59:09.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:59:09.415: INFO: namespace: e2e-tests-projected-flf5p, resource: bindings, ignored listing per whitelist
Jun 14 12:59:09.454: INFO: namespace e2e-tests-projected-flf5p deletion completed in 6.06032516s

• [SLOW TEST:8.150 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:59:09.454: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 14 12:59:15.524: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:15.527: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:17.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:17.529: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:19.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:19.529: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:21.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:21.529: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:23.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:23.533: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:25.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:25.529: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:27.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:27.529: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:29.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:29.530: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:31.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:31.530: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 14 12:59:33.527: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 14 12:59:33.529: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:59:33.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jlb4d" for this suite.
Jun 14 12:59:55.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 12:59:55.605: INFO: namespace: e2e-tests-container-lifecycle-hook-jlb4d, resource: bindings, ignored listing per whitelist
Jun 14 12:59:55.605: INFO: namespace e2e-tests-container-lifecycle-hook-jlb4d deletion completed in 22.0644542s

• [SLOW TEST:46.151 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 12:59:55.605: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 14 12:59:55.659: INFO: Waiting up to 5m0s for pod "pod-4ea235c8-8ea4-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-lsw48" to be "success or failure"
Jun 14 12:59:55.661: INFO: Pod "pod-4ea235c8-8ea4-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.681107ms
Jun 14 12:59:57.664: INFO: Pod "pod-4ea235c8-8ea4-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004602769s
STEP: Saw pod success
Jun 14 12:59:57.664: INFO: Pod "pod-4ea235c8-8ea4-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 12:59:57.666: INFO: Trying to get logs from node 192.168.0.235 pod pod-4ea235c8-8ea4-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 12:59:57.678: INFO: Waiting for pod pod-4ea235c8-8ea4-11e9-82a6-0255ac100014 to disappear
Jun 14 12:59:57.681: INFO: Pod pod-4ea235c8-8ea4-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 12:59:57.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lsw48" for this suite.
Jun 14 13:00:03.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:00:03.736: INFO: namespace: e2e-tests-emptydir-lsw48, resource: bindings, ignored listing per whitelist
Jun 14 13:00:03.744: INFO: namespace e2e-tests-emptydir-lsw48 deletion completed in 6.060654439s

• [SLOW TEST:8.139 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:00:03.744: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 14 13:00:09.828: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:09.830: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:11.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:11.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:13.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:13.832: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:15.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:15.836: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:17.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:17.832: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:19.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:19.832: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:21.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:21.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:23.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:23.833: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:25.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:25.832: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 14 13:00:27.830: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 14 13:00:27.837: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:00:27.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-k8kgf" for this suite.
Jun 14 13:00:49.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:00:49.865: INFO: namespace: e2e-tests-container-lifecycle-hook-k8kgf, resource: bindings, ignored listing per whitelist
Jun 14 13:00:49.897: INFO: namespace e2e-tests-container-lifecycle-hook-k8kgf deletion completed in 22.058243163s

• [SLOW TEST:46.153 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:00:49.897: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-hpvgv
I0614 13:00:49.950184      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-hpvgv, replica count: 1
I0614 13:00:51.000453      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0614 13:00:52.000594      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 14 13:00:52.117: INFO: Created: latency-svc-lr28m
Jun 14 13:00:52.124: INFO: Got endpoints: latency-svc-lr28m [23.821775ms]
Jun 14 13:00:52.134: INFO: Created: latency-svc-fmxg4
Jun 14 13:00:52.141: INFO: Got endpoints: latency-svc-fmxg4 [17.303473ms]
Jun 14 13:00:52.142: INFO: Created: latency-svc-768fb
Jun 14 13:00:52.148: INFO: Got endpoints: latency-svc-768fb [23.406728ms]
Jun 14 13:00:52.151: INFO: Created: latency-svc-k54t9
Jun 14 13:00:52.156: INFO: Got endpoints: latency-svc-k54t9 [31.621862ms]
Jun 14 13:00:52.157: INFO: Created: latency-svc-wm7zh
Jun 14 13:00:52.162: INFO: Got endpoints: latency-svc-wm7zh [37.139926ms]
Jun 14 13:00:52.163: INFO: Created: latency-svc-5k5hl
Jun 14 13:00:52.166: INFO: Got endpoints: latency-svc-5k5hl [41.20256ms]
Jun 14 13:00:52.168: INFO: Created: latency-svc-c5pjw
Jun 14 13:00:52.174: INFO: Got endpoints: latency-svc-c5pjw [49.4632ms]
Jun 14 13:00:52.174: INFO: Created: latency-svc-jqfpv
Jun 14 13:00:52.180: INFO: Got endpoints: latency-svc-jqfpv [55.112147ms]
Jun 14 13:00:52.181: INFO: Created: latency-svc-jlrd5
Jun 14 13:00:52.185: INFO: Got endpoints: latency-svc-jlrd5 [60.487134ms]
Jun 14 13:00:52.188: INFO: Created: latency-svc-9wm58
Jun 14 13:00:52.193: INFO: Got endpoints: latency-svc-9wm58 [67.995433ms]
Jun 14 13:00:52.196: INFO: Created: latency-svc-4nlfk
Jun 14 13:00:52.199: INFO: Created: latency-svc-29h4f
Jun 14 13:00:52.201: INFO: Got endpoints: latency-svc-4nlfk [75.874482ms]
Jun 14 13:00:52.207: INFO: Got endpoints: latency-svc-29h4f [81.763584ms]
Jun 14 13:00:52.208: INFO: Created: latency-svc-q2w6r
Jun 14 13:00:52.213: INFO: Got endpoints: latency-svc-q2w6r [89.065168ms]
Jun 14 13:00:52.216: INFO: Created: latency-svc-f552k
Jun 14 13:00:52.222: INFO: Got endpoints: latency-svc-f552k [97.657171ms]
Jun 14 13:00:52.224: INFO: Created: latency-svc-ms9vw
Jun 14 13:00:52.229: INFO: Got endpoints: latency-svc-ms9vw [103.96936ms]
Jun 14 13:00:52.230: INFO: Created: latency-svc-kf7jf
Jun 14 13:00:52.238: INFO: Got endpoints: latency-svc-kf7jf [113.342214ms]
Jun 14 13:00:52.242: INFO: Created: latency-svc-q5l4q
Jun 14 13:00:52.247: INFO: Got endpoints: latency-svc-q5l4q [105.414961ms]
Jun 14 13:00:52.250: INFO: Created: latency-svc-b6qxb
Jun 14 13:00:52.256: INFO: Got endpoints: latency-svc-b6qxb [108.18085ms]
Jun 14 13:00:52.258: INFO: Created: latency-svc-skf7x
Jun 14 13:00:52.265: INFO: Got endpoints: latency-svc-skf7x [108.653587ms]
Jun 14 13:00:52.266: INFO: Created: latency-svc-6xl68
Jun 14 13:00:52.271: INFO: Got endpoints: latency-svc-6xl68 [109.604946ms]
Jun 14 13:00:52.276: INFO: Created: latency-svc-jcxk4
Jun 14 13:00:52.292: INFO: Got endpoints: latency-svc-jcxk4 [125.893031ms]
Jun 14 13:00:52.297: INFO: Created: latency-svc-jrd29
Jun 14 13:00:52.311: INFO: Got endpoints: latency-svc-jrd29 [136.801124ms]
Jun 14 13:00:52.314: INFO: Created: latency-svc-lkncs
Jun 14 13:00:52.325: INFO: Got endpoints: latency-svc-lkncs [145.191267ms]
Jun 14 13:00:52.327: INFO: Created: latency-svc-jkbnm
Jun 14 13:00:52.332: INFO: Got endpoints: latency-svc-jkbnm [146.497471ms]
Jun 14 13:00:52.335: INFO: Created: latency-svc-rct7f
Jun 14 13:00:52.344: INFO: Got endpoints: latency-svc-rct7f [151.796545ms]
Jun 14 13:00:52.347: INFO: Created: latency-svc-xq2xk
Jun 14 13:00:52.354: INFO: Got endpoints: latency-svc-xq2xk [153.918836ms]
Jun 14 13:00:52.357: INFO: Created: latency-svc-27bxn
Jun 14 13:00:52.361: INFO: Got endpoints: latency-svc-27bxn [154.583681ms]
Jun 14 13:00:52.363: INFO: Created: latency-svc-vdnqj
Jun 14 13:00:52.367: INFO: Got endpoints: latency-svc-vdnqj [153.773123ms]
Jun 14 13:00:52.369: INFO: Created: latency-svc-j6qwn
Jun 14 13:00:52.375: INFO: Got endpoints: latency-svc-j6qwn [152.713746ms]
Jun 14 13:00:52.377: INFO: Created: latency-svc-k4d45
Jun 14 13:00:52.384: INFO: Got endpoints: latency-svc-k4d45 [155.678947ms]
Jun 14 13:00:52.385: INFO: Created: latency-svc-m4mc7
Jun 14 13:00:52.390: INFO: Got endpoints: latency-svc-m4mc7 [152.21913ms]
Jun 14 13:00:52.392: INFO: Created: latency-svc-cstm8
Jun 14 13:00:52.397: INFO: Got endpoints: latency-svc-cstm8 [150.204397ms]
Jun 14 13:00:52.398: INFO: Created: latency-svc-l9q29
Jun 14 13:00:52.404: INFO: Got endpoints: latency-svc-l9q29 [148.069668ms]
Jun 14 13:00:52.405: INFO: Created: latency-svc-47kr4
Jun 14 13:00:52.411: INFO: Got endpoints: latency-svc-47kr4 [146.358965ms]
Jun 14 13:00:52.412: INFO: Created: latency-svc-s86rt
Jun 14 13:00:52.423: INFO: Got endpoints: latency-svc-s86rt [151.751532ms]
Jun 14 13:00:52.427: INFO: Created: latency-svc-lm7ms
Jun 14 13:00:52.430: INFO: Created: latency-svc-9gqd6
Jun 14 13:00:52.434: INFO: Got endpoints: latency-svc-lm7ms [141.897322ms]
Jun 14 13:00:52.440: INFO: Created: latency-svc-d749h
Jun 14 13:00:52.452: INFO: Created: latency-svc-n5t82
Jun 14 13:00:52.461: INFO: Created: latency-svc-ml8rn
Jun 14 13:00:52.472: INFO: Created: latency-svc-z22b4
Jun 14 13:00:52.476: INFO: Got endpoints: latency-svc-9gqd6 [165.137637ms]
Jun 14 13:00:52.481: INFO: Created: latency-svc-5pl6c
Jun 14 13:00:52.493: INFO: Created: latency-svc-j86kf
Jun 14 13:00:52.500: INFO: Created: latency-svc-pv2fk
Jun 14 13:00:52.507: INFO: Created: latency-svc-tlpxv
Jun 14 13:00:52.515: INFO: Created: latency-svc-tqpng
Jun 14 13:00:52.529: INFO: Got endpoints: latency-svc-d749h [203.775211ms]
Jun 14 13:00:52.534: INFO: Created: latency-svc-87fls
Jun 14 13:00:52.542: INFO: Created: latency-svc-qjtpv
Jun 14 13:00:52.551: INFO: Created: latency-svc-gs8lh
Jun 14 13:00:52.555: INFO: Created: latency-svc-dhl57
Jun 14 13:00:52.571: INFO: Got endpoints: latency-svc-n5t82 [239.036705ms]
Jun 14 13:00:52.572: INFO: Created: latency-svc-fx6hn
Jun 14 13:00:52.581: INFO: Created: latency-svc-tzqmf
Jun 14 13:00:52.588: INFO: Created: latency-svc-9tdnk
Jun 14 13:00:52.594: INFO: Created: latency-svc-96xvm
Jun 14 13:00:52.620: INFO: Got endpoints: latency-svc-ml8rn [275.410756ms]
Jun 14 13:00:52.629: INFO: Created: latency-svc-jcczf
Jun 14 13:00:52.670: INFO: Got endpoints: latency-svc-z22b4 [315.828515ms]
Jun 14 13:00:52.678: INFO: Created: latency-svc-k4kgr
Jun 14 13:00:52.720: INFO: Got endpoints: latency-svc-5pl6c [358.43781ms]
Jun 14 13:00:52.731: INFO: Created: latency-svc-4xhvf
Jun 14 13:00:52.772: INFO: Got endpoints: latency-svc-j86kf [404.309173ms]
Jun 14 13:00:52.783: INFO: Created: latency-svc-998j9
Jun 14 13:00:52.820: INFO: Got endpoints: latency-svc-pv2fk [444.66544ms]
Jun 14 13:00:52.829: INFO: Created: latency-svc-2ds5k
Jun 14 13:00:52.870: INFO: Got endpoints: latency-svc-tlpxv [485.551738ms]
Jun 14 13:00:52.880: INFO: Created: latency-svc-k4s7j
Jun 14 13:00:52.920: INFO: Got endpoints: latency-svc-tqpng [529.342381ms]
Jun 14 13:00:52.928: INFO: Created: latency-svc-7m5lw
Jun 14 13:00:52.977: INFO: Got endpoints: latency-svc-87fls [579.421206ms]
Jun 14 13:00:52.990: INFO: Created: latency-svc-gzwj2
Jun 14 13:00:53.022: INFO: Got endpoints: latency-svc-qjtpv [618.388254ms]
Jun 14 13:00:53.031: INFO: Created: latency-svc-xlbp2
Jun 14 13:00:53.070: INFO: Got endpoints: latency-svc-gs8lh [659.074989ms]
Jun 14 13:00:53.084: INFO: Created: latency-svc-qf8xg
Jun 14 13:00:53.120: INFO: Got endpoints: latency-svc-dhl57 [696.954893ms]
Jun 14 13:00:53.134: INFO: Created: latency-svc-hrhvx
Jun 14 13:00:53.171: INFO: Got endpoints: latency-svc-fx6hn [736.776246ms]
Jun 14 13:00:53.181: INFO: Created: latency-svc-2ghpm
Jun 14 13:00:53.220: INFO: Got endpoints: latency-svc-tzqmf [744.447902ms]
Jun 14 13:00:53.232: INFO: Created: latency-svc-96mp9
Jun 14 13:00:53.280: INFO: Got endpoints: latency-svc-9tdnk [750.933045ms]
Jun 14 13:00:53.299: INFO: Created: latency-svc-gh7p4
Jun 14 13:00:53.320: INFO: Got endpoints: latency-svc-96xvm [749.204953ms]
Jun 14 13:00:53.328: INFO: Created: latency-svc-6bcpr
Jun 14 13:00:53.370: INFO: Got endpoints: latency-svc-jcczf [750.033183ms]
Jun 14 13:00:53.380: INFO: Created: latency-svc-lgjct
Jun 14 13:00:53.420: INFO: Got endpoints: latency-svc-k4kgr [749.598145ms]
Jun 14 13:00:53.435: INFO: Created: latency-svc-j8lj7
Jun 14 13:00:53.471: INFO: Got endpoints: latency-svc-4xhvf [751.708071ms]
Jun 14 13:00:53.486: INFO: Created: latency-svc-b4gs2
Jun 14 13:00:53.522: INFO: Got endpoints: latency-svc-998j9 [750.408056ms]
Jun 14 13:00:53.530: INFO: Created: latency-svc-4xf5v
Jun 14 13:00:53.575: INFO: Got endpoints: latency-svc-2ds5k [755.792062ms]
Jun 14 13:00:53.584: INFO: Created: latency-svc-q7wjf
Jun 14 13:00:53.621: INFO: Got endpoints: latency-svc-k4s7j [750.925686ms]
Jun 14 13:00:53.631: INFO: Created: latency-svc-clzdl
Jun 14 13:00:53.677: INFO: Got endpoints: latency-svc-7m5lw [756.787767ms]
Jun 14 13:00:53.710: INFO: Created: latency-svc-pg5f4
Jun 14 13:00:53.719: INFO: Got endpoints: latency-svc-gzwj2 [742.79679ms]
Jun 14 13:00:53.727: INFO: Created: latency-svc-vcxsg
Jun 14 13:00:53.770: INFO: Got endpoints: latency-svc-xlbp2 [747.767019ms]
Jun 14 13:00:53.780: INFO: Created: latency-svc-6wwp6
Jun 14 13:00:53.822: INFO: Got endpoints: latency-svc-qf8xg [752.099022ms]
Jun 14 13:00:53.831: INFO: Created: latency-svc-qmlqd
Jun 14 13:00:53.873: INFO: Got endpoints: latency-svc-hrhvx [753.373196ms]
Jun 14 13:00:53.883: INFO: Created: latency-svc-wn8mx
Jun 14 13:00:53.920: INFO: Got endpoints: latency-svc-2ghpm [748.868992ms]
Jun 14 13:00:53.930: INFO: Created: latency-svc-l2ngv
Jun 14 13:00:53.971: INFO: Got endpoints: latency-svc-96mp9 [750.709003ms]
Jun 14 13:00:53.981: INFO: Created: latency-svc-zwdv5
Jun 14 13:00:54.020: INFO: Got endpoints: latency-svc-gh7p4 [740.266421ms]
Jun 14 13:00:54.034: INFO: Created: latency-svc-zckx9
Jun 14 13:00:54.070: INFO: Got endpoints: latency-svc-6bcpr [750.094915ms]
Jun 14 13:00:54.079: INFO: Created: latency-svc-tcj5d
Jun 14 13:00:54.124: INFO: Got endpoints: latency-svc-lgjct [754.05519ms]
Jun 14 13:00:54.132: INFO: Created: latency-svc-rgt7t
Jun 14 13:00:54.170: INFO: Got endpoints: latency-svc-j8lj7 [750.151943ms]
Jun 14 13:00:54.182: INFO: Created: latency-svc-tbpmg
Jun 14 13:00:54.220: INFO: Got endpoints: latency-svc-b4gs2 [748.68122ms]
Jun 14 13:00:54.232: INFO: Created: latency-svc-bfmg8
Jun 14 13:00:54.270: INFO: Got endpoints: latency-svc-4xf5v [748.339838ms]
Jun 14 13:00:54.284: INFO: Created: latency-svc-9vrw4
Jun 14 13:00:54.320: INFO: Got endpoints: latency-svc-q7wjf [744.373697ms]
Jun 14 13:00:54.330: INFO: Created: latency-svc-spfrh
Jun 14 13:00:54.370: INFO: Got endpoints: latency-svc-clzdl [749.127171ms]
Jun 14 13:00:54.379: INFO: Created: latency-svc-vqgwz
Jun 14 13:00:54.420: INFO: Got endpoints: latency-svc-pg5f4 [743.267385ms]
Jun 14 13:00:54.432: INFO: Created: latency-svc-tp8rl
Jun 14 13:00:54.470: INFO: Got endpoints: latency-svc-vcxsg [750.376984ms]
Jun 14 13:00:54.485: INFO: Created: latency-svc-fnnbh
Jun 14 13:00:54.523: INFO: Got endpoints: latency-svc-6wwp6 [753.030238ms]
Jun 14 13:00:54.533: INFO: Created: latency-svc-2d9hw
Jun 14 13:00:54.571: INFO: Got endpoints: latency-svc-qmlqd [748.725552ms]
Jun 14 13:00:54.587: INFO: Created: latency-svc-z6ns6
Jun 14 13:00:54.620: INFO: Got endpoints: latency-svc-wn8mx [746.583994ms]
Jun 14 13:00:54.627: INFO: Created: latency-svc-pdm9x
Jun 14 13:00:54.672: INFO: Got endpoints: latency-svc-l2ngv [752.095361ms]
Jun 14 13:00:54.679: INFO: Created: latency-svc-s5xl7
Jun 14 13:00:54.720: INFO: Got endpoints: latency-svc-zwdv5 [748.86096ms]
Jun 14 13:00:54.729: INFO: Created: latency-svc-wmxl2
Jun 14 13:00:54.789: INFO: Got endpoints: latency-svc-zckx9 [769.186837ms]
Jun 14 13:00:54.798: INFO: Created: latency-svc-nmjpl
Jun 14 13:00:54.820: INFO: Got endpoints: latency-svc-tcj5d [750.200935ms]
Jun 14 13:00:54.831: INFO: Created: latency-svc-gfwf4
Jun 14 13:00:54.870: INFO: Got endpoints: latency-svc-rgt7t [745.598671ms]
Jun 14 13:00:54.878: INFO: Created: latency-svc-lbfn7
Jun 14 13:00:54.931: INFO: Got endpoints: latency-svc-tbpmg [761.003475ms]
Jun 14 13:00:54.939: INFO: Created: latency-svc-4q74q
Jun 14 13:00:54.970: INFO: Got endpoints: latency-svc-bfmg8 [750.222112ms]
Jun 14 13:00:54.981: INFO: Created: latency-svc-xm65f
Jun 14 13:00:55.020: INFO: Got endpoints: latency-svc-9vrw4 [749.726757ms]
Jun 14 13:00:55.041: INFO: Created: latency-svc-55gbn
Jun 14 13:00:55.070: INFO: Got endpoints: latency-svc-spfrh [749.852773ms]
Jun 14 13:00:55.079: INFO: Created: latency-svc-k74c8
Jun 14 13:00:55.120: INFO: Got endpoints: latency-svc-vqgwz [749.814165ms]
Jun 14 13:00:55.129: INFO: Created: latency-svc-xch74
Jun 14 13:00:55.171: INFO: Got endpoints: latency-svc-tp8rl [750.88793ms]
Jun 14 13:00:55.179: INFO: Created: latency-svc-h6xb2
Jun 14 13:00:55.221: INFO: Got endpoints: latency-svc-fnnbh [751.185718ms]
Jun 14 13:00:55.236: INFO: Created: latency-svc-lknxv
Jun 14 13:00:55.270: INFO: Got endpoints: latency-svc-2d9hw [746.666572ms]
Jun 14 13:00:55.280: INFO: Created: latency-svc-whfhp
Jun 14 13:00:55.321: INFO: Got endpoints: latency-svc-z6ns6 [749.894029ms]
Jun 14 13:00:55.328: INFO: Created: latency-svc-8f2ql
Jun 14 13:00:55.378: INFO: Got endpoints: latency-svc-pdm9x [757.994957ms]
Jun 14 13:00:55.388: INFO: Created: latency-svc-w9k8g
Jun 14 13:00:55.423: INFO: Got endpoints: latency-svc-s5xl7 [751.388784ms]
Jun 14 13:00:55.432: INFO: Created: latency-svc-ncs4w
Jun 14 13:00:55.470: INFO: Got endpoints: latency-svc-wmxl2 [749.726602ms]
Jun 14 13:00:55.481: INFO: Created: latency-svc-j2kmw
Jun 14 13:00:55.520: INFO: Got endpoints: latency-svc-nmjpl [730.339215ms]
Jun 14 13:00:55.528: INFO: Created: latency-svc-zc8wn
Jun 14 13:00:55.570: INFO: Got endpoints: latency-svc-gfwf4 [749.896183ms]
Jun 14 13:00:55.584: INFO: Created: latency-svc-hgnl5
Jun 14 13:00:55.624: INFO: Got endpoints: latency-svc-lbfn7 [754.795069ms]
Jun 14 13:00:55.633: INFO: Created: latency-svc-hjd7q
Jun 14 13:00:55.674: INFO: Got endpoints: latency-svc-4q74q [742.968003ms]
Jun 14 13:00:55.683: INFO: Created: latency-svc-g7fnb
Jun 14 13:00:55.720: INFO: Got endpoints: latency-svc-xm65f [749.792211ms]
Jun 14 13:00:55.733: INFO: Created: latency-svc-74986
Jun 14 13:00:55.770: INFO: Got endpoints: latency-svc-55gbn [749.808116ms]
Jun 14 13:00:55.779: INFO: Created: latency-svc-h78kj
Jun 14 13:00:55.822: INFO: Got endpoints: latency-svc-k74c8 [752.388647ms]
Jun 14 13:00:55.834: INFO: Created: latency-svc-schlv
Jun 14 13:00:55.870: INFO: Got endpoints: latency-svc-xch74 [750.168095ms]
Jun 14 13:00:55.882: INFO: Created: latency-svc-qqb88
Jun 14 13:00:55.927: INFO: Got endpoints: latency-svc-h6xb2 [756.348118ms]
Jun 14 13:00:55.940: INFO: Created: latency-svc-wjtjb
Jun 14 13:00:55.973: INFO: Got endpoints: latency-svc-lknxv [751.826287ms]
Jun 14 13:00:55.980: INFO: Created: latency-svc-b9m7x
Jun 14 13:00:56.022: INFO: Got endpoints: latency-svc-whfhp [752.337938ms]
Jun 14 13:00:56.035: INFO: Created: latency-svc-htsmw
Jun 14 13:00:56.070: INFO: Got endpoints: latency-svc-8f2ql [749.292035ms]
Jun 14 13:00:56.080: INFO: Created: latency-svc-kpkm2
Jun 14 13:00:56.121: INFO: Got endpoints: latency-svc-w9k8g [743.089455ms]
Jun 14 13:00:56.129: INFO: Created: latency-svc-m4x22
Jun 14 13:00:56.170: INFO: Got endpoints: latency-svc-ncs4w [746.794877ms]
Jun 14 13:00:56.179: INFO: Created: latency-svc-gj5tw
Jun 14 13:00:56.221: INFO: Got endpoints: latency-svc-j2kmw [751.146187ms]
Jun 14 13:00:56.235: INFO: Created: latency-svc-qc2gx
Jun 14 13:00:56.271: INFO: Got endpoints: latency-svc-zc8wn [751.135707ms]
Jun 14 13:00:56.282: INFO: Created: latency-svc-hxslt
Jun 14 13:00:56.320: INFO: Got endpoints: latency-svc-hgnl5 [749.771421ms]
Jun 14 13:00:56.332: INFO: Created: latency-svc-scfvz
Jun 14 13:00:56.370: INFO: Got endpoints: latency-svc-hjd7q [745.745104ms]
Jun 14 13:00:56.379: INFO: Created: latency-svc-5spth
Jun 14 13:00:56.427: INFO: Got endpoints: latency-svc-g7fnb [752.924319ms]
Jun 14 13:00:56.435: INFO: Created: latency-svc-vf7fx
Jun 14 13:00:56.471: INFO: Got endpoints: latency-svc-74986 [750.992518ms]
Jun 14 13:00:56.482: INFO: Created: latency-svc-q2k29
Jun 14 13:00:56.521: INFO: Got endpoints: latency-svc-h78kj [750.71183ms]
Jun 14 13:00:56.529: INFO: Created: latency-svc-bqw85
Jun 14 13:00:56.576: INFO: Got endpoints: latency-svc-schlv [753.654482ms]
Jun 14 13:00:56.585: INFO: Created: latency-svc-8jpjv
Jun 14 13:00:56.620: INFO: Got endpoints: latency-svc-qqb88 [749.634817ms]
Jun 14 13:00:56.629: INFO: Created: latency-svc-d8sx4
Jun 14 13:00:56.671: INFO: Got endpoints: latency-svc-wjtjb [743.897273ms]
Jun 14 13:00:56.681: INFO: Created: latency-svc-t86tt
Jun 14 13:00:56.720: INFO: Got endpoints: latency-svc-b9m7x [746.953895ms]
Jun 14 13:00:56.731: INFO: Created: latency-svc-zs7hw
Jun 14 13:00:56.770: INFO: Got endpoints: latency-svc-htsmw [747.704739ms]
Jun 14 13:00:56.781: INFO: Created: latency-svc-fcl9n
Jun 14 13:00:56.821: INFO: Got endpoints: latency-svc-kpkm2 [750.248149ms]
Jun 14 13:00:56.834: INFO: Created: latency-svc-4w65m
Jun 14 13:00:56.870: INFO: Got endpoints: latency-svc-m4x22 [748.760311ms]
Jun 14 13:00:56.894: INFO: Created: latency-svc-5cn85
Jun 14 13:00:56.920: INFO: Got endpoints: latency-svc-gj5tw [749.975541ms]
Jun 14 13:00:56.928: INFO: Created: latency-svc-4k86j
Jun 14 13:00:56.971: INFO: Got endpoints: latency-svc-qc2gx [749.644767ms]
Jun 14 13:00:56.980: INFO: Created: latency-svc-rv7tv
Jun 14 13:00:57.020: INFO: Got endpoints: latency-svc-hxslt [749.528032ms]
Jun 14 13:00:57.030: INFO: Created: latency-svc-p976k
Jun 14 13:00:57.070: INFO: Got endpoints: latency-svc-scfvz [750.050934ms]
Jun 14 13:00:57.080: INFO: Created: latency-svc-j2hr9
Jun 14 13:00:57.120: INFO: Got endpoints: latency-svc-5spth [750.00688ms]
Jun 14 13:00:57.134: INFO: Created: latency-svc-578vl
Jun 14 13:00:57.171: INFO: Got endpoints: latency-svc-vf7fx [743.766356ms]
Jun 14 13:00:57.184: INFO: Created: latency-svc-kvf89
Jun 14 13:00:57.221: INFO: Got endpoints: latency-svc-q2k29 [749.861796ms]
Jun 14 13:00:57.230: INFO: Created: latency-svc-lgphj
Jun 14 13:00:57.270: INFO: Got endpoints: latency-svc-bqw85 [749.296761ms]
Jun 14 13:00:57.280: INFO: Created: latency-svc-sp85z
Jun 14 13:00:57.320: INFO: Got endpoints: latency-svc-8jpjv [744.369163ms]
Jun 14 13:00:57.330: INFO: Created: latency-svc-x79q2
Jun 14 13:00:57.376: INFO: Got endpoints: latency-svc-d8sx4 [756.021166ms]
Jun 14 13:00:57.383: INFO: Created: latency-svc-fmr88
Jun 14 13:00:57.421: INFO: Got endpoints: latency-svc-t86tt [750.221595ms]
Jun 14 13:00:57.430: INFO: Created: latency-svc-vrcrx
Jun 14 13:00:57.474: INFO: Got endpoints: latency-svc-zs7hw [753.962582ms]
Jun 14 13:00:57.489: INFO: Created: latency-svc-zrbn4
Jun 14 13:00:57.520: INFO: Got endpoints: latency-svc-fcl9n [750.042936ms]
Jun 14 13:00:57.531: INFO: Created: latency-svc-4bnpj
Jun 14 13:00:57.571: INFO: Got endpoints: latency-svc-4w65m [750.791153ms]
Jun 14 13:00:57.580: INFO: Created: latency-svc-ccrq2
Jun 14 13:00:57.623: INFO: Got endpoints: latency-svc-5cn85 [753.258197ms]
Jun 14 13:00:57.638: INFO: Created: latency-svc-skwk2
Jun 14 13:00:57.671: INFO: Got endpoints: latency-svc-4k86j [750.527165ms]
Jun 14 13:00:57.685: INFO: Created: latency-svc-fgdw6
Jun 14 13:00:57.720: INFO: Got endpoints: latency-svc-rv7tv [749.524985ms]
Jun 14 13:00:57.732: INFO: Created: latency-svc-nbxbb
Jun 14 13:00:57.770: INFO: Got endpoints: latency-svc-p976k [749.249367ms]
Jun 14 13:00:57.785: INFO: Created: latency-svc-fbjhv
Jun 14 13:00:57.820: INFO: Got endpoints: latency-svc-j2hr9 [749.621784ms]
Jun 14 13:00:57.830: INFO: Created: latency-svc-477b4
Jun 14 13:00:57.877: INFO: Got endpoints: latency-svc-578vl [757.19043ms]
Jun 14 13:00:57.887: INFO: Created: latency-svc-xmxpd
Jun 14 13:00:57.920: INFO: Got endpoints: latency-svc-kvf89 [748.991399ms]
Jun 14 13:00:57.928: INFO: Created: latency-svc-7z78n
Jun 14 13:00:57.970: INFO: Got endpoints: latency-svc-lgphj [748.736359ms]
Jun 14 13:00:57.999: INFO: Created: latency-svc-tmshw
Jun 14 13:00:58.020: INFO: Got endpoints: latency-svc-sp85z [750.042729ms]
Jun 14 13:00:58.030: INFO: Created: latency-svc-vspsg
Jun 14 13:00:58.074: INFO: Got endpoints: latency-svc-x79q2 [753.968792ms]
Jun 14 13:00:58.082: INFO: Created: latency-svc-dvfnk
Jun 14 13:00:58.120: INFO: Got endpoints: latency-svc-fmr88 [744.328926ms]
Jun 14 13:00:58.129: INFO: Created: latency-svc-79qxg
Jun 14 13:00:58.171: INFO: Got endpoints: latency-svc-vrcrx [749.594015ms]
Jun 14 13:00:58.184: INFO: Created: latency-svc-j25bl
Jun 14 13:00:58.225: INFO: Got endpoints: latency-svc-zrbn4 [750.853287ms]
Jun 14 13:00:58.279: INFO: Got endpoints: latency-svc-4bnpj [758.506099ms]
Jun 14 13:00:58.280: INFO: Created: latency-svc-gs2kb
Jun 14 13:00:58.288: INFO: Created: latency-svc-9wnjr
Jun 14 13:00:58.321: INFO: Got endpoints: latency-svc-ccrq2 [749.250845ms]
Jun 14 13:00:58.331: INFO: Created: latency-svc-t67xm
Jun 14 13:00:58.370: INFO: Got endpoints: latency-svc-skwk2 [746.802245ms]
Jun 14 13:00:58.388: INFO: Created: latency-svc-fqqbl
Jun 14 13:00:58.420: INFO: Got endpoints: latency-svc-fgdw6 [749.407049ms]
Jun 14 13:00:58.429: INFO: Created: latency-svc-xqbxn
Jun 14 13:00:58.470: INFO: Got endpoints: latency-svc-nbxbb [750.155952ms]
Jun 14 13:00:58.478: INFO: Created: latency-svc-q97zd
Jun 14 13:00:58.525: INFO: Got endpoints: latency-svc-fbjhv [755.133803ms]
Jun 14 13:00:58.534: INFO: Created: latency-svc-5b2h9
Jun 14 13:00:58.571: INFO: Got endpoints: latency-svc-477b4 [750.753094ms]
Jun 14 13:00:58.582: INFO: Created: latency-svc-bw5vw
Jun 14 13:00:58.620: INFO: Got endpoints: latency-svc-xmxpd [742.891015ms]
Jun 14 13:00:58.635: INFO: Created: latency-svc-96529
Jun 14 13:00:58.672: INFO: Got endpoints: latency-svc-7z78n [751.643724ms]
Jun 14 13:00:58.682: INFO: Created: latency-svc-8x2l8
Jun 14 13:00:58.720: INFO: Got endpoints: latency-svc-tmshw [750.295242ms]
Jun 14 13:00:58.732: INFO: Created: latency-svc-8qkvj
Jun 14 13:00:58.770: INFO: Got endpoints: latency-svc-vspsg [749.961593ms]
Jun 14 13:00:58.792: INFO: Created: latency-svc-wsv6r
Jun 14 13:00:58.820: INFO: Got endpoints: latency-svc-dvfnk [745.853262ms]
Jun 14 13:00:58.832: INFO: Created: latency-svc-8hkp2
Jun 14 13:00:58.870: INFO: Got endpoints: latency-svc-79qxg [750.08124ms]
Jun 14 13:00:58.879: INFO: Created: latency-svc-28psg
Jun 14 13:00:58.920: INFO: Got endpoints: latency-svc-j25bl [749.01517ms]
Jun 14 13:00:58.929: INFO: Created: latency-svc-f9xkb
Jun 14 13:00:58.973: INFO: Got endpoints: latency-svc-gs2kb [748.276456ms]
Jun 14 13:00:58.992: INFO: Created: latency-svc-cm4ks
Jun 14 13:00:59.021: INFO: Got endpoints: latency-svc-9wnjr [742.52913ms]
Jun 14 13:00:59.034: INFO: Created: latency-svc-fr6q8
Jun 14 13:00:59.070: INFO: Got endpoints: latency-svc-t67xm [749.49055ms]
Jun 14 13:00:59.082: INFO: Created: latency-svc-g56hp
Jun 14 13:00:59.120: INFO: Got endpoints: latency-svc-fqqbl [749.84525ms]
Jun 14 13:00:59.133: INFO: Created: latency-svc-pgd72
Jun 14 13:00:59.172: INFO: Got endpoints: latency-svc-xqbxn [751.709287ms]
Jun 14 13:00:59.193: INFO: Created: latency-svc-qz5fx
Jun 14 13:00:59.224: INFO: Got endpoints: latency-svc-q97zd [753.570861ms]
Jun 14 13:00:59.244: INFO: Created: latency-svc-pzhnp
Jun 14 13:00:59.273: INFO: Got endpoints: latency-svc-5b2h9 [747.848979ms]
Jun 14 13:00:59.286: INFO: Created: latency-svc-t4jmg
Jun 14 13:00:59.321: INFO: Got endpoints: latency-svc-bw5vw [750.762858ms]
Jun 14 13:00:59.329: INFO: Created: latency-svc-zxw8l
Jun 14 13:00:59.370: INFO: Got endpoints: latency-svc-96529 [749.530979ms]
Jun 14 13:00:59.380: INFO: Created: latency-svc-czr4q
Jun 14 13:00:59.420: INFO: Got endpoints: latency-svc-8x2l8 [748.122773ms]
Jun 14 13:00:59.432: INFO: Created: latency-svc-bbn4w
Jun 14 13:00:59.474: INFO: Got endpoints: latency-svc-8qkvj [753.892936ms]
Jun 14 13:00:59.481: INFO: Created: latency-svc-tmglc
Jun 14 13:00:59.520: INFO: Got endpoints: latency-svc-wsv6r [750.008365ms]
Jun 14 13:00:59.536: INFO: Created: latency-svc-fz2cn
Jun 14 13:00:59.570: INFO: Got endpoints: latency-svc-8hkp2 [750.183518ms]
Jun 14 13:00:59.583: INFO: Created: latency-svc-sx8d7
Jun 14 13:00:59.620: INFO: Got endpoints: latency-svc-28psg [749.913889ms]
Jun 14 13:00:59.630: INFO: Created: latency-svc-dsclb
Jun 14 13:00:59.670: INFO: Got endpoints: latency-svc-f9xkb [750.110967ms]
Jun 14 13:00:59.684: INFO: Created: latency-svc-wc7tm
Jun 14 13:00:59.720: INFO: Got endpoints: latency-svc-cm4ks [747.352613ms]
Jun 14 13:00:59.728: INFO: Created: latency-svc-b9nxp
Jun 14 13:00:59.771: INFO: Got endpoints: latency-svc-fr6q8 [749.747474ms]
Jun 14 13:00:59.779: INFO: Created: latency-svc-qflh2
Jun 14 13:00:59.821: INFO: Got endpoints: latency-svc-g56hp [750.514058ms]
Jun 14 13:00:59.834: INFO: Created: latency-svc-hrslx
Jun 14 13:00:59.870: INFO: Got endpoints: latency-svc-pgd72 [750.36367ms]
Jun 14 13:00:59.892: INFO: Created: latency-svc-fwn7t
Jun 14 13:00:59.921: INFO: Got endpoints: latency-svc-qz5fx [749.596691ms]
Jun 14 13:00:59.961: INFO: Created: latency-svc-pzr5n
Jun 14 13:00:59.970: INFO: Got endpoints: latency-svc-pzhnp [746.408091ms]
Jun 14 13:01:00.020: INFO: Got endpoints: latency-svc-t4jmg [747.277005ms]
Jun 14 13:01:00.070: INFO: Got endpoints: latency-svc-zxw8l [748.557165ms]
Jun 14 13:01:00.120: INFO: Got endpoints: latency-svc-czr4q [750.586945ms]
Jun 14 13:01:00.172: INFO: Got endpoints: latency-svc-bbn4w [751.793913ms]
Jun 14 13:01:00.221: INFO: Got endpoints: latency-svc-tmglc [747.016756ms]
Jun 14 13:01:00.271: INFO: Got endpoints: latency-svc-fz2cn [750.575112ms]
Jun 14 13:01:00.321: INFO: Got endpoints: latency-svc-sx8d7 [750.196621ms]
Jun 14 13:01:00.375: INFO: Got endpoints: latency-svc-dsclb [754.713047ms]
Jun 14 13:01:00.424: INFO: Got endpoints: latency-svc-wc7tm [753.668816ms]
Jun 14 13:01:00.471: INFO: Got endpoints: latency-svc-b9nxp [751.029065ms]
Jun 14 13:01:00.523: INFO: Got endpoints: latency-svc-qflh2 [752.155628ms]
Jun 14 13:01:00.571: INFO: Got endpoints: latency-svc-hrslx [750.179608ms]
Jun 14 13:01:00.620: INFO: Got endpoints: latency-svc-fwn7t [749.492347ms]
Jun 14 13:01:00.673: INFO: Got endpoints: latency-svc-pzr5n [751.536433ms]
Jun 14 13:01:00.673: INFO: Latencies: [17.303473ms 23.406728ms 31.621862ms 37.139926ms 41.20256ms 49.4632ms 55.112147ms 60.487134ms 67.995433ms 75.874482ms 81.763584ms 89.065168ms 97.657171ms 103.96936ms 105.414961ms 108.18085ms 108.653587ms 109.604946ms 113.342214ms 125.893031ms 136.801124ms 141.897322ms 145.191267ms 146.358965ms 146.497471ms 148.069668ms 150.204397ms 151.751532ms 151.796545ms 152.21913ms 152.713746ms 153.773123ms 153.918836ms 154.583681ms 155.678947ms 165.137637ms 203.775211ms 239.036705ms 275.410756ms 315.828515ms 358.43781ms 404.309173ms 444.66544ms 485.551738ms 529.342381ms 579.421206ms 618.388254ms 659.074989ms 696.954893ms 730.339215ms 736.776246ms 740.266421ms 742.52913ms 742.79679ms 742.891015ms 742.968003ms 743.089455ms 743.267385ms 743.766356ms 743.897273ms 744.328926ms 744.369163ms 744.373697ms 744.447902ms 745.598671ms 745.745104ms 745.853262ms 746.408091ms 746.583994ms 746.666572ms 746.794877ms 746.802245ms 746.953895ms 747.016756ms 747.277005ms 747.352613ms 747.704739ms 747.767019ms 747.848979ms 748.122773ms 748.276456ms 748.339838ms 748.557165ms 748.68122ms 748.725552ms 748.736359ms 748.760311ms 748.86096ms 748.868992ms 748.991399ms 749.01517ms 749.127171ms 749.204953ms 749.249367ms 749.250845ms 749.292035ms 749.296761ms 749.407049ms 749.49055ms 749.492347ms 749.524985ms 749.528032ms 749.530979ms 749.594015ms 749.596691ms 749.598145ms 749.621784ms 749.634817ms 749.644767ms 749.726602ms 749.726757ms 749.747474ms 749.771421ms 749.792211ms 749.808116ms 749.814165ms 749.84525ms 749.852773ms 749.861796ms 749.894029ms 749.896183ms 749.913889ms 749.961593ms 749.975541ms 750.00688ms 750.008365ms 750.033183ms 750.042729ms 750.042936ms 750.050934ms 750.08124ms 750.094915ms 750.110967ms 750.151943ms 750.155952ms 750.168095ms 750.179608ms 750.183518ms 750.196621ms 750.200935ms 750.221595ms 750.222112ms 750.248149ms 750.295242ms 750.36367ms 750.376984ms 750.408056ms 750.514058ms 750.527165ms 750.575112ms 750.586945ms 750.709003ms 750.71183ms 750.753094ms 750.762858ms 750.791153ms 750.853287ms 750.88793ms 750.925686ms 750.933045ms 750.992518ms 751.029065ms 751.135707ms 751.146187ms 751.185718ms 751.388784ms 751.536433ms 751.643724ms 751.708071ms 751.709287ms 751.793913ms 751.826287ms 752.095361ms 752.099022ms 752.155628ms 752.337938ms 752.388647ms 752.924319ms 753.030238ms 753.258197ms 753.373196ms 753.570861ms 753.654482ms 753.668816ms 753.892936ms 753.962582ms 753.968792ms 754.05519ms 754.713047ms 754.795069ms 755.133803ms 755.792062ms 756.021166ms 756.348118ms 756.787767ms 757.19043ms 757.994957ms 758.506099ms 761.003475ms 769.186837ms]
Jun 14 13:01:00.673: INFO: 50 %ile: 749.524985ms
Jun 14 13:01:00.673: INFO: 90 %ile: 753.373196ms
Jun 14 13:01:00.673: INFO: 99 %ile: 761.003475ms
Jun 14 13:01:00.673: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:01:00.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-hpvgv" for this suite.
Jun 14 13:01:12.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:01:12.709: INFO: namespace: e2e-tests-svc-latency-hpvgv, resource: bindings, ignored listing per whitelist
Jun 14 13:01:12.743: INFO: namespace e2e-tests-svc-latency-hpvgv deletion completed in 12.066982504s

• [SLOW TEST:22.846 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:01:12.743: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jun 14 13:01:12.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:13.045: INFO: stderr: ""
Jun 14 13:01:13.045: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 14 13:01:13.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:13.101: INFO: stderr: ""
Jun 14 13:01:13.101: INFO: stdout: "update-demo-nautilus-bzp4l update-demo-nautilus-fx8b9 "
Jun 14 13:01:13.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-bzp4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:13.154: INFO: stderr: ""
Jun 14 13:01:13.154: INFO: stdout: ""
Jun 14 13:01:13.154: INFO: update-demo-nautilus-bzp4l is created but not running
Jun 14 13:01:18.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:18.206: INFO: stderr: ""
Jun 14 13:01:18.206: INFO: stdout: "update-demo-nautilus-bzp4l update-demo-nautilus-fx8b9 "
Jun 14 13:01:18.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-bzp4l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:18.257: INFO: stderr: ""
Jun 14 13:01:18.257: INFO: stdout: "true"
Jun 14 13:01:18.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-bzp4l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:18.307: INFO: stderr: ""
Jun 14 13:01:18.307: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 13:01:18.307: INFO: validating pod update-demo-nautilus-bzp4l
Jun 14 13:01:18.322: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 13:01:18.322: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 13:01:18.322: INFO: update-demo-nautilus-bzp4l is verified up and running
Jun 14 13:01:18.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:18.372: INFO: stderr: ""
Jun 14 13:01:18.372: INFO: stdout: "true"
Jun 14 13:01:18.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:18.421: INFO: stderr: ""
Jun 14 13:01:18.421: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 13:01:18.421: INFO: validating pod update-demo-nautilus-fx8b9
Jun 14 13:01:18.430: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 13:01:18.430: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 13:01:18.430: INFO: update-demo-nautilus-fx8b9 is verified up and running
STEP: scaling down the replication controller
Jun 14 13:01:18.431: INFO: scanned /root for discovery docs: <nil>
Jun 14 13:01:18.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:19.501: INFO: stderr: ""
Jun 14 13:01:19.501: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 14 13:01:19.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:19.556: INFO: stderr: ""
Jun 14 13:01:19.556: INFO: stdout: "update-demo-nautilus-bzp4l update-demo-nautilus-fx8b9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 14 13:01:24.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:24.612: INFO: stderr: ""
Jun 14 13:01:24.612: INFO: stdout: "update-demo-nautilus-bzp4l update-demo-nautilus-fx8b9 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 14 13:01:29.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:29.670: INFO: stderr: ""
Jun 14 13:01:29.670: INFO: stdout: "update-demo-nautilus-fx8b9 "
Jun 14 13:01:29.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:29.723: INFO: stderr: ""
Jun 14 13:01:29.723: INFO: stdout: "true"
Jun 14 13:01:29.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:29.774: INFO: stderr: ""
Jun 14 13:01:29.774: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 13:01:29.774: INFO: validating pod update-demo-nautilus-fx8b9
Jun 14 13:01:29.778: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 13:01:29.778: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 13:01:29.778: INFO: update-demo-nautilus-fx8b9 is verified up and running
STEP: scaling up the replication controller
Jun 14 13:01:29.778: INFO: scanned /root for discovery docs: <nil>
Jun 14 13:01:29.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:30.860: INFO: stderr: ""
Jun 14 13:01:30.860: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 14 13:01:30.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:30.922: INFO: stderr: ""
Jun 14 13:01:30.922: INFO: stdout: "update-demo-nautilus-fx8b9 update-demo-nautilus-mgj57 "
Jun 14 13:01:30.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:30.975: INFO: stderr: ""
Jun 14 13:01:30.975: INFO: stdout: "true"
Jun 14 13:01:30.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:31.026: INFO: stderr: ""
Jun 14 13:01:31.026: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 13:01:31.026: INFO: validating pod update-demo-nautilus-fx8b9
Jun 14 13:01:31.032: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 13:01:31.032: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 13:01:31.032: INFO: update-demo-nautilus-fx8b9 is verified up and running
Jun 14 13:01:31.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-mgj57 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:31.083: INFO: stderr: ""
Jun 14 13:01:31.083: INFO: stdout: ""
Jun 14 13:01:31.083: INFO: update-demo-nautilus-mgj57 is created but not running
Jun 14 13:01:36.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:36.137: INFO: stderr: ""
Jun 14 13:01:36.137: INFO: stdout: "update-demo-nautilus-fx8b9 update-demo-nautilus-mgj57 "
Jun 14 13:01:36.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:36.189: INFO: stderr: ""
Jun 14 13:01:36.189: INFO: stdout: "true"
Jun 14 13:01:36.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-fx8b9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:36.244: INFO: stderr: ""
Jun 14 13:01:36.244: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 13:01:36.244: INFO: validating pod update-demo-nautilus-fx8b9
Jun 14 13:01:36.247: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 13:01:36.247: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 13:01:36.247: INFO: update-demo-nautilus-fx8b9 is verified up and running
Jun 14 13:01:36.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-mgj57 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:36.296: INFO: stderr: ""
Jun 14 13:01:36.296: INFO: stdout: "true"
Jun 14 13:01:36.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods update-demo-nautilus-mgj57 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:36.345: INFO: stderr: ""
Jun 14 13:01:36.345: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 14 13:01:36.345: INFO: validating pod update-demo-nautilus-mgj57
Jun 14 13:01:36.357: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 14 13:01:36.357: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 14 13:01:36.357: INFO: update-demo-nautilus-mgj57 is verified up and running
STEP: using delete to clean up resources
Jun 14 13:01:36.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:36.410: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 13:01:36.410: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 14 13:01:36.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-c5bj8'
Jun 14 13:01:36.473: INFO: stderr: "No resources found.\n"
Jun 14 13:01:36.473: INFO: stdout: ""
Jun 14 13:01:36.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -l name=update-demo --namespace=e2e-tests-kubectl-c5bj8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 14 13:01:36.526: INFO: stderr: ""
Jun 14 13:01:36.526: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:01:36.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c5bj8" for this suite.
Jun 14 13:01:58.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:01:58.595: INFO: namespace: e2e-tests-kubectl-c5bj8, resource: bindings, ignored listing per whitelist
Jun 14 13:01:58.598: INFO: namespace e2e-tests-kubectl-c5bj8 deletion completed in 22.069880746s

• [SLOW TEST:45.855 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:01:58.598: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-btlq9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 14 13:01:58.661: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 14 13:02:22.708: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.16.0.29 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-btlq9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 13:02:22.708: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 13:02:23.769: INFO: Found all expected endpoints: [netserver-0]
Jun 14 13:02:23.771: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.16.0.62 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-btlq9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 14 13:02:23.771: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
Jun 14 13:02:24.825: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:02:24.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-btlq9" for this suite.
Jun 14 13:02:46.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:02:46.877: INFO: namespace: e2e-tests-pod-network-test-btlq9, resource: bindings, ignored listing per whitelist
Jun 14 13:02:46.887: INFO: namespace e2e-tests-pod-network-test-btlq9 deletion completed in 22.058994926s

• [SLOW TEST:48.288 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:02:46.887: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-fkq66
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fkq66 to expose endpoints map[]
Jun 14 13:02:46.941: INFO: Get endpoints failed (1.455852ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jun 14 13:02:47.943: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fkq66 exposes endpoints map[] (1.003657286s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-fkq66
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fkq66 to expose endpoints map[pod1:[80]]
Jun 14 13:02:49.962: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fkq66 exposes endpoints map[pod1:[80]] (2.014017356s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-fkq66
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fkq66 to expose endpoints map[pod1:[80] pod2:[80]]
Jun 14 13:02:52.018: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fkq66 exposes endpoints map[pod1:[80] pod2:[80]] (2.052616377s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-fkq66
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fkq66 to expose endpoints map[pod2:[80]]
Jun 14 13:02:53.032: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fkq66 exposes endpoints map[pod2:[80]] (1.008384032s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-fkq66
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-fkq66 to expose endpoints map[]
Jun 14 13:02:54.049: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-fkq66 exposes endpoints map[] (1.003814339s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:02:54.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-fkq66" for this suite.
Jun 14 13:03:16.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:03:16.108: INFO: namespace: e2e-tests-services-fkq66, resource: bindings, ignored listing per whitelist
Jun 14 13:03:16.124: INFO: namespace e2e-tests-services-fkq66 deletion completed in 22.058617952s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.237 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:03:16.124: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 14 13:03:16.173: INFO: Waiting up to 5m0s for pod "pod-c62625b5-8ea4-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-kkwnq" to be "success or failure"
Jun 14 13:03:16.175: INFO: Pod "pod-c62625b5-8ea4-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.168708ms
Jun 14 13:03:18.178: INFO: Pod "pod-c62625b5-8ea4-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004694652s
STEP: Saw pod success
Jun 14 13:03:18.178: INFO: Pod "pod-c62625b5-8ea4-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:03:18.180: INFO: Trying to get logs from node 192.168.0.235 pod pod-c62625b5-8ea4-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 13:03:18.198: INFO: Waiting for pod pod-c62625b5-8ea4-11e9-82a6-0255ac100014 to disappear
Jun 14 13:03:18.199: INFO: Pod pod-c62625b5-8ea4-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:03:18.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kkwnq" for this suite.
Jun 14 13:03:24.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:03:24.236: INFO: namespace: e2e-tests-emptydir-kkwnq, resource: bindings, ignored listing per whitelist
Jun 14 13:03:24.259: INFO: namespace e2e-tests-emptydir-kkwnq deletion completed in 6.057635489s

• [SLOW TEST:8.135 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:03:24.259: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-caff1437-8ea4-11e9-82a6-0255ac100014
STEP: Creating secret with name s-test-opt-upd-caff146c-8ea4-11e9-82a6-0255ac100014
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-caff1437-8ea4-11e9-82a6-0255ac100014
STEP: Updating secret s-test-opt-upd-caff146c-8ea4-11e9-82a6-0255ac100014
STEP: Creating secret with name s-test-opt-create-caff148e-8ea4-11e9-82a6-0255ac100014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:04:52.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wvdjn" for this suite.
Jun 14 13:05:14.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:05:14.689: INFO: namespace: e2e-tests-projected-wvdjn, resource: bindings, ignored listing per whitelist
Jun 14 13:05:14.706: INFO: namespace e2e-tests-projected-wvdjn deletion completed in 22.057685555s

• [SLOW TEST:110.447 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:05:14.706: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:05:16.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-94wsc" for this suite.
Jun 14 13:05:56.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:05:56.839: INFO: namespace: e2e-tests-kubelet-test-94wsc, resource: bindings, ignored listing per whitelist
Jun 14 13:05:56.852: INFO: namespace e2e-tests-kubelet-test-94wsc deletion completed in 40.066081455s

• [SLOW TEST:42.147 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:05:56.853: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-v6ql5/secret-test-25f37c96-8ea5-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 13:05:56.906: INFO: Waiting up to 5m0s for pod "pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-v6ql5" to be "success or failure"
Jun 14 13:05:56.907: INFO: Pod "pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.409908ms
Jun 14 13:05:58.910: INFO: Pod "pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003981582s
Jun 14 13:06:00.915: INFO: Pod "pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009420987s
STEP: Saw pod success
Jun 14 13:06:00.915: INFO: Pod "pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:06:00.917: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014 container env-test: <nil>
STEP: delete the pod
Jun 14 13:06:00.930: INFO: Waiting for pod pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014 to disappear
Jun 14 13:06:00.931: INFO: Pod pod-configmaps-25f41866-8ea5-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:06:00.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v6ql5" for this suite.
Jun 14 13:06:06.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:06:06.975: INFO: namespace: e2e-tests-secrets-v6ql5, resource: bindings, ignored listing per whitelist
Jun 14 13:06:06.991: INFO: namespace e2e-tests-secrets-v6ql5 deletion completed in 6.057804614s

• [SLOW TEST:10.139 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:06:06.991: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-svmvn
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-svmvn
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-svmvn
Jun 14 13:06:07.051: INFO: Found 0 stateful pods, waiting for 1
Jun 14 13:06:17.056: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jun 14 13:06:17.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-svmvn ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 13:06:17.169: INFO: stderr: ""
Jun 14 13:06:17.169: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 13:06:17.169: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 13:06:17.172: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 14 13:06:27.180: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 13:06:27.180: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 13:06:27.190: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:27.190: INFO: ss-0  192.168.0.235  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:27.191: INFO: 
Jun 14 13:06:27.191: INFO: StatefulSet ss has not reached scale 3, at 1
Jun 14 13:06:28.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998200494s
Jun 14 13:06:29.197: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995417211s
Jun 14 13:06:30.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.99201809s
Jun 14 13:06:31.202: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989190146s
Jun 14 13:06:32.205: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.986540305s
Jun 14 13:06:33.208: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.983827143s
Jun 14 13:06:34.210: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.980938391s
Jun 14 13:06:35.213: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.978472601s
Jun 14 13:06:36.216: INFO: Verifying statefulset ss doesn't scale past 3 for another 975.653136ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-svmvn
Jun 14 13:06:37.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-svmvn ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 13:06:37.334: INFO: stderr: ""
Jun 14 13:06:37.334: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 13:06:37.334: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 13:06:37.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-svmvn ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 13:06:37.452: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jun 14 13:06:37.452: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 13:06:37.452: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 13:06:37.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-svmvn ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 14 13:06:37.571: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jun 14 13:06:37.571: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 14 13:06:37.571: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 14 13:06:37.573: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 13:06:37.573: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 14 13:06:37.573: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jun 14 13:06:37.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-svmvn ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 13:06:37.687: INFO: stderr: ""
Jun 14 13:06:37.687: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 13:06:37.687: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 13:06:37.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-svmvn ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 13:06:37.792: INFO: stderr: ""
Jun 14 13:06:37.792: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 13:06:37.792: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 13:06:37.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 exec --namespace=e2e-tests-statefulset-svmvn ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 14 13:06:37.897: INFO: stderr: ""
Jun 14 13:06:37.897: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 14 13:06:37.897: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 14 13:06:37.897: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 13:06:37.899: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jun 14 13:06:47.907: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 13:06:47.907: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 13:06:47.908: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 14 13:06:47.915: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:47.915: INFO: ss-0  192.168.0.235  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:47.915: INFO: ss-1  192.168.0.19   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:47.915: INFO: ss-2  192.168.0.19   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:47.915: INFO: 
Jun 14 13:06:47.915: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:48.918: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:48.918: INFO: ss-0  192.168.0.235  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:48.918: INFO: ss-1  192.168.0.19   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:48.918: INFO: ss-2  192.168.0.19   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:48.918: INFO: 
Jun 14 13:06:48.918: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:49.921: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:49.921: INFO: ss-0  192.168.0.235  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:49.921: INFO: ss-1  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:49.921: INFO: ss-2  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:49.921: INFO: 
Jun 14 13:06:49.921: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:50.924: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:50.924: INFO: ss-0  192.168.0.235  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:50.924: INFO: ss-1  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:50.924: INFO: ss-2  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:50.924: INFO: 
Jun 14 13:06:50.924: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:51.927: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:51.927: INFO: ss-0  192.168.0.235  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:51.927: INFO: ss-1  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:51.927: INFO: ss-2  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:51.927: INFO: 
Jun 14 13:06:51.927: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:52.930: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:52.930: INFO: ss-0  192.168.0.235  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:52.930: INFO: ss-1  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:52.930: INFO: ss-2  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:52.930: INFO: 
Jun 14 13:06:52.930: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:53.933: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:53.933: INFO: ss-0  192.168.0.235  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:53.933: INFO: ss-1  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:53.933: INFO: ss-2  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:53.933: INFO: 
Jun 14 13:06:53.933: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:54.935: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:54.935: INFO: ss-0  192.168.0.235  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:54.935: INFO: ss-1  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:54.935: INFO: ss-2  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:54.935: INFO: 
Jun 14 13:06:54.935: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:55.938: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Jun 14 13:06:55.938: INFO: ss-0  192.168.0.235  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:07 +0000 UTC  }]
Jun 14 13:06:55.938: INFO: ss-1  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:55.938: INFO: ss-2  192.168.0.19   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:06:27 +0000 UTC  }]
Jun 14 13:06:55.938: INFO: 
Jun 14 13:06:55.938: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 14 13:06:56.941: INFO: Verifying statefulset ss doesn't scale past 0 for another 974.56676ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-svmvn
Jun 14 13:06:57.946: INFO: Scaling statefulset ss to 0
Jun 14 13:06:57.952: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 14 13:06:57.953: INFO: Deleting all statefulset in ns e2e-tests-statefulset-svmvn
Jun 14 13:06:57.955: INFO: Scaling statefulset ss to 0
Jun 14 13:06:57.959: INFO: Waiting for statefulset status.replicas updated to 0
Jun 14 13:06:57.961: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:06:57.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-svmvn" for this suite.
Jun 14 13:07:03.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:07:03.994: INFO: namespace: e2e-tests-statefulset-svmvn, resource: bindings, ignored listing per whitelist
Jun 14 13:07:04.030: INFO: namespace e2e-tests-statefulset-svmvn deletion completed in 6.060474383s

• [SLOW TEST:57.039 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:07:04.030: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:07:04.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-6b5t8" for this suite.
Jun 14 13:07:10.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:07:10.109: INFO: namespace: e2e-tests-services-6b5t8, resource: bindings, ignored listing per whitelist
Jun 14 13:07:10.133: INFO: namespace e2e-tests-services-6b5t8 deletion completed in 6.055612121s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.103 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:07:10.133: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jun 14 13:07:14.193: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-51a15057-8ea5-11e9-82a6-0255ac100014", GenerateName:"", Namespace:"e2e-tests-pods-m8wkk", SelfLink:"/api/v1/namespaces/e2e-tests-pods-m8wkk/pods/pod-submit-remove-51a15057-8ea5-11e9-82a6-0255ac100014", UID:"51b847ca-8ea5-11e9-a0dc-fa163eff1b62", ResourceVersion:"49997", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63696114430, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"178520775"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-stg5b", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001dda300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-stg5b", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001baa068), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.0.235", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000c46000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001baa0b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001baa0d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001baa0d8), DNSConfig:(*v1.PodDNSConfig)(0xc0021b4190), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001baa0e7)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696114430, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696114432, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696114432, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696114430, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.235", PodIP:"172.16.0.57", StartTime:(*v1.Time)(0xc00251aa00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00251aac0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://cd61b308045ccfb55ef4045bf8012f405af5fa49ae9ebdd021c82608ed763a61"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jun 14 13:07:19.206: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:07:19.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m8wkk" for this suite.
Jun 14 13:07:25.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:07:25.255: INFO: namespace: e2e-tests-pods-m8wkk, resource: bindings, ignored listing per whitelist
Jun 14 13:07:25.266: INFO: namespace e2e-tests-pods-m8wkk deletion completed in 6.056448297s

• [SLOW TEST:15.133 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:07:25.266: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-5aa64a69-8ea5-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 13:07:25.320: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-679xh" to be "success or failure"
Jun 14 13:07:25.322: INFO: Pod "pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.74219ms
Jun 14 13:07:27.324: INFO: Pod "pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004215868s
Jun 14 13:07:29.330: INFO: Pod "pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010209075s
STEP: Saw pod success
Jun 14 13:07:29.330: INFO: Pod "pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:07:29.332: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 13:07:29.343: INFO: Waiting for pod pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014 to disappear
Jun 14 13:07:29.344: INFO: Pod pod-projected-configmaps-5aa6f2d7-8ea5-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:07:29.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-679xh" for this suite.
Jun 14 13:07:35.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:07:35.395: INFO: namespace: e2e-tests-projected-679xh, resource: bindings, ignored listing per whitelist
Jun 14 13:07:35.404: INFO: namespace e2e-tests-projected-679xh deletion completed in 6.057629891s

• [SLOW TEST:10.137 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:07:35.404: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 13:07:35.452: INFO: (0) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.584569ms)
Jun 14 13:07:35.455: INFO: (1) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.49309ms)
Jun 14 13:07:35.457: INFO: (2) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.17611ms)
Jun 14 13:07:35.459: INFO: (3) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.043495ms)
Jun 14 13:07:35.461: INFO: (4) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.048913ms)
Jun 14 13:07:35.463: INFO: (5) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.972394ms)
Jun 14 13:07:35.467: INFO: (6) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.163178ms)
Jun 14 13:07:35.469: INFO: (7) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.191804ms)
Jun 14 13:07:35.471: INFO: (8) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.991462ms)
Jun 14 13:07:35.474: INFO: (9) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.080842ms)
Jun 14 13:07:35.476: INFO: (10) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.03019ms)
Jun 14 13:07:35.478: INFO: (11) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.993541ms)
Jun 14 13:07:35.480: INFO: (12) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.050504ms)
Jun 14 13:07:35.484: INFO: (13) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.993867ms)
Jun 14 13:07:35.486: INFO: (14) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.034906ms)
Jun 14 13:07:35.488: INFO: (15) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.051987ms)
Jun 14 13:07:35.490: INFO: (16) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 1.977308ms)
Jun 14 13:07:35.492: INFO: (17) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.072401ms)
Jun 14 13:07:35.494: INFO: (18) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.036006ms)
Jun 14 13:07:35.496: INFO: (19) /api/v1/nodes/192.168.0.19:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 2.292212ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:07:35.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-2f64c" for this suite.
Jun 14 13:07:41.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:07:41.512: INFO: namespace: e2e-tests-proxy-2f64c, resource: bindings, ignored listing per whitelist
Jun 14 13:07:41.556: INFO: namespace e2e-tests-proxy-2f64c deletion completed in 6.057591294s

• [SLOW TEST:6.152 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:07:41.556: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 14 13:07:41.602: INFO: Waiting up to 5m0s for pod "pod-645b64c0-8ea5-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-pvf2h" to be "success or failure"
Jun 14 13:07:41.604: INFO: Pod "pod-645b64c0-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.661156ms
Jun 14 13:07:43.606: INFO: Pod "pod-645b64c0-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004184456s
Jun 14 13:07:45.609: INFO: Pod "pod-645b64c0-8ea5-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006682336s
STEP: Saw pod success
Jun 14 13:07:45.609: INFO: Pod "pod-645b64c0-8ea5-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:07:45.611: INFO: Trying to get logs from node 192.168.0.235 pod pod-645b64c0-8ea5-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 13:07:45.624: INFO: Waiting for pod pod-645b64c0-8ea5-11e9-82a6-0255ac100014 to disappear
Jun 14 13:07:45.625: INFO: Pod pod-645b64c0-8ea5-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:07:45.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pvf2h" for this suite.
Jun 14 13:07:51.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:07:51.662: INFO: namespace: e2e-tests-emptydir-pvf2h, resource: bindings, ignored listing per whitelist
Jun 14 13:07:51.684: INFO: namespace e2e-tests-emptydir-pvf2h deletion completed in 6.0572555s

• [SLOW TEST:10.128 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:07:51.684: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 13:07:51.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a661793-8ea5-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-dlbv2" to be "success or failure"
Jun 14 13:07:51.745: INFO: Pod "downwardapi-volume-6a661793-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 3.893287ms
Jun 14 13:07:53.747: INFO: Pod "downwardapi-volume-6a661793-8ea5-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006043051s
STEP: Saw pod success
Jun 14 13:07:53.747: INFO: Pod "downwardapi-volume-6a661793-8ea5-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:07:53.748: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-6a661793-8ea5-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 13:07:53.765: INFO: Waiting for pod downwardapi-volume-6a661793-8ea5-11e9-82a6-0255ac100014 to disappear
Jun 14 13:07:53.767: INFO: Pod downwardapi-volume-6a661793-8ea5-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:07:53.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dlbv2" for this suite.
Jun 14 13:07:59.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:07:59.792: INFO: namespace: e2e-tests-projected-dlbv2, resource: bindings, ignored listing per whitelist
Jun 14 13:07:59.827: INFO: namespace e2e-tests-projected-dlbv2 deletion completed in 6.058485365s

• [SLOW TEST:8.143 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:07:59.827: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:08:03.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7mhmx" for this suite.
Jun 14 13:08:09.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:08:09.924: INFO: namespace: e2e-tests-kubelet-test-7mhmx, resource: bindings, ignored listing per whitelist
Jun 14 13:08:09.941: INFO: namespace e2e-tests-kubelet-test-7mhmx deletion completed in 6.060498824s

• [SLOW TEST:10.114 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:08:09.941: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jun 14 13:08:10.002: INFO: Pod name pod-release: Found 0 pods out of 1
Jun 14 13:08:15.005: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:08:16.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-b4h8c" for this suite.
Jun 14 13:08:22.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:08:22.056: INFO: namespace: e2e-tests-replication-controller-b4h8c, resource: bindings, ignored listing per whitelist
Jun 14 13:08:22.083: INFO: namespace e2e-tests-replication-controller-b4h8c deletion completed in 6.062526609s

• [SLOW TEST:12.142 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:08:22.083: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7c855c5d-8ea5-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 13:08:22.146: INFO: Waiting up to 5m0s for pod "pod-secrets-7c8625dd-8ea5-11e9-82a6-0255ac100014" in namespace "e2e-tests-secrets-7hlrr" to be "success or failure"
Jun 14 13:08:22.148: INFO: Pod "pod-secrets-7c8625dd-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.951033ms
Jun 14 13:08:24.150: INFO: Pod "pod-secrets-7c8625dd-8ea5-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004158587s
STEP: Saw pod success
Jun 14 13:08:24.150: INFO: Pod "pod-secrets-7c8625dd-8ea5-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:08:24.152: INFO: Trying to get logs from node 192.168.0.235 pod pod-secrets-7c8625dd-8ea5-11e9-82a6-0255ac100014 container secret-volume-test: <nil>
STEP: delete the pod
Jun 14 13:08:24.164: INFO: Waiting for pod pod-secrets-7c8625dd-8ea5-11e9-82a6-0255ac100014 to disappear
Jun 14 13:08:24.166: INFO: Pod pod-secrets-7c8625dd-8ea5-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:08:24.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7hlrr" for this suite.
Jun 14 13:08:30.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:08:30.236: INFO: namespace: e2e-tests-secrets-7hlrr, resource: bindings, ignored listing per whitelist
Jun 14 13:08:30.254: INFO: namespace e2e-tests-secrets-7hlrr deletion completed in 6.085759656s

• [SLOW TEST:8.171 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:08:30.254: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 14 13:08:30.321: INFO: Number of nodes with available pods: 0
Jun 14 13:08:30.321: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:31.326: INFO: Number of nodes with available pods: 0
Jun 14 13:08:31.326: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:32.326: INFO: Number of nodes with available pods: 1
Jun 14 13:08:32.326: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:33.325: INFO: Number of nodes with available pods: 2
Jun 14 13:08:33.325: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jun 14 13:08:33.337: INFO: Number of nodes with available pods: 1
Jun 14 13:08:33.337: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:34.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:34.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:35.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:35.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:36.343: INFO: Number of nodes with available pods: 1
Jun 14 13:08:36.343: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:37.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:37.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:38.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:38.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:39.342: INFO: Number of nodes with available pods: 1
Jun 14 13:08:39.342: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:40.344: INFO: Number of nodes with available pods: 1
Jun 14 13:08:40.344: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:41.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:41.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:42.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:42.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:43.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:43.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:44.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:44.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:45.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:45.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:46.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:46.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:47.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:47.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:48.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:48.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:49.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:49.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:50.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:50.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:51.344: INFO: Number of nodes with available pods: 1
Jun 14 13:08:51.344: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:52.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:52.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:53.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:53.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:54.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:54.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:55.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:55.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:56.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:56.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:57.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:57.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:58.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:58.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:08:59.341: INFO: Number of nodes with available pods: 1
Jun 14 13:08:59.342: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:00.341: INFO: Number of nodes with available pods: 1
Jun 14 13:09:00.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:01.341: INFO: Number of nodes with available pods: 1
Jun 14 13:09:01.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:02.344: INFO: Number of nodes with available pods: 1
Jun 14 13:09:02.344: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:03.341: INFO: Number of nodes with available pods: 1
Jun 14 13:09:03.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:04.341: INFO: Number of nodes with available pods: 1
Jun 14 13:09:04.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:05.341: INFO: Number of nodes with available pods: 1
Jun 14 13:09:05.342: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:06.341: INFO: Number of nodes with available pods: 1
Jun 14 13:09:06.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:07.341: INFO: Number of nodes with available pods: 1
Jun 14 13:09:07.341: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:08.342: INFO: Number of nodes with available pods: 1
Jun 14 13:09:08.342: INFO: Node 192.168.0.19 is running more than one daemon pod
Jun 14 13:09:09.341: INFO: Number of nodes with available pods: 2
Jun 14 13:09:09.341: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-9k7q4, will wait for the garbage collector to delete the pods
Jun 14 13:09:09.400: INFO: Deleting DaemonSet.extensions daemon-set took: 5.717383ms
Jun 14 13:09:09.500: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.136578ms
Jun 14 13:09:46.405: INFO: Number of nodes with available pods: 0
Jun 14 13:09:46.405: INFO: Number of running nodes: 0, number of available pods: 0
Jun 14 13:09:46.407: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9k7q4/daemonsets","resourceVersion":"50627"},"items":null}

Jun 14 13:09:46.408: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9k7q4/pods","resourceVersion":"50627"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:09:46.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9k7q4" for this suite.
Jun 14 13:09:52.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:09:52.459: INFO: namespace: e2e-tests-daemonsets-9k7q4, resource: bindings, ignored listing per whitelist
Jun 14 13:09:52.488: INFO: namespace e2e-tests-daemonsets-9k7q4 deletion completed in 6.066113244s

• [SLOW TEST:82.234 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:09:52.488: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 14 13:09:52.533: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:09:56.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vmwk2" for this suite.
Jun 14 13:10:02.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:10:02.732: INFO: namespace: e2e-tests-init-container-vmwk2, resource: bindings, ignored listing per whitelist
Jun 14 13:10:02.768: INFO: namespace e2e-tests-init-container-vmwk2 deletion completed in 6.055788136s

• [SLOW TEST:10.280 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:10:02.768: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-b886e075-8ea5-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 13:10:02.822: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b887b6cd-8ea5-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-bbzwh" to be "success or failure"
Jun 14 13:10:02.823: INFO: Pod "pod-projected-secrets-b887b6cd-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.530255ms
Jun 14 13:10:04.826: INFO: Pod "pod-projected-secrets-b887b6cd-8ea5-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003714067s
STEP: Saw pod success
Jun 14 13:10:04.826: INFO: Pod "pod-projected-secrets-b887b6cd-8ea5-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:10:04.827: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-secrets-b887b6cd-8ea5-11e9-82a6-0255ac100014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 14 13:10:04.843: INFO: Waiting for pod pod-projected-secrets-b887b6cd-8ea5-11e9-82a6-0255ac100014 to disappear
Jun 14 13:10:04.845: INFO: Pod pod-projected-secrets-b887b6cd-8ea5-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:10:04.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bbzwh" for this suite.
Jun 14 13:10:10.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:10:10.930: INFO: namespace: e2e-tests-projected-bbzwh, resource: bindings, ignored listing per whitelist
Jun 14 13:10:10.932: INFO: namespace e2e-tests-projected-bbzwh deletion completed in 6.084481475s

• [SLOW TEST:8.163 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:10:10.932: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 13:10:13.000: INFO: Waiting up to 5m0s for pod "client-envvars-be991719-8ea5-11e9-82a6-0255ac100014" in namespace "e2e-tests-pods-pf8pf" to be "success or failure"
Jun 14 13:10:13.002: INFO: Pod "client-envvars-be991719-8ea5-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.585554ms
Jun 14 13:10:15.005: INFO: Pod "client-envvars-be991719-8ea5-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005127549s
STEP: Saw pod success
Jun 14 13:10:15.005: INFO: Pod "client-envvars-be991719-8ea5-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:10:15.006: INFO: Trying to get logs from node 192.168.0.19 pod client-envvars-be991719-8ea5-11e9-82a6-0255ac100014 container env3cont: <nil>
STEP: delete the pod
Jun 14 13:10:15.020: INFO: Waiting for pod client-envvars-be991719-8ea5-11e9-82a6-0255ac100014 to disappear
Jun 14 13:10:15.023: INFO: Pod client-envvars-be991719-8ea5-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:10:15.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pf8pf" for this suite.
Jun 14 13:11:01.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:11:01.036: INFO: namespace: e2e-tests-pods-pf8pf, resource: bindings, ignored listing per whitelist
Jun 14 13:11:01.081: INFO: namespace e2e-tests-pods-pf8pf deletion completed in 46.056313186s

• [SLOW TEST:50.149 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:11:01.081: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 14 13:11:01.134: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 14 13:11:01.138: INFO: Waiting for terminating namespaces to be deleted...
Jun 14 13:11:01.139: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.19 before test
Jun 14 13:11:01.144: INFO: web-terminal-78fcf4fd59-smd5z from default started at 2019-06-14 09:17:03 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.144: INFO: 	Container web-terminal ready: true, restart count 0
Jun 14 13:11:01.144: INFO: sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-8q7tm from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 13:11:01.144: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 14 13:11:01.144: INFO: 	Container systemd-logs ready: true, restart count 1
Jun 14 13:11:01.144: INFO: storage-driver-pz5nn from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.144: INFO: 	Container storage-driver ready: true, restart count 0
Jun 14 13:11:01.144: INFO: icagent-pbhr4 from kube-system started at 2019-06-14 08:59:55 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.144: INFO: 	Container icagent ready: true, restart count 0
Jun 14 13:11:01.144: INFO: coredns-7d456d978c-xkjtl from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.144: INFO: 	Container coredns ready: true, restart count 0
Jun 14 13:11:01.144: INFO: sonobuoy-e2e-job-99d77d11689f4bcf from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 13:11:01.144: INFO: 	Container e2e ready: true, restart count 0
Jun 14 13:11:01.144: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 14 13:11:01.144: INFO: 
Logging pods the kubelet thinks is on node 192.168.0.235 before test
Jun 14 13:11:01.154: INFO: icagent-qzxb7 from kube-system started at 2019-06-14 08:59:56 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.154: INFO: 	Container icagent ready: true, restart count 0
Jun 14 13:11:01.154: INFO: sonobuoy-systemd-logs-daemon-set-77e83a72e3f8456c-t2dvh from heptio-sonobuoy started at 2019-06-14 11:56:03 +0000 UTC (2 container statuses recorded)
Jun 14 13:11:01.154: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 14 13:11:01.154: INFO: 	Container systemd-logs ready: true, restart count 1
Jun 14 13:11:01.154: INFO: storage-driver-m898l from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.154: INFO: 	Container storage-driver ready: true, restart count 0
Jun 14 13:11:01.154: INFO: coredns-7d456d978c-vklzn from kube-system started at 2019-06-14 08:59:11 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.154: INFO: 	Container coredns ready: true, restart count 0
Jun 14 13:11:01.154: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-14 11:55:55 +0000 UTC (1 container statuses recorded)
Jun 14 13:11:01.154: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a812ba15644093], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:11:02.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-m4wtt" for this suite.
Jun 14 13:11:08.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:11:08.181: INFO: namespace: e2e-tests-sched-pred-m4wtt, resource: bindings, ignored listing per whitelist
Jun 14 13:11:08.224: INFO: namespace e2e-tests-sched-pred-m4wtt deletion completed in 6.054478314s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.143 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:11:08.224: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 14 13:11:12.305: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 14 13:11:12.306: INFO: Pod pod-with-prestop-http-hook still exists
Jun 14 13:11:14.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 14 13:11:14.313: INFO: Pod pod-with-prestop-http-hook still exists
Jun 14 13:11:16.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 14 13:11:16.309: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:11:16.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hr2q9" for this suite.
Jun 14 13:11:38.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:11:38.358: INFO: namespace: e2e-tests-container-lifecycle-hook-hr2q9, resource: bindings, ignored listing per whitelist
Jun 14 13:11:38.372: INFO: namespace e2e-tests-container-lifecycle-hook-hr2q9 deletion completed in 22.055743872s

• [SLOW TEST:30.148 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:11:38.372: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jun 14 13:11:38.418: INFO: namespace e2e-tests-kubectl-vn4rn
Jun 14 13:11:38.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-vn4rn'
Jun 14 13:11:38.659: INFO: stderr: ""
Jun 14 13:11:38.659: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 14 13:11:39.662: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 13:11:39.662: INFO: Found 0 / 1
Jun 14 13:11:40.661: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 13:11:40.661: INFO: Found 1 / 1
Jun 14 13:11:40.661: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 14 13:11:40.664: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 13:11:40.664: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 14 13:11:40.664: INFO: wait on redis-master startup in e2e-tests-kubectl-vn4rn 
Jun 14 13:11:40.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 logs redis-master-pvzzm redis-master --namespace=e2e-tests-kubectl-vn4rn'
Jun 14 13:11:40.723: INFO: stderr: ""
Jun 14 13:11:40.723: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Jun 13:11:40.188 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Jun 13:11:40.188 # Server started, Redis version 3.2.12\n1:M 14 Jun 13:11:40.188 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Jun 13:11:40.188 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jun 14 13:11:40.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-vn4rn'
Jun 14 13:11:40.791: INFO: stderr: ""
Jun 14 13:11:40.792: INFO: stdout: "service/rm2 exposed\n"
Jun 14 13:11:40.794: INFO: Service rm2 in namespace e2e-tests-kubectl-vn4rn found.
STEP: exposing service
Jun 14 13:11:42.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-vn4rn'
Jun 14 13:11:42.861: INFO: stderr: ""
Jun 14 13:11:42.861: INFO: stdout: "service/rm3 exposed\n"
Jun 14 13:11:42.864: INFO: Service rm3 in namespace e2e-tests-kubectl-vn4rn found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:11:44.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vn4rn" for this suite.
Jun 14 13:12:06.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:12:06.897: INFO: namespace: e2e-tests-kubectl-vn4rn, resource: bindings, ignored listing per whitelist
Jun 14 13:12:06.936: INFO: namespace e2e-tests-kubectl-vn4rn deletion completed in 22.065387241s

• [SLOW TEST:28.564 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:12:06.936: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jun 14 13:12:06.985: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-059955192 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:12:07.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7hnfd" for this suite.
Jun 14 13:12:13.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:12:13.050: INFO: namespace: e2e-tests-kubectl-7hnfd, resource: bindings, ignored listing per whitelist
Jun 14 13:12:13.093: INFO: namespace e2e-tests-kubectl-7hnfd deletion completed in 6.056050358s

• [SLOW TEST:6.157 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:12:13.093: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 14 13:12:13.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-9smvn'
Jun 14 13:12:13.195: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 14 13:12:13.195: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jun 14 13:12:17.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-9smvn'
Jun 14 13:12:17.258: INFO: stderr: ""
Jun 14 13:12:17.258: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:12:17.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9smvn" for this suite.
Jun 14 13:12:39.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:12:39.305: INFO: namespace: e2e-tests-kubectl-9smvn, resource: bindings, ignored listing per whitelist
Jun 14 13:12:39.317: INFO: namespace e2e-tests-kubectl-9smvn deletion completed in 22.056395324s

• [SLOW TEST:26.224 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:12:39.317: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-15d6a3f6-8ea6-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 13:12:39.376: INFO: Waiting up to 5m0s for pod "pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-7bd2v" to be "success or failure"
Jun 14 13:12:39.377: INFO: Pod "pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.627423ms
Jun 14 13:12:41.383: INFO: Pod "pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007412035s
Jun 14 13:12:43.385: INFO: Pod "pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009717611s
STEP: Saw pod success
Jun 14 13:12:43.385: INFO: Pod "pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:12:43.387: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 13:12:43.402: INFO: Waiting for pod pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:12:43.403: INFO: Pod pod-configmaps-15d803e9-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:12:43.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7bd2v" for this suite.
Jun 14 13:12:49.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:12:49.418: INFO: namespace: e2e-tests-configmap-7bd2v, resource: bindings, ignored listing per whitelist
Jun 14 13:12:49.466: INFO: namespace e2e-tests-configmap-7bd2v deletion completed in 6.061269324s

• [SLOW TEST:10.150 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:12:49.466: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jun 14 13:12:49.521: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-fxlkd" to be "success or failure"
Jun 14 13:12:49.522: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.891793ms
Jun 14 13:12:51.530: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009051913s
Jun 14 13:12:53.532: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011782745s
STEP: Saw pod success
Jun 14 13:12:53.532: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jun 14 13:12:53.534: INFO: Trying to get logs from node 192.168.0.19 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jun 14 13:12:53.557: INFO: Waiting for pod pod-host-path-test to disappear
Jun 14 13:12:53.559: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:12:53.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-fxlkd" for this suite.
Jun 14 13:12:59.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:12:59.574: INFO: namespace: e2e-tests-hostpath-fxlkd, resource: bindings, ignored listing per whitelist
Jun 14 13:12:59.618: INFO: namespace e2e-tests-hostpath-fxlkd deletion completed in 6.057719275s

• [SLOW TEST:10.152 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:12:59.618: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 13:12:59.686: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-6bmj6" to be "success or failure"
Jun 14 13:12:59.688: INFO: Pod "downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.242859ms
Jun 14 13:13:01.694: INFO: Pod "downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007845625s
Jun 14 13:13:03.696: INFO: Pod "downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010312641s
STEP: Saw pod success
Jun 14 13:13:03.696: INFO: Pod "downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:13:03.698: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 13:13:03.713: INFO: Waiting for pod downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:13:03.715: INFO: Pod downwardapi-volume-21f16f36-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:13:03.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6bmj6" for this suite.
Jun 14 13:13:09.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:13:09.765: INFO: namespace: e2e-tests-downward-api-6bmj6, resource: bindings, ignored listing per whitelist
Jun 14 13:13:09.786: INFO: namespace e2e-tests-downward-api-6bmj6 deletion completed in 6.068901948s

• [SLOW TEST:10.168 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:13:09.786: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:13:13.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-p8qmq" for this suite.
Jun 14 13:13:57.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:13:57.890: INFO: namespace: e2e-tests-kubelet-test-p8qmq, resource: bindings, ignored listing per whitelist
Jun 14 13:13:57.920: INFO: namespace e2e-tests-kubelet-test-p8qmq deletion completed in 44.061255985s

• [SLOW TEST:48.134 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:13:57.920: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 13:13:57.972: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-d2vvw" to be "success or failure"
Jun 14 13:13:57.974: INFO: Pod "downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.793399ms
Jun 14 13:13:59.977: INFO: Pod "downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004615849s
Jun 14 13:14:01.980: INFO: Pod "downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00723581s
STEP: Saw pod success
Jun 14 13:14:01.980: INFO: Pod "downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:14:01.981: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 13:14:01.996: INFO: Waiting for pod downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:14:01.997: INFO: Pod downwardapi-volume-44b08c04-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:14:01.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2vvw" for this suite.
Jun 14 13:14:08.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:14:08.054: INFO: namespace: e2e-tests-projected-d2vvw, resource: bindings, ignored listing per whitelist
Jun 14 13:14:08.062: INFO: namespace e2e-tests-projected-d2vvw deletion completed in 6.06262613s

• [SLOW TEST:10.142 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:14:08.062: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 13:14:08.110: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4abbcbeb-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-downward-api-4zq8s" to be "success or failure"
Jun 14 13:14:08.112: INFO: Pod "downwardapi-volume-4abbcbeb-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.881428ms
Jun 14 13:14:10.115: INFO: Pod "downwardapi-volume-4abbcbeb-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004659607s
STEP: Saw pod success
Jun 14 13:14:10.115: INFO: Pod "downwardapi-volume-4abbcbeb-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:14:10.116: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-4abbcbeb-8ea6-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 13:14:10.137: INFO: Waiting for pod downwardapi-volume-4abbcbeb-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:14:10.139: INFO: Pod downwardapi-volume-4abbcbeb-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:14:10.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4zq8s" for this suite.
Jun 14 13:14:16.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:14:16.171: INFO: namespace: e2e-tests-downward-api-4zq8s, resource: bindings, ignored listing per whitelist
Jun 14 13:14:16.202: INFO: namespace e2e-tests-downward-api-4zq8s deletion completed in 6.059674576s

• [SLOW TEST:8.140 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:14:16.202: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-4lcg
STEP: Creating a pod to test atomic-volume-subpath
Jun 14 13:14:16.266: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4lcg" in namespace "e2e-tests-subpath-dzgdg" to be "success or failure"
Jun 14 13:14:16.267: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Pending", Reason="", readiness=false. Elapsed: 1.620713ms
Jun 14 13:14:18.273: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007083488s
Jun 14 13:14:20.277: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 4.011503932s
Jun 14 13:14:22.280: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 6.014217797s
Jun 14 13:14:24.283: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 8.016765135s
Jun 14 13:14:26.285: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 10.019487774s
Jun 14 13:14:28.291: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 12.025239466s
Jun 14 13:14:30.294: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 14.027806281s
Jun 14 13:14:32.296: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 16.030523931s
Jun 14 13:14:34.299: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 18.033133418s
Jun 14 13:14:36.301: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 20.035573259s
Jun 14 13:14:38.307: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Running", Reason="", readiness=false. Elapsed: 22.041407353s
Jun 14 13:14:40.310: INFO: Pod "pod-subpath-test-secret-4lcg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.044073494s
STEP: Saw pod success
Jun 14 13:14:40.310: INFO: Pod "pod-subpath-test-secret-4lcg" satisfied condition "success or failure"
Jun 14 13:14:40.312: INFO: Trying to get logs from node 192.168.0.235 pod pod-subpath-test-secret-4lcg container test-container-subpath-secret-4lcg: <nil>
STEP: delete the pod
Jun 14 13:14:40.325: INFO: Waiting for pod pod-subpath-test-secret-4lcg to disappear
Jun 14 13:14:40.326: INFO: Pod pod-subpath-test-secret-4lcg no longer exists
STEP: Deleting pod pod-subpath-test-secret-4lcg
Jun 14 13:14:40.326: INFO: Deleting pod "pod-subpath-test-secret-4lcg" in namespace "e2e-tests-subpath-dzgdg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:14:40.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dzgdg" for this suite.
Jun 14 13:14:46.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:14:46.378: INFO: namespace: e2e-tests-subpath-dzgdg, resource: bindings, ignored listing per whitelist
Jun 14 13:14:46.389: INFO: namespace e2e-tests-subpath-dzgdg deletion completed in 6.056457395s

• [SLOW TEST:30.187 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:14:46.389: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 14 13:14:46.443: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-t765v" to be "success or failure"
Jun 14 13:14:46.445: INFO: Pod "downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.812208ms
Jun 14 13:14:48.450: INFO: Pod "downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007131286s
Jun 14 13:14:50.452: INFO: Pod "downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009239775s
STEP: Saw pod success
Jun 14 13:14:50.452: INFO: Pod "downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:14:50.454: INFO: Trying to get logs from node 192.168.0.235 pod downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014 container client-container: <nil>
STEP: delete the pod
Jun 14 13:14:50.467: INFO: Waiting for pod downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:14:50.468: INFO: Pod downwardapi-volume-6194fde2-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:14:50.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t765v" for this suite.
Jun 14 13:14:56.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:14:56.506: INFO: namespace: e2e-tests-projected-t765v, resource: bindings, ignored listing per whitelist
Jun 14 13:14:56.531: INFO: namespace e2e-tests-projected-t765v deletion completed in 6.060634259s

• [SLOW TEST:10.143 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:14:56.531: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jun 14 13:14:56.587: INFO: Waiting up to 5m0s for pod "pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-65mj5" to be "success or failure"
Jun 14 13:14:56.590: INFO: Pod "pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.364909ms
Jun 14 13:14:58.595: INFO: Pod "pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007915392s
Jun 14 13:15:00.598: INFO: Pod "pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010722878s
STEP: Saw pod success
Jun 14 13:15:00.598: INFO: Pod "pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:15:00.600: INFO: Trying to get logs from node 192.168.0.235 pod pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 13:15:00.621: INFO: Waiting for pod pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:15:00.622: INFO: Pod pod-67a0cf1e-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:15:00.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-65mj5" for this suite.
Jun 14 13:15:06.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:15:06.684: INFO: namespace: e2e-tests-emptydir-65mj5, resource: bindings, ignored listing per whitelist
Jun 14 13:15:06.685: INFO: namespace e2e-tests-emptydir-65mj5 deletion completed in 6.060123181s

• [SLOW TEST:10.154 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:15:06.686: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jun 14 13:15:06.741: INFO: Waiting up to 5m0s for pod "var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-var-expansion-9c88w" to be "success or failure"
Jun 14 13:15:06.742: INFO: Pod "var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.914656ms
Jun 14 13:15:08.748: INFO: Pod "var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007344584s
Jun 14 13:15:10.750: INFO: Pod "var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009903132s
STEP: Saw pod success
Jun 14 13:15:10.750: INFO: Pod "var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:15:10.752: INFO: Trying to get logs from node 192.168.0.235 pod var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014 container dapi-container: <nil>
STEP: delete the pod
Jun 14 13:15:10.765: INFO: Waiting for pod var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:15:10.766: INFO: Pod var-expansion-6dae0de4-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:15:10.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9c88w" for this suite.
Jun 14 13:15:16.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:15:16.796: INFO: namespace: e2e-tests-var-expansion-9c88w, resource: bindings, ignored listing per whitelist
Jun 14 13:15:16.830: INFO: namespace e2e-tests-var-expansion-9c88w deletion completed in 6.061543543s

• [SLOW TEST:10.144 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:15:16.830: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:15:16.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zqjkq" for this suite.
Jun 14 13:15:38.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:15:38.935: INFO: namespace: e2e-tests-pods-zqjkq, resource: bindings, ignored listing per whitelist
Jun 14 13:15:38.948: INFO: namespace e2e-tests-pods-zqjkq deletion completed in 22.059045468s

• [SLOW TEST:22.118 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:15:38.948: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-80ea0699-8ea6-11e9-82a6-0255ac100014
STEP: Creating secret with name secret-projected-all-test-volume-80ea0685-8ea6-11e9-82a6-0255ac100014
STEP: Creating a pod to test Check all projections for projected volume plugin
Jun 14 13:15:39.028: INFO: Waiting up to 5m0s for pod "projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-58t9x" to be "success or failure"
Jun 14 13:15:39.033: INFO: Pod "projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 5.554674ms
Jun 14 13:15:41.039: INFO: Pod "projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011093378s
Jun 14 13:15:43.042: INFO: Pod "projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014253948s
STEP: Saw pod success
Jun 14 13:15:43.042: INFO: Pod "projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:15:43.044: INFO: Trying to get logs from node 192.168.0.235 pod projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014 container projected-all-volume-test: <nil>
STEP: delete the pod
Jun 14 13:15:43.056: INFO: Waiting for pod projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:15:43.058: INFO: Pod projected-volume-80ea0662-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:15:43.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-58t9x" for this suite.
Jun 14 13:15:49.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:15:49.094: INFO: namespace: e2e-tests-projected-58t9x, resource: bindings, ignored listing per whitelist
Jun 14 13:15:49.126: INFO: namespace e2e-tests-projected-58t9x deletion completed in 6.066122663s

• [SLOW TEST:10.178 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:15:49.126: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-86f94ef7-8ea6-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 13:15:49.180: INFO: Waiting up to 5m0s for pod "pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-9s877" to be "success or failure"
Jun 14 13:15:49.181: INFO: Pod "pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.545422ms
Jun 14 13:15:51.187: INFO: Pod "pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006680518s
Jun 14 13:15:53.189: INFO: Pod "pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009191132s
STEP: Saw pod success
Jun 14 13:15:53.189: INFO: Pod "pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:15:53.191: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 13:15:53.203: INFO: Waiting for pod pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:15:53.205: INFO: Pod pod-configmaps-86f9ef21-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:15:53.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9s877" for this suite.
Jun 14 13:15:59.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:15:59.235: INFO: namespace: e2e-tests-configmap-9s877, resource: bindings, ignored listing per whitelist
Jun 14 13:15:59.262: INFO: namespace e2e-tests-configmap-9s877 deletion completed in 6.055773328s

• [SLOW TEST:10.137 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:15:59.262: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0614 13:16:05.337367      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 14 13:16:05.337: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:16:05.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-j7sxf" for this suite.
Jun 14 13:16:11.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:16:11.372: INFO: namespace: e2e-tests-gc-j7sxf, resource: bindings, ignored listing per whitelist
Jun 14 13:16:11.408: INFO: namespace e2e-tests-gc-j7sxf deletion completed in 6.0692212s

• [SLOW TEST:12.146 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:16:11.408: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9441d75d-8ea6-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 13:16:11.470: INFO: Waiting up to 5m0s for pod "pod-configmaps-94429c05-8ea6-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-krmp2" to be "success or failure"
Jun 14 13:16:11.472: INFO: Pod "pod-configmaps-94429c05-8ea6-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03327ms
Jun 14 13:16:13.476: INFO: Pod "pod-configmaps-94429c05-8ea6-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006626548s
STEP: Saw pod success
Jun 14 13:16:13.476: INFO: Pod "pod-configmaps-94429c05-8ea6-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:16:13.478: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-94429c05-8ea6-11e9-82a6-0255ac100014 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 13:16:13.493: INFO: Waiting for pod pod-configmaps-94429c05-8ea6-11e9-82a6-0255ac100014 to disappear
Jun 14 13:16:13.495: INFO: Pod pod-configmaps-94429c05-8ea6-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:16:13.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-krmp2" for this suite.
Jun 14 13:16:19.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:16:19.526: INFO: namespace: e2e-tests-configmap-krmp2, resource: bindings, ignored listing per whitelist
Jun 14 13:16:19.559: INFO: namespace e2e-tests-configmap-krmp2 deletion completed in 6.062967767s

• [SLOW TEST:8.151 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:16:19.560: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:16:22.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-9r76k" for this suite.
Jun 14 13:16:44.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:16:44.670: INFO: namespace: e2e-tests-replication-controller-9r76k, resource: bindings, ignored listing per whitelist
Jun 14 13:16:44.686: INFO: namespace e2e-tests-replication-controller-9r76k deletion completed in 22.057598775s

• [SLOW TEST:25.127 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:16:44.686: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-2nkcc
Jun 14 13:16:46.742: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-2nkcc
STEP: checking the pod's current state and verifying that restartCount is present
Jun 14 13:16:46.743: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:20:47.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2nkcc" for this suite.
Jun 14 13:20:53.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:20:53.225: INFO: namespace: e2e-tests-container-probe-2nkcc, resource: bindings, ignored listing per whitelist
Jun 14 13:20:53.237: INFO: namespace e2e-tests-container-probe-2nkcc deletion completed in 6.061012503s

• [SLOW TEST:248.551 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:20:53.237: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jun 14 13:20:53.295: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53161,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 14 13:20:53.295: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53161,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jun 14 13:21:03.303: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53194,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 14 13:21:03.303: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53194,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jun 14 13:21:13.314: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53223,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 14 13:21:13.314: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53223,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jun 14 13:21:23.326: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53256,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 14 13:21:23.326: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-a,UID:3c566869-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53256,Generation:0,CreationTimestamp:2019-06-14 13:20:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jun 14 13:21:33.335: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-b,UID:5433fca2-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53285,Generation:0,CreationTimestamp:2019-06-14 13:21:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 14 13:21:33.335: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-b,UID:5433fca2-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53285,Generation:0,CreationTimestamp:2019-06-14 13:21:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jun 14 13:21:43.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-b,UID:5433fca2-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53315,Generation:0,CreationTimestamp:2019-06-14 13:21:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 14 13:21:43.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ksw47,SelfLink:/api/v1/namespaces/e2e-tests-watch-ksw47/configmaps/e2e-watch-test-configmap-b,UID:5433fca2-8ea7-11e9-a0dc-fa163eff1b62,ResourceVersion:53315,Generation:0,CreationTimestamp:2019-06-14 13:21:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:21:53.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ksw47" for this suite.
Jun 14 13:21:59.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:21:59.382: INFO: namespace: e2e-tests-watch-ksw47, resource: bindings, ignored listing per whitelist
Jun 14 13:21:59.422: INFO: namespace e2e-tests-watch-ksw47 deletion completed in 6.063832048s

• [SLOW TEST:66.185 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:21:59.422: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-63b08110-8ea7-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 13:21:59.479: INFO: Waiting up to 5m0s for pod "pod-configmaps-63b11b5d-8ea7-11e9-82a6-0255ac100014" in namespace "e2e-tests-configmap-xch64" to be "success or failure"
Jun 14 13:21:59.480: INFO: Pod "pod-configmaps-63b11b5d-8ea7-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.573563ms
Jun 14 13:22:01.483: INFO: Pod "pod-configmaps-63b11b5d-8ea7-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004297531s
STEP: Saw pod success
Jun 14 13:22:01.483: INFO: Pod "pod-configmaps-63b11b5d-8ea7-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:22:01.485: INFO: Trying to get logs from node 192.168.0.235 pod pod-configmaps-63b11b5d-8ea7-11e9-82a6-0255ac100014 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 13:22:01.504: INFO: Waiting for pod pod-configmaps-63b11b5d-8ea7-11e9-82a6-0255ac100014 to disappear
Jun 14 13:22:01.506: INFO: Pod pod-configmaps-63b11b5d-8ea7-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:22:01.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xch64" for this suite.
Jun 14 13:22:07.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:22:07.556: INFO: namespace: e2e-tests-configmap-xch64, resource: bindings, ignored listing per whitelist
Jun 14 13:22:07.584: INFO: namespace e2e-tests-configmap-xch64 deletion completed in 6.063905602s

• [SLOW TEST:8.162 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:22:07.584: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-qwmc
STEP: Creating a pod to test atomic-volume-subpath
Jun 14 13:22:07.672: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qwmc" in namespace "e2e-tests-subpath-5jpdf" to be "success or failure"
Jun 14 13:22:07.674: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.993575ms
Jun 14 13:22:09.677: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004690076s
Jun 14 13:22:11.679: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 4.007088304s
Jun 14 13:22:13.685: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 6.012999274s
Jun 14 13:22:15.688: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 8.015305876s
Jun 14 13:22:17.690: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 10.017377561s
Jun 14 13:22:19.692: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 12.019593973s
Jun 14 13:22:21.695: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 14.022784634s
Jun 14 13:22:23.702: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 16.029101049s
Jun 14 13:22:25.704: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 18.031619036s
Jun 14 13:22:27.707: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 20.03414263s
Jun 14 13:22:29.709: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Running", Reason="", readiness=false. Elapsed: 22.036560573s
Jun 14 13:22:31.712: INFO: Pod "pod-subpath-test-configmap-qwmc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.03914204s
STEP: Saw pod success
Jun 14 13:22:31.712: INFO: Pod "pod-subpath-test-configmap-qwmc" satisfied condition "success or failure"
Jun 14 13:22:31.713: INFO: Trying to get logs from node 192.168.0.19 pod pod-subpath-test-configmap-qwmc container test-container-subpath-configmap-qwmc: <nil>
STEP: delete the pod
Jun 14 13:22:31.729: INFO: Waiting for pod pod-subpath-test-configmap-qwmc to disappear
Jun 14 13:22:31.730: INFO: Pod pod-subpath-test-configmap-qwmc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qwmc
Jun 14 13:22:31.730: INFO: Deleting pod "pod-subpath-test-configmap-qwmc" in namespace "e2e-tests-subpath-5jpdf"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:22:31.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5jpdf" for this suite.
Jun 14 13:22:37.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:22:37.780: INFO: namespace: e2e-tests-subpath-5jpdf, resource: bindings, ignored listing per whitelist
Jun 14 13:22:37.792: INFO: namespace e2e-tests-subpath-5jpdf deletion completed in 6.058170959s

• [SLOW TEST:30.209 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:22:37.792: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jun 14 13:22:37.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 create -f - --namespace=e2e-tests-kubectl-rcxxt'
Jun 14 13:22:38.081: INFO: stderr: ""
Jun 14 13:22:38.081: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jun 14 13:22:39.084: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 13:22:39.084: INFO: Found 0 / 1
Jun 14 13:22:40.084: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 13:22:40.084: INFO: Found 0 / 1
Jun 14 13:22:41.084: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 13:22:41.084: INFO: Found 1 / 1
Jun 14 13:22:41.084: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 14 13:22:41.086: INFO: Selector matched 1 pods for map[app:redis]
Jun 14 13:22:41.086: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jun 14 13:22:41.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 logs redis-master-m49jv redis-master --namespace=e2e-tests-kubectl-rcxxt'
Jun 14 13:22:41.143: INFO: stderr: ""
Jun 14 13:22:41.143: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Jun 13:22:39.686 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Jun 13:22:39.686 # Server started, Redis version 3.2.12\n1:M 14 Jun 13:22:39.686 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Jun 13:22:39.686 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jun 14 13:22:41.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 log redis-master-m49jv redis-master --namespace=e2e-tests-kubectl-rcxxt --tail=1'
Jun 14 13:22:41.204: INFO: stderr: ""
Jun 14 13:22:41.204: INFO: stdout: "1:M 14 Jun 13:22:39.686 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jun 14 13:22:41.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 log redis-master-m49jv redis-master --namespace=e2e-tests-kubectl-rcxxt --limit-bytes=1'
Jun 14 13:22:41.262: INFO: stderr: ""
Jun 14 13:22:41.262: INFO: stdout: " "
STEP: exposing timestamps
Jun 14 13:22:41.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 log redis-master-m49jv redis-master --namespace=e2e-tests-kubectl-rcxxt --tail=1 --timestamps'
Jun 14 13:22:41.318: INFO: stderr: ""
Jun 14 13:22:41.318: INFO: stdout: "2019-06-14T13:22:39.686697802Z 1:M 14 Jun 13:22:39.686 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jun 14 13:22:43.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 log redis-master-m49jv redis-master --namespace=e2e-tests-kubectl-rcxxt --since=1s'
Jun 14 13:22:43.876: INFO: stderr: ""
Jun 14 13:22:43.876: INFO: stdout: ""
Jun 14 13:22:43.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 log redis-master-m49jv redis-master --namespace=e2e-tests-kubectl-rcxxt --since=24h'
Jun 14 13:22:43.933: INFO: stderr: ""
Jun 14 13:22:43.933: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Jun 13:22:39.686 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Jun 13:22:39.686 # Server started, Redis version 3.2.12\n1:M 14 Jun 13:22:39.686 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Jun 13:22:39.686 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jun 14 13:22:43.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-rcxxt'
Jun 14 13:22:43.984: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 14 13:22:43.984: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jun 14 13:22:43.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-rcxxt'
Jun 14 13:22:44.036: INFO: stderr: "No resources found.\n"
Jun 14 13:22:44.036: INFO: stdout: ""
Jun 14 13:22:44.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059955192 get pods -l name=nginx --namespace=e2e-tests-kubectl-rcxxt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 14 13:22:44.084: INFO: stderr: ""
Jun 14 13:22:44.084: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:22:44.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rcxxt" for this suite.
Jun 14 13:23:06.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:23:06.106: INFO: namespace: e2e-tests-kubectl-rcxxt, resource: bindings, ignored listing per whitelist
Jun 14 13:23:06.147: INFO: namespace e2e-tests-kubectl-rcxxt deletion completed in 22.057070355s

• [SLOW TEST:28.355 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:23:06.147: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0614 13:23:16.255043      18 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 14 13:23:16.255: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:23:16.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xl6jp" for this suite.
Jun 14 13:23:22.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:23:22.296: INFO: namespace: e2e-tests-gc-xl6jp, resource: bindings, ignored listing per whitelist
Jun 14 13:23:22.314: INFO: namespace e2e-tests-gc-xl6jp deletion completed in 6.057911519s

• [SLOW TEST:16.167 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:23:22.314: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-9518b6eb-8ea7-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume secrets
Jun 14 13:23:22.371: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-95197ced-8ea7-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-x64fl" to be "success or failure"
Jun 14 13:23:22.372: INFO: Pod "pod-projected-secrets-95197ced-8ea7-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.427262ms
Jun 14 13:23:24.374: INFO: Pod "pod-projected-secrets-95197ced-8ea7-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003764273s
STEP: Saw pod success
Jun 14 13:23:24.374: INFO: Pod "pod-projected-secrets-95197ced-8ea7-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:23:24.376: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-secrets-95197ced-8ea7-11e9-82a6-0255ac100014 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 14 13:23:24.390: INFO: Waiting for pod pod-projected-secrets-95197ced-8ea7-11e9-82a6-0255ac100014 to disappear
Jun 14 13:23:24.391: INFO: Pod pod-projected-secrets-95197ced-8ea7-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:23:24.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x64fl" for this suite.
Jun 14 13:23:30.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:23:30.444: INFO: namespace: e2e-tests-projected-x64fl, resource: bindings, ignored listing per whitelist
Jun 14 13:23:30.458: INFO: namespace e2e-tests-projected-x64fl deletion completed in 6.065057916s

• [SLOW TEST:8.144 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:23:30.458: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-99f3dbe3-8ea7-11e9-82a6-0255ac100014
STEP: Creating secret with name s-test-opt-upd-99f3dc14-8ea7-11e9-82a6-0255ac100014
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-99f3dbe3-8ea7-11e9-82a6-0255ac100014
STEP: Updating secret s-test-opt-upd-99f3dc14-8ea7-11e9-82a6-0255ac100014
STEP: Creating secret with name s-test-opt-create-99f3dc26-8ea7-11e9-82a6-0255ac100014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:24:46.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-s5kg8" for this suite.
Jun 14 13:25:08.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:25:08.844: INFO: namespace: e2e-tests-secrets-s5kg8, resource: bindings, ignored listing per whitelist
Jun 14 13:25:08.874: INFO: namespace e2e-tests-secrets-s5kg8 deletion completed in 22.062878189s

• [SLOW TEST:98.415 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:25:08.874: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 13:25:34.927: INFO: Container started at 2019-06-14 13:25:10 +0000 UTC, pod became ready at 2019-06-14 13:25:34 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:25:34.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-6g9pw" for this suite.
Jun 14 13:25:56.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:25:56.950: INFO: namespace: e2e-tests-container-probe-6g9pw, resource: bindings, ignored listing per whitelist
Jun 14 13:25:56.994: INFO: namespace e2e-tests-container-probe-6g9pw deletion completed in 22.065153888s

• [SLOW TEST:48.120 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:25:56.994: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 14 13:25:57.049: INFO: Waiting up to 5m0s for pod "pod-f14b2659-8ea7-11e9-82a6-0255ac100014" in namespace "e2e-tests-emptydir-w8hlz" to be "success or failure"
Jun 14 13:25:57.050: INFO: Pod "pod-f14b2659-8ea7-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.483496ms
Jun 14 13:25:59.052: INFO: Pod "pod-f14b2659-8ea7-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003820862s
Jun 14 13:26:01.055: INFO: Pod "pod-f14b2659-8ea7-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005994945s
STEP: Saw pod success
Jun 14 13:26:01.055: INFO: Pod "pod-f14b2659-8ea7-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:26:01.056: INFO: Trying to get logs from node 192.168.0.235 pod pod-f14b2659-8ea7-11e9-82a6-0255ac100014 container test-container: <nil>
STEP: delete the pod
Jun 14 13:26:01.069: INFO: Waiting for pod pod-f14b2659-8ea7-11e9-82a6-0255ac100014 to disappear
Jun 14 13:26:01.071: INFO: Pod pod-f14b2659-8ea7-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:26:01.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w8hlz" for this suite.
Jun 14 13:26:07.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:26:07.113: INFO: namespace: e2e-tests-emptydir-w8hlz, resource: bindings, ignored listing per whitelist
Jun 14 13:26:07.131: INFO: namespace e2e-tests-emptydir-w8hlz deletion completed in 6.057871733s

• [SLOW TEST:10.137 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:26:07.131: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 13:26:07.185: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jun 14 13:26:07.188: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-v5g62/daemonsets","resourceVersion":"54356"},"items":null}

Jun 14 13:26:07.190: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-v5g62/pods","resourceVersion":"54356"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:26:07.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-v5g62" for this suite.
Jun 14 13:26:13.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:26:13.261: INFO: namespace: e2e-tests-daemonsets-v5g62, resource: bindings, ignored listing per whitelist
Jun 14 13:26:13.264: INFO: namespace e2e-tests-daemonsets-v5g62 deletion completed in 6.067996185s

S [SKIPPING] [6.133 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jun 14 13:26:07.185: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:26:13.264: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jun 14 13:26:13.492: INFO: Pod name wrapped-volume-race-fb174b97-8ea7-11e9-82a6-0255ac100014: Found 0 pods out of 5
Jun 14 13:26:18.496: INFO: Pod name wrapped-volume-race-fb174b97-8ea7-11e9-82a6-0255ac100014: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fb174b97-8ea7-11e9-82a6-0255ac100014 in namespace e2e-tests-emptydir-wrapper-ms4fr, will wait for the garbage collector to delete the pods
Jun 14 13:28:04.577: INFO: Deleting ReplicationController wrapped-volume-race-fb174b97-8ea7-11e9-82a6-0255ac100014 took: 8.230486ms
Jun 14 13:28:04.678: INFO: Terminating ReplicationController wrapped-volume-race-fb174b97-8ea7-11e9-82a6-0255ac100014 pods took: 100.17349ms
STEP: Creating RC which spawns configmap-volume pods
Jun 14 13:28:46.873: INFO: Pod name wrapped-volume-race-5676b9fd-8ea8-11e9-82a6-0255ac100014: Found 0 pods out of 5
Jun 14 13:28:51.877: INFO: Pod name wrapped-volume-race-5676b9fd-8ea8-11e9-82a6-0255ac100014: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5676b9fd-8ea8-11e9-82a6-0255ac100014 in namespace e2e-tests-emptydir-wrapper-ms4fr, will wait for the garbage collector to delete the pods
Jun 14 13:30:35.955: INFO: Deleting ReplicationController wrapped-volume-race-5676b9fd-8ea8-11e9-82a6-0255ac100014 took: 12.71383ms
Jun 14 13:30:36.055: INFO: Terminating ReplicationController wrapped-volume-race-5676b9fd-8ea8-11e9-82a6-0255ac100014 pods took: 100.141254ms
STEP: Creating RC which spawns configmap-volume pods
Jun 14 13:31:16.775: INFO: Pod name wrapped-volume-race-afdb8268-8ea8-11e9-82a6-0255ac100014: Found 0 pods out of 5
Jun 14 13:31:21.780: INFO: Pod name wrapped-volume-race-afdb8268-8ea8-11e9-82a6-0255ac100014: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-afdb8268-8ea8-11e9-82a6-0255ac100014 in namespace e2e-tests-emptydir-wrapper-ms4fr, will wait for the garbage collector to delete the pods
Jun 14 13:33:07.851: INFO: Deleting ReplicationController wrapped-volume-race-afdb8268-8ea8-11e9-82a6-0255ac100014 took: 6.528563ms
Jun 14 13:33:07.952: INFO: Terminating ReplicationController wrapped-volume-race-afdb8268-8ea8-11e9-82a6-0255ac100014 pods took: 100.157391ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:33:47.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-ms4fr" for this suite.
Jun 14 13:33:53.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:33:53.037: INFO: namespace: e2e-tests-emptydir-wrapper-ms4fr, resource: bindings, ignored listing per whitelist
Jun 14 13:33:53.076: INFO: namespace e2e-tests-emptydir-wrapper-ms4fr deletion completed in 6.05996603s

• [SLOW TEST:459.812 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:33:53.076: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0d0edca7-8ea9-11e9-82a6-0255ac100014
STEP: Creating a pod to test consume configMaps
Jun 14 13:33:53.129: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014" in namespace "e2e-tests-projected-jqdxj" to be "success or failure"
Jun 14 13:33:53.130: INFO: Pod "pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 1.412463ms
Jun 14 13:33:55.133: INFO: Pod "pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004013156s
Jun 14 13:33:57.139: INFO: Pod "pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01026096s
STEP: Saw pod success
Jun 14 13:33:57.139: INFO: Pod "pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014" satisfied condition "success or failure"
Jun 14 13:33:57.140: INFO: Trying to get logs from node 192.168.0.235 pod pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 14 13:33:57.153: INFO: Waiting for pod pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014 to disappear
Jun 14 13:33:57.155: INFO: Pod pod-projected-configmaps-0d0f7c71-8ea9-11e9-82a6-0255ac100014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:33:57.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jqdxj" for this suite.
Jun 14 13:34:03.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:34:03.173: INFO: namespace: e2e-tests-projected-jqdxj, resource: bindings, ignored listing per whitelist
Jun 14 13:34:03.215: INFO: namespace e2e-tests-projected-jqdxj deletion completed in 6.058136349s

• [SLOW TEST:10.139 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:34:03.215: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 14 13:34:03.260: INFO: Creating deployment "test-recreate-deployment"
Jun 14 13:34:03.266: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jun 14 13:34:03.270: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jun 14 13:34:05.275: INFO: Waiting deployment "test-recreate-deployment" to complete
Jun 14 13:34:05.276: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696116043, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696116043, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696116043, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696116043, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 14 13:34:07.282: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jun 14 13:34:07.287: INFO: Updating deployment test-recreate-deployment
Jun 14 13:34:07.287: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 14 13:34:07.348: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-6dhwp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6dhwp/deployments/test-recreate-deployment,UID:1333830b-8ea9-11e9-a0dc-fa163eff1b62,ResourceVersion:56089,Generation:2,CreationTimestamp:2019-06-14 13:34:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-06-14 13:34:07 +0000 UTC 2019-06-14 13:34:07 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-14 13:34:07 +0000 UTC 2019-06-14 13:34:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jun 14 13:34:07.351: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-6dhwp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6dhwp/replicasets/test-recreate-deployment-697fbf54bf,UID:157deab2-8ea9-11e9-8a76-fa163e95400d,ResourceVersion:56088,Generation:1,CreationTimestamp:2019-06-14 13:34:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1333830b-8ea9-11e9-a0dc-fa163eff1b62 0xc001a81e77 0xc001a81e78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 14 13:34:07.351: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jun 14 13:34:07.351: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-6dhwp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-6dhwp/replicasets/test-recreate-deployment-5dfdcc846d,UID:1313efed-8ea9-11e9-8a76-fa163e95400d,ResourceVersion:56081,Generation:2,CreationTimestamp:2019-06-14 13:34:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 1333830b-8ea9-11e9-a0dc-fa163eff1b62 0xc001a81c17 0xc001a81c18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 14 13:34:07.353: INFO: Pod "test-recreate-deployment-697fbf54bf-pqjfg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-pqjfg,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-6dhwp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-6dhwp/pods/test-recreate-deployment-697fbf54bf-pqjfg,UID:157e7631-8ea9-11e9-8a76-fa163e95400d,ResourceVersion:56090,Generation:0,CreationTimestamp:2019-06-14 13:34:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 157deab2-8ea9-11e9-8a76-fa163e95400d 0xc001c1c767 0xc001c1c768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-66n4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-66n4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-66n4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.0.235,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c1c7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c1c800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[],Searches:[],Options:[{single-request-reopen 0xc0011a19c0} {timeout 0xc0011a19d0}],},ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:34:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:34:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:34:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-14 13:34:07 +0000 UTC  }],Message:,Reason:,HostIP:192.168.0.235,PodIP:,StartTime:2019-06-14 13:34:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:34:07.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-6dhwp" for this suite.
Jun 14 13:34:13.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:34:13.406: INFO: namespace: e2e-tests-deployment-6dhwp, resource: bindings, ignored listing per whitelist
Jun 14 13:34:13.413: INFO: namespace e2e-tests-deployment-6dhwp deletion completed in 6.057815049s

• [SLOW TEST:10.197 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 14 13:34:13.413: INFO: >>> kubeConfig: /tmp/kubeconfig-059955192
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 14 13:34:15.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-8cxg9" for this suite.
Jun 14 13:34:21.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 14 13:34:21.534: INFO: namespace: e2e-tests-emptydir-wrapper-8cxg9, resource: bindings, ignored listing per whitelist
Jun 14 13:34:21.569: INFO: namespace e2e-tests-emptydir-wrapper-8cxg9 deletion completed in 6.06451118s

• [SLOW TEST:8.156 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSJun 14 13:34:21.569: INFO: Running AfterSuite actions on all nodes
Jun 14 13:34:21.571: INFO: Running AfterSuite actions on node 1
Jun 14 13:34:21.571: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5862.702 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h37m43.683550747s
Test Suite Passed
